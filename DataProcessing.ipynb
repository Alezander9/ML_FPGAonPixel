{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def process_datasets(numbers):\n",
    "    with h5py.File('/gpfs/slac/atlas/fs1/d/hjia625/Smart_Pixel/data.hdf5', 'w') as h5f:\n",
    "        for charge_type in ['positive-charge', 'negative-charge']:\n",
    "            sig_input_list = []\n",
    "            sig_target_list = []\n",
    "            bkg_input_list = []\n",
    "            bkg_target_list = []\n",
    "\n",
    "            for number in numbers:\n",
    "                print(\"Processing \", charge_type, number)\n",
    "                \n",
    "                # Read the target data\n",
    "                target_file = f'/gpfs/slac/atlas/fs1/d/hjia625/Smart_Pixel/{charge_type}/labels_d{number}.csv'\n",
    "                target_df = pd.read_csv(target_file)\n",
    "\n",
    "                # Read the input data\n",
    "                input_file = f'/gpfs/slac/atlas/fs1/d/hjia625/Smart_Pixel/{charge_type}/recon8t_d{number}.csv'\n",
    "                input_df = pd.read_csv(input_file)\n",
    "\n",
    "                # Filter for significant and background data\n",
    "                sig_indices = target_df['pt'].abs() >= 2\n",
    "                bkg_indices = ~sig_indices\n",
    "\n",
    "                # Reshape and append the significant input data\n",
    "                sig_input_reshaped = input_df[sig_indices].to_numpy().reshape(-1, 8*13*21).astype(np.float16)\n",
    "                sig_input_list.append(sig_input_reshaped)\n",
    "\n",
    "                # Reshape and append the significant target data\n",
    "                sig_target_reshaped = target_df[sig_indices].to_numpy().reshape(-1, 13).astype(np.float16)\n",
    "                sig_target_list.append(sig_target_reshaped)\n",
    "\n",
    "                # Reshape background data\n",
    "                bkg_input_reshaped = input_df[bkg_indices].to_numpy().reshape(-1, 8*13*21).astype(np.float16)\n",
    "                bkg_target_reshaped = target_df[bkg_indices].to_numpy().reshape(-1, 13).astype(np.float16)\n",
    "\n",
    "                # Random undersampling of the background data\n",
    "                num_sig_samples = sig_input_reshaped.shape[0]\n",
    "                random_indices = np.random.choice(bkg_input_reshaped.shape[0], num_sig_samples, replace=False)\n",
    "                bkg_input_undersampled = bkg_input_reshaped[random_indices]\n",
    "                bkg_target_undersampled = bkg_target_reshaped[random_indices]\n",
    "\n",
    "                bkg_input_list.append(bkg_input_undersampled)\n",
    "                bkg_target_list.append(bkg_target_undersampled)\n",
    "\n",
    "            # Convert lists to NumPy arrays\n",
    "            sig_input_combined = np.vstack(sig_input_list)\n",
    "            sig_target_combined = np.vstack(sig_target_list)\n",
    "            bkg_input_combined = np.vstack(bkg_input_list)\n",
    "            bkg_target_combined = np.vstack(bkg_target_list)\n",
    "\n",
    "            # Save data in HDF5 format\n",
    "            h5f.create_dataset(f'{charge_type}_sig_input', data=sig_input_combined)\n",
    "            h5f.create_dataset(f'{charge_type}_sig_target', data=sig_target_combined)\n",
    "            h5f.create_dataset(f'{charge_type}_bkg_input', data=bkg_input_combined)\n",
    "            h5f.create_dataset(f'{charge_type}_bkg_target', data=bkg_target_combined)\n",
    "\n",
    "number_list = list(range(16501,16651))\n",
    "process_datasets(number_list)  # Replace with actual numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  positive-charge 16625\n",
      "Processing  positive-charge 16626\n",
      "Processing  positive-charge 16627\n",
      "Processing  positive-charge 16628\n",
      "Processing  positive-charge 16629\n",
      "Processing  positive-charge 16630\n",
      "Processing  positive-charge 16631\n",
      "Processing  positive-charge 16632\n",
      "Processing  positive-charge 16633\n",
      "Processing  positive-charge 16634\n",
      "Processing  positive-charge 16635\n",
      "Processing  positive-charge 16636\n",
      "Processing  positive-charge 16637\n",
      "Processing  positive-charge 16638\n",
      "Processing  positive-charge 16639\n",
      "Processing  positive-charge 16640\n",
      "Processing  positive-charge 16641\n",
      "Processing  positive-charge 16642\n",
      "Processing  positive-charge 16643\n",
      "Processing  positive-charge 16644\n",
      "Processing  positive-charge 16645\n",
      "Processing  positive-charge 16646\n",
      "Processing  positive-charge 16647\n",
      "Processing  positive-charge 16648\n",
      "Processing  positive-charge 16649\n",
      "Processing  positive-charge 16650\n",
      "Processing  positive-charge 16651\n",
      "Processing  positive-charge 16652\n",
      "Processing  positive-charge 16653\n",
      "Processing  positive-charge 16654\n",
      "Processing  positive-charge 16655\n",
      "Processing  positive-charge 16656\n",
      "Processing  positive-charge 16657\n",
      "Processing  positive-charge 16658\n",
      "Processing  positive-charge 16659\n",
      "Processing  positive-charge 16660\n",
      "Processing  positive-charge 16661\n",
      "Processing  positive-charge 16662\n",
      "Processing  positive-charge 16663\n",
      "Processing  positive-charge 16664\n",
      "Processing  positive-charge 16665\n",
      "Processing  positive-charge 16666\n",
      "Processing  positive-charge 16667\n",
      "Processing  positive-charge 16668\n",
      "Processing  positive-charge 16669\n",
      "Processing  positive-charge 16670\n",
      "Processing  positive-charge 16671\n",
      "Processing  positive-charge 16672\n",
      "Processing  positive-charge 16673\n",
      "Processing  positive-charge 16674\n",
      "Processing  positive-charge 16675\n",
      "Processing  positive-charge 16676\n",
      "Processing  positive-charge 16677\n",
      "Processing  positive-charge 16678\n",
      "Processing  positive-charge 16679\n",
      "Processing  positive-charge 16680\n",
      "Processing  positive-charge 16681\n",
      "Processing  positive-charge 16682\n",
      "Processing  positive-charge 16683\n",
      "Processing  positive-charge 16684\n",
      "Processing  positive-charge 16685\n",
      "Processing  positive-charge 16686\n",
      "Processing  positive-charge 16687\n",
      "Processing  positive-charge 16688\n",
      "Processing  positive-charge 16689\n",
      "Processing  positive-charge 16690\n",
      "Processing  positive-charge 16691\n",
      "Processing  positive-charge 16692\n",
      "Processing  positive-charge 16693\n",
      "Processing  positive-charge 16694\n",
      "Processing  positive-charge 16695\n",
      "Processing  positive-charge 16696\n",
      "Processing  positive-charge 16697\n",
      "Processing  positive-charge 16698\n",
      "Processing  positive-charge 16699\n",
      "Processing  positive-charge 16700\n",
      "Processing  positive-charge 16701\n",
      "Processing  positive-charge 16702\n",
      "Processing  positive-charge 16703\n",
      "Processing  positive-charge 16704\n",
      "Processing  positive-charge 16705\n",
      "Processing  positive-charge 16706\n",
      "Processing  positive-charge 16707\n",
      "Processing  positive-charge 16708\n",
      "Processing  positive-charge 16709\n",
      "Processing  positive-charge 16710\n",
      "Processing  positive-charge 16711\n",
      "Processing  positive-charge 16712\n",
      "Processing  positive-charge 16713\n",
      "Processing  positive-charge 16714\n",
      "Processing  positive-charge 16715\n",
      "Processing  positive-charge 16716\n",
      "Processing  positive-charge 16717\n",
      "Processing  positive-charge 16718\n",
      "Processing  positive-charge 16719\n",
      "Processing  positive-charge 16720\n",
      "Processing  positive-charge 16721\n",
      "Processing  positive-charge 16722\n",
      "Processing  positive-charge 16723\n",
      "Processing  positive-charge 16724\n",
      "Processing  positive-charge 16725\n",
      "Processing  negative-charge 16625\n",
      "Processing  negative-charge 16626\n",
      "Processing  negative-charge 16627\n",
      "Processing  negative-charge 16628\n",
      "Processing  negative-charge 16629\n",
      "Processing  negative-charge 16630\n",
      "Processing  negative-charge 16631\n",
      "Processing  negative-charge 16632\n",
      "Processing  negative-charge 16633\n",
      "Processing  negative-charge 16634\n",
      "Processing  negative-charge 16635\n",
      "Processing  negative-charge 16636\n",
      "Processing  negative-charge 16637\n",
      "Processing  negative-charge 16638\n",
      "Processing  negative-charge 16639\n",
      "Processing  negative-charge 16640\n",
      "Processing  negative-charge 16641\n",
      "Processing  negative-charge 16642\n",
      "Processing  negative-charge 16643\n",
      "Processing  negative-charge 16644\n",
      "Processing  negative-charge 16645\n",
      "Processing  negative-charge 16646\n",
      "Processing  negative-charge 16647\n",
      "Processing  negative-charge 16648\n",
      "Processing  negative-charge 16649\n",
      "Processing  negative-charge 16650\n",
      "Processing  negative-charge 16651\n",
      "Processing  negative-charge 16652\n",
      "Processing  negative-charge 16653\n",
      "Processing  negative-charge 16654\n",
      "Processing  negative-charge 16655\n",
      "Processing  negative-charge 16656\n",
      "Processing  negative-charge 16657\n",
      "Processing  negative-charge 16658\n",
      "Processing  negative-charge 16659\n",
      "Processing  negative-charge 16660\n",
      "Processing  negative-charge 16661\n",
      "Processing  negative-charge 16662\n",
      "Processing  negative-charge 16663\n",
      "Processing  negative-charge 16664\n",
      "Processing  negative-charge 16665\n",
      "Processing  negative-charge 16666\n",
      "Processing  negative-charge 16667\n",
      "Processing  negative-charge 16668\n",
      "Processing  negative-charge 16669\n",
      "Processing  negative-charge 16670\n",
      "Processing  negative-charge 16671\n",
      "Processing  negative-charge 16672\n",
      "Processing  negative-charge 16673\n",
      "Processing  negative-charge 16674\n",
      "Processing  negative-charge 16675\n",
      "Processing  negative-charge 16676\n",
      "Processing  negative-charge 16677\n",
      "Processing  negative-charge 16678\n",
      "Processing  negative-charge 16679\n",
      "Processing  negative-charge 16680\n",
      "Processing  negative-charge 16681\n",
      "Processing  negative-charge 16682\n",
      "Processing  negative-charge 16683\n",
      "Processing  negative-charge 16684\n",
      "Processing  negative-charge 16685\n",
      "Processing  negative-charge 16686\n",
      "Processing  negative-charge 16687\n",
      "Processing  negative-charge 16688\n",
      "Processing  negative-charge 16689\n",
      "Processing  negative-charge 16690\n",
      "Processing  negative-charge 16691\n",
      "Processing  negative-charge 16692\n",
      "Processing  negative-charge 16693\n",
      "Processing  negative-charge 16694\n",
      "Processing  negative-charge 16695\n",
      "Processing  negative-charge 16696\n",
      "Processing  negative-charge 16697\n",
      "Processing  negative-charge 16698\n",
      "Processing  negative-charge 16699\n",
      "Processing  negative-charge 16700\n",
      "Processing  negative-charge 16701\n",
      "Processing  negative-charge 16702\n",
      "Processing  negative-charge 16703\n",
      "Processing  negative-charge 16704\n",
      "Processing  negative-charge 16705\n",
      "Processing  negative-charge 16706\n",
      "Processing  negative-charge 16707\n",
      "Processing  negative-charge 16708\n",
      "Processing  negative-charge 16709\n",
      "Processing  negative-charge 16710\n",
      "Processing  negative-charge 16711\n",
      "Processing  negative-charge 16712\n",
      "Processing  negative-charge 16713\n",
      "Processing  negative-charge 16714\n",
      "Processing  negative-charge 16715\n",
      "Processing  negative-charge 16716\n",
      "Processing  negative-charge 16717\n",
      "Processing  negative-charge 16718\n",
      "Processing  negative-charge 16719\n",
      "Processing  negative-charge 16720\n",
      "Processing  negative-charge 16721\n",
      "Processing  negative-charge 16722\n",
      "Processing  negative-charge 16723\n",
      "Processing  negative-charge 16724\n",
      "Processing  negative-charge 16725\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def process_datasets(numbers):\n",
    "    with h5py.File('/gpfs/slac/atlas/fs1/d/hjia625/Smart_Pixel/fl32_data_1.hdf5', 'w') as h5f:\n",
    "        for charge_type in ['positive-charge', 'negative-charge']:\n",
    "            sig_input_list = []\n",
    "            sig_target_list = []\n",
    "            bkg_input_list = []\n",
    "            bkg_target_list = []\n",
    "\n",
    "            for number in numbers:\n",
    "                print(\"Processing \", charge_type, number)\n",
    "                \n",
    "                # Read the target data\n",
    "                target_file = f'/gpfs/slac/atlas/fs1/d/hjia625/Smart_Pixel/{charge_type}/labels_d{number}.csv'\n",
    "                target_df = pd.read_csv(target_file)\n",
    "\n",
    "                # Read the input data\n",
    "                input_file = f'/gpfs/slac/atlas/fs1/d/hjia625/Smart_Pixel/{charge_type}/recon8t_d{number}.csv'\n",
    "                input_df = pd.read_csv(input_file)\n",
    "\n",
    "                # Filter for significant and background data\n",
    "                sig_indices = target_df['pt'].abs() >= 2\n",
    "                bkg_indices = ~sig_indices\n",
    "\n",
    "                # Reshape and append the significant input data\n",
    "                sig_input_reshaped = input_df[sig_indices].to_numpy().reshape(-1, 8*13*21).astype(np.float32)\n",
    "                sig_input_list.append(sig_input_reshaped)\n",
    "\n",
    "                # Reshape and append the significant target data\n",
    "                sig_target_reshaped = target_df[sig_indices].to_numpy().reshape(-1, 13).astype(np.float32)\n",
    "                sig_target_list.append(sig_target_reshaped)\n",
    "\n",
    "                # Reshape background data\n",
    "                bkg_input_reshaped = input_df[bkg_indices].to_numpy().reshape(-1, 8*13*21).astype(np.float32)\n",
    "                bkg_target_reshaped = target_df[bkg_indices].to_numpy().reshape(-1, 13).astype(np.float32)\n",
    "\n",
    "                # Random undersampling of the background data\n",
    "                num_sig_samples = sig_input_reshaped.shape[0]\n",
    "                random_indices = np.random.choice(bkg_input_reshaped.shape[0], num_sig_samples, replace=False)\n",
    "                bkg_input_undersampled = bkg_input_reshaped[random_indices]\n",
    "                bkg_target_undersampled = bkg_target_reshaped[random_indices]\n",
    "\n",
    "                bkg_input_list.append(bkg_input_undersampled)\n",
    "                bkg_target_list.append(bkg_target_undersampled)\n",
    "\n",
    "            # Convert lists to NumPy arrays\n",
    "            sig_input_combined = np.vstack(sig_input_list)\n",
    "            sig_target_combined = np.vstack(sig_target_list)\n",
    "            bkg_input_combined = np.vstack(bkg_input_list)\n",
    "            bkg_target_combined = np.vstack(bkg_target_list)\n",
    "\n",
    "            # Save data in HDF5 format\n",
    "            h5f.create_dataset(f'{charge_type}_sig_input', data=sig_input_combined)\n",
    "            h5f.create_dataset(f'{charge_type}_sig_target', data=sig_target_combined)\n",
    "            h5f.create_dataset(f'{charge_type}_bkg_input', data=bkg_input_combined)\n",
    "            h5f.create_dataset(f'{charge_type}_bkg_target', data=bkg_target_combined)\n",
    "\n",
    "#number_list = list(range(16501,16626))\n",
    "number_list = list(range(16625,16726))\n",
    "process_datasets(number_list)  # Replace with actual numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset number 17301\n",
      "Processing dataset number 17302\n",
      "Processing dataset number 17303\n",
      "Processing dataset number 17304\n",
      "Processing dataset number 17305\n",
      "Processing dataset number 17306\n",
      "Processing dataset number 17307\n",
      "Processing dataset number 17308\n",
      "Processing dataset number 17309\n",
      "Processing dataset number 17310\n",
      "Processing dataset number 17311\n",
      "Processing dataset number 17312\n",
      "Processing dataset number 17313\n",
      "Processing dataset number 17314\n",
      "Processing dataset number 17315\n",
      "Processing dataset number 17316\n",
      "Processing dataset number 17317\n",
      "Processing dataset number 17318\n",
      "Processing dataset number 17319\n",
      "Processing dataset number 17320\n",
      "Processing dataset number 17321\n",
      "Processing dataset number 17322\n",
      "Processing dataset number 17323\n",
      "Processing dataset number 17324\n",
      "Processing dataset number 17325\n",
      "Processing dataset number 17326\n",
      "Processing dataset number 17327\n",
      "Processing dataset number 17328\n",
      "Processing dataset number 17329\n",
      "Processing dataset number 17330\n",
      "Processing dataset number 17331\n",
      "Processing dataset number 17332\n",
      "Processing dataset number 17333\n",
      "Processing dataset number 17334\n",
      "Processing dataset number 17335\n",
      "Processing dataset number 17336\n",
      "Processing dataset number 17337\n",
      "Processing dataset number 17338\n",
      "Processing dataset number 17339\n",
      "Processing dataset number 17340\n",
      "Processing dataset number 17341\n",
      "Processing dataset number 17342\n",
      "Processing dataset number 17343\n",
      "Processing dataset number 17344\n",
      "Processing dataset number 17345\n",
      "Processing dataset number 17346\n",
      "Processing dataset number 17347\n",
      "Processing dataset number 17348\n",
      "Processing dataset number 17349\n",
      "Processing dataset number 17350\n",
      "Processing dataset number 17351\n",
      "Failed to read input file 17351: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "Processing dataset number 17352\n",
      "Failed to read input file 17352: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "Processing dataset number 17353\n",
      "Processing dataset number 17354\n",
      "Processing dataset number 17355\n",
      "Processing dataset number 17356\n",
      "Processing dataset number 17357\n",
      "Processing dataset number 17358\n",
      "Processing dataset number 17359\n",
      "Processing dataset number 17360\n",
      "Processing dataset number 17361\n",
      "Processing dataset number 17362\n",
      "Processing dataset number 17363\n",
      "Processing dataset number 17364\n",
      "Processing dataset number 17365\n",
      "Processing dataset number 17366\n",
      "Processing dataset number 17367\n",
      "Processing dataset number 17368\n",
      "Processing dataset number 17369\n",
      "Processing dataset number 17370\n",
      "Processing dataset number 17371\n",
      "Processing dataset number 17372\n",
      "Processing dataset number 17373\n",
      "Processing dataset number 17374\n",
      "Processing dataset number 17375\n",
      "Processing dataset number 17376\n",
      "Processing dataset number 17377\n",
      "Processing dataset number 17378\n",
      "Processing dataset number 17379\n",
      "Processing dataset number 17380\n",
      "Processing dataset number 17381\n",
      "Processing dataset number 17382\n",
      "Processing dataset number 17383\n",
      "Processing dataset number 17384\n",
      "Processing dataset number 17385\n",
      "Processing dataset number 17386\n",
      "Processing dataset number 17387\n",
      "Processing dataset number 17388\n",
      "Processing dataset number 17389\n",
      "Processing dataset number 17390\n",
      "Processing dataset number 17391\n",
      "Processing dataset number 17392\n",
      "Processing dataset number 17393\n",
      "Processing dataset number 17394\n",
      "Processing dataset number 17395\n",
      "Processing dataset number 17396\n",
      "Processing dataset number 17397\n",
      "Processing dataset number 17398\n",
      "Processing dataset number 17399\n",
      "Processing dataset number 17400\n",
      "Processing dataset number 17401\n",
      "Processing dataset number 17402\n",
      "Processing dataset number 17403\n",
      "Processing dataset number 17404\n",
      "Processing dataset number 17405\n",
      "Processing dataset number 17406\n",
      "Processing dataset number 17407\n",
      "Processing dataset number 17408\n",
      "Processing dataset number 17409\n",
      "Processing dataset number 17410\n",
      "Processing dataset number 17411\n",
      "Processing dataset number 17412\n",
      "Processing dataset number 17413\n",
      "Processing dataset number 17414\n",
      "Processing dataset number 17415\n",
      "Processing dataset number 17416\n",
      "Processing dataset number 17417\n",
      "Processing dataset number 17418\n",
      "Processing dataset number 17419\n",
      "Processing dataset number 17420\n",
      "Processing dataset number 17421\n",
      "Processing dataset number 17422\n",
      "Processing dataset number 17423\n",
      "Processing dataset number 17424\n",
      "Processing dataset number 17425\n",
      "Processing dataset number 17426\n",
      "Processing dataset number 17427\n",
      "Processing dataset number 17428\n",
      "Processing dataset number 17429\n",
      "Processing dataset number 17430\n",
      "Processing dataset number 17431\n",
      "Processing dataset number 17432\n",
      "Processing dataset number 17433\n",
      "Processing dataset number 17434\n",
      "Processing dataset number 17435\n",
      "Processing dataset number 17436\n",
      "Processing dataset number 17437\n",
      "Processing dataset number 17438\n",
      "Processing dataset number 17439\n",
      "Processing dataset number 17440\n",
      "Processing dataset number 17441\n",
      "Failed to read input file 17441: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "Processing dataset number 17442\n",
      "Processing dataset number 17443\n",
      "Processing dataset number 17444\n",
      "Processing dataset number 17445\n",
      "Processing dataset number 17446\n",
      "Processing dataset number 17447\n",
      "Processing dataset number 17448\n",
      "Processing dataset number 17449\n",
      "Processing dataset number 17450\n",
      "Processing dataset number 17451\n",
      "Processing dataset number 17452\n",
      "Processing dataset number 17453\n",
      "Processing dataset number 17454\n",
      "Processing dataset number 17455\n",
      "Processing dataset number 17456\n",
      "Processing dataset number 17457\n",
      "Processing dataset number 17458\n",
      "Processing dataset number 17459\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def process_datasets(numbers):\n",
    "    with h5py.File('/fs/ddn/sdf/group/atlas/d/hjia625/Smart_Pixel/fl32_data_v2.hdf5', 'w') as h5f:\n",
    "        sig_input_list = []\n",
    "        sig_target_list = []\n",
    "        bkg_input_list = []\n",
    "        bkg_target_list = []\n",
    "\n",
    "        for number in numbers:\n",
    "            \n",
    "            print(\"Processing dataset number\", number)\n",
    "            \n",
    "            # # Read the target data from Parquet\n",
    "            # target_file = f'/fs/ddn/sdf/group/atlas/d/hjia625/Smart_Pixel/data_v2/labels/labels_d{number}.parquet'\n",
    "            # target_df = pd.read_parquet(target_file)\n",
    "\n",
    "            # # Read the input data from Parquet\n",
    "            # input_file = f'/fs/ddn/sdf/group/atlas/d/hjia625/Smart_Pixel/data_v2/recon3D/recon3D_d{number}.parquet'\n",
    "            # input_df = pd.read_parquet(input_file)\n",
    "\n",
    "            # Initialize file paths\n",
    "            target_file = f'/fs/ddn/sdf/group/atlas/d/hjia625/Smart_Pixel/data_v2/labels/labels_d{number}.parquet'\n",
    "            input_file = f'/fs/ddn/sdf/group/atlas/d/hjia625/Smart_Pixel/data_v2/recon3D/recon3D_d{number}.parquet'\n",
    "\n",
    "            # Read the target data from Parquet with integrity check\n",
    "            try:\n",
    "                target_df = pd.read_parquet(target_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to read target file {number}: {e}\")\n",
    "                continue  # Skip this iteration and proceed to the next file\n",
    "\n",
    "            # Read the input data from Parquet with integrity check\n",
    "            try:\n",
    "                input_df = pd.read_parquet(input_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to read input file {number}: {e}\")\n",
    "                continue  # Skip this iteration and proceed to the next file\n",
    "\n",
    "            # Filter for significant and background data\n",
    "            sig_indices = target_df['pt'].abs() >= 2\n",
    "            bkg_indices = ~sig_indices\n",
    "\n",
    "            # Reshape and append the significant input data\n",
    "            sig_input_reshaped = input_df[sig_indices].to_numpy().reshape(-1, 20*13*21).astype(np.float32)\n",
    "            sig_input_list.append(sig_input_reshaped)\n",
    "\n",
    "            # Reshape and append the significant target data\n",
    "            sig_target_reshaped = target_df[sig_indices].to_numpy().reshape(-1, 13).astype(np.float32)\n",
    "            sig_target_list.append(sig_target_reshaped)\n",
    "\n",
    "            # Reshape background data\n",
    "            bkg_input_reshaped = input_df[bkg_indices].to_numpy().reshape(-1, 20*13*21).astype(np.float32)\n",
    "            bkg_target_reshaped = target_df[bkg_indices].to_numpy().reshape(-1, 13).astype(np.float32)\n",
    "\n",
    "            # Random undersampling of the background data\n",
    "            num_sig_samples = sig_input_reshaped.shape[0]\n",
    "            random_indices = np.random.choice(bkg_input_reshaped.shape[0], num_sig_samples, replace=False)\n",
    "            bkg_input_undersampled = bkg_input_reshaped[random_indices]\n",
    "            bkg_target_undersampled = bkg_target_reshaped[random_indices]\n",
    "\n",
    "            bkg_input_list.append(bkg_input_undersampled)\n",
    "            bkg_target_list.append(bkg_target_undersampled)\n",
    "\n",
    "        # Convert lists to NumPy arrays\n",
    "        sig_input_combined = np.vstack(sig_input_list)\n",
    "        sig_target_combined = np.vstack(sig_target_list)\n",
    "        bkg_input_combined = np.vstack(bkg_input_list)\n",
    "        bkg_target_combined = np.vstack(bkg_target_list)\n",
    "\n",
    "        # Save data in HDF5 format\n",
    "        h5f.create_dataset('sig_input', data=sig_input_combined)\n",
    "        h5f.create_dataset('sig_target', data=sig_target_combined)\n",
    "        h5f.create_dataset('bkg_input', data=bkg_input_combined)\n",
    "        h5f.create_dataset('bkg_target', data=bkg_target_combined)\n",
    "\n",
    "# Example usage with a list of dataset numbers\n",
    "number_list = list(range(17301, 17460))\n",
    "process_datasets(number_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Smart_Pixel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
