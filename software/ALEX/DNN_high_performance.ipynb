{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 15:55:07.332983: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-18 15:55:07.416191: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-18 15:55:07.417192: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-18 15:55:09.515984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.13.1\n",
      "keras version: 2.13.1\n",
      "qkeras version: 2.13.1\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "# Machine Learning imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import PReLU, Input, LSTM, Flatten, Concatenate, Dense, Conv2D, TimeDistributed, MaxPooling2D, ReLU, Dropout, BatchNormalization, Activation, Lambda\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "import tensorflow_model_optimization\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "print(\"tensorflow version:\", tf.__version__)\n",
    "import keras\n",
    "print(\"keras version:\",keras.__version__)\n",
    "import qkeras\n",
    "from qkeras import QActivation, QDense, QConv2D, QBatchNormalization, QConv2DBatchnorm\n",
    "from qkeras import quantized_relu, quantized_bits\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "from qkeras.autoqkeras.utils import print_qmodel_summary\n",
    "print(\"qkeras version:\",keras.__version__)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Display and plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.animation import PillowWriter\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Data management\n",
    "import psutil\n",
    "import h5py\n",
    "# Memory management\n",
    "import gc\n",
    "# Notifications\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "def send_email_notification(subject, content):\n",
    "    sender_email = os.getenv('EMAIL_USER')\n",
    "    receiver_email = \"alexander.j.yue@gmail.com\"\n",
    "    password = os.getenv('EMAIL_PASS')\n",
    "\n",
    "    message = MIMEMultipart()\n",
    "    message[\"From\"] = sender_email\n",
    "    message[\"To\"] = receiver_email\n",
    "    message[\"Subject\"] = subject\n",
    "    body = content\n",
    "    message.attach(MIMEText(body, \"plain\"))\n",
    "\n",
    "    with smtplib.SMTP(\"smtp.gmail.com\", 587) as server:\n",
    "        server.starttls()\n",
    "        server.login(sender_email, password)\n",
    "        server.sendmail(sender_email, receiver_email, message.as_string())\n",
    "\n",
    "# Memory monitoring functions\n",
    "def print_memory_usage():\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"Total memory: {memory.total / (1024**3):.2f} GB\")\n",
    "    print(f\"Available memory: {memory.available / (1024**3):.2f} GB\")\n",
    "    print(f\"Used memory: {memory.used / (1024**3):.2f} GB\")\n",
    "    print(f\"Memory usage percentage: {memory.percent}%\")\n",
    "\n",
    "def print_cpu_usage():\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "    print(f\"CPU Usage: {cpu_percent}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pixel cluster to transverse momentum dataset into the input_data and target_data\n",
    "def load_combine_shuffle_data_optimized_hdf5():\n",
    "    # Load the dataset from Kenny's computer\n",
    "    with h5py.File('/fs/ddn/sdf/group/atlas/d/hjia625/Smart_Pixel/fl32_data_v3.hdf5', 'r') as h5f:\n",
    "        combined_input = None\n",
    "        combined_target = None\n",
    "\n",
    "        for data_type in ['sig', 'bkg']:\n",
    "            # Construct dataset names\n",
    "            input_dataset_name = f'{data_type}_input'\n",
    "            target_dataset_name = f'{data_type}_target'\n",
    "\n",
    "            # Check if the dataset exists and load data sequentially\n",
    "            if input_dataset_name in h5f and target_dataset_name in h5f:\n",
    "                input_data = h5f[input_dataset_name][:].astype(np.float32)\n",
    "                target_data = h5f[target_dataset_name][:].astype(np.float32)\n",
    "\n",
    "                if combined_input is None:\n",
    "                    combined_input = input_data\n",
    "                    combined_target = target_data\n",
    "                    # Free memory of the loaded data\n",
    "                    del input_data, target_data\n",
    "                    gc.collect()\n",
    "\n",
    "                else:\n",
    "                    print_memory_usage()\n",
    "                    combined_input = np.vstack((combined_input, input_data))\n",
    "                    combined_target = np.vstack((combined_target, target_data))\n",
    "                    # Free memory of the loaded data\n",
    "                    del input_data, target_data\n",
    "                    gc.collect()\n",
    "\n",
    "            else:\n",
    "                print(f\"Dataset {input_dataset_name} or {target_dataset_name} not found.\")\n",
    "\n",
    "        # Shuffling\n",
    "        indices = np.arange(combined_input.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        combined_input = combined_input[indices]\n",
    "        combined_target = combined_target[indices]\n",
    "\n",
    "        return combined_input, combined_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    # Load dataset into memory\n",
    "    input_data, target_data = load_combine_shuffle_data_optimized_hdf5()\n",
    "    # Format the dataset into a 20x13x21 tensor (time, y, x)\n",
    "    input_data = input_data.reshape(input_data.shape[0],20,13,21)\n",
    "    return input_data, target_data\n",
    "\n",
    "def process_dataset(input_data, target_data, hyperparams):\n",
    "    NUM_TIME_SLICES = hyperparams[\"NUM_TIME_SLICES\"]\n",
    "    MODEL_TYPE = hyperparams[\"MODEL_TYPE\"]\n",
    "    TRAIN_PT_THRESHOLD = hyperparams[\"TRAIN_PT_THRESHOLD\"]\n",
    "    TEST_PT_THRESHOLD = hyperparams[\"TEST_PT_THRESHOLD\"]\n",
    "    OUTPUT = hyperparams[\"OUTPUT\"]\n",
    "    \n",
    "\n",
    "    # Split 80% of data into training data, 10% for validation data and 10% for testing data\n",
    "    input_train_data, input_temp, target_train_data, target_temp = \\\n",
    "    train_test_split(input_data, target_data, test_size=0.2, random_state=42)\n",
    "    del input_data\n",
    "    del target_data\n",
    "    gc.collect()\n",
    "    input_validate_data, input_test_data, target_validate_data, target_test_data = \\\n",
    "    train_test_split(input_temp, target_temp, test_size=0.5, random_state=42)\n",
    "    del input_temp\n",
    "    del target_temp\n",
    "    gc.collect()\n",
    "\n",
    "    # Save some data for displaying\n",
    "    input_data_example = input_test_data[0:100,:]\n",
    "    target_data_example = target_test_data[0:100,:]\n",
    "\n",
    "    # Fit the scalers on the training data to it all scales the exact same\n",
    "    input_scaler = StandardScaler()\n",
    "    input_scaler.fit(input_train_data[:, :NUM_TIME_SLICES, :, :].reshape(-1,8*13))\n",
    "    y0_scaler = StandardScaler()\n",
    "    y0_scaler.fit(target_train_data[:,7].reshape(-1, 1))\n",
    "\n",
    "    # Process the data into input shape and labels for training\n",
    "    def process_data(input_data, target_data, pt_threshold):\n",
    "        if input_data.shape[1:] == (20, 13, 21) and target_data.shape[1:] == (13, ):\n",
    "\n",
    "            # Truncate down to first time slices\n",
    "            input_data = input_data[:, :NUM_TIME_SLICES, :, :]\n",
    "\n",
    "            # sum over the x axis to turn the input data into a 2D NUM_TIME_SLICES x 13 tensor (time, y)\n",
    "            input_data = np.sum(input_data, axis=3)\n",
    "\n",
    "            if OUTPUT == \"SOFTMAX\" or OUTPUT == \"LINEAR\":\n",
    "                # Encode the target data into one_hot encoding\n",
    "                one_hot = np.zeros((target_data.shape[0], 3))\n",
    "                # Assign 1 for p_t > pt_threshold in GeV, for low p_t put 1 in slot 2 for negative and a 1 in slot 3 for positive\n",
    "                one_hot[np.abs(target_data[:, 8]) >= pt_threshold, 0] = 1\n",
    "                one_hot[(np.abs(target_data[:, 8]) < pt_threshold) & (target_data[:, 8] > 0), 1] = 1\n",
    "                one_hot[(np.abs(target_data[:, 8]) < pt_threshold) & (target_data[:, 8] < 0), 2] = 1\n",
    "                label_data = one_hot\n",
    "            # elif OUTPUT == \"ARGMAX\": # DOES NOT WORK \n",
    "            #     label_data = np.argmax(one_hot, axis=1).astype(np.int64)\n",
    "            #     print(\"one hot is \", one_hot)\n",
    "            elif OUTPUT == \"SINGLE\":\n",
    "            # Binary labels for 0th category\n",
    "                label_data = (np.abs(target_data[:, 8]) >= pt_threshold).astype(np.int64)\n",
    "\n",
    "            # Flatten the input data\n",
    "            input_data = input_data.reshape(-1,NUM_TIME_SLICES*13)\n",
    "\n",
    "            # Normalize the input data to have mean| 0 and std 1\n",
    "            \n",
    "            input_data = input_scaler.transform(input_data)\n",
    "            # # Replace all values < 1 with 1 so they log to 0\n",
    "            # input_data = np.where(np.abs(input_data) < 1.0, 1.0, input_data)\n",
    "            # # Apply logarithmic scaling\n",
    "            # input_data = np.log(np.abs(input_data)) * np.sign(input_data)\n",
    "            # # Min-max normalization (global)\n",
    "            # min_val = np.min(input_data)\n",
    "            # max_val = np.max(input_data)\n",
    "            # print(f\"max of log of data is {max_val} and min is {min_val}\")\n",
    "            # input_data = (input_data) / np.max([max_val,min_val])\n",
    "\n",
    "            # Get the y_0 data\n",
    "            y0_data = target_data[:,7].reshape(-1, 1)\n",
    "            y0_data = y0_scaler.transform(y0_data)\n",
    "            # Combine with input data\n",
    "            if (MODEL_TYPE == \"DNN\"):\n",
    "                # For DNN we concatenate in the y_0 data\n",
    "                input_data_combined = np.hstack((input_data, y0_data))\n",
    "\n",
    "                \n",
    "            elif (MODEL_TYPE == \"CNN\"):\n",
    "                # Reshape data into a matrix for the convolutions\n",
    "                input_data= input_data.reshape(-1, NUM_TIME_SLICES, 13)\n",
    "                # Package with the y_0 data to be added later\n",
    "                input_data_combined = [input_data, y0_data]\n",
    "\n",
    "            return input_data_combined, label_data\n",
    "        else:\n",
    "            raise ValueError(\"Wrong array shape!\")\n",
    "\n",
    "    # Apply data processing to our datasets\n",
    "    input_train_data_combined, target_train_data_coded = process_data(input_train_data, target_train_data, TRAIN_PT_THRESHOLD)\n",
    "    input_validate_data_combined, target_validate_data_coded = process_data(input_validate_data, target_validate_data, TRAIN_PT_THRESHOLD)\n",
    "    input_test_data_combined, target_test_data_coded = process_data(input_test_data, target_test_data, TEST_PT_THRESHOLD)\n",
    "\n",
    "    # Save some data for displaying\n",
    "    if MODEL_TYPE == \"DNN\":\n",
    "        input_data_combined_example = input_test_data_combined[0:100,:]\n",
    "        if OUTPUT == \"ARGMAX\" or OUTPUT == \"SINGLE\":\n",
    "            target_data_coded_example = target_test_data_coded[0:100]\n",
    "        else:\n",
    "            target_data_coded_example = target_test_data_coded[0:100,:]\n",
    "    elif MODEL_TYPE == \"CNN\":\n",
    "        input_data_combined_example = np.hstack((input_test_data_combined[0][0:100,:].reshape(100, -1), input_test_data_combined[1][0:100,:]))\n",
    "        target_data_coded_example = target_test_data_coded[0:100,:]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type\")\n",
    "\n",
    "    print_memory_usage()\n",
    "\n",
    "    processed_dataset = {\n",
    "        \"input_train_data_combined\": input_train_data_combined,\n",
    "        \"target_train_data_coded\": target_train_data_coded,\n",
    "        \"input_validate_data_combined\": input_validate_data_combined,\n",
    "        \"target_validate_data_coded\": target_validate_data_coded,\n",
    "        \"input_test_data_combined\": input_test_data_combined,\n",
    "        \"target_test_data_coded\": target_test_data_coded,\n",
    "\n",
    "        \"input_data_example\": input_data_example,\n",
    "        \"target_data_example\": target_data_example,\n",
    "        \"input_data_combined_example\": input_data_combined_example,\n",
    "        \"target_data_coded_example\": target_data_coded_example,\n",
    "    }\n",
    "\n",
    "    return processed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "class ArgmaxLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ArgmaxLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.cast(tf.argmax(inputs, axis=-1), dtype=tf.int64)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ArgmaxLayer, self).get_config()\n",
    "        return config\n",
    "    \n",
    "def qDNNmodel(hyperparams):\n",
    "    NUM_TIME_SLICES = hyperparams[\"NUM_TIME_SLICES\"]\n",
    "    DNN_LAYERS = hyperparams[\"DNN_LAYERS\"]\n",
    "    WEIGHTS_BITS = hyperparams[\"WEIGHTS_BITS\"]\n",
    "    BIAS_BITS = hyperparams[\"BIAS_BITS\"]\n",
    "    ACTIVATION_BITS = hyperparams[\"ACTIVATION_BITS\"]\n",
    "    LEARNING_RATE = hyperparams[\"LEARNING_RATE\"]\n",
    "    OUTPUT = hyperparams[\"OUTPUT\"]\n",
    "    \n",
    "    y_timed_input = Input(shape=(NUM_TIME_SLICES*13 + 1,), name='y_timed_input')\n",
    "    layer = y_timed_input\n",
    "    \n",
    "    for i, size in enumerate(DNN_LAYERS):\n",
    "        layer = QDense(size, kernel_quantizer=quantized_bits(WEIGHTS_BITS), bias_quantizer=quantized_bits(BIAS_BITS), name=f'dense{i+1}')(layer)\n",
    "        layer = BatchNormalization()(layer)\n",
    "        layer = QActivation(quantized_relu(ACTIVATION_BITS))(layer)\n",
    "\n",
    "    if OUTPUT == \"SOFTMAX\":\n",
    "        output = QDense(3, kernel_quantizer=quantized_bits(WEIGHTS_BITS), bias_quantizer=quantized_bits(BIAS_BITS), name='dense_output')(layer)\n",
    "        output = Activation(\"softmax\", name='output_softmax')(output)\n",
    "    elif OUTPUT == \"ARGMAX\":\n",
    "        output = QDense(3, kernel_quantizer=quantized_bits(WEIGHTS_BITS), bias_quantizer=quantized_bits(BIAS_BITS), name='dense_output')(layer)\n",
    "        output = ArgmaxLayer(name='output_argmax')(output)\n",
    "        print(f\"Argmax output dtype: {output.dtype}\")\n",
    "    elif OUTPUT == \"LINEAR\":\n",
    "        output = QDense(3, kernel_quantizer=quantized_bits(WEIGHTS_BITS), bias_quantizer=quantized_bits(BIAS_BITS), name='dense_output')(layer)\n",
    "    elif OUTPUT == \"SINGLE\":\n",
    "        output = QDense(1, kernel_quantizer=quantized_bits(WEIGHTS_BITS), \n",
    "                bias_quantizer=quantized_bits(BIAS_BITS), \n",
    "                # activation='sigmoid', \n",
    "                name='dense_output')(layer)\n",
    "    else:\n",
    "        raise ValueError(\"Not a supported output type\")\n",
    "   \n",
    "    model = Model(inputs=y_timed_input, outputs=output)\n",
    "\n",
    "    if OUTPUT == \"SOFTMAX\":\n",
    "        model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=[Precision()])\n",
    "    elif OUTPUT == \"ARGMAX\":\n",
    "        model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), \n",
    "                      loss='sparse_categorical_crossentropy', \n",
    "                      metrics=[Precision()])\n",
    "    elif OUTPUT == \"LINEAR\":\n",
    "        model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), \n",
    "              loss='mse', \n",
    "              metrics=[Precision()])\n",
    "    elif OUTPUT == \"SINGLE\":\n",
    "        model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def qCNNmodel(hyperparams):\n",
    "    NUM_TIME_SLICES = hyperparams[\"NUM_TIME_SLICES\"]\n",
    "    CONV_LAYER_DEPTHS = hyperparams[\"CONV_LAYER_DEPTHS\"]\n",
    "    CONV_LAYER_KERNELS = hyperparams[\"CONV_LAYER_KERNELS\"]\n",
    "    CONV_LAYER_STRIDES = hyperparams[\"CONV_LAYER_STRIDES\"]\n",
    "    MAX_POOLING_SIZE = hyperparams[\"MAX_POOLING_SIZE\"]\n",
    "    FLATTENED_LAYERS = hyperparams[\"FLATTENED_LAYERS\"]\n",
    "    WEIGHTS_BITS = hyperparams[\"WEIGHTS_BITS\"]\n",
    "    BIAS_BITS = hyperparams[\"BIAS_BITS\"]\n",
    "    INTEGER_BITS = hyperparams[\"INTEGER_BITS\"]\n",
    "    ACTIVATION_BITS = hyperparams[\"ACTIVATION_BITS\"]\n",
    "    LEARNING_RATE = hyperparams[\"LEARNING_RATE\"]\n",
    "\n",
    "    y_profile_input = Input(shape=(NUM_TIME_SLICES, 13, 1), name='y_profile_input')  # Adjust the shape based on your input\n",
    "    layer = y_profile_input\n",
    "\n",
    "    # Convolutional layers\n",
    "    for i in range(len(CONV_LAYER_DEPTHS)):\n",
    "        layer = QConv2D(\n",
    "        CONV_LAYER_DEPTHS[i],\n",
    "        kernel_size=CONV_LAYER_KERNELS[i],\n",
    "        strides=CONV_LAYER_STRIDES[i],\n",
    "        kernel_quantizer=quantized_bits(WEIGHTS_BITS,INTEGER_BITS,alpha=1.0),\n",
    "        bias_quantizer=quantized_bits(BIAS_BITS,INTEGER_BITS,alpha=1.0),\n",
    "        padding='same',\n",
    "        use_bias=True,\n",
    "        name=f'conv{i+1}'\n",
    "        )(layer)\n",
    "        layer = QActivation(quantized_relu(ACTIVATION_BITS), name=f'relu{i+1}')(layer)\n",
    "        layer = MaxPooling2D(pool_size=MAX_POOLING_SIZE, name=f'maxpool{i+1}')(layer)\n",
    "\n",
    "    # Flatten the output to feed into a dense layer\n",
    "    layer = Flatten(name='flattened')(layer)\n",
    "\n",
    "    # Flatten and concatenate with y0 input\n",
    "    y0_input = Input(shape=(1,), name='y0_input')\n",
    "    layer = Concatenate(name='concat')([layer, y0_input])\n",
    "\n",
    "    # Post-flattening dense layers\n",
    "    for i in range(len(FLATTENED_LAYERS)):\n",
    "        layer = QDense(FLATTENED_LAYERS[i], kernel_quantizer=quantized_bits(WEIGHTS_BITS,INTEGER_BITS,alpha=1.0),\n",
    "                    bias_quantizer=quantized_bits(BIAS_BITS,INTEGER_BITS,alpha=1.0), name=f'dense{i+1}')(layer)\n",
    "        layer = QActivation(quantized_relu(10), name=f'relu{len(CONV_LAYER_DEPTHS)+i+1}')(layer)\n",
    "\n",
    "    # Output layer (adjust based on your classification problem)\n",
    "    output = QDense(3, kernel_quantizer=quantized_bits(WEIGHTS_BITS), bias_quantizer=quantized_bits(BIAS_BITS), name='dense_output')(layer)\n",
    "    output = Activation(\"softmax\", name='output_softmax')(output)\n",
    "    # layer = QDense(1, kernel_quantizer=quantized_bits(WEIGHTS_BITS,INTEGER_BITS,alpha=1.0), \n",
    "    #                bias_quantizer=quantized_bits(BIAS_BITS,INTEGER_BITS,alpha=1.0), name='output_dense')(layer)\n",
    "    # output = Activation(\"sigmoid\", name='output_sigmoid')(layer)\n",
    "\n",
    "    model = Model(inputs=[y_profile_input, y0_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='categorical_crossentropy', metrics=['accuracy']) # loss='binary_crossentropy'\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Pruning the model\n",
    "def pruneFunction(layer, train_data_size, hyperparams):\n",
    "    BATCH_SIZE = hyperparams[\"BATCH_SIZE\"]\n",
    "    FINAL_SPARSITY = hyperparams[\"FINAL_SPARSITY\"]\n",
    "    PRUNE_START_EPOCH = hyperparams[\"PRUNE_START_EPOCH\"]\n",
    "    NUM_PRUNE_EPOCHS = hyperparams[\"NUM_PRUNE_EPOCHS\"]\n",
    "\n",
    "    steps_per_epoch = train_data_size // BATCH_SIZE #input_train_data_combined.shape[0]\n",
    "    pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=0.0,\n",
    "            final_sparsity=FINAL_SPARSITY,\n",
    "            begin_step=steps_per_epoch * PRUNE_START_EPOCH,\n",
    "            end_step=steps_per_epoch * (PRUNE_START_EPOCH + NUM_PRUNE_EPOCHS),\n",
    "            frequency=steps_per_epoch # prune after every epoch\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "    if isinstance(layer, QDense):\n",
    "        if layer.name != 'output_softmax' and layer.name != 'dense2':\n",
    "            print(f\"pruning layer {layer.name}\")\n",
    "            return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "        elif layer.name != 'output_softmax' and layer.name != 'dense1':\n",
    "            print(f\"pruning layer {layer.name}\")\n",
    "            return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "        else:\n",
    "            print(f\"cannot prune layer {layer.name}\")\n",
    "            return layer\n",
    "\n",
    "    else:\n",
    "        print(f\"cannot prune layer {layer.name}\")\n",
    "        return layer\n",
    "    \n",
    "def pruneFunctionWrapper(train_data_size, hyperparams):\n",
    "    def wrapper(layer):\n",
    "        return pruneFunction(layer, train_data_size, hyperparams)\n",
    "    return wrapper\n",
    "    \n",
    "\n",
    "# Function to calculate sparsity\n",
    "def calculate_sparsity(model):\n",
    "    total_params = 0\n",
    "    zero_params = 0\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Dense):\n",
    "            weights = layer.get_weights()[0]\n",
    "            total_params += weights.size\n",
    "            zero_params += np.sum(weights == 0)\n",
    "    sparsity = zero_params / total_params\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, hyperparams):\n",
    "    input_train_data_combined = data[\"input_train_data_combined\"]\n",
    "    target_train_data_coded = data[\"target_train_data_coded\"]\n",
    "    input_validate_data_combined = data[\"input_validate_data_combined\"]\n",
    "    target_validate_data_coded = data[\"target_validate_data_coded\"]\n",
    "\n",
    "    MODEL_TYPE = hyperparams[\"MODEL_TYPE\"]\n",
    "    PATIENCE = hyperparams[\"PATIENCE\"]\n",
    "    EPOCHS = hyperparams[\"EPOCHS\"]\n",
    "    BATCH_SIZE = hyperparams[\"BATCH_SIZE\"]\n",
    "    LEARNING_RATE = hyperparams[\"LEARNING_RATE\"]\n",
    "    POST_PRUNE_EPOCHS = hyperparams[\"POST_PRUNE_EPOCHS\"]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Define the model\n",
    "    if (MODEL_TYPE == \"DNN\"):\n",
    "        model = qDNNmodel(hyperparams)\n",
    "    elif (MODEL_TYPE == \"CNN\"):\n",
    "        model = qCNNmodel(hyperparams)\n",
    "    else:\n",
    "        raise ValueError(\"Not a supported model type\")\n",
    "\n",
    "    model.summary()\n",
    "    print_qmodel_summary(model)\n",
    "    print(f\"Initial Sparsity: {calculate_sparsity(model) * 100:.2f}%\")\n",
    "\n",
    "    train_metrics = {}\n",
    "\n",
    "    # Train the model\n",
    "    earlyStop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=PATIENCE, restore_best_weights=True)\n",
    "    print(\"shape 12323 is \", target_train_data_coded.shape, \"data is like\", target_validate_data_coded[1:5])\n",
    "    history = model.fit(\n",
    "        input_train_data_combined, target_train_data_coded,  # Training data and labels\n",
    "        validation_data=(input_validate_data_combined, target_validate_data_coded),  # Validation data\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[earlyStop_callback]\n",
    "    )\n",
    "    # Best at this step val_loss 0.7085\n",
    "    train_metrics[\"val_loss\"] = history.history['val_loss'][-1]\n",
    "\n",
    "    # Prune the DNN model \n",
    "    if MODEL_TYPE == \"DNN\":\n",
    "        model_pruned = keras.models.clone_model(model, clone_function=pruneFunctionWrapper(input_train_data_combined.shape[0], hyperparams))\n",
    "        model_pruned.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Re-train the pruned model\n",
    "        history = model_pruned.fit(\n",
    "            input_train_data_combined, target_train_data_coded,  # Training data and labels\n",
    "            validation_data=(input_validate_data_combined, target_validate_data_coded),  # Validation data\n",
    "            epochs=POST_PRUNE_EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks = [pruning_callbacks.UpdatePruningStep()]\n",
    "        ) \n",
    "        # best at this step val_loss 0.4314\n",
    "\n",
    "        model = strip_pruning(model_pruned)\n",
    "        # train_metrics[\"pruned_sparsity\"] = calculate_sparsity(model)\n",
    "\n",
    "    try:\n",
    "        train_metrics[\"pruned_val_loss\"] = history.history['val_loss'][-1]\n",
    "    except:\n",
    "        print(\"Error: no post-pruning val_loss found\")\n",
    "        train_metrics[\"pruned_val_loss\"] = train_metrics[\"val_loss\"]\n",
    "\n",
    "    return model, train_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(data, model, hyperparams):\n",
    "    OUTPUT = hyperparams[\"OUTPUT\"]\n",
    "    \n",
    "    input_test_data_combined = data[\"input_test_data_combined\"]\n",
    "    target_test_data_coded = data[\"target_test_data_coded\"]\n",
    "\n",
    "    \n",
    "    # Test the model at threshold 0.5\n",
    "    predictions = model.predict(input_test_data_combined)\n",
    "    print(predictions[:10, :])\n",
    "    predictions_prob = predictions[:,0]\n",
    "    predictions_labels = (predictions_prob >= 0.5).astype(int).flatten()\n",
    "\n",
    "    # Test the model at different thresholds\n",
    "    thresholds = np.linspace(0.0, 1.0, 1000)\n",
    "    signal_efficiencies = []\n",
    "    background_rejections = []\n",
    "    max_sum_se = 0\n",
    "    max_sum_br = 0\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        # predicted_class = ((predictions_prob[:, 0] + threshold > predictions_prob[:, 1]) & (predictions_prob[:, 0] + threshold > predictions_prob[:, 2])).astype(int)\n",
    "        predicted_class = (predictions_prob > threshold).astype(int)\n",
    "        # Compute confusion matrix\n",
    "        if OUTPUT == \"SINGLE\":\n",
    "            cm = confusion_matrix(target_test_data_coded[:], predicted_class)\n",
    "        else:\n",
    "            cm = confusion_matrix(target_test_data_coded[:, 0], predicted_class)\n",
    "\n",
    "        # Calculate signal efficiency and background rejection\n",
    "        signal_efficiency = cm[1, 1] / np.sum(cm[1, :])\n",
    "        background_rejection = cm[0, 0] / np.sum(cm[0, :])\n",
    "\n",
    "        # Store metrics\n",
    "        signal_efficiencies.append(signal_efficiency)\n",
    "        background_rejections.append(background_rejection)\n",
    "\n",
    "        # get maximum added score\n",
    "        if signal_efficiency + background_rejection > max_sum_se + max_sum_br:\n",
    "            max_sum_se = signal_efficiency\n",
    "            max_sum_br = background_rejection\n",
    "    \n",
    "    test_results = {\n",
    "        \"predictions_prob\": predictions_prob,\n",
    "        \"predictions_labels\": predictions_labels,\n",
    "        \"thresholds\": thresholds,\n",
    "        \"signal_efficiencies\": signal_efficiencies,\n",
    "        \"background_rejections\": background_rejections,\n",
    "        \"max_sum_se\": max_sum_se,\n",
    "        \"max_sum_br\": max_sum_br,\n",
    "    }\n",
    "\n",
    "    return test_results\n",
    "\n",
    "def ShowConfusionMatrix(data, test_results, hyperparams):\n",
    "    OUTPUT = hyperparams[\"OUTPUT\"]\n",
    "    \n",
    "    target_test_data_coded = data[\"target_test_data_coded\"]\n",
    "    predictions_labels = test_results[\"predictions_labels\"]\n",
    "\n",
    "    if OUTPUT == \"SINGLE\":\n",
    "        cm = confusion_matrix(target_test_data_coded[:], predictions_labels)\n",
    "    else:\n",
    "        cm = confusion_matrix(target_test_data_coded[:, 0], predictions_labels)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='YlGnBu')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def showMetricsByThreshold(test_results):\n",
    "    thresholds = test_results[\"thresholds\"]\n",
    "    signal_efficiencies = test_results[\"signal_efficiencies\"]\n",
    "    background_rejections = test_results[\"background_rejections\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(thresholds, signal_efficiencies, label='Signal Efficiency')\n",
    "    plt.plot(thresholds, background_rejections, label='Background Rejection')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.title('Effect of Threshold on Signal Efficiency and Background Rejection')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def showEfficiencyVSRejection(test_results):\n",
    "    signal_efficiencies = test_results[\"signal_efficiencies\"]\n",
    "    background_rejections = test_results[\"background_rejections\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(signal_efficiencies, background_rejections, marker='o')\n",
    "    plt.xlabel('Signal Efficiency')\n",
    "    plt.ylabel('Background Rejection')\n",
    "    plt.title('Background Rejection vs. Signal Efficiency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def find_closest(sorted_array, value):\n",
    "    # Ensure the array is a NumPy array\n",
    "    sorted_array = np.array(sorted_array)\n",
    "    # Compute the absolute difference\n",
    "    abs_diff = np.abs(sorted_array - value)\n",
    "    # Find the index of the minimum difference\n",
    "    closest_index = np.argmin(abs_diff)\n",
    "    return closest_index\n",
    "\n",
    "def getTargetMetrics(test_results):\n",
    "    signal_efficiencies = test_results[\"signal_efficiencies\"]\n",
    "    background_rejections = test_results[\"background_rejections\"]\n",
    "\n",
    "    target_efficiencies = [0.873, 0.90, 0.93, 0.96, 0.98, 0.99, 0.995, 0.999]\n",
    "    metrics = []\n",
    "    for target in target_efficiencies:\n",
    "        index = find_closest(signal_efficiencies, target)\n",
    "        metrics.append((signal_efficiencies[index], background_rejections[index]))\n",
    "        # print(f\"Signal Efficiency: {signal_efficiencies[index]*100:.1f}%,\",f\"Background Rejections: {background_rejections[index]*100:.1f}%\")\n",
    "    return metrics\n",
    "\n",
    "def displayPerformance(data, test_results, metrics, hyperparams):\n",
    "    ShowConfusionMatrix(data, test_results, hyperparams)\n",
    "    showMetricsByThreshold(test_results)\n",
    "    showEfficiencyVSRejection(test_results)\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_metrics(metrics):\n",
    "    # Convert metrics list of tuples to a formatted string\n",
    "    return \", \".join([f\"({m1:.2f}, {m2:.2f})\" for m1, m2 in metrics])\n",
    "\n",
    "def hyperparameter_search(data, base_hyperparams, param_grid, result_file='hyperparameter_results.json'):\n",
    "    best_metric = 0.0\n",
    "\n",
    "    # Load existing results from file if it exists\n",
    "    if os.path.exists(result_file):\n",
    "        with open(result_file, 'r') as file:\n",
    "            all_results = json.load(file)\n",
    "    else:\n",
    "        all_results = {}\n",
    "\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    for v in itertools.product(*values):\n",
    "        hyperparams = dict(zip(keys, v))\n",
    "        # Update base hyperparameters with the current set\n",
    "        current_hyperparams = base_hyperparams.copy()\n",
    "        current_hyperparams.update(hyperparams)\n",
    "\n",
    "        # Convert hyperparameters to a string for use as a dictionary key\n",
    "        hyperparams_str = json.dumps(current_hyperparams, sort_keys=True)\n",
    "\n",
    "        # Check if these hyperparameters have been tried before\n",
    "        if hyperparams_str in all_results:\n",
    "            print(f\"Skipping already tested hyperparameters: {current_hyperparams}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Testing hyperparameters: {current_hyperparams}\")\n",
    "\n",
    "        # Train the model\n",
    "        model, train_metrics = train_model(data, current_hyperparams)\n",
    "\n",
    "        # Test the model\n",
    "        test_results = test_model(data, model, current_hyperparams)\n",
    "        metrics = getTargetMetrics(test_results)\n",
    "        \n",
    "        test_scores = {\n",
    "            \"max_sum_se\": test_results[\"max_sum_se\"],\n",
    "            \"max_sum_br\": test_results[\"max_sum_br\"],\n",
    "            \"metrics\": format_metrics(metrics),\n",
    "        }\n",
    "        # Add all keys and values from train_metrics into test_scores\n",
    "        test_scores.update(train_metrics)\n",
    "\n",
    "        # Save the results to the file\n",
    "        all_results[hyperparams_str] = test_scores\n",
    "        with open(result_file, 'w') as file:\n",
    "            json.dump(all_results, file, indent=4)\n",
    "\n",
    "\n",
    "        # If new best found, email alex\n",
    "        if metrics[0][1] > best_metric:\n",
    "            best_metric = metrics[0][1]\n",
    "            print(f\"########### FOUND NEW BEST METRIC {best_metric} ##############\")\n",
    "            model.save(f'./hyperparam_search_recent_best.h5')\n",
    "\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def find_min_pruned_val_loss(result_file='hyperparameter_results.json'):\n",
    "    # Load existing results from file\n",
    "    if os.path.exists(result_file):\n",
    "        with open(result_file, 'r') as file:\n",
    "            all_results = json.load(file)\n",
    "    else:\n",
    "        print(f\"No results found in {result_file}\")\n",
    "        return None\n",
    "\n",
    "    min_loss = float('inf')\n",
    "    min_hyperparams = None\n",
    "\n",
    "    # Iterate through the results to find the minimum pruned_val_loss\n",
    "    for hyperparams_str, results in all_results.items():\n",
    "        if \"pruned_val_loss\" in results:\n",
    "            pruned_val_loss = results[\"pruned_val_loss\"]\n",
    "            if pruned_val_loss < min_loss:\n",
    "                min_loss = pruned_val_loss\n",
    "                min_hyperparams = hyperparams_str\n",
    "\n",
    "    # Print the hyperparameters with the minimum pruned_val_loss\n",
    "    if min_hyperparams is not None:\n",
    "        print(f\"Hyperparameters with minimum pruned_val_loss: {min_hyperparams}\")\n",
    "        print(f\"Minimum pruned_val_loss: {min_loss}\")\n",
    "    else:\n",
    "        print(\"No entry with pruned_val_loss found\")\n",
    "\n",
    "    return min_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters with minimum pruned_val_loss: {\"ACTIVATION_BITS\": 15, \"BATCH_SIZE\": 1024, \"BIAS_BITS\": 10, \"CONV_LAYER_DEPTHS\": [4, 7], \"CONV_LAYER_KERNELS\": [[3, 3], [3, 3]], \"CONV_LAYER_STRIDES\": [[1, 1], [1, 1]], \"DNN_LAYERS\": [24, 12], \"EPOCHS\": 150, \"FINAL_SPARSITY\": 0.3, \"FLATTENED_LAYERS\": [7], \"INTEGER_BITS\": 2, \"LEARNING_RATE\": 0.001, \"MAX_POOLING_SIZE\": [2, 2], \"MODEL_TYPE\": \"DNN\", \"NUM_PRUNE_EPOCHS\": 10, \"NUM_TIME_SLICES\": 8, \"OUTPUT\": \"SINGLE\", \"PATIENCE\": 20, \"POST_PRUNE_EPOCHS\": 50, \"PRUNE_START_EPOCH\": 0, \"TEST_PT_THRESHOLD\": 2, \"TRAIN_PT_THRESHOLD\": 2, \"WEIGHTS_BITS\": 10}\n",
      "Minimum pruned_val_loss: 0.6217492818832397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6217492818832397"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HYPERPARAMETERS = {\n",
    "    # Model Type\n",
    "    \"MODEL_TYPE\": \"DNN\",  # DNN or CNN\n",
    "    # Input format\n",
    "    \"NUM_TIME_SLICES\": 8,\n",
    "    \"TRAIN_PT_THRESHOLD\": 2,  # in GeV\n",
    "    \"TEST_PT_THRESHOLD\": 2,  # in GeV\n",
    "    # DNN model mormat\n",
    "    \"DNN_LAYERS\": [24, 12],\n",
    "    # CNN model format\n",
    "    \"CONV_LAYER_DEPTHS\": [4, 7],\n",
    "    \"CONV_LAYER_KERNELS\": [(3, 3), (3, 3)],\n",
    "    \"CONV_LAYER_STRIDES\": [(1, 1), (1, 1)],\n",
    "    \"FLATTENED_LAYERS\": [7],\n",
    "    \"MAX_POOLING_SIZE\": (2, 2),\n",
    "    # Output function\n",
    "    \"OUTPUT\": \"SINGLE\", # SOFTMAX or ARGMAX (not working) or LINEAR or SINGLE\n",
    "    # Model quantization\n",
    "    \"WEIGHTS_BITS\": 10,\n",
    "    \"BIAS_BITS\": 10,\n",
    "    \"ACTIVATION_BITS\": 15,\n",
    "    \"INTEGER_BITS\": 2,\n",
    "    # Training\n",
    "    \"LEARNING_RATE\": 0.001,\n",
    "    \"BATCH_SIZE\": 1024,  # Number of samples per gradient update\n",
    "    \"EPOCHS\": 150,  # Number of epochs to train\n",
    "    \"PATIENCE\": 20,  # Stop after this number of epochs without improvement\n",
    "    # Pruning\n",
    "    \"PRUNE_START_EPOCH\": 0,  # Number of epochs before pruning\n",
    "    \"NUM_PRUNE_EPOCHS\": 10,\n",
    "    \"FINAL_SPARSITY\": 0.0,\n",
    "    \"POST_PRUNE_EPOCHS\": 50,\n",
    "}\n",
    "\n",
    "SAVE_FILE = \"L2_S24_10_15_results.json\"\n",
    "\n",
    "param_grid = {\n",
    "    \"FINAL_SPARSITY\": [0.0, 0.15, 0.3], \n",
    "    \"LEARNING_RATE\": [0.002, 0.001, 0.0005],\n",
    "    \"EPOCHS\": [150, 200]\n",
    "}\n",
    "\n",
    "find_min_pruned_val_loss(result_file=(SAVE_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 376.23 GB\n",
      "Available memory: 303.49 GB\n",
      "Used memory: 61.31 GB\n",
      "Memory usage percentage: 19.3%\n",
      "Total memory: 376.23 GB\n",
      "Available memory: 292.27 GB\n",
      "Used memory: 72.53 GB\n",
      "Memory usage percentage: 22.3%\n"
     ]
    }
   ],
   "source": [
    "input_data, target_data = load_dataset()\n",
    "data = process_dataset(input_data, target_data, HYPERPARAMETERS) # Depends only on: NUM_TIME_SLICES MODEL_TYPE TRAIN_PT_THRESHOLD TEST_PT_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.002, 'BATCH_SIZE': 1024, 'EPOCHS': 100, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.0, 'POST_PRUNE_EPOCHS': 50}\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 24)                96        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " q_activation_2 (QActivatio  (None, 24)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 12)                48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " q_activation_3 (QActivatio  (None, 12)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_2 is normal keras bn layer\n",
      "q_activation_2       quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_3 is normal keras bn layer\n",
      "q_activation_3       quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/100\n",
      "429/429 [==============================] - 6s 7ms/step - loss: 1.1908 - accuracy: 0.5003 - val_loss: 0.7064 - val_accuracy: 0.4999\n",
      "Epoch 2/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7012 - accuracy: 0.5019 - val_loss: 0.6997 - val_accuracy: 0.5002\n",
      "Epoch 3/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6975 - accuracy: 0.5034 - val_loss: 0.6969 - val_accuracy: 0.5023\n",
      "Epoch 4/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6956 - accuracy: 0.5051 - val_loss: 0.6956 - val_accuracy: 0.5020\n",
      "Epoch 5/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6947 - accuracy: 0.5077 - val_loss: 0.6948 - val_accuracy: 0.5054\n",
      "Epoch 6/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6941 - accuracy: 0.5086 - val_loss: 0.6945 - val_accuracy: 0.5067\n",
      "Epoch 7/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6936 - accuracy: 0.5100 - val_loss: 0.6951 - val_accuracy: 0.5007\n",
      "Epoch 8/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6934 - accuracy: 0.5097 - val_loss: 0.6942 - val_accuracy: 0.5071\n",
      "Epoch 9/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6931 - accuracy: 0.5102 - val_loss: 0.6938 - val_accuracy: 0.5083\n",
      "Epoch 10/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6929 - accuracy: 0.5122 - val_loss: 0.6936 - val_accuracy: 0.5076\n",
      "Epoch 11/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6927 - accuracy: 0.5120 - val_loss: 0.6938 - val_accuracy: 0.5098\n",
      "Epoch 12/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5134 - val_loss: 0.6935 - val_accuracy: 0.5106\n",
      "Epoch 13/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6925 - accuracy: 0.5123 - val_loss: 0.6936 - val_accuracy: 0.5114\n",
      "Epoch 14/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5145 - val_loss: 0.6934 - val_accuracy: 0.5090\n",
      "Epoch 15/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5143 - val_loss: 0.6945 - val_accuracy: 0.5001\n",
      "Epoch 16/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5144 - val_loss: 0.6932 - val_accuracy: 0.5093\n",
      "Epoch 17/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6921 - accuracy: 0.5155 - val_loss: 0.6931 - val_accuracy: 0.5152\n",
      "Epoch 18/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6920 - accuracy: 0.5168 - val_loss: 0.6928 - val_accuracy: 0.5144\n",
      "Epoch 19/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6920 - accuracy: 0.5157 - val_loss: 0.6934 - val_accuracy: 0.5071\n",
      "Epoch 20/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6919 - accuracy: 0.5173 - val_loss: 0.6932 - val_accuracy: 0.5132\n",
      "Epoch 21/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6916 - accuracy: 0.5183 - val_loss: 0.6932 - val_accuracy: 0.5154\n",
      "Epoch 22/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6914 - accuracy: 0.5206 - val_loss: 0.6923 - val_accuracy: 0.5235\n",
      "Epoch 23/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6909 - accuracy: 0.5220 - val_loss: 0.6919 - val_accuracy: 0.5238\n",
      "Epoch 24/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6896 - accuracy: 0.5296 - val_loss: 0.6908 - val_accuracy: 0.5239\n",
      "Epoch 25/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6877 - accuracy: 0.5358 - val_loss: 0.6887 - val_accuracy: 0.5315\n",
      "Epoch 26/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6856 - accuracy: 0.5411 - val_loss: 0.6840 - val_accuracy: 0.5463\n",
      "Epoch 27/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6824 - accuracy: 0.5481 - val_loss: 0.6860 - val_accuracy: 0.5359\n",
      "Epoch 28/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6793 - accuracy: 0.5566 - val_loss: 0.6770 - val_accuracy: 0.5649\n",
      "Epoch 29/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6764 - accuracy: 0.5635 - val_loss: 0.6793 - val_accuracy: 0.5554\n",
      "Epoch 30/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6752 - accuracy: 0.5658 - val_loss: 0.6798 - val_accuracy: 0.5592\n",
      "Epoch 31/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6913 - accuracy: 0.5248 - val_loss: 0.6950 - val_accuracy: 0.5009\n",
      "Epoch 32/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6934 - accuracy: 0.5094 - val_loss: 0.6939 - val_accuracy: 0.5027\n",
      "Epoch 33/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5143 - val_loss: 0.6929 - val_accuracy: 0.5172\n",
      "Epoch 34/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6912 - val_accuracy: 0.5240\n",
      "Epoch 35/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6893 - accuracy: 0.5336 - val_loss: 0.6900 - val_accuracy: 0.5306\n",
      "Epoch 36/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6849 - accuracy: 0.5480 - val_loss: 0.6805 - val_accuracy: 0.5585\n",
      "Epoch 37/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6803 - accuracy: 0.5564 - val_loss: 0.6969 - val_accuracy: 0.5263\n",
      "Epoch 38/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6794 - accuracy: 0.5563 - val_loss: 0.6862 - val_accuracy: 0.5422\n",
      "Epoch 39/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6764 - accuracy: 0.5629 - val_loss: 0.6733 - val_accuracy: 0.5691\n",
      "Epoch 40/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6757 - accuracy: 0.5636 - val_loss: 0.6743 - val_accuracy: 0.5697\n",
      "Epoch 41/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6701 - accuracy: 0.5734 - val_loss: 0.6716 - val_accuracy: 0.5677\n",
      "Epoch 42/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6726 - accuracy: 0.5676 - val_loss: 0.6656 - val_accuracy: 0.5855\n",
      "Epoch 43/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6844 - accuracy: 0.5386 - val_loss: 0.6949 - val_accuracy: 0.5056\n",
      "Epoch 44/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6931 - accuracy: 0.5091 - val_loss: 0.6928 - val_accuracy: 0.5154\n",
      "Epoch 45/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6900 - accuracy: 0.5237 - val_loss: 0.6906 - val_accuracy: 0.5307\n",
      "Epoch 46/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6777 - accuracy: 0.5570 - val_loss: 0.6992 - val_accuracy: 0.5104\n",
      "Epoch 47/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6908 - accuracy: 0.5208 - val_loss: 0.6931 - val_accuracy: 0.5071\n",
      "Epoch 48/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6919 - accuracy: 0.5151 - val_loss: 0.6921 - val_accuracy: 0.5171\n",
      "Epoch 49/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6876 - accuracy: 0.5319 - val_loss: 0.6900 - val_accuracy: 0.5315\n",
      "Epoch 50/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6741 - accuracy: 0.5651 - val_loss: 0.6686 - val_accuracy: 0.5726\n",
      "Epoch 51/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6674 - accuracy: 0.5772 - val_loss: 0.6641 - val_accuracy: 0.5807\n",
      "Epoch 52/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6643 - accuracy: 0.5819 - val_loss: 0.6715 - val_accuracy: 0.5734\n",
      "Epoch 53/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6766 - accuracy: 0.5613 - val_loss: 0.6892 - val_accuracy: 0.5158\n",
      "Epoch 54/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6769 - accuracy: 0.5604 - val_loss: 0.7061 - val_accuracy: 0.5171\n",
      "Epoch 55/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6807 - accuracy: 0.5533 - val_loss: 0.7050 - val_accuracy: 0.5226\n",
      "Epoch 56/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6714 - accuracy: 0.5696 - val_loss: 0.6630 - val_accuracy: 0.5809\n",
      "Epoch 57/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6610 - accuracy: 0.5899 - val_loss: 0.6536 - val_accuracy: 0.5949\n",
      "Epoch 58/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6652 - accuracy: 0.5845 - val_loss: 0.7082 - val_accuracy: 0.5020\n",
      "Epoch 59/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6944 - accuracy: 0.5058 - val_loss: 0.6927 - val_accuracy: 0.5071\n",
      "Epoch 60/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6924 - accuracy: 0.5115 - val_loss: 0.6925 - val_accuracy: 0.5160\n",
      "Epoch 61/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6917 - accuracy: 0.5162 - val_loss: 0.6915 - val_accuracy: 0.5171\n",
      "Epoch 62/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6884 - accuracy: 0.5317 - val_loss: 0.6860 - val_accuracy: 0.5472\n",
      "Epoch 63/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6767 - accuracy: 0.5615 - val_loss: 0.6728 - val_accuracy: 0.5708\n",
      "Epoch 64/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6836 - accuracy: 0.5375 - val_loss: 0.6939 - val_accuracy: 0.5034\n",
      "Epoch 65/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6931 - accuracy: 0.5075 - val_loss: 0.6930 - val_accuracy: 0.5056\n",
      "Epoch 66/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6926 - accuracy: 0.5115 - val_loss: 0.6926 - val_accuracy: 0.5093\n",
      "Epoch 67/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5134 - val_loss: 0.6924 - val_accuracy: 0.5131\n",
      "Epoch 68/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.5175 - val_loss: 0.6918 - val_accuracy: 0.5182\n",
      "Epoch 69/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6906 - accuracy: 0.5238 - val_loss: 0.6904 - val_accuracy: 0.5219\n",
      "Epoch 70/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6942 - accuracy: 0.5147 - val_loss: 0.6945 - val_accuracy: 0.5030\n",
      "Epoch 71/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.5087 - val_loss: 0.6932 - val_accuracy: 0.5045\n",
      "Epoch 72/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5095 - val_loss: 0.6930 - val_accuracy: 0.5069\n",
      "Epoch 73/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6926 - accuracy: 0.5107 - val_loss: 0.6928 - val_accuracy: 0.5118\n",
      "Epoch 74/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6925 - accuracy: 0.5117 - val_loss: 0.6929 - val_accuracy: 0.5090\n",
      "Epoch 75/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6924 - accuracy: 0.5109 - val_loss: 0.6928 - val_accuracy: 0.5090\n",
      "Epoch 76/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5125 - val_loss: 0.6927 - val_accuracy: 0.5087\n",
      "Epoch 77/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6920 - accuracy: 0.5136 - val_loss: 0.6928 - val_accuracy: 0.5102\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_2\n",
      "cannot prune layer q_activation_2\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_3\n",
      "cannot prune layer q_activation_3\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 8s 7ms/step - loss: 0.6639 - accuracy: 0.5833 - val_loss: 0.6685 - val_accuracy: 0.5784\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6715 - accuracy: 0.5674 - val_loss: 0.6658 - val_accuracy: 0.5821\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6650 - accuracy: 0.5802 - val_loss: 0.6847 - val_accuracy: 0.5583\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6839 - accuracy: 0.5359 - val_loss: 0.6946 - val_accuracy: 0.5017\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6933 - accuracy: 0.5081 - val_loss: 0.6933 - val_accuracy: 0.5052\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5108 - val_loss: 0.6926 - val_accuracy: 0.5103\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6919 - accuracy: 0.5159 - val_loss: 0.6916 - val_accuracy: 0.5215\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6870 - accuracy: 0.5363 - val_loss: 0.6843 - val_accuracy: 0.5479\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6747 - accuracy: 0.5646 - val_loss: 0.6727 - val_accuracy: 0.5685\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6835 - accuracy: 0.5441 - val_loss: 0.6792 - val_accuracy: 0.5552\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6707 - accuracy: 0.5684 - val_loss: 0.6665 - val_accuracy: 0.5831\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6649 - accuracy: 0.5783 - val_loss: 0.6664 - val_accuracy: 0.5763\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6620 - accuracy: 0.5832 - val_loss: 0.6565 - val_accuracy: 0.5906\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6851 - accuracy: 0.5326 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6845 - accuracy: 0.5377 - val_loss: 0.6795 - val_accuracy: 0.5547\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6689 - accuracy: 0.5722 - val_loss: 0.6689 - val_accuracy: 0.5707\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6812 - accuracy: 0.5521 - val_loss: 0.7026 - val_accuracy: 0.5089\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6977 - accuracy: 0.5039 - val_loss: 0.6941 - val_accuracy: 0.5055\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6935 - accuracy: 0.5069 - val_loss: 0.6936 - val_accuracy: 0.5077\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6930 - accuracy: 0.5081 - val_loss: 0.6930 - val_accuracy: 0.5064\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6929 - accuracy: 0.5081 - val_loss: 0.6930 - val_accuracy: 0.5096\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.5094 - val_loss: 0.6930 - val_accuracy: 0.5101\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.5095 - val_loss: 0.6929 - val_accuracy: 0.5101\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6927 - accuracy: 0.5103 - val_loss: 0.6929 - val_accuracy: 0.5118\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5116 - val_loss: 0.6929 - val_accuracy: 0.5081\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6925 - accuracy: 0.5110 - val_loss: 0.6930 - val_accuracy: 0.5095\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6925 - accuracy: 0.5127 - val_loss: 0.6927 - val_accuracy: 0.5125\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5128 - val_loss: 0.6925 - val_accuracy: 0.5085\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6922 - accuracy: 0.5153 - val_loss: 0.6925 - val_accuracy: 0.5144\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6918 - val_accuracy: 0.5216\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6883 - accuracy: 0.5330 - val_loss: 0.6861 - val_accuracy: 0.5466\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5531 - val_loss: 0.6785 - val_accuracy: 0.5605\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6882 - accuracy: 0.5302 - val_loss: 0.6910 - val_accuracy: 0.5153\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6890 - accuracy: 0.5269 - val_loss: 0.6870 - val_accuracy: 0.5403\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6788 - accuracy: 0.5593 - val_loss: 0.6774 - val_accuracy: 0.5595\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6756 - accuracy: 0.5610 - val_loss: 0.6752 - val_accuracy: 0.5577\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6670 - accuracy: 0.5755 - val_loss: 0.6634 - val_accuracy: 0.5817\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6655 - accuracy: 0.5794 - val_loss: 0.6626 - val_accuracy: 0.5816\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6621 - accuracy: 0.5818 - val_loss: 0.6635 - val_accuracy: 0.5814\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6590 - accuracy: 0.5883 - val_loss: 0.6679 - val_accuracy: 0.5783\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6714 - accuracy: 0.5646 - val_loss: 0.6938 - val_accuracy: 0.5128\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6900 - accuracy: 0.5221 - val_loss: 0.6889 - val_accuracy: 0.5232\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6803 - accuracy: 0.5514 - val_loss: 0.6792 - val_accuracy: 0.5636\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6698 - accuracy: 0.5718 - val_loss: 0.6664 - val_accuracy: 0.5771\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6652 - accuracy: 0.5782 - val_loss: 0.6645 - val_accuracy: 0.5803\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6564 - accuracy: 0.5942 - val_loss: 0.6524 - val_accuracy: 0.6023\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6606 - accuracy: 0.5868 - val_loss: 0.6646 - val_accuracy: 0.5875\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6852 - accuracy: 0.5324 - val_loss: 0.6927 - val_accuracy: 0.5088\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6915 - accuracy: 0.5181 - val_loss: 0.6908 - val_accuracy: 0.5193\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6881 - accuracy: 0.5322 - val_loss: 0.6893 - val_accuracy: 0.5272\n",
      "1714/1714 [==============================] - 3s 1ms/step\n",
      "[[0.49674785]\n",
      " [0.5451554 ]\n",
      " [0.5389303 ]\n",
      " [0.5399257 ]\n",
      " [0.5302012 ]\n",
      " [0.5436375 ]\n",
      " [0.5428493 ]\n",
      " [0.49215496]\n",
      " [0.44253922]\n",
      " [0.5521493 ]]\n",
      "########### FOUND NEW BEST METRIC 0.18306886009608386 ##############\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sdf/home/a/alexyue/miniconda3/envs/SmartPixel/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.002, 'BATCH_SIZE': 1024, 'EPOCHS': 150, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.0, 'POST_PRUNE_EPOCHS': 50}\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 24)                96        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " q_activation_4 (QActivatio  (None, 24)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 12)                48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " q_activation_5 (QActivatio  (None, 12)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_4 is normal keras bn layer\n",
      "q_activation_4       quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_5 is normal keras bn layer\n",
      "q_activation_5       quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/150\n",
      "429/429 [==============================] - 6s 7ms/step - loss: 0.8564 - accuracy: 0.4995 - val_loss: 0.7167 - val_accuracy: 0.5007\n",
      "Epoch 2/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7095 - accuracy: 0.5014 - val_loss: 0.7050 - val_accuracy: 0.5030\n",
      "Epoch 3/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7024 - accuracy: 0.5032 - val_loss: 0.7003 - val_accuracy: 0.5052\n",
      "Epoch 4/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6989 - accuracy: 0.5039 - val_loss: 0.6976 - val_accuracy: 0.5052\n",
      "Epoch 5/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6970 - accuracy: 0.5067 - val_loss: 0.6966 - val_accuracy: 0.5045\n",
      "Epoch 6/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6960 - accuracy: 0.5068 - val_loss: 0.6962 - val_accuracy: 0.5050\n",
      "Epoch 7/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6951 - accuracy: 0.5076 - val_loss: 0.6952 - val_accuracy: 0.5043\n",
      "Epoch 8/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6944 - accuracy: 0.5093 - val_loss: 0.6958 - val_accuracy: 0.5066\n",
      "Epoch 9/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6940 - accuracy: 0.5100 - val_loss: 0.6948 - val_accuracy: 0.5045\n",
      "Epoch 10/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6936 - accuracy: 0.5118 - val_loss: 0.6943 - val_accuracy: 0.5081\n",
      "Epoch 11/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6933 - accuracy: 0.5119 - val_loss: 0.6944 - val_accuracy: 0.5107\n",
      "Epoch 12/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6930 - accuracy: 0.5133 - val_loss: 0.6942 - val_accuracy: 0.5048\n",
      "Epoch 13/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6929 - accuracy: 0.5135 - val_loss: 0.6942 - val_accuracy: 0.5117\n",
      "Epoch 14/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.5144 - val_loss: 0.6941 - val_accuracy: 0.5060\n",
      "Epoch 15/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5150 - val_loss: 0.6936 - val_accuracy: 0.5048\n",
      "Epoch 16/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5160 - val_loss: 0.6939 - val_accuracy: 0.5102\n",
      "Epoch 17/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5151 - val_loss: 0.6934 - val_accuracy: 0.5089\n",
      "Epoch 18/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6923 - accuracy: 0.5152 - val_loss: 0.6938 - val_accuracy: 0.5078\n",
      "Epoch 19/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6920 - accuracy: 0.5161 - val_loss: 0.6933 - val_accuracy: 0.5071\n",
      "Epoch 20/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6933 - val_accuracy: 0.5122\n",
      "Epoch 21/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6916 - accuracy: 0.5193 - val_loss: 0.6927 - val_accuracy: 0.5172\n",
      "Epoch 22/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6914 - accuracy: 0.5217 - val_loss: 0.6928 - val_accuracy: 0.5164\n",
      "Epoch 23/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6910 - accuracy: 0.5233 - val_loss: 0.6929 - val_accuracy: 0.5152\n",
      "Epoch 24/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6903 - accuracy: 0.5275 - val_loss: 0.6938 - val_accuracy: 0.5194\n",
      "Epoch 25/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6896 - accuracy: 0.5298 - val_loss: 0.6916 - val_accuracy: 0.5236\n",
      "Epoch 26/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6887 - accuracy: 0.5345 - val_loss: 0.6885 - val_accuracy: 0.5299\n",
      "Epoch 27/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6866 - accuracy: 0.5407 - val_loss: 0.6896 - val_accuracy: 0.5275\n",
      "Epoch 28/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6849 - accuracy: 0.5459 - val_loss: 0.6838 - val_accuracy: 0.5476\n",
      "Epoch 29/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6814 - accuracy: 0.5536 - val_loss: 0.6815 - val_accuracy: 0.5519\n",
      "Epoch 30/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6782 - accuracy: 0.5611 - val_loss: 0.6849 - val_accuracy: 0.5500\n",
      "Epoch 31/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6763 - accuracy: 0.5651 - val_loss: 0.6766 - val_accuracy: 0.5663\n",
      "Epoch 32/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6729 - accuracy: 0.5720 - val_loss: 0.6812 - val_accuracy: 0.5574\n",
      "Epoch 33/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6715 - accuracy: 0.5737 - val_loss: 0.6806 - val_accuracy: 0.5568\n",
      "Epoch 34/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6689 - accuracy: 0.5775 - val_loss: 0.6829 - val_accuracy: 0.5552\n",
      "Epoch 35/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6672 - accuracy: 0.5805 - val_loss: 0.6674 - val_accuracy: 0.5768\n",
      "Epoch 36/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6653 - accuracy: 0.5827 - val_loss: 0.6667 - val_accuracy: 0.5819\n",
      "Epoch 37/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6632 - accuracy: 0.5871 - val_loss: 0.6611 - val_accuracy: 0.5948\n",
      "Epoch 38/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6757 - accuracy: 0.5592 - val_loss: 0.6974 - val_accuracy: 0.5140\n",
      "Epoch 39/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6932 - accuracy: 0.5118 - val_loss: 0.6924 - val_accuracy: 0.5146\n",
      "Epoch 40/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6881 - accuracy: 0.5339 - val_loss: 0.7008 - val_accuracy: 0.5048\n",
      "Epoch 41/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6732 - accuracy: 0.5700 - val_loss: 0.6768 - val_accuracy: 0.5691\n",
      "Epoch 42/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6661 - accuracy: 0.5838 - val_loss: 0.6601 - val_accuracy: 0.5978\n",
      "Epoch 43/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6622 - accuracy: 0.5893 - val_loss: 0.6598 - val_accuracy: 0.5933\n",
      "Epoch 44/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6620 - accuracy: 0.5904 - val_loss: 0.6587 - val_accuracy: 0.5986\n",
      "Epoch 45/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6594 - accuracy: 0.5935 - val_loss: 0.6778 - val_accuracy: 0.5740\n",
      "Epoch 46/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6574 - accuracy: 0.5968 - val_loss: 0.6627 - val_accuracy: 0.5848\n",
      "Epoch 47/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6570 - accuracy: 0.5963 - val_loss: 0.6511 - val_accuracy: 0.6047\n",
      "Epoch 48/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6568 - accuracy: 0.5968 - val_loss: 0.6892 - val_accuracy: 0.5563\n",
      "Epoch 49/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6576 - accuracy: 0.5955 - val_loss: 0.6932 - val_accuracy: 0.5667\n",
      "Epoch 50/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6759 - accuracy: 0.5612 - val_loss: 0.6868 - val_accuracy: 0.5422\n",
      "Epoch 51/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6753 - accuracy: 0.5638 - val_loss: 0.6682 - val_accuracy: 0.5761\n",
      "Epoch 52/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6635 - accuracy: 0.5822 - val_loss: 0.6728 - val_accuracy: 0.5698\n",
      "Epoch 53/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6594 - accuracy: 0.5906 - val_loss: 0.6549 - val_accuracy: 0.5960\n",
      "Epoch 54/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6757 - accuracy: 0.5598 - val_loss: 0.6918 - val_accuracy: 0.5173\n",
      "Epoch 55/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6766 - accuracy: 0.5576 - val_loss: 0.6654 - val_accuracy: 0.5850\n",
      "Epoch 56/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6610 - accuracy: 0.5897 - val_loss: 0.6563 - val_accuracy: 0.5919\n",
      "Epoch 57/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6834 - accuracy: 0.5500 - val_loss: 0.6982 - val_accuracy: 0.5035\n",
      "Epoch 58/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6951 - accuracy: 0.5038 - val_loss: 0.6938 - val_accuracy: 0.5059\n",
      "Epoch 59/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6936 - accuracy: 0.5052 - val_loss: 0.6932 - val_accuracy: 0.5077\n",
      "Epoch 60/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6931 - accuracy: 0.5079 - val_loss: 0.6931 - val_accuracy: 0.5079\n",
      "Epoch 61/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6929 - accuracy: 0.5093 - val_loss: 0.6930 - val_accuracy: 0.5055\n",
      "Epoch 62/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6926 - accuracy: 0.5115 - val_loss: 0.6930 - val_accuracy: 0.5089\n",
      "Epoch 63/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5147 - val_loss: 0.6928 - val_accuracy: 0.5128\n",
      "Epoch 64/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6914 - accuracy: 0.5225 - val_loss: 0.6905 - val_accuracy: 0.5277\n",
      "Epoch 65/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6826 - accuracy: 0.5492 - val_loss: 0.7367 - val_accuracy: 0.4971\n",
      "Epoch 66/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6724 - accuracy: 0.5717 - val_loss: 0.6797 - val_accuracy: 0.5573\n",
      "Epoch 67/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6749 - accuracy: 0.5685 - val_loss: 0.6838 - val_accuracy: 0.5339\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_4\n",
      "cannot prune layer q_activation_4\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_5\n",
      "cannot prune layer q_activation_5\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 0.6562 - accuracy: 0.5982 - val_loss: 0.6585 - val_accuracy: 0.5927\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6550 - accuracy: 0.5996 - val_loss: 0.6496 - val_accuracy: 0.6108\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6537 - accuracy: 0.6018 - val_loss: 0.6556 - val_accuracy: 0.6025\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6527 - accuracy: 0.6032 - val_loss: 0.6482 - val_accuracy: 0.6085\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6545 - accuracy: 0.6002 - val_loss: 0.6508 - val_accuracy: 0.6086\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6598 - accuracy: 0.5944 - val_loss: 0.6518 - val_accuracy: 0.6074\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6626 - accuracy: 0.5875 - val_loss: 0.6753 - val_accuracy: 0.5614\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6563 - accuracy: 0.5949 - val_loss: 0.6539 - val_accuracy: 0.6026\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6645 - accuracy: 0.5859 - val_loss: 0.7037 - val_accuracy: 0.5152\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5535 - val_loss: 0.6709 - val_accuracy: 0.5800\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6780 - accuracy: 0.5575 - val_loss: 0.6830 - val_accuracy: 0.5447\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6670 - accuracy: 0.5812 - val_loss: 0.6607 - val_accuracy: 0.5954\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6571 - accuracy: 0.5972 - val_loss: 0.6619 - val_accuracy: 0.5913\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6518 - accuracy: 0.6051 - val_loss: 0.6710 - val_accuracy: 0.5851\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6499 - accuracy: 0.6076 - val_loss: 0.6469 - val_accuracy: 0.6113\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6494 - accuracy: 0.6075 - val_loss: 0.6671 - val_accuracy: 0.5725\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6487 - accuracy: 0.6083 - val_loss: 0.6489 - val_accuracy: 0.6055\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6481 - accuracy: 0.6100 - val_loss: 0.6438 - val_accuracy: 0.6119\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6472 - accuracy: 0.6104 - val_loss: 0.6616 - val_accuracy: 0.5934\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6457 - accuracy: 0.6121 - val_loss: 0.6426 - val_accuracy: 0.6186\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6450 - accuracy: 0.6129 - val_loss: 0.6466 - val_accuracy: 0.6158\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6445 - accuracy: 0.6131 - val_loss: 0.6384 - val_accuracy: 0.6225\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6443 - accuracy: 0.6151 - val_loss: 0.6563 - val_accuracy: 0.5940\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6448 - accuracy: 0.6132 - val_loss: 0.6429 - val_accuracy: 0.6140\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6439 - accuracy: 0.6134 - val_loss: 0.6406 - val_accuracy: 0.6142\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6422 - accuracy: 0.6159 - val_loss: 0.6611 - val_accuracy: 0.5904\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6454 - accuracy: 0.6122 - val_loss: 0.6583 - val_accuracy: 0.5899\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6640 - accuracy: 0.5779 - val_loss: 0.6973 - val_accuracy: 0.5076\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6819 - accuracy: 0.5446 - val_loss: 0.6808 - val_accuracy: 0.5521\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6532 - accuracy: 0.6043 - val_loss: 0.6582 - val_accuracy: 0.6057\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6491 - accuracy: 0.6087 - val_loss: 0.6371 - val_accuracy: 0.6284\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6424 - accuracy: 0.6170 - val_loss: 0.6520 - val_accuracy: 0.6003\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6444 - accuracy: 0.6147 - val_loss: 0.7349 - val_accuracy: 0.5143\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6497 - accuracy: 0.6069 - val_loss: 0.6452 - val_accuracy: 0.6077\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6441 - accuracy: 0.6134 - val_loss: 0.6471 - val_accuracy: 0.6047\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6950 - accuracy: 0.5260 - val_loss: 0.6975 - val_accuracy: 0.5053\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6950 - accuracy: 0.5095 - val_loss: 0.6938 - val_accuracy: 0.5122\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6929 - accuracy: 0.5134 - val_loss: 0.6926 - val_accuracy: 0.5141\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6921 - accuracy: 0.5160 - val_loss: 0.6918 - val_accuracy: 0.5198\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6914 - accuracy: 0.5193 - val_loss: 0.6910 - val_accuracy: 0.5257\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6904 - accuracy: 0.5252 - val_loss: 0.6898 - val_accuracy: 0.5307\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6888 - accuracy: 0.5329 - val_loss: 0.6882 - val_accuracy: 0.5355\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6825 - accuracy: 0.5516 - val_loss: 0.6756 - val_accuracy: 0.5732\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6697 - accuracy: 0.5739 - val_loss: 0.6674 - val_accuracy: 0.5796\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6613 - accuracy: 0.5864 - val_loss: 0.6552 - val_accuracy: 0.5937\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6572 - accuracy: 0.5928 - val_loss: 0.6592 - val_accuracy: 0.5862\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6518 - accuracy: 0.6004 - val_loss: 0.6418 - val_accuracy: 0.6193\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6469 - accuracy: 0.6075 - val_loss: 0.6547 - val_accuracy: 0.6007\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6479 - accuracy: 0.6079 - val_loss: 0.6567 - val_accuracy: 0.5982\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6652 - accuracy: 0.5848 - val_loss: 0.6452 - val_accuracy: 0.6134\n",
      "1714/1714 [==============================] - 3s 1ms/step\n",
      "[[0.54780424]\n",
      " [0.33243984]\n",
      " [0.5780505 ]\n",
      " [0.45871645]\n",
      " [0.5290667 ]\n",
      " [0.48191267]\n",
      " [0.58797646]\n",
      " [0.22693619]\n",
      " [0.63463795]\n",
      " [0.35054937]]\n",
      "########### FOUND NEW BEST METRIC 0.3466661813946717 ##############\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.001, 'BATCH_SIZE': 1024, 'EPOCHS': 100, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.0, 'POST_PRUNE_EPOCHS': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sdf/home/a/alexyue/miniconda3/envs/SmartPixel/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 24)                96        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " q_activation_6 (QActivatio  (None, 24)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 12)                48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " q_activation_7 (QActivatio  (None, 12)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_6 is normal keras bn layer\n",
      "q_activation_6       quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_7 is normal keras bn layer\n",
      "q_activation_7       quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/100\n",
      "429/429 [==============================] - 5s 7ms/step - loss: 3.0707 - accuracy: 0.5032 - val_loss: 1.8643 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "429/429 [==============================] - 3s 6ms/step - loss: 1.3399 - accuracy: 0.4998 - val_loss: 1.1815 - val_accuracy: 0.4974\n",
      "Epoch 3/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.8584 - accuracy: 0.4990 - val_loss: 0.7986 - val_accuracy: 0.4984\n",
      "Epoch 4/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7749 - accuracy: 0.5000 - val_loss: 0.7576 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7470 - accuracy: 0.5009 - val_loss: 0.7360 - val_accuracy: 0.5022\n",
      "Epoch 6/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7302 - accuracy: 0.5008 - val_loss: 0.7250 - val_accuracy: 0.5035\n",
      "Epoch 7/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7180 - accuracy: 0.5019 - val_loss: 0.7120 - val_accuracy: 0.5023\n",
      "Epoch 8/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7220 - accuracy: 0.5006 - val_loss: 0.7092 - val_accuracy: 0.5019\n",
      "Epoch 9/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7080 - accuracy: 0.5009 - val_loss: 0.7047 - val_accuracy: 0.5032\n",
      "Epoch 10/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7042 - accuracy: 0.5022 - val_loss: 0.7023 - val_accuracy: 0.5009\n",
      "Epoch 11/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7018 - accuracy: 0.5028 - val_loss: 0.7021 - val_accuracy: 0.5030\n",
      "Epoch 12/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7004 - accuracy: 0.5032 - val_loss: 0.6997 - val_accuracy: 0.5025\n",
      "Epoch 13/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6992 - accuracy: 0.5042 - val_loss: 0.6986 - val_accuracy: 0.5019\n",
      "Epoch 14/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6979 - accuracy: 0.5059 - val_loss: 0.6977 - val_accuracy: 0.5025\n",
      "Epoch 15/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6971 - accuracy: 0.5057 - val_loss: 0.6971 - val_accuracy: 0.5028\n",
      "Epoch 16/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6964 - accuracy: 0.5056 - val_loss: 0.6965 - val_accuracy: 0.5043\n",
      "Epoch 17/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6957 - accuracy: 0.5067 - val_loss: 0.6962 - val_accuracy: 0.5024\n",
      "Epoch 18/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6952 - accuracy: 0.5071 - val_loss: 0.6959 - val_accuracy: 0.4996\n",
      "Epoch 19/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6947 - accuracy: 0.5086 - val_loss: 0.6954 - val_accuracy: 0.5041\n",
      "Epoch 20/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6943 - accuracy: 0.5088 - val_loss: 0.6951 - val_accuracy: 0.5038\n",
      "Epoch 21/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6951 - accuracy: 0.5076 - val_loss: 0.7014 - val_accuracy: 0.5028\n",
      "Epoch 22/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6947 - accuracy: 0.5074 - val_loss: 0.6946 - val_accuracy: 0.5034\n",
      "Epoch 23/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6937 - accuracy: 0.5085 - val_loss: 0.6944 - val_accuracy: 0.5056\n",
      "Epoch 24/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6934 - accuracy: 0.5101 - val_loss: 0.6939 - val_accuracy: 0.5069\n",
      "Epoch 25/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6930 - accuracy: 0.5102 - val_loss: 0.6938 - val_accuracy: 0.5058\n",
      "Epoch 26/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5110 - val_loss: 0.6940 - val_accuracy: 0.5099\n",
      "Epoch 27/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6927 - accuracy: 0.5111 - val_loss: 0.6938 - val_accuracy: 0.5074\n",
      "Epoch 28/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6925 - accuracy: 0.5119 - val_loss: 0.6932 - val_accuracy: 0.5141\n",
      "Epoch 29/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5131 - val_loss: 0.6932 - val_accuracy: 0.5107\n",
      "Epoch 30/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6921 - accuracy: 0.5136 - val_loss: 0.6935 - val_accuracy: 0.5117\n",
      "Epoch 31/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6920 - accuracy: 0.5145 - val_loss: 0.6930 - val_accuracy: 0.5134\n",
      "Epoch 32/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.5158 - val_loss: 0.6931 - val_accuracy: 0.5119\n",
      "Epoch 33/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6916 - accuracy: 0.5165 - val_loss: 0.6931 - val_accuracy: 0.5113\n",
      "Epoch 34/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6914 - accuracy: 0.5179 - val_loss: 0.6928 - val_accuracy: 0.5094\n",
      "Epoch 35/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6913 - accuracy: 0.5192 - val_loss: 0.6922 - val_accuracy: 0.5190\n",
      "Epoch 36/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6910 - accuracy: 0.5207 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
      "Epoch 37/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6907 - accuracy: 0.5219 - val_loss: 0.6915 - val_accuracy: 0.5213\n",
      "Epoch 38/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6904 - accuracy: 0.5238 - val_loss: 0.6912 - val_accuracy: 0.5192\n",
      "Epoch 39/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6898 - accuracy: 0.5266 - val_loss: 0.6904 - val_accuracy: 0.5269\n",
      "Epoch 40/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6889 - accuracy: 0.5303 - val_loss: 0.6904 - val_accuracy: 0.5268\n",
      "Epoch 41/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6879 - accuracy: 0.5345 - val_loss: 0.6922 - val_accuracy: 0.5234\n",
      "Epoch 42/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6866 - accuracy: 0.5377 - val_loss: 0.6880 - val_accuracy: 0.5340\n",
      "Epoch 43/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6857 - accuracy: 0.5407 - val_loss: 0.6871 - val_accuracy: 0.5337\n",
      "Epoch 44/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6843 - accuracy: 0.5435 - val_loss: 0.6856 - val_accuracy: 0.5394\n",
      "Epoch 45/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6831 - accuracy: 0.5467 - val_loss: 0.6843 - val_accuracy: 0.5511\n",
      "Epoch 46/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6818 - accuracy: 0.5510 - val_loss: 0.6819 - val_accuracy: 0.5539\n",
      "Epoch 47/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6818 - accuracy: 0.5500 - val_loss: 0.6848 - val_accuracy: 0.5451\n",
      "Epoch 48/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6795 - accuracy: 0.5564 - val_loss: 0.6819 - val_accuracy: 0.5485\n",
      "Epoch 49/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6790 - accuracy: 0.5570 - val_loss: 0.6825 - val_accuracy: 0.5518\n",
      "Epoch 50/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6778 - accuracy: 0.5612 - val_loss: 0.6988 - val_accuracy: 0.5253\n",
      "Epoch 51/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6768 - accuracy: 0.5637 - val_loss: 0.6790 - val_accuracy: 0.5610\n",
      "Epoch 52/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6767 - accuracy: 0.5642 - val_loss: 0.6785 - val_accuracy: 0.5623\n",
      "Epoch 53/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6742 - accuracy: 0.5695 - val_loss: 0.6829 - val_accuracy: 0.5490\n",
      "Epoch 54/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6829 - accuracy: 0.5523 - val_loss: 0.7011 - val_accuracy: 0.5184\n",
      "Epoch 55/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6831 - accuracy: 0.5499 - val_loss: 0.6821 - val_accuracy: 0.5558\n",
      "Epoch 56/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6726 - accuracy: 0.5728 - val_loss: 0.6743 - val_accuracy: 0.5654\n",
      "Epoch 57/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6709 - accuracy: 0.5767 - val_loss: 0.6732 - val_accuracy: 0.5718\n",
      "Epoch 58/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6697 - accuracy: 0.5776 - val_loss: 0.6689 - val_accuracy: 0.5796\n",
      "Epoch 59/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6764 - accuracy: 0.5654 - val_loss: 0.6796 - val_accuracy: 0.5544\n",
      "Epoch 60/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6723 - accuracy: 0.5714 - val_loss: 0.6836 - val_accuracy: 0.5527\n",
      "Epoch 61/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6667 - accuracy: 0.5815 - val_loss: 0.6641 - val_accuracy: 0.5877\n",
      "Epoch 62/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6724 - accuracy: 0.5737 - val_loss: 0.6746 - val_accuracy: 0.5719\n",
      "Epoch 63/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6657 - accuracy: 0.5839 - val_loss: 0.6649 - val_accuracy: 0.5855\n",
      "Epoch 64/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6621 - accuracy: 0.5892 - val_loss: 0.6609 - val_accuracy: 0.5904\n",
      "Epoch 65/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6606 - accuracy: 0.5903 - val_loss: 0.6600 - val_accuracy: 0.5909\n",
      "Epoch 66/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6602 - accuracy: 0.5907 - val_loss: 0.6656 - val_accuracy: 0.5731\n",
      "Epoch 67/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6613 - accuracy: 0.5900 - val_loss: 0.6690 - val_accuracy: 0.5812\n",
      "Epoch 68/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6572 - accuracy: 0.5949 - val_loss: 0.6631 - val_accuracy: 0.5794\n",
      "Epoch 69/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6565 - accuracy: 0.5950 - val_loss: 0.6581 - val_accuracy: 0.5919\n",
      "Epoch 70/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6548 - accuracy: 0.5986 - val_loss: 0.6509 - val_accuracy: 0.6055\n",
      "Epoch 71/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6542 - accuracy: 0.5990 - val_loss: 0.6538 - val_accuracy: 0.5926\n",
      "Epoch 72/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6524 - accuracy: 0.6021 - val_loss: 0.6643 - val_accuracy: 0.5884\n",
      "Epoch 73/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6537 - accuracy: 0.6000 - val_loss: 0.6534 - val_accuracy: 0.5930\n",
      "Epoch 74/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6524 - accuracy: 0.6015 - val_loss: 0.6551 - val_accuracy: 0.5973\n",
      "Epoch 75/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6507 - accuracy: 0.6039 - val_loss: 0.6548 - val_accuracy: 0.6036\n",
      "Epoch 76/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6495 - accuracy: 0.6066 - val_loss: 0.6466 - val_accuracy: 0.6122\n",
      "Epoch 77/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6502 - accuracy: 0.6060 - val_loss: 0.6478 - val_accuracy: 0.6107\n",
      "Epoch 78/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6485 - accuracy: 0.6080 - val_loss: 0.6530 - val_accuracy: 0.6081\n",
      "Epoch 79/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6636 - accuracy: 0.5896 - val_loss: 0.6560 - val_accuracy: 0.5984\n",
      "Epoch 80/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6480 - accuracy: 0.6074 - val_loss: 0.6533 - val_accuracy: 0.6043\n",
      "Epoch 81/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6477 - accuracy: 0.6083 - val_loss: 0.6441 - val_accuracy: 0.6132\n",
      "Epoch 82/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6539 - accuracy: 0.6009 - val_loss: 0.6527 - val_accuracy: 0.6004\n",
      "Epoch 83/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6475 - accuracy: 0.6082 - val_loss: 0.6428 - val_accuracy: 0.6143\n",
      "Epoch 84/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6453 - accuracy: 0.6120 - val_loss: 0.6531 - val_accuracy: 0.5927\n",
      "Epoch 85/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6456 - accuracy: 0.6114 - val_loss: 0.6633 - val_accuracy: 0.6000\n",
      "Epoch 86/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6444 - accuracy: 0.6129 - val_loss: 0.6376 - val_accuracy: 0.6201\n",
      "Epoch 87/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6438 - accuracy: 0.6129 - val_loss: 0.6417 - val_accuracy: 0.6157\n",
      "Epoch 88/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6432 - accuracy: 0.6146 - val_loss: 0.6572 - val_accuracy: 0.6053\n",
      "Epoch 89/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6414 - accuracy: 0.6170 - val_loss: 0.6565 - val_accuracy: 0.6125\n",
      "Epoch 90/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6430 - accuracy: 0.6157 - val_loss: 0.6497 - val_accuracy: 0.6077\n",
      "Epoch 91/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6403 - accuracy: 0.6189 - val_loss: 0.6364 - val_accuracy: 0.6201\n",
      "Epoch 92/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6428 - accuracy: 0.6142 - val_loss: 0.6352 - val_accuracy: 0.6233\n",
      "Epoch 93/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6389 - accuracy: 0.6196 - val_loss: 0.6751 - val_accuracy: 0.5887\n",
      "Epoch 94/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6378 - accuracy: 0.6197 - val_loss: 0.6356 - val_accuracy: 0.6244\n",
      "Epoch 95/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6378 - accuracy: 0.6209 - val_loss: 0.6322 - val_accuracy: 0.6311\n",
      "Epoch 96/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6407 - accuracy: 0.6190 - val_loss: 0.8515 - val_accuracy: 0.5006\n",
      "Epoch 97/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6519 - accuracy: 0.6020 - val_loss: 0.6371 - val_accuracy: 0.6248\n",
      "Epoch 98/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6373 - accuracy: 0.6209 - val_loss: 0.6303 - val_accuracy: 0.6332\n",
      "Epoch 99/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6358 - accuracy: 0.6227 - val_loss: 0.6362 - val_accuracy: 0.6219\n",
      "Epoch 100/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6656 - accuracy: 0.5870 - val_loss: 0.6430 - val_accuracy: 0.6168\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_6\n",
      "cannot prune layer q_activation_6\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_7\n",
      "cannot prune layer q_activation_7\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 6s 7ms/step - loss: 0.6407 - accuracy: 0.6169 - val_loss: 0.6507 - val_accuracy: 0.6006\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6380 - accuracy: 0.6202 - val_loss: 0.6327 - val_accuracy: 0.6252\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6320 - accuracy: 0.6266 - val_loss: 0.6322 - val_accuracy: 0.6276\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6323 - accuracy: 0.6263 - val_loss: 0.6265 - val_accuracy: 0.6329\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6316 - accuracy: 0.6269 - val_loss: 0.6522 - val_accuracy: 0.6103\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6446 - accuracy: 0.6140 - val_loss: 0.7225 - val_accuracy: 0.5209\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6715 - accuracy: 0.5709 - val_loss: 0.6587 - val_accuracy: 0.5992\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6397 - accuracy: 0.6180 - val_loss: 0.6315 - val_accuracy: 0.6274\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6323 - accuracy: 0.6264 - val_loss: 0.6252 - val_accuracy: 0.6389\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6312 - accuracy: 0.6274 - val_loss: 0.6241 - val_accuracy: 0.6388\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6310 - accuracy: 0.6275 - val_loss: 0.6340 - val_accuracy: 0.6290\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6301 - accuracy: 0.6295 - val_loss: 0.6239 - val_accuracy: 0.6389\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6297 - accuracy: 0.6289 - val_loss: 0.6244 - val_accuracy: 0.6363\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6600 - accuracy: 0.5903 - val_loss: 0.6543 - val_accuracy: 0.5994\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6420 - accuracy: 0.6144 - val_loss: 0.6342 - val_accuracy: 0.6264\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6374 - accuracy: 0.6201 - val_loss: 0.6402 - val_accuracy: 0.6178\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6337 - accuracy: 0.6249 - val_loss: 0.6298 - val_accuracy: 0.6293\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6402 - accuracy: 0.6179 - val_loss: 0.6305 - val_accuracy: 0.6301\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6309 - accuracy: 0.6283 - val_loss: 0.6417 - val_accuracy: 0.6198\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6290 - accuracy: 0.6299 - val_loss: 0.6242 - val_accuracy: 0.6382\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6280 - accuracy: 0.6308 - val_loss: 0.6213 - val_accuracy: 0.6421\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6635 - accuracy: 0.5805 - val_loss: 0.7056 - val_accuracy: 0.5022\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6979 - accuracy: 0.5033 - val_loss: 0.6960 - val_accuracy: 0.5022\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6953 - accuracy: 0.5049 - val_loss: 0.6948 - val_accuracy: 0.5060\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6944 - accuracy: 0.5062 - val_loss: 0.6942 - val_accuracy: 0.5061\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6938 - accuracy: 0.5085 - val_loss: 0.6938 - val_accuracy: 0.5073\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6934 - accuracy: 0.5100 - val_loss: 0.6934 - val_accuracy: 0.5098\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6931 - accuracy: 0.5124 - val_loss: 0.6933 - val_accuracy: 0.5133\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6929 - accuracy: 0.5128 - val_loss: 0.6933 - val_accuracy: 0.5124\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6925 - accuracy: 0.5154 - val_loss: 0.6929 - val_accuracy: 0.5114\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6921 - accuracy: 0.5176 - val_loss: 0.6925 - val_accuracy: 0.5171\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6919 - val_accuracy: 0.5216\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6907 - accuracy: 0.5247 - val_loss: 0.6905 - val_accuracy: 0.5228\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6886 - accuracy: 0.5326 - val_loss: 0.6894 - val_accuracy: 0.5279\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6833 - accuracy: 0.5498 - val_loss: 0.6841 - val_accuracy: 0.5512\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6699 - accuracy: 0.5784 - val_loss: 0.6669 - val_accuracy: 0.5847\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6549 - accuracy: 0.5995 - val_loss: 0.6485 - val_accuracy: 0.6075\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6478 - accuracy: 0.6085 - val_loss: 0.6722 - val_accuracy: 0.5945\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6451 - accuracy: 0.6126 - val_loss: 0.6334 - val_accuracy: 0.6287\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6406 - accuracy: 0.6188 - val_loss: 0.6500 - val_accuracy: 0.6121\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6390 - accuracy: 0.6194 - val_loss: 0.6545 - val_accuracy: 0.6180\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6345 - accuracy: 0.6244 - val_loss: 0.6306 - val_accuracy: 0.6306\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6314 - accuracy: 0.6281 - val_loss: 0.6517 - val_accuracy: 0.6242\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6351 - accuracy: 0.6243 - val_loss: 0.6280 - val_accuracy: 0.6311\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6314 - accuracy: 0.6270 - val_loss: 0.6219 - val_accuracy: 0.6414\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6365 - accuracy: 0.6216 - val_loss: 0.6321 - val_accuracy: 0.6288\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6301 - accuracy: 0.6285 - val_loss: 0.6376 - val_accuracy: 0.6195\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6290 - accuracy: 0.6301 - val_loss: 0.6199 - val_accuracy: 0.6428\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6298 - accuracy: 0.6286 - val_loss: 0.6324 - val_accuracy: 0.6278\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6356 - accuracy: 0.6236 - val_loss: 0.6366 - val_accuracy: 0.6221\n",
      "1714/1714 [==============================] - 4s 2ms/step\n",
      "[[0.3988336 ]\n",
      " [0.6234314 ]\n",
      " [0.6092339 ]\n",
      " [0.36644515]\n",
      " [0.6229558 ]\n",
      " [0.5189848 ]\n",
      " [0.57746744]\n",
      " [0.4263329 ]\n",
      " [0.56217635]\n",
      " [0.58859956]]\n",
      "########### FOUND NEW BEST METRIC 0.36180666763721064 ##############\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.001, 'BATCH_SIZE': 1024, 'EPOCHS': 150, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.0, 'POST_PRUNE_EPOCHS': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sdf/home/a/alexyue/miniconda3/envs/SmartPixel/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 24)                96        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " q_activation_8 (QActivatio  (None, 24)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 12)                48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " q_activation_9 (QActivatio  (None, 12)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_8 is normal keras bn layer\n",
      "q_activation_8       quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_9 is normal keras bn layer\n",
      "q_activation_9       quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/150\n",
      "429/429 [==============================] - 6s 7ms/step - loss: 1.9973 - accuracy: 0.5016 - val_loss: 0.8726 - val_accuracy: 0.4993\n",
      "Epoch 2/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.8022 - accuracy: 0.4999 - val_loss: 0.7714 - val_accuracy: 0.4992\n",
      "Epoch 3/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7358 - accuracy: 0.5007 - val_loss: 0.7211 - val_accuracy: 0.5019\n",
      "Epoch 4/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7192 - accuracy: 0.5005 - val_loss: 0.7139 - val_accuracy: 0.5006\n",
      "Epoch 5/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7140 - accuracy: 0.5007 - val_loss: 0.7081 - val_accuracy: 0.5007\n",
      "Epoch 6/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7087 - accuracy: 0.5008 - val_loss: 0.7048 - val_accuracy: 0.5009\n",
      "Epoch 7/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7153 - accuracy: 0.5018 - val_loss: 0.7072 - val_accuracy: 0.5058\n",
      "Epoch 8/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7224 - accuracy: 0.5010 - val_loss: 0.7189 - val_accuracy: 0.5045\n",
      "Epoch 9/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7239 - accuracy: 0.5001 - val_loss: 0.7219 - val_accuracy: 0.5044\n",
      "Epoch 10/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7188 - accuracy: 0.4991 - val_loss: 0.7079 - val_accuracy: 0.4989\n",
      "Epoch 11/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7131 - accuracy: 0.5018 - val_loss: 0.7027 - val_accuracy: 0.4977\n",
      "Epoch 12/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7086 - accuracy: 0.5004 - val_loss: 0.7530 - val_accuracy: 0.5031\n",
      "Epoch 13/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7029 - accuracy: 0.5025 - val_loss: 0.7764 - val_accuracy: 0.5042\n",
      "Epoch 14/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6969 - accuracy: 0.5050 - val_loss: 0.6946 - val_accuracy: 0.5061\n",
      "Epoch 15/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6946 - accuracy: 0.5065 - val_loss: 0.6943 - val_accuracy: 0.5069\n",
      "Epoch 16/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6941 - accuracy: 0.5075 - val_loss: 0.6939 - val_accuracy: 0.5089\n",
      "Epoch 17/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6938 - accuracy: 0.5091 - val_loss: 0.6939 - val_accuracy: 0.5057\n",
      "Epoch 18/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6935 - accuracy: 0.5090 - val_loss: 0.6935 - val_accuracy: 0.5085\n",
      "Epoch 19/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.5108 - val_loss: 0.6938 - val_accuracy: 0.5082\n",
      "Epoch 20/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6931 - accuracy: 0.5098 - val_loss: 0.6933 - val_accuracy: 0.5077\n",
      "Epoch 21/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6929 - accuracy: 0.5108 - val_loss: 0.6933 - val_accuracy: 0.5056\n",
      "Epoch 22/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5110 - val_loss: 0.6936 - val_accuracy: 0.5075\n",
      "Epoch 23/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6927 - accuracy: 0.5118 - val_loss: 0.6929 - val_accuracy: 0.5125\n",
      "Epoch 24/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6925 - accuracy: 0.5124 - val_loss: 0.6933 - val_accuracy: 0.5118\n",
      "Epoch 25/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6923 - accuracy: 0.5139 - val_loss: 0.6929 - val_accuracy: 0.5154\n",
      "Epoch 26/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5137 - val_loss: 0.6929 - val_accuracy: 0.5113\n",
      "Epoch 27/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6921 - accuracy: 0.5150 - val_loss: 0.6930 - val_accuracy: 0.5139\n",
      "Epoch 28/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6919 - accuracy: 0.5157 - val_loss: 0.6925 - val_accuracy: 0.5133\n",
      "Epoch 29/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.5162 - val_loss: 0.6931 - val_accuracy: 0.5121\n",
      "Epoch 30/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6917 - accuracy: 0.5172 - val_loss: 0.6926 - val_accuracy: 0.5130\n",
      "Epoch 31/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6913 - accuracy: 0.5191 - val_loss: 0.6927 - val_accuracy: 0.5106\n",
      "Epoch 32/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6911 - accuracy: 0.5199 - val_loss: 0.6917 - val_accuracy: 0.5211\n",
      "Epoch 33/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6909 - accuracy: 0.5218 - val_loss: 0.6917 - val_accuracy: 0.5181\n",
      "Epoch 34/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6906 - accuracy: 0.5234 - val_loss: 0.6913 - val_accuracy: 0.5236\n",
      "Epoch 35/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6901 - accuracy: 0.5258 - val_loss: 0.6907 - val_accuracy: 0.5241\n",
      "Epoch 36/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6896 - accuracy: 0.5287 - val_loss: 0.6906 - val_accuracy: 0.5280\n",
      "Epoch 37/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6892 - accuracy: 0.5298 - val_loss: 0.6897 - val_accuracy: 0.5315\n",
      "Epoch 38/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6882 - accuracy: 0.5335 - val_loss: 0.6889 - val_accuracy: 0.5275\n",
      "Epoch 39/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6872 - accuracy: 0.5376 - val_loss: 0.6869 - val_accuracy: 0.5387\n",
      "Epoch 40/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6867 - accuracy: 0.5386 - val_loss: 0.6869 - val_accuracy: 0.5393\n",
      "Epoch 41/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6849 - accuracy: 0.5441 - val_loss: 0.6855 - val_accuracy: 0.5397\n",
      "Epoch 42/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6824 - accuracy: 0.5511 - val_loss: 0.6823 - val_accuracy: 0.5537\n",
      "Epoch 43/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6807 - accuracy: 0.5554 - val_loss: 0.6804 - val_accuracy: 0.5506\n",
      "Epoch 44/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6786 - accuracy: 0.5611 - val_loss: 0.6779 - val_accuracy: 0.5610\n",
      "Epoch 45/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6765 - accuracy: 0.5660 - val_loss: 0.6781 - val_accuracy: 0.5501\n",
      "Epoch 46/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6743 - accuracy: 0.5704 - val_loss: 0.6747 - val_accuracy: 0.5680\n",
      "Epoch 47/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6749 - accuracy: 0.5707 - val_loss: 0.6795 - val_accuracy: 0.5748\n",
      "Epoch 48/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6706 - accuracy: 0.5797 - val_loss: 0.6704 - val_accuracy: 0.5768\n",
      "Epoch 49/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6716 - accuracy: 0.5776 - val_loss: 0.6715 - val_accuracy: 0.5799\n",
      "Epoch 50/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6667 - accuracy: 0.5866 - val_loss: 0.6653 - val_accuracy: 0.5915\n",
      "Epoch 51/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6637 - accuracy: 0.5925 - val_loss: 0.6623 - val_accuracy: 0.5960\n",
      "Epoch 52/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6620 - accuracy: 0.5935 - val_loss: 0.6695 - val_accuracy: 0.5684\n",
      "Epoch 53/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6605 - accuracy: 0.5970 - val_loss: 0.6698 - val_accuracy: 0.5724\n",
      "Epoch 54/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6830 - accuracy: 0.5548 - val_loss: 0.6849 - val_accuracy: 0.5415\n",
      "Epoch 55/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6681 - accuracy: 0.5851 - val_loss: 0.6639 - val_accuracy: 0.5948\n",
      "Epoch 56/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6583 - accuracy: 0.5998 - val_loss: 0.7534 - val_accuracy: 0.5158\n",
      "Epoch 57/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6701 - accuracy: 0.5777 - val_loss: 0.6699 - val_accuracy: 0.5788\n",
      "Epoch 58/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6551 - accuracy: 0.6031 - val_loss: 0.6532 - val_accuracy: 0.6061\n",
      "Epoch 59/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6525 - accuracy: 0.6068 - val_loss: 0.6504 - val_accuracy: 0.6130\n",
      "Epoch 60/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6527 - accuracy: 0.6068 - val_loss: 0.6533 - val_accuracy: 0.6050\n",
      "Epoch 61/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6532 - accuracy: 0.6078 - val_loss: 0.6535 - val_accuracy: 0.6085\n",
      "Epoch 62/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6540 - accuracy: 0.6063 - val_loss: 0.6491 - val_accuracy: 0.6116\n",
      "Epoch 63/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6534 - accuracy: 0.6057 - val_loss: 0.6530 - val_accuracy: 0.6064\n",
      "Epoch 64/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6509 - accuracy: 0.6110 - val_loss: 0.6553 - val_accuracy: 0.6046\n",
      "Epoch 65/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6498 - accuracy: 0.6127 - val_loss: 0.6510 - val_accuracy: 0.6141\n",
      "Epoch 66/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6494 - accuracy: 0.6131 - val_loss: 0.6470 - val_accuracy: 0.6183\n",
      "Epoch 67/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6499 - accuracy: 0.6122 - val_loss: 0.6470 - val_accuracy: 0.6160\n",
      "Epoch 68/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6530 - accuracy: 0.6071 - val_loss: 0.6483 - val_accuracy: 0.6138\n",
      "Epoch 69/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6658 - accuracy: 0.5842 - val_loss: 0.6820 - val_accuracy: 0.5674\n",
      "Epoch 70/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6492 - accuracy: 0.6124 - val_loss: 0.6520 - val_accuracy: 0.6108\n",
      "Epoch 71/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6491 - accuracy: 0.6116 - val_loss: 0.6551 - val_accuracy: 0.5978\n",
      "Epoch 72/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6456 - accuracy: 0.6164 - val_loss: 0.6477 - val_accuracy: 0.6139\n",
      "Epoch 73/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6470 - accuracy: 0.6141 - val_loss: 0.6529 - val_accuracy: 0.6097\n",
      "Epoch 74/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6555 - accuracy: 0.6042 - val_loss: 0.6492 - val_accuracy: 0.6145\n",
      "Epoch 75/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6723 - accuracy: 0.5778 - val_loss: 0.6623 - val_accuracy: 0.6023\n",
      "Epoch 76/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6501 - accuracy: 0.6124 - val_loss: 0.6428 - val_accuracy: 0.6218\n",
      "Epoch 77/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6451 - accuracy: 0.6186 - val_loss: 0.6581 - val_accuracy: 0.6052\n",
      "Epoch 78/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6679 - accuracy: 0.5872 - val_loss: 0.6632 - val_accuracy: 0.6031\n",
      "Epoch 79/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6624 - accuracy: 0.5921 - val_loss: 0.6756 - val_accuracy: 0.5643\n",
      "Epoch 80/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6491 - accuracy: 0.6117 - val_loss: 0.6390 - val_accuracy: 0.6326\n",
      "Epoch 81/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6461 - accuracy: 0.6166 - val_loss: 0.6607 - val_accuracy: 0.6060\n",
      "Epoch 82/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6417 - accuracy: 0.6208 - val_loss: 0.6395 - val_accuracy: 0.6275\n",
      "Epoch 83/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6607 - accuracy: 0.5924 - val_loss: 0.6970 - val_accuracy: 0.5227\n",
      "Epoch 84/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6837 - accuracy: 0.5456 - val_loss: 0.6775 - val_accuracy: 0.5614\n",
      "Epoch 85/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6538 - accuracy: 0.6058 - val_loss: 0.6475 - val_accuracy: 0.6139\n",
      "Epoch 86/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6448 - accuracy: 0.6170 - val_loss: 0.6363 - val_accuracy: 0.6307\n",
      "Epoch 87/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6431 - accuracy: 0.6190 - val_loss: 0.6344 - val_accuracy: 0.6302\n",
      "Epoch 88/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6375 - accuracy: 0.6257 - val_loss: 0.6411 - val_accuracy: 0.6156\n",
      "Epoch 89/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6450 - accuracy: 0.6152 - val_loss: 0.6410 - val_accuracy: 0.6206\n",
      "Epoch 90/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6371 - accuracy: 0.6253 - val_loss: 0.6335 - val_accuracy: 0.6314\n",
      "Epoch 91/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6743 - accuracy: 0.5712 - val_loss: 0.7060 - val_accuracy: 0.5462\n",
      "Epoch 92/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6503 - accuracy: 0.6093 - val_loss: 0.6365 - val_accuracy: 0.6267\n",
      "Epoch 93/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6685 - accuracy: 0.5833 - val_loss: 0.7010 - val_accuracy: 0.5237\n",
      "Epoch 94/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6827 - accuracy: 0.5526 - val_loss: 0.6739 - val_accuracy: 0.5637\n",
      "Epoch 95/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6537 - accuracy: 0.6037 - val_loss: 0.6534 - val_accuracy: 0.6097\n",
      "Epoch 96/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6411 - accuracy: 0.6211 - val_loss: 0.6440 - val_accuracy: 0.6167\n",
      "Epoch 97/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6356 - accuracy: 0.6270 - val_loss: 0.6554 - val_accuracy: 0.6090\n",
      "Epoch 98/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6719 - accuracy: 0.5649 - val_loss: 0.6909 - val_accuracy: 0.5310\n",
      "Epoch 99/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6838 - accuracy: 0.5489 - val_loss: 0.6775 - val_accuracy: 0.5682\n",
      "Epoch 100/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6664 - accuracy: 0.5857 - val_loss: 0.6550 - val_accuracy: 0.6017\n",
      "Epoch 101/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6540 - accuracy: 0.6041 - val_loss: 0.6445 - val_accuracy: 0.6170\n",
      "Epoch 102/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6434 - accuracy: 0.6173 - val_loss: 0.6435 - val_accuracy: 0.6143\n",
      "Epoch 103/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7111 - accuracy: 0.5036 - val_loss: 0.7048 - val_accuracy: 0.5090\n",
      "Epoch 104/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7018 - accuracy: 0.5044 - val_loss: 0.6983 - val_accuracy: 0.5028\n",
      "Epoch 105/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6998 - accuracy: 0.5073 - val_loss: 0.7013 - val_accuracy: 0.5130\n",
      "Epoch 106/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6981 - accuracy: 0.5102 - val_loss: 0.7021 - val_accuracy: 0.5157\n",
      "Epoch 107/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6974 - accuracy: 0.5107 - val_loss: 0.6950 - val_accuracy: 0.5140\n",
      "Epoch 108/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6967 - accuracy: 0.5116 - val_loss: 0.6935 - val_accuracy: 0.5154\n",
      "Epoch 109/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6955 - accuracy: 0.5150 - val_loss: 0.6934 - val_accuracy: 0.5151\n",
      "Epoch 110/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6943 - accuracy: 0.5181 - val_loss: 0.6971 - val_accuracy: 0.5259\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_8\n",
      "cannot prune layer q_activation_8\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_9\n",
      "cannot prune layer q_activation_9\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 0.6405 - accuracy: 0.6221 - val_loss: 0.6396 - val_accuracy: 0.6277\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6346 - accuracy: 0.6288 - val_loss: 0.6305 - val_accuracy: 0.6367\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6381 - accuracy: 0.6244 - val_loss: 0.6441 - val_accuracy: 0.6187\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6503 - accuracy: 0.6077 - val_loss: 0.6461 - val_accuracy: 0.6174\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6352 - accuracy: 0.6268 - val_loss: 0.6319 - val_accuracy: 0.6332\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6370 - accuracy: 0.6258 - val_loss: 0.6366 - val_accuracy: 0.6261\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6334 - accuracy: 0.6294 - val_loss: 0.6365 - val_accuracy: 0.6273\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6518 - accuracy: 0.6029 - val_loss: 0.6824 - val_accuracy: 0.5623\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6652 - accuracy: 0.5889 - val_loss: 0.6519 - val_accuracy: 0.6137\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6452 - accuracy: 0.6162 - val_loss: 0.6505 - val_accuracy: 0.6041\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6402 - accuracy: 0.6228 - val_loss: 0.6325 - val_accuracy: 0.6304\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6355 - accuracy: 0.6274 - val_loss: 0.6451 - val_accuracy: 0.6100\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6390 - accuracy: 0.6214 - val_loss: 0.6875 - val_accuracy: 0.5554\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6362 - accuracy: 0.6265 - val_loss: 0.6317 - val_accuracy: 0.6325\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6310 - accuracy: 0.6326 - val_loss: 0.6330 - val_accuracy: 0.6296\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6312 - accuracy: 0.6330 - val_loss: 0.6293 - val_accuracy: 0.6403\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6389 - accuracy: 0.6231 - val_loss: 0.6292 - val_accuracy: 0.6378\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6420 - accuracy: 0.6200 - val_loss: 0.6458 - val_accuracy: 0.6132\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6307 - accuracy: 0.6340 - val_loss: 0.6252 - val_accuracy: 0.6413\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6637 - accuracy: 0.5851 - val_loss: 0.6762 - val_accuracy: 0.5682\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6365 - accuracy: 0.6263 - val_loss: 0.6324 - val_accuracy: 0.6331\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6299 - accuracy: 0.6341 - val_loss: 0.6233 - val_accuracy: 0.6444\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6314 - accuracy: 0.6320 - val_loss: 0.6260 - val_accuracy: 0.6421\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6376 - accuracy: 0.6246 - val_loss: 0.6400 - val_accuracy: 0.6189\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6356 - accuracy: 0.6269 - val_loss: 0.6304 - val_accuracy: 0.6374\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6339 - accuracy: 0.6294 - val_loss: 0.6257 - val_accuracy: 0.6433\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6290 - accuracy: 0.6356 - val_loss: 0.6251 - val_accuracy: 0.6399\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6285 - accuracy: 0.6349 - val_loss: 0.6262 - val_accuracy: 0.6395\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6359 - accuracy: 0.6268 - val_loss: 0.6278 - val_accuracy: 0.6361\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6854 - accuracy: 0.5437 - val_loss: 0.6878 - val_accuracy: 0.5350\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6634 - accuracy: 0.5879 - val_loss: 0.6600 - val_accuracy: 0.5932\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6358 - accuracy: 0.6277 - val_loss: 0.6347 - val_accuracy: 0.6266\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6389 - accuracy: 0.6245 - val_loss: 0.6376 - val_accuracy: 0.6224\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6312 - accuracy: 0.6331 - val_loss: 0.6291 - val_accuracy: 0.6347\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6284 - accuracy: 0.6360 - val_loss: 0.6292 - val_accuracy: 0.6370\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6264 - accuracy: 0.6376 - val_loss: 0.6323 - val_accuracy: 0.6318\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6451 - accuracy: 0.6142 - val_loss: 0.6316 - val_accuracy: 0.6317\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6270 - accuracy: 0.6370 - val_loss: 0.6229 - val_accuracy: 0.6435\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6289 - accuracy: 0.6352 - val_loss: 0.6324 - val_accuracy: 0.6302\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6279 - accuracy: 0.6367 - val_loss: 0.6285 - val_accuracy: 0.6324\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6387 - accuracy: 0.6230 - val_loss: 0.6336 - val_accuracy: 0.6310\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6306 - accuracy: 0.6327 - val_loss: 0.6448 - val_accuracy: 0.6189\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6273 - accuracy: 0.6374 - val_loss: 0.6242 - val_accuracy: 0.6414\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6320 - accuracy: 0.6321 - val_loss: 0.6392 - val_accuracy: 0.6210\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6248 - accuracy: 0.6403 - val_loss: 0.6283 - val_accuracy: 0.6398\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6292 - accuracy: 0.6356 - val_loss: 0.6244 - val_accuracy: 0.6364\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6442 - accuracy: 0.6159 - val_loss: 0.6304 - val_accuracy: 0.6389\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6283 - accuracy: 0.6362 - val_loss: 0.6214 - val_accuracy: 0.6474\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6252 - accuracy: 0.6403 - val_loss: 0.6237 - val_accuracy: 0.6418\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6486 - accuracy: 0.6085 - val_loss: 0.6991 - val_accuracy: 0.5275\n",
      "1714/1714 [==============================] - 3s 1ms/step\n",
      "[[0.54579234]\n",
      " [0.4348504 ]\n",
      " [0.5169034 ]\n",
      " [0.5122197 ]\n",
      " [0.33744186]\n",
      " [0.43942976]\n",
      " [0.52986157]\n",
      " [0.24951267]\n",
      " [0.5816762 ]\n",
      " [0.62328565]]\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.0005, 'BATCH_SIZE': 1024, 'EPOCHS': 100, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.0, 'POST_PRUNE_EPOCHS': 50}\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 24)                96        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_10 (QActivati  (None, 24)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 12)                48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_11 (QActivati  (None, 12)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_10 is normal keras bn layer\n",
      "q_activation_10      quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_11 is normal keras bn layer\n",
      "q_activation_11      quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/100\n",
      "429/429 [==============================] - 6s 7ms/step - loss: 1.4552 - accuracy: 0.4988 - val_loss: 0.9414 - val_accuracy: 0.4993\n",
      "Epoch 2/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.8509 - accuracy: 0.4972 - val_loss: 0.8127 - val_accuracy: 0.5012\n",
      "Epoch 3/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7865 - accuracy: 0.4965 - val_loss: 0.7730 - val_accuracy: 0.5001\n",
      "Epoch 4/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7624 - accuracy: 0.4976 - val_loss: 0.7624 - val_accuracy: 0.5012\n",
      "Epoch 5/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7464 - accuracy: 0.4989 - val_loss: 0.7390 - val_accuracy: 0.5029\n",
      "Epoch 6/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7394 - accuracy: 0.4992 - val_loss: 0.7339 - val_accuracy: 0.5037\n",
      "Epoch 7/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7282 - accuracy: 0.4991 - val_loss: 0.7262 - val_accuracy: 0.5025\n",
      "Epoch 8/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7243 - accuracy: 0.4995 - val_loss: 0.7219 - val_accuracy: 0.5016\n",
      "Epoch 9/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7170 - accuracy: 0.5010 - val_loss: 0.7155 - val_accuracy: 0.5034\n",
      "Epoch 10/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7136 - accuracy: 0.4998 - val_loss: 0.7105 - val_accuracy: 0.5039\n",
      "Epoch 11/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7092 - accuracy: 0.5011 - val_loss: 0.7073 - val_accuracy: 0.5043\n",
      "Epoch 12/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7064 - accuracy: 0.5025 - val_loss: 0.7070 - val_accuracy: 0.5059\n",
      "Epoch 13/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7043 - accuracy: 0.5037 - val_loss: 0.7028 - val_accuracy: 0.5067\n",
      "Epoch 14/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7018 - accuracy: 0.5041 - val_loss: 0.7025 - val_accuracy: 0.5059\n",
      "Epoch 15/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7002 - accuracy: 0.5042 - val_loss: 0.7010 - val_accuracy: 0.5054\n",
      "Epoch 16/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6990 - accuracy: 0.5045 - val_loss: 0.6989 - val_accuracy: 0.5081\n",
      "Epoch 17/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6981 - accuracy: 0.5060 - val_loss: 0.6981 - val_accuracy: 0.5069\n",
      "Epoch 18/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6973 - accuracy: 0.5065 - val_loss: 0.6992 - val_accuracy: 0.5045\n",
      "Epoch 19/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6966 - accuracy: 0.5076 - val_loss: 0.6966 - val_accuracy: 0.5067\n",
      "Epoch 20/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6966 - accuracy: 0.5079 - val_loss: 0.6974 - val_accuracy: 0.5063\n",
      "Epoch 21/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6959 - accuracy: 0.5071 - val_loss: 0.6955 - val_accuracy: 0.5081\n",
      "Epoch 22/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6950 - accuracy: 0.5095 - val_loss: 0.6953 - val_accuracy: 0.5081\n",
      "Epoch 23/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6946 - accuracy: 0.5093 - val_loss: 0.6948 - val_accuracy: 0.5086\n",
      "Epoch 24/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6942 - accuracy: 0.5097 - val_loss: 0.6945 - val_accuracy: 0.5092\n",
      "Epoch 25/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6939 - accuracy: 0.5105 - val_loss: 0.6947 - val_accuracy: 0.5049\n",
      "Epoch 26/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6937 - accuracy: 0.5113 - val_loss: 0.6943 - val_accuracy: 0.5099\n",
      "Epoch 27/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6934 - accuracy: 0.5115 - val_loss: 0.6942 - val_accuracy: 0.5106\n",
      "Epoch 28/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6931 - accuracy: 0.5125 - val_loss: 0.6940 - val_accuracy: 0.5126\n",
      "Epoch 29/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6930 - accuracy: 0.5133 - val_loss: 0.6938 - val_accuracy: 0.5087\n",
      "Epoch 30/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6927 - accuracy: 0.5139 - val_loss: 0.6938 - val_accuracy: 0.5092\n",
      "Epoch 31/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5144 - val_loss: 0.6940 - val_accuracy: 0.5090\n",
      "Epoch 32/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6925 - accuracy: 0.5156 - val_loss: 0.6936 - val_accuracy: 0.5148\n",
      "Epoch 33/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6923 - accuracy: 0.5164 - val_loss: 0.6937 - val_accuracy: 0.5132\n",
      "Epoch 34/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6922 - accuracy: 0.5165 - val_loss: 0.6934 - val_accuracy: 0.5102\n",
      "Epoch 35/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6922 - accuracy: 0.5163 - val_loss: 0.6932 - val_accuracy: 0.5115\n",
      "Epoch 36/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6921 - accuracy: 0.5176 - val_loss: 0.6931 - val_accuracy: 0.5109\n",
      "Epoch 37/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6929 - val_accuracy: 0.5144\n",
      "Epoch 38/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6918 - accuracy: 0.5187 - val_loss: 0.6929 - val_accuracy: 0.5159\n",
      "Epoch 39/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.5174 - val_loss: 0.6931 - val_accuracy: 0.5112\n",
      "Epoch 40/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6916 - accuracy: 0.5201 - val_loss: 0.6930 - val_accuracy: 0.5223\n",
      "Epoch 41/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6916 - accuracy: 0.5198 - val_loss: 0.6929 - val_accuracy: 0.5128\n",
      "Epoch 42/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6914 - accuracy: 0.5208 - val_loss: 0.6929 - val_accuracy: 0.5186\n",
      "Epoch 43/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6914 - accuracy: 0.5206 - val_loss: 0.6927 - val_accuracy: 0.5223\n",
      "Epoch 44/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6925 - val_accuracy: 0.5199\n",
      "Epoch 45/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6924 - val_accuracy: 0.5200\n",
      "Epoch 46/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6927 - val_accuracy: 0.5234\n",
      "Epoch 47/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6911 - accuracy: 0.5232 - val_loss: 0.6923 - val_accuracy: 0.5233\n",
      "Epoch 48/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6911 - accuracy: 0.5222 - val_loss: 0.6925 - val_accuracy: 0.5197\n",
      "Epoch 49/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6910 - accuracy: 0.5241 - val_loss: 0.6923 - val_accuracy: 0.5242\n",
      "Epoch 50/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6909 - accuracy: 0.5240 - val_loss: 0.6922 - val_accuracy: 0.5204\n",
      "Epoch 51/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6908 - accuracy: 0.5253 - val_loss: 0.6925 - val_accuracy: 0.5155\n",
      "Epoch 52/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6907 - accuracy: 0.5264 - val_loss: 0.6921 - val_accuracy: 0.5241\n",
      "Epoch 53/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6905 - accuracy: 0.5266 - val_loss: 0.6919 - val_accuracy: 0.5261\n",
      "Epoch 54/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6904 - accuracy: 0.5278 - val_loss: 0.6917 - val_accuracy: 0.5290\n",
      "Epoch 55/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6901 - accuracy: 0.5303 - val_loss: 0.6922 - val_accuracy: 0.5207\n",
      "Epoch 56/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6899 - accuracy: 0.5314 - val_loss: 0.6912 - val_accuracy: 0.5266\n",
      "Epoch 57/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6896 - accuracy: 0.5330 - val_loss: 0.6921 - val_accuracy: 0.5124\n",
      "Epoch 58/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6895 - accuracy: 0.5333 - val_loss: 0.6911 - val_accuracy: 0.5307\n",
      "Epoch 59/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6891 - accuracy: 0.5354 - val_loss: 0.6905 - val_accuracy: 0.5339\n",
      "Epoch 60/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6888 - accuracy: 0.5360 - val_loss: 0.6906 - val_accuracy: 0.5329\n",
      "Epoch 61/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6884 - accuracy: 0.5373 - val_loss: 0.6902 - val_accuracy: 0.5294\n",
      "Epoch 62/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6882 - accuracy: 0.5386 - val_loss: 0.6902 - val_accuracy: 0.5325\n",
      "Epoch 63/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6877 - accuracy: 0.5395 - val_loss: 0.6892 - val_accuracy: 0.5391\n",
      "Epoch 64/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6874 - accuracy: 0.5408 - val_loss: 0.6887 - val_accuracy: 0.5447\n",
      "Epoch 65/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6867 - accuracy: 0.5424 - val_loss: 0.6884 - val_accuracy: 0.5396\n",
      "Epoch 66/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6862 - accuracy: 0.5434 - val_loss: 0.6885 - val_accuracy: 0.5365\n",
      "Epoch 67/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6856 - accuracy: 0.5456 - val_loss: 0.6869 - val_accuracy: 0.5454\n",
      "Epoch 68/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6849 - accuracy: 0.5474 - val_loss: 0.6864 - val_accuracy: 0.5453\n",
      "Epoch 69/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6841 - accuracy: 0.5487 - val_loss: 0.6854 - val_accuracy: 0.5460\n",
      "Epoch 70/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6834 - accuracy: 0.5500 - val_loss: 0.6861 - val_accuracy: 0.5381\n",
      "Epoch 71/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6824 - accuracy: 0.5519 - val_loss: 0.6845 - val_accuracy: 0.5457\n",
      "Epoch 72/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6820 - accuracy: 0.5526 - val_loss: 0.6837 - val_accuracy: 0.5468\n",
      "Epoch 73/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6815 - accuracy: 0.5540 - val_loss: 0.6841 - val_accuracy: 0.5506\n",
      "Epoch 74/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6809 - accuracy: 0.5551 - val_loss: 0.6830 - val_accuracy: 0.5486\n",
      "Epoch 75/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6800 - accuracy: 0.5566 - val_loss: 0.6833 - val_accuracy: 0.5499\n",
      "Epoch 76/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6798 - accuracy: 0.5574 - val_loss: 0.6813 - val_accuracy: 0.5555\n",
      "Epoch 77/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6788 - accuracy: 0.5583 - val_loss: 0.6824 - val_accuracy: 0.5531\n",
      "Epoch 78/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6783 - accuracy: 0.5585 - val_loss: 0.6806 - val_accuracy: 0.5549\n",
      "Epoch 79/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6783 - accuracy: 0.5586 - val_loss: 0.6808 - val_accuracy: 0.5529\n",
      "Epoch 80/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6781 - accuracy: 0.5597 - val_loss: 0.6834 - val_accuracy: 0.5496\n",
      "Epoch 81/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6769 - accuracy: 0.5608 - val_loss: 0.6798 - val_accuracy: 0.5556\n",
      "Epoch 82/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6757 - accuracy: 0.5623 - val_loss: 0.6777 - val_accuracy: 0.5638\n",
      "Epoch 83/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6776 - accuracy: 0.5593 - val_loss: 0.6799 - val_accuracy: 0.5548\n",
      "Epoch 84/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6748 - accuracy: 0.5644 - val_loss: 0.6862 - val_accuracy: 0.5394\n",
      "Epoch 85/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6740 - accuracy: 0.5652 - val_loss: 0.6777 - val_accuracy: 0.5610\n",
      "Epoch 86/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6732 - accuracy: 0.5655 - val_loss: 0.6826 - val_accuracy: 0.5480\n",
      "Epoch 87/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6726 - accuracy: 0.5664 - val_loss: 0.6757 - val_accuracy: 0.5628\n",
      "Epoch 88/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6718 - accuracy: 0.5677 - val_loss: 0.6740 - val_accuracy: 0.5653\n",
      "Epoch 89/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6715 - accuracy: 0.5688 - val_loss: 0.6724 - val_accuracy: 0.5713\n",
      "Epoch 90/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6739 - accuracy: 0.5653 - val_loss: 0.6743 - val_accuracy: 0.5634\n",
      "Epoch 91/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6712 - accuracy: 0.5686 - val_loss: 0.6748 - val_accuracy: 0.5661\n",
      "Epoch 92/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6708 - accuracy: 0.5686 - val_loss: 0.6714 - val_accuracy: 0.5702\n",
      "Epoch 93/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6719 - accuracy: 0.5678 - val_loss: 0.6733 - val_accuracy: 0.5729\n",
      "Epoch 94/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6700 - accuracy: 0.5711 - val_loss: 0.6904 - val_accuracy: 0.5304\n",
      "Epoch 95/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6700 - accuracy: 0.5696 - val_loss: 0.6696 - val_accuracy: 0.5740\n",
      "Epoch 96/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6691 - accuracy: 0.5725 - val_loss: 0.6702 - val_accuracy: 0.5753\n",
      "Epoch 97/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6684 - accuracy: 0.5729 - val_loss: 0.6728 - val_accuracy: 0.5726\n",
      "Epoch 98/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6750 - accuracy: 0.5640 - val_loss: 0.6764 - val_accuracy: 0.5528\n",
      "Epoch 99/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6720 - accuracy: 0.5673 - val_loss: 0.6799 - val_accuracy: 0.5661\n",
      "Epoch 100/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6731 - accuracy: 0.5648 - val_loss: 0.6766 - val_accuracy: 0.5707\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_10\n",
      "cannot prune layer q_activation_10\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_11\n",
      "cannot prune layer q_activation_11\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 0.6742 - accuracy: 0.5655 - val_loss: 0.6729 - val_accuracy: 0.5732\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6691 - accuracy: 0.5731 - val_loss: 0.6824 - val_accuracy: 0.5531\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6907 - accuracy: 0.5432 - val_loss: 0.6898 - val_accuracy: 0.5431\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6859 - accuracy: 0.5452 - val_loss: 0.6813 - val_accuracy: 0.5595\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6784 - accuracy: 0.5590 - val_loss: 0.6770 - val_accuracy: 0.5687\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6743 - accuracy: 0.5653 - val_loss: 0.6798 - val_accuracy: 0.5515\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6724 - accuracy: 0.5690 - val_loss: 0.6717 - val_accuracy: 0.5758\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6701 - accuracy: 0.5717 - val_loss: 0.6779 - val_accuracy: 0.5531\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6690 - accuracy: 0.5735 - val_loss: 0.6682 - val_accuracy: 0.5784\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6707 - accuracy: 0.5709 - val_loss: 0.6799 - val_accuracy: 0.5435\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6689 - accuracy: 0.5739 - val_loss: 0.6685 - val_accuracy: 0.5803\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6701 - accuracy: 0.5733 - val_loss: 0.6683 - val_accuracy: 0.5777\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6666 - accuracy: 0.5782 - val_loss: 0.6646 - val_accuracy: 0.5849\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6669 - accuracy: 0.5769 - val_loss: 0.6661 - val_accuracy: 0.5781\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6662 - accuracy: 0.5790 - val_loss: 0.6670 - val_accuracy: 0.5761\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6657 - accuracy: 0.5781 - val_loss: 0.6666 - val_accuracy: 0.5799\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6641 - accuracy: 0.5816 - val_loss: 0.6939 - val_accuracy: 0.5440\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6642 - accuracy: 0.5821 - val_loss: 0.6641 - val_accuracy: 0.5838\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6642 - accuracy: 0.5807 - val_loss: 0.6783 - val_accuracy: 0.5560\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6641 - accuracy: 0.5802 - val_loss: 0.6659 - val_accuracy: 0.5790\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6635 - accuracy: 0.5817 - val_loss: 0.6640 - val_accuracy: 0.5867\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6651 - accuracy: 0.5799 - val_loss: 0.6884 - val_accuracy: 0.5531\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6643 - accuracy: 0.5807 - val_loss: 0.6645 - val_accuracy: 0.5866\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6618 - accuracy: 0.5840 - val_loss: 0.6681 - val_accuracy: 0.5840\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6714 - accuracy: 0.5715 - val_loss: 0.7017 - val_accuracy: 0.5263\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6893 - accuracy: 0.5350 - val_loss: 0.6862 - val_accuracy: 0.5396\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6790 - accuracy: 0.5556 - val_loss: 0.6795 - val_accuracy: 0.5524\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6744 - accuracy: 0.5658 - val_loss: 0.6734 - val_accuracy: 0.5668\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6677 - accuracy: 0.5779 - val_loss: 0.6688 - val_accuracy: 0.5782\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6638 - accuracy: 0.5833 - val_loss: 0.6631 - val_accuracy: 0.5847\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6647 - accuracy: 0.5822 - val_loss: 0.6875 - val_accuracy: 0.5542\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6818 - accuracy: 0.5594 - val_loss: 0.7136 - val_accuracy: 0.5150\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6963 - accuracy: 0.5215 - val_loss: 0.6923 - val_accuracy: 0.5257\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6891 - accuracy: 0.5341 - val_loss: 0.6886 - val_accuracy: 0.5381\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6861 - accuracy: 0.5423 - val_loss: 0.6859 - val_accuracy: 0.5465\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6833 - accuracy: 0.5516 - val_loss: 0.6829 - val_accuracy: 0.5535\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6802 - accuracy: 0.5581 - val_loss: 0.6794 - val_accuracy: 0.5620\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6779 - accuracy: 0.5639 - val_loss: 0.6776 - val_accuracy: 0.5638\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6757 - accuracy: 0.5674 - val_loss: 0.6758 - val_accuracy: 0.5675\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6736 - accuracy: 0.5710 - val_loss: 0.6761 - val_accuracy: 0.5648\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6711 - accuracy: 0.5743 - val_loss: 0.6883 - val_accuracy: 0.5326\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6692 - accuracy: 0.5766 - val_loss: 0.6675 - val_accuracy: 0.5852\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6713 - accuracy: 0.5740 - val_loss: 0.6820 - val_accuracy: 0.5573\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6658 - accuracy: 0.5817 - val_loss: 0.6613 - val_accuracy: 0.5931\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6622 - accuracy: 0.5864 - val_loss: 0.6605 - val_accuracy: 0.5957\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6601 - accuracy: 0.5910 - val_loss: 0.6591 - val_accuracy: 0.6006\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6602 - accuracy: 0.5907 - val_loss: 0.6623 - val_accuracy: 0.5887\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6583 - accuracy: 0.5927 - val_loss: 0.6588 - val_accuracy: 0.5979\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6572 - accuracy: 0.5954 - val_loss: 0.6611 - val_accuracy: 0.5850\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6563 - accuracy: 0.5969 - val_loss: 0.6569 - val_accuracy: 0.6056\n",
      "1714/1714 [==============================] - 3s 1ms/step\n",
      "[[0.27307528]\n",
      " [0.6358222 ]\n",
      " [0.5243123 ]\n",
      " [0.5187469 ]\n",
      " [0.5577334 ]\n",
      " [0.4231012 ]\n",
      " [0.54711086]\n",
      " [0.5295411 ]\n",
      " [0.56466675]\n",
      " [0.4248014 ]]\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.0005, 'BATCH_SIZE': 1024, 'EPOCHS': 150, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.0, 'POST_PRUNE_EPOCHS': 50}\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 24)                96        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_12 (QActivati  (None, 24)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 12)                48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_13 (QActivati  (None, 12)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_12 is normal keras bn layer\n",
      "q_activation_12      quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_13 is normal keras bn layer\n",
      "q_activation_13      quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/150\n",
      "429/429 [==============================] - 5s 7ms/step - loss: 1.9584 - accuracy: 0.5000 - val_loss: 1.1441 - val_accuracy: 0.5006\n",
      "Epoch 2/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 1.0288 - accuracy: 0.4977 - val_loss: 0.9168 - val_accuracy: 0.4994\n",
      "Epoch 3/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.9161 - accuracy: 0.4979 - val_loss: 1.0121 - val_accuracy: 0.4994\n",
      "Epoch 4/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.8543 - accuracy: 0.4983 - val_loss: 0.8380 - val_accuracy: 0.5003\n",
      "Epoch 5/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7848 - accuracy: 0.4997 - val_loss: 0.7659 - val_accuracy: 0.5027\n",
      "Epoch 6/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7679 - accuracy: 0.5002 - val_loss: 0.8133 - val_accuracy: 0.5005\n",
      "Epoch 7/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7570 - accuracy: 0.5004 - val_loss: 0.7455 - val_accuracy: 0.5033\n",
      "Epoch 8/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7439 - accuracy: 0.5001 - val_loss: 0.7372 - val_accuracy: 0.5043\n",
      "Epoch 9/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7344 - accuracy: 0.4998 - val_loss: 0.7280 - val_accuracy: 0.5015\n",
      "Epoch 10/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7277 - accuracy: 0.5001 - val_loss: 0.7242 - val_accuracy: 0.5021\n",
      "Epoch 11/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7229 - accuracy: 0.5003 - val_loss: 0.7194 - val_accuracy: 0.5023\n",
      "Epoch 12/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7189 - accuracy: 0.5008 - val_loss: 0.7162 - val_accuracy: 0.5019\n",
      "Epoch 13/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7152 - accuracy: 0.5015 - val_loss: 0.7129 - val_accuracy: 0.5006\n",
      "Epoch 14/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7123 - accuracy: 0.5023 - val_loss: 0.7106 - val_accuracy: 0.4999\n",
      "Epoch 15/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7093 - accuracy: 0.5031 - val_loss: 0.7080 - val_accuracy: 0.5003\n",
      "Epoch 16/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7067 - accuracy: 0.5028 - val_loss: 0.7058 - val_accuracy: 0.4998\n",
      "Epoch 17/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7047 - accuracy: 0.5033 - val_loss: 0.7038 - val_accuracy: 0.5003\n",
      "Epoch 18/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7029 - accuracy: 0.5042 - val_loss: 0.7025 - val_accuracy: 0.5023\n",
      "Epoch 19/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7012 - accuracy: 0.5044 - val_loss: 0.7011 - val_accuracy: 0.5025\n",
      "Epoch 20/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6998 - accuracy: 0.5054 - val_loss: 0.6996 - val_accuracy: 0.5045\n",
      "Epoch 21/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6986 - accuracy: 0.5054 - val_loss: 0.6988 - val_accuracy: 0.5047\n",
      "Epoch 22/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6974 - accuracy: 0.5066 - val_loss: 0.6977 - val_accuracy: 0.5064\n",
      "Epoch 23/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6965 - accuracy: 0.5064 - val_loss: 0.6973 - val_accuracy: 0.5037\n",
      "Epoch 24/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6957 - accuracy: 0.5076 - val_loss: 0.6959 - val_accuracy: 0.5071\n",
      "Epoch 25/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6952 - accuracy: 0.5076 - val_loss: 0.6972 - val_accuracy: 0.5041\n",
      "Epoch 26/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6946 - accuracy: 0.5092 - val_loss: 0.6951 - val_accuracy: 0.5095\n",
      "Epoch 27/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6941 - accuracy: 0.5095 - val_loss: 0.6948 - val_accuracy: 0.5082\n",
      "Epoch 28/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6938 - accuracy: 0.5108 - val_loss: 0.6942 - val_accuracy: 0.5110\n",
      "Epoch 29/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6935 - accuracy: 0.5113 - val_loss: 0.6941 - val_accuracy: 0.5112\n",
      "Epoch 30/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6932 - accuracy: 0.5128 - val_loss: 0.6938 - val_accuracy: 0.5100\n",
      "Epoch 31/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6929 - accuracy: 0.5136 - val_loss: 0.6935 - val_accuracy: 0.5143\n",
      "Epoch 32/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5138 - val_loss: 0.6935 - val_accuracy: 0.5108\n",
      "Epoch 33/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6926 - accuracy: 0.5156 - val_loss: 0.6932 - val_accuracy: 0.5142\n",
      "Epoch 34/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6924 - accuracy: 0.5149 - val_loss: 0.6933 - val_accuracy: 0.5138\n",
      "Epoch 35/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6922 - accuracy: 0.5162 - val_loss: 0.6930 - val_accuracy: 0.5131\n",
      "Epoch 36/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6921 - accuracy: 0.5164 - val_loss: 0.6932 - val_accuracy: 0.5126\n",
      "Epoch 37/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6919 - accuracy: 0.5171 - val_loss: 0.6933 - val_accuracy: 0.5102\n",
      "Epoch 38/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6927 - val_accuracy: 0.5159\n",
      "Epoch 39/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6929 - val_accuracy: 0.5099\n",
      "Epoch 40/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6928 - val_accuracy: 0.5081\n",
      "Epoch 41/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6914 - accuracy: 0.5198 - val_loss: 0.6925 - val_accuracy: 0.5189\n",
      "Epoch 42/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6913 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5180\n",
      "Epoch 43/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6911 - accuracy: 0.5219 - val_loss: 0.6925 - val_accuracy: 0.5186\n",
      "Epoch 44/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6911 - accuracy: 0.5225 - val_loss: 0.6923 - val_accuracy: 0.5168\n",
      "Epoch 45/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6910 - accuracy: 0.5227 - val_loss: 0.6924 - val_accuracy: 0.5179\n",
      "Epoch 46/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6908 - accuracy: 0.5235 - val_loss: 0.6933 - val_accuracy: 0.5057\n",
      "Epoch 47/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6906 - accuracy: 0.5246 - val_loss: 0.6922 - val_accuracy: 0.5225\n",
      "Epoch 48/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6903 - accuracy: 0.5265 - val_loss: 0.6923 - val_accuracy: 0.5162\n",
      "Epoch 49/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6900 - accuracy: 0.5276 - val_loss: 0.6913 - val_accuracy: 0.5230\n",
      "Epoch 50/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6895 - accuracy: 0.5302 - val_loss: 0.6915 - val_accuracy: 0.5272\n",
      "Epoch 51/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6890 - accuracy: 0.5320 - val_loss: 0.6906 - val_accuracy: 0.5293\n",
      "Epoch 52/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6884 - accuracy: 0.5353 - val_loss: 0.6899 - val_accuracy: 0.5344\n",
      "Epoch 53/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6876 - accuracy: 0.5386 - val_loss: 0.6899 - val_accuracy: 0.5324\n",
      "Epoch 54/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6869 - accuracy: 0.5406 - val_loss: 0.6893 - val_accuracy: 0.5310\n",
      "Epoch 55/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6860 - accuracy: 0.5445 - val_loss: 0.6879 - val_accuracy: 0.5417\n",
      "Epoch 56/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6851 - accuracy: 0.5471 - val_loss: 0.6878 - val_accuracy: 0.5421\n",
      "Epoch 57/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6840 - accuracy: 0.5491 - val_loss: 0.6861 - val_accuracy: 0.5448\n",
      "Epoch 58/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6834 - accuracy: 0.5522 - val_loss: 0.6841 - val_accuracy: 0.5508\n",
      "Epoch 59/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6815 - accuracy: 0.5556 - val_loss: 0.6828 - val_accuracy: 0.5561\n",
      "Epoch 60/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6803 - accuracy: 0.5583 - val_loss: 0.6813 - val_accuracy: 0.5536\n",
      "Epoch 61/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6787 - accuracy: 0.5612 - val_loss: 0.6833 - val_accuracy: 0.5498\n",
      "Epoch 62/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6776 - accuracy: 0.5636 - val_loss: 0.6776 - val_accuracy: 0.5635\n",
      "Epoch 63/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6761 - accuracy: 0.5662 - val_loss: 0.6776 - val_accuracy: 0.5627\n",
      "Epoch 64/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6771 - accuracy: 0.5674 - val_loss: 0.6769 - val_accuracy: 0.5644\n",
      "Epoch 65/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6759 - accuracy: 0.5694 - val_loss: 0.6757 - val_accuracy: 0.5700\n",
      "Epoch 66/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6744 - accuracy: 0.5725 - val_loss: 0.6731 - val_accuracy: 0.5761\n",
      "Epoch 67/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6753 - accuracy: 0.5713 - val_loss: 0.6727 - val_accuracy: 0.5788\n",
      "Epoch 68/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6748 - accuracy: 0.5728 - val_loss: 0.6734 - val_accuracy: 0.5697\n",
      "Epoch 69/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6741 - accuracy: 0.5730 - val_loss: 0.6763 - val_accuracy: 0.5728\n",
      "Epoch 70/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6730 - accuracy: 0.5762 - val_loss: 0.6711 - val_accuracy: 0.5787\n",
      "Epoch 71/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6727 - accuracy: 0.5762 - val_loss: 0.6764 - val_accuracy: 0.5795\n",
      "Epoch 72/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6716 - accuracy: 0.5784 - val_loss: 0.6682 - val_accuracy: 0.5840\n",
      "Epoch 73/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6709 - accuracy: 0.5801 - val_loss: 0.6673 - val_accuracy: 0.5894\n",
      "Epoch 74/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6710 - accuracy: 0.5786 - val_loss: 0.6696 - val_accuracy: 0.5744\n",
      "Epoch 75/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6682 - accuracy: 0.5830 - val_loss: 0.6692 - val_accuracy: 0.5813\n",
      "Epoch 76/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6652 - accuracy: 0.5861 - val_loss: 0.6671 - val_accuracy: 0.5889\n",
      "Epoch 77/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6659 - accuracy: 0.5858 - val_loss: 0.6723 - val_accuracy: 0.5801\n",
      "Epoch 78/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6755 - accuracy: 0.5709 - val_loss: 0.6739 - val_accuracy: 0.5788\n",
      "Epoch 79/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6702 - accuracy: 0.5800 - val_loss: 0.6667 - val_accuracy: 0.5915\n",
      "Epoch 80/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6681 - accuracy: 0.5841 - val_loss: 0.6713 - val_accuracy: 0.5830\n",
      "Epoch 81/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6673 - accuracy: 0.5862 - val_loss: 0.6646 - val_accuracy: 0.5943\n",
      "Epoch 82/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6651 - accuracy: 0.5890 - val_loss: 0.6658 - val_accuracy: 0.5797\n",
      "Epoch 83/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6638 - accuracy: 0.5910 - val_loss: 0.6690 - val_accuracy: 0.5841\n",
      "Epoch 84/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6666 - accuracy: 0.5872 - val_loss: 0.6690 - val_accuracy: 0.5797\n",
      "Epoch 85/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6636 - accuracy: 0.5896 - val_loss: 0.6610 - val_accuracy: 0.5988\n",
      "Epoch 86/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6751 - accuracy: 0.5739 - val_loss: 0.6849 - val_accuracy: 0.5521\n",
      "Epoch 87/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6758 - accuracy: 0.5646 - val_loss: 0.6719 - val_accuracy: 0.5726\n",
      "Epoch 88/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6652 - accuracy: 0.5845 - val_loss: 0.6664 - val_accuracy: 0.5895\n",
      "Epoch 89/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6610 - accuracy: 0.5931 - val_loss: 0.6599 - val_accuracy: 0.5960\n",
      "Epoch 90/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6609 - accuracy: 0.5939 - val_loss: 0.6573 - val_accuracy: 0.6043\n",
      "Epoch 91/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6593 - accuracy: 0.5965 - val_loss: 0.6581 - val_accuracy: 0.5972\n",
      "Epoch 92/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6603 - accuracy: 0.5964 - val_loss: 0.6844 - val_accuracy: 0.5672\n",
      "Epoch 93/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6665 - accuracy: 0.5866 - val_loss: 0.6882 - val_accuracy: 0.5615\n",
      "Epoch 94/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6655 - accuracy: 0.5881 - val_loss: 0.6588 - val_accuracy: 0.5984\n",
      "Epoch 95/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6613 - accuracy: 0.5946 - val_loss: 0.6943 - val_accuracy: 0.5563\n",
      "Epoch 96/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6588 - accuracy: 0.5985 - val_loss: 0.6603 - val_accuracy: 0.6026\n",
      "Epoch 97/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6588 - accuracy: 0.5967 - val_loss: 0.6557 - val_accuracy: 0.6060\n",
      "Epoch 98/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6583 - accuracy: 0.5983 - val_loss: 0.6604 - val_accuracy: 0.5883\n",
      "Epoch 99/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6660 - accuracy: 0.5886 - val_loss: 0.8308 - val_accuracy: 0.5107\n",
      "Epoch 100/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6944 - accuracy: 0.5396 - val_loss: 0.6844 - val_accuracy: 0.5449\n",
      "Epoch 101/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6626 - accuracy: 0.5934 - val_loss: 0.6601 - val_accuracy: 0.5966\n",
      "Epoch 102/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6594 - accuracy: 0.5969 - val_loss: 0.6579 - val_accuracy: 0.6046\n",
      "Epoch 103/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6586 - accuracy: 0.5977 - val_loss: 0.6563 - val_accuracy: 0.6044\n",
      "Epoch 104/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6587 - accuracy: 0.5978 - val_loss: 0.6569 - val_accuracy: 0.6043\n",
      "Epoch 105/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6568 - accuracy: 0.6007 - val_loss: 0.6713 - val_accuracy: 0.5783\n",
      "Epoch 106/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6762 - accuracy: 0.5697 - val_loss: 0.6936 - val_accuracy: 0.5420\n",
      "Epoch 107/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6815 - accuracy: 0.5605 - val_loss: 0.6895 - val_accuracy: 0.5469\n",
      "Epoch 108/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6660 - accuracy: 0.5852 - val_loss: 0.6584 - val_accuracy: 0.6032\n",
      "Epoch 109/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6578 - accuracy: 0.5980 - val_loss: 0.6673 - val_accuracy: 0.5775\n",
      "Epoch 110/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6558 - accuracy: 0.6014 - val_loss: 0.6533 - val_accuracy: 0.6094\n",
      "Epoch 111/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6558 - accuracy: 0.6012 - val_loss: 0.6546 - val_accuracy: 0.5977\n",
      "Epoch 112/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6582 - accuracy: 0.5976 - val_loss: 0.6523 - val_accuracy: 0.6140\n",
      "Epoch 113/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6546 - accuracy: 0.6029 - val_loss: 0.6643 - val_accuracy: 0.5833\n",
      "Epoch 114/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6532 - accuracy: 0.6048 - val_loss: 0.6528 - val_accuracy: 0.6017\n",
      "Epoch 115/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6542 - accuracy: 0.6036 - val_loss: 0.6673 - val_accuracy: 0.5808\n",
      "Epoch 116/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6544 - accuracy: 0.6035 - val_loss: 0.6523 - val_accuracy: 0.6048\n",
      "Epoch 117/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6551 - accuracy: 0.6022 - val_loss: 0.6508 - val_accuracy: 0.6126\n",
      "Epoch 118/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6512 - accuracy: 0.6075 - val_loss: 0.6640 - val_accuracy: 0.5845\n",
      "Epoch 119/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6510 - accuracy: 0.6081 - val_loss: 0.6473 - val_accuracy: 0.6142\n",
      "Epoch 120/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6500 - accuracy: 0.6086 - val_loss: 0.6658 - val_accuracy: 0.5864\n",
      "Epoch 121/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6503 - accuracy: 0.6084 - val_loss: 0.6466 - val_accuracy: 0.6170\n",
      "Epoch 122/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6821 - accuracy: 0.5638 - val_loss: 0.7073 - val_accuracy: 0.5180\n",
      "Epoch 123/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7028 - accuracy: 0.5166 - val_loss: 0.6991 - val_accuracy: 0.5192\n",
      "Epoch 124/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6973 - accuracy: 0.5209 - val_loss: 0.6952 - val_accuracy: 0.5233\n",
      "Epoch 125/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6943 - accuracy: 0.5244 - val_loss: 0.6928 - val_accuracy: 0.5264\n",
      "Epoch 126/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5276 - val_loss: 0.6912 - val_accuracy: 0.5300\n",
      "Epoch 127/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6907 - accuracy: 0.5306 - val_loss: 0.6896 - val_accuracy: 0.5331\n",
      "Epoch 128/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6886 - accuracy: 0.5351 - val_loss: 0.6874 - val_accuracy: 0.5406\n",
      "Epoch 129/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6860 - accuracy: 0.5415 - val_loss: 0.6846 - val_accuracy: 0.5478\n",
      "Epoch 130/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6813 - accuracy: 0.5525 - val_loss: 0.6789 - val_accuracy: 0.5631\n",
      "Epoch 131/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6740 - accuracy: 0.5716 - val_loss: 0.6702 - val_accuracy: 0.5808\n",
      "Epoch 132/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6677 - accuracy: 0.5835 - val_loss: 0.6655 - val_accuracy: 0.5908\n",
      "Epoch 133/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6628 - accuracy: 0.5910 - val_loss: 0.6596 - val_accuracy: 0.5971\n",
      "Epoch 134/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6585 - accuracy: 0.5970 - val_loss: 0.6554 - val_accuracy: 0.6007\n",
      "Epoch 135/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6553 - accuracy: 0.6010 - val_loss: 0.6534 - val_accuracy: 0.6039\n",
      "Epoch 136/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6502 - accuracy: 0.6081 - val_loss: 0.6491 - val_accuracy: 0.6092\n",
      "Epoch 137/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6480 - accuracy: 0.6113 - val_loss: 0.6489 - val_accuracy: 0.6117\n",
      "Epoch 138/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6467 - accuracy: 0.6126 - val_loss: 0.6471 - val_accuracy: 0.6116\n",
      "Epoch 139/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6463 - accuracy: 0.6131 - val_loss: 0.6453 - val_accuracy: 0.6187\n",
      "Epoch 140/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6474 - accuracy: 0.6124 - val_loss: 0.6461 - val_accuracy: 0.6163\n",
      "Epoch 141/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6700 - accuracy: 0.5788 - val_loss: 0.6979 - val_accuracy: 0.5379\n",
      "Epoch 142/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6640 - accuracy: 0.5882 - val_loss: 0.6503 - val_accuracy: 0.6107\n",
      "Epoch 143/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6485 - accuracy: 0.6106 - val_loss: 0.6452 - val_accuracy: 0.6163\n",
      "Epoch 144/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6513 - accuracy: 0.6074 - val_loss: 0.6524 - val_accuracy: 0.6027\n",
      "Epoch 145/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6491 - accuracy: 0.6100 - val_loss: 0.6460 - val_accuracy: 0.6189\n",
      "Epoch 146/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6445 - accuracy: 0.6158 - val_loss: 0.6432 - val_accuracy: 0.6178\n",
      "Epoch 147/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6458 - accuracy: 0.6131 - val_loss: 0.6440 - val_accuracy: 0.6197\n",
      "Epoch 148/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6426 - accuracy: 0.6181 - val_loss: 0.6456 - val_accuracy: 0.6122\n",
      "Epoch 149/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6428 - accuracy: 0.6176 - val_loss: 0.6395 - val_accuracy: 0.6229\n",
      "Epoch 150/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6429 - accuracy: 0.6178 - val_loss: 0.6421 - val_accuracy: 0.6181\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_12\n",
      "cannot prune layer q_activation_12\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_13\n",
      "cannot prune layer q_activation_13\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 0.6416 - accuracy: 0.6192 - val_loss: 0.6511 - val_accuracy: 0.6077\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6413 - accuracy: 0.6194 - val_loss: 0.6400 - val_accuracy: 0.6236\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6437 - accuracy: 0.6172 - val_loss: 0.6395 - val_accuracy: 0.6231\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6443 - accuracy: 0.6158 - val_loss: 0.6417 - val_accuracy: 0.6217\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6415 - accuracy: 0.6191 - val_loss: 0.6361 - val_accuracy: 0.6282\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6384 - accuracy: 0.6238 - val_loss: 0.6380 - val_accuracy: 0.6257\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6400 - accuracy: 0.6214 - val_loss: 0.6381 - val_accuracy: 0.6246\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6403 - accuracy: 0.6213 - val_loss: 0.6458 - val_accuracy: 0.6144\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6376 - accuracy: 0.6237 - val_loss: 0.6409 - val_accuracy: 0.6186\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6374 - accuracy: 0.6248 - val_loss: 0.6424 - val_accuracy: 0.6214\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6363 - accuracy: 0.6264 - val_loss: 0.6354 - val_accuracy: 0.6290\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6702 - accuracy: 0.5841 - val_loss: 0.6700 - val_accuracy: 0.5756\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6469 - accuracy: 0.6122 - val_loss: 0.6397 - val_accuracy: 0.6213\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6982 - accuracy: 0.5273 - val_loss: 0.6943 - val_accuracy: 0.5203\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6902 - accuracy: 0.5306 - val_loss: 0.6885 - val_accuracy: 0.5359\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6847 - accuracy: 0.5441 - val_loss: 0.6817 - val_accuracy: 0.5568\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6714 - accuracy: 0.5762 - val_loss: 0.6655 - val_accuracy: 0.5894\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6571 - accuracy: 0.6000 - val_loss: 0.6506 - val_accuracy: 0.6116\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6510 - accuracy: 0.6076 - val_loss: 0.6469 - val_accuracy: 0.6140\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6464 - accuracy: 0.6145 - val_loss: 0.6425 - val_accuracy: 0.6209\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6434 - accuracy: 0.6179 - val_loss: 0.6391 - val_accuracy: 0.6264\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6411 - accuracy: 0.6210 - val_loss: 0.6359 - val_accuracy: 0.6299\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6394 - accuracy: 0.6234 - val_loss: 0.6352 - val_accuracy: 0.6293\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6386 - accuracy: 0.6238 - val_loss: 0.6448 - val_accuracy: 0.6185\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6378 - accuracy: 0.6246 - val_loss: 0.6336 - val_accuracy: 0.6305\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6351 - accuracy: 0.6277 - val_loss: 0.6350 - val_accuracy: 0.6292\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6538 - accuracy: 0.6076 - val_loss: 0.6889 - val_accuracy: 0.5610\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6582 - accuracy: 0.6027 - val_loss: 0.6481 - val_accuracy: 0.6195\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6377 - accuracy: 0.6275 - val_loss: 0.6320 - val_accuracy: 0.6316\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6342 - accuracy: 0.6291 - val_loss: 0.6336 - val_accuracy: 0.6274\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6358 - accuracy: 0.6272 - val_loss: 0.6358 - val_accuracy: 0.6231\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6384 - accuracy: 0.6237 - val_loss: 0.6461 - val_accuracy: 0.6153\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6359 - accuracy: 0.6264 - val_loss: 0.6320 - val_accuracy: 0.6317\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6328 - accuracy: 0.6303 - val_loss: 0.6275 - val_accuracy: 0.6371\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6323 - accuracy: 0.6307 - val_loss: 0.6287 - val_accuracy: 0.6331\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6391 - accuracy: 0.6238 - val_loss: 0.6495 - val_accuracy: 0.6108\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6354 - accuracy: 0.6277 - val_loss: 0.6265 - val_accuracy: 0.6386\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6320 - accuracy: 0.6317 - val_loss: 0.6269 - val_accuracy: 0.6361\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6324 - accuracy: 0.6302 - val_loss: 0.6289 - val_accuracy: 0.6339\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6331 - accuracy: 0.6299 - val_loss: 0.6466 - val_accuracy: 0.6170\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6370 - accuracy: 0.6266 - val_loss: 0.6290 - val_accuracy: 0.6389\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6307 - accuracy: 0.6324 - val_loss: 0.6255 - val_accuracy: 0.6391\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6343 - accuracy: 0.6292 - val_loss: 0.6286 - val_accuracy: 0.6364\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6321 - accuracy: 0.6316 - val_loss: 0.6256 - val_accuracy: 0.6400\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6370 - accuracy: 0.6253 - val_loss: 0.6358 - val_accuracy: 0.6286\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6309 - accuracy: 0.6322 - val_loss: 0.6260 - val_accuracy: 0.6417\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6287 - accuracy: 0.6354 - val_loss: 0.6230 - val_accuracy: 0.6414\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6297 - accuracy: 0.6340 - val_loss: 0.6230 - val_accuracy: 0.6430\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6301 - accuracy: 0.6338 - val_loss: 0.6241 - val_accuracy: 0.6418\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6281 - accuracy: 0.6359 - val_loss: 0.6282 - val_accuracy: 0.6366\n",
      "1714/1714 [==============================] - 4s 1ms/step\n",
      "[[0.5646422 ]\n",
      " [0.6856685 ]\n",
      " [0.5818889 ]\n",
      " [0.62254953]\n",
      " [0.5955776 ]\n",
      " [0.45701313]\n",
      " [0.68934625]\n",
      " [0.61444587]\n",
      " [0.6912729 ]\n",
      " [0.5918588 ]]\n",
      "########### FOUND NEW BEST METRIC 0.3889212403552191 ##############\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.002, 'BATCH_SIZE': 1024, 'EPOCHS': 100, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.15, 'POST_PRUNE_EPOCHS': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sdf/home/a/alexyue/miniconda3/envs/SmartPixel/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 24)                96        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_14 (QActivati  (None, 24)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 12)                48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_15 (QActivati  (None, 12)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_14 is normal keras bn layer\n",
      "q_activation_14      quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_15 is normal keras bn layer\n",
      "q_activation_15      quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/100\n",
      "429/429 [==============================] - 5s 7ms/step - loss: 1.5097 - accuracy: 0.5017 - val_loss: 0.7125 - val_accuracy: 0.5040\n",
      "Epoch 2/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7041 - accuracy: 0.5042 - val_loss: 0.6994 - val_accuracy: 0.5030\n",
      "Epoch 3/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6973 - accuracy: 0.5052 - val_loss: 0.6963 - val_accuracy: 0.5085\n",
      "Epoch 4/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6951 - accuracy: 0.5072 - val_loss: 0.6949 - val_accuracy: 0.5090\n",
      "Epoch 5/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6941 - accuracy: 0.5083 - val_loss: 0.6940 - val_accuracy: 0.5097\n",
      "Epoch 6/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6936 - accuracy: 0.5091 - val_loss: 0.6939 - val_accuracy: 0.5101\n",
      "Epoch 7/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6932 - accuracy: 0.5097 - val_loss: 0.6935 - val_accuracy: 0.5124\n",
      "Epoch 8/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6930 - accuracy: 0.5096 - val_loss: 0.6933 - val_accuracy: 0.5094\n",
      "Epoch 9/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5111 - val_loss: 0.6929 - val_accuracy: 0.5133\n",
      "Epoch 10/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6926 - accuracy: 0.5119 - val_loss: 0.6932 - val_accuracy: 0.5134\n",
      "Epoch 11/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6924 - accuracy: 0.5127 - val_loss: 0.6928 - val_accuracy: 0.5145\n",
      "Epoch 12/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6922 - accuracy: 0.5146 - val_loss: 0.6930 - val_accuracy: 0.5132\n",
      "Epoch 13/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6920 - accuracy: 0.5158 - val_loss: 0.6927 - val_accuracy: 0.5157\n",
      "Epoch 14/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6920 - accuracy: 0.5154 - val_loss: 0.6931 - val_accuracy: 0.5071\n",
      "Epoch 15/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.5167 - val_loss: 0.6925 - val_accuracy: 0.5165\n",
      "Epoch 16/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6922 - val_accuracy: 0.5157\n",
      "Epoch 17/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6914 - accuracy: 0.5189 - val_loss: 0.6924 - val_accuracy: 0.5162\n",
      "Epoch 18/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6909 - accuracy: 0.5207 - val_loss: 0.6921 - val_accuracy: 0.5212\n",
      "Epoch 19/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6904 - accuracy: 0.5248 - val_loss: 0.6911 - val_accuracy: 0.5204\n",
      "Epoch 20/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6890 - accuracy: 0.5317 - val_loss: 0.6897 - val_accuracy: 0.5326\n",
      "Epoch 21/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6871 - accuracy: 0.5383 - val_loss: 0.6871 - val_accuracy: 0.5415\n",
      "Epoch 22/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6851 - accuracy: 0.5429 - val_loss: 0.6883 - val_accuracy: 0.5359\n",
      "Epoch 23/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6825 - accuracy: 0.5475 - val_loss: 0.6871 - val_accuracy: 0.5348\n",
      "Epoch 24/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6799 - accuracy: 0.5544 - val_loss: 0.6755 - val_accuracy: 0.5660\n",
      "Epoch 25/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6777 - accuracy: 0.5579 - val_loss: 0.6722 - val_accuracy: 0.5700\n",
      "Epoch 26/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6716 - accuracy: 0.5694 - val_loss: 0.6720 - val_accuracy: 0.5733\n",
      "Epoch 27/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6890 - accuracy: 0.5303 - val_loss: 0.6888 - val_accuracy: 0.5342\n",
      "Epoch 28/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6737 - accuracy: 0.5657 - val_loss: 0.6898 - val_accuracy: 0.5336\n",
      "Epoch 29/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6886 - accuracy: 0.5295 - val_loss: 0.6942 - val_accuracy: 0.5041\n",
      "Epoch 30/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5137 - val_loss: 0.6924 - val_accuracy: 0.5192\n",
      "Epoch 31/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6915 - val_accuracy: 0.5215\n",
      "Epoch 32/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6909 - accuracy: 0.5244 - val_loss: 0.6918 - val_accuracy: 0.5133\n",
      "Epoch 33/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6896 - accuracy: 0.5282 - val_loss: 0.6911 - val_accuracy: 0.5148\n",
      "Epoch 34/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6876 - accuracy: 0.5343 - val_loss: 0.6879 - val_accuracy: 0.5313\n",
      "Epoch 35/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6843 - accuracy: 0.5464 - val_loss: 0.6846 - val_accuracy: 0.5432\n",
      "Epoch 36/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6800 - accuracy: 0.5572 - val_loss: 0.6797 - val_accuracy: 0.5556\n",
      "Epoch 37/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6760 - accuracy: 0.5657 - val_loss: 0.6754 - val_accuracy: 0.5668\n",
      "Epoch 38/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6724 - accuracy: 0.5697 - val_loss: 0.6685 - val_accuracy: 0.5790\n",
      "Epoch 39/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6825 - accuracy: 0.5513 - val_loss: 0.7011 - val_accuracy: 0.5094\n",
      "Epoch 40/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6934 - accuracy: 0.5113 - val_loss: 0.6929 - val_accuracy: 0.5116\n",
      "Epoch 41/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6922 - accuracy: 0.5143 - val_loss: 0.6923 - val_accuracy: 0.5113\n",
      "Epoch 42/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6914 - accuracy: 0.5184 - val_loss: 0.6915 - val_accuracy: 0.5178\n",
      "Epoch 43/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6904 - accuracy: 0.5217 - val_loss: 0.6902 - val_accuracy: 0.5257\n",
      "Epoch 44/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6862 - accuracy: 0.5392 - val_loss: 0.6859 - val_accuracy: 0.5431\n",
      "Epoch 45/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6867 - accuracy: 0.5369 - val_loss: 0.6948 - val_accuracy: 0.5125\n",
      "Epoch 46/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6908 - accuracy: 0.5222 - val_loss: 0.6895 - val_accuracy: 0.5264\n",
      "Epoch 47/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6829 - accuracy: 0.5481 - val_loss: 0.6888 - val_accuracy: 0.5303\n",
      "Epoch 48/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6725 - accuracy: 0.5682 - val_loss: 0.6695 - val_accuracy: 0.5734\n",
      "Epoch 49/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6824 - accuracy: 0.5422 - val_loss: 0.6884 - val_accuracy: 0.5251\n",
      "Epoch 50/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6777 - accuracy: 0.5556 - val_loss: 0.6942 - val_accuracy: 0.5298\n",
      "Epoch 51/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6707 - accuracy: 0.5722 - val_loss: 0.6830 - val_accuracy: 0.5605\n",
      "Epoch 52/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6661 - accuracy: 0.5787 - val_loss: 0.6658 - val_accuracy: 0.5753\n",
      "Epoch 53/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6609 - accuracy: 0.5871 - val_loss: 0.6585 - val_accuracy: 0.5925\n",
      "Epoch 54/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6582 - accuracy: 0.5913 - val_loss: 0.6630 - val_accuracy: 0.5813\n",
      "Epoch 55/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6627 - accuracy: 0.5830 - val_loss: 0.7390 - val_accuracy: 0.5145\n",
      "Epoch 56/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6774 - accuracy: 0.5546 - val_loss: 0.6695 - val_accuracy: 0.5753\n",
      "Epoch 57/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6597 - accuracy: 0.5902 - val_loss: 0.7133 - val_accuracy: 0.5292\n",
      "Epoch 58/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6592 - accuracy: 0.5868 - val_loss: 0.6519 - val_accuracy: 0.6004\n",
      "Epoch 59/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6604 - accuracy: 0.5870 - val_loss: 0.6560 - val_accuracy: 0.5991\n",
      "Epoch 60/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6513 - accuracy: 0.6005 - val_loss: 0.6514 - val_accuracy: 0.6016\n",
      "Epoch 61/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6492 - accuracy: 0.6030 - val_loss: 0.6588 - val_accuracy: 0.5864\n",
      "Epoch 62/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6469 - accuracy: 0.6064 - val_loss: 0.6481 - val_accuracy: 0.6061\n",
      "Epoch 63/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6484 - accuracy: 0.6045 - val_loss: 0.6512 - val_accuracy: 0.6041\n",
      "Epoch 64/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6446 - accuracy: 0.6101 - val_loss: 0.6411 - val_accuracy: 0.6142\n",
      "Epoch 65/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6603 - accuracy: 0.5860 - val_loss: 0.6923 - val_accuracy: 0.5372\n",
      "Epoch 66/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6663 - accuracy: 0.5754 - val_loss: 0.6570 - val_accuracy: 0.5938\n",
      "Epoch 67/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6536 - accuracy: 0.5974 - val_loss: 0.6689 - val_accuracy: 0.5821\n",
      "Epoch 68/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6457 - accuracy: 0.6110 - val_loss: 0.6398 - val_accuracy: 0.6197\n",
      "Epoch 69/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6472 - accuracy: 0.6081 - val_loss: 0.6409 - val_accuracy: 0.6175\n",
      "Epoch 70/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6483 - accuracy: 0.6069 - val_loss: 0.6438 - val_accuracy: 0.6118\n",
      "Epoch 71/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6452 - accuracy: 0.6103 - val_loss: 0.6488 - val_accuracy: 0.6031\n",
      "Epoch 72/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6430 - accuracy: 0.6127 - val_loss: 0.6561 - val_accuracy: 0.6085\n",
      "Epoch 73/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6421 - accuracy: 0.6136 - val_loss: 0.6369 - val_accuracy: 0.6228\n",
      "Epoch 74/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6441 - accuracy: 0.6118 - val_loss: 0.6463 - val_accuracy: 0.6122\n",
      "Epoch 75/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6397 - accuracy: 0.6169 - val_loss: 0.6369 - val_accuracy: 0.6253\n",
      "Epoch 76/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6388 - accuracy: 0.6190 - val_loss: 0.6450 - val_accuracy: 0.6185\n",
      "Epoch 77/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6392 - accuracy: 0.6178 - val_loss: 0.6363 - val_accuracy: 0.6228\n",
      "Epoch 78/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6889 - accuracy: 0.5212 - val_loss: 0.6941 - val_accuracy: 0.5024\n",
      "Epoch 79/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.5107 - val_loss: 0.6934 - val_accuracy: 0.5102\n",
      "Epoch 80/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6925 - accuracy: 0.5144 - val_loss: 0.6927 - val_accuracy: 0.5133\n",
      "Epoch 81/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6919 - accuracy: 0.5182 - val_loss: 0.6920 - val_accuracy: 0.5188\n",
      "Epoch 82/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6905 - accuracy: 0.5241 - val_loss: 0.6893 - val_accuracy: 0.5268\n",
      "Epoch 83/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6737 - accuracy: 0.5672 - val_loss: 0.6777 - val_accuracy: 0.5709\n",
      "Epoch 84/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6531 - accuracy: 0.5997 - val_loss: 0.6574 - val_accuracy: 0.5953\n",
      "Epoch 85/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6498 - accuracy: 0.6041 - val_loss: 0.6606 - val_accuracy: 0.5760\n",
      "Epoch 86/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6431 - accuracy: 0.6120 - val_loss: 0.6578 - val_accuracy: 0.5927\n",
      "Epoch 87/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6424 - accuracy: 0.6140 - val_loss: 0.6467 - val_accuracy: 0.6083\n",
      "Epoch 88/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6423 - accuracy: 0.6144 - val_loss: 0.6402 - val_accuracy: 0.6195\n",
      "Epoch 89/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6582 - accuracy: 0.5899 - val_loss: 0.6591 - val_accuracy: 0.5897\n",
      "Epoch 90/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6423 - accuracy: 0.6137 - val_loss: 0.6453 - val_accuracy: 0.6074\n",
      "Epoch 91/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6532 - accuracy: 0.5987 - val_loss: 0.6403 - val_accuracy: 0.6180\n",
      "Epoch 92/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6419 - accuracy: 0.6151 - val_loss: 0.6362 - val_accuracy: 0.6192\n",
      "Epoch 93/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6412 - accuracy: 0.6161 - val_loss: 0.6361 - val_accuracy: 0.6241\n",
      "Epoch 94/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6362 - accuracy: 0.6209 - val_loss: 0.6520 - val_accuracy: 0.6094\n",
      "Epoch 95/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6425 - accuracy: 0.6134 - val_loss: 0.6353 - val_accuracy: 0.6228\n",
      "Epoch 96/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6359 - accuracy: 0.6211 - val_loss: 0.6328 - val_accuracy: 0.6296\n",
      "Epoch 97/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6392 - accuracy: 0.6188 - val_loss: 0.6370 - val_accuracy: 0.6231\n",
      "Epoch 98/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6586 - accuracy: 0.5824 - val_loss: 0.6962 - val_accuracy: 0.5035\n",
      "Epoch 99/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6938 - accuracy: 0.5083 - val_loss: 0.6935 - val_accuracy: 0.5088\n",
      "Epoch 100/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5124 - val_loss: 0.6929 - val_accuracy: 0.5116\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_14\n",
      "cannot prune layer q_activation_14\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_15\n",
      "cannot prune layer q_activation_15\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 0.6786 - accuracy: 0.5503 - val_loss: 0.6843 - val_accuracy: 0.5517\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6569 - accuracy: 0.5929 - val_loss: 0.6844 - val_accuracy: 0.5681\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6431 - accuracy: 0.6126 - val_loss: 0.6363 - val_accuracy: 0.6183\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6394 - accuracy: 0.6160 - val_loss: 0.6322 - val_accuracy: 0.6286\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6377 - accuracy: 0.6182 - val_loss: 0.6419 - val_accuracy: 0.6129\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6356 - accuracy: 0.6216 - val_loss: 0.6261 - val_accuracy: 0.6338\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6402 - accuracy: 0.6173 - val_loss: 0.6328 - val_accuracy: 0.6237\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6338 - accuracy: 0.6251 - val_loss: 0.6373 - val_accuracy: 0.6199\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6366 - accuracy: 0.6215 - val_loss: 0.6505 - val_accuracy: 0.5993\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6373 - accuracy: 0.6225 - val_loss: 0.6256 - val_accuracy: 0.6374\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6349 - accuracy: 0.6242 - val_loss: 0.6356 - val_accuracy: 0.6199\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6313 - accuracy: 0.6277 - val_loss: 0.6259 - val_accuracy: 0.6360\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6319 - accuracy: 0.6263 - val_loss: 0.6376 - val_accuracy: 0.6234\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6303 - accuracy: 0.6286 - val_loss: 0.6271 - val_accuracy: 0.6338\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6301 - accuracy: 0.6285 - val_loss: 0.6352 - val_accuracy: 0.6257\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6301 - accuracy: 0.6296 - val_loss: 0.6240 - val_accuracy: 0.6354\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6315 - accuracy: 0.6273 - val_loss: 0.6280 - val_accuracy: 0.6367\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6880 - accuracy: 0.5424 - val_loss: 0.6863 - val_accuracy: 0.5466\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6707 - accuracy: 0.5757 - val_loss: 0.6736 - val_accuracy: 0.5735\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6529 - accuracy: 0.6004 - val_loss: 0.6643 - val_accuracy: 0.5894\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6487 - accuracy: 0.6055 - val_loss: 0.6453 - val_accuracy: 0.6081\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6413 - accuracy: 0.6143 - val_loss: 0.6316 - val_accuracy: 0.6331\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6353 - accuracy: 0.6223 - val_loss: 0.6557 - val_accuracy: 0.6086\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6330 - accuracy: 0.6258 - val_loss: 0.6251 - val_accuracy: 0.6377\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6311 - accuracy: 0.6281 - val_loss: 0.6326 - val_accuracy: 0.6268\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6308 - accuracy: 0.6280 - val_loss: 0.6252 - val_accuracy: 0.6386\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6294 - accuracy: 0.6294 - val_loss: 0.6308 - val_accuracy: 0.6312\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6331 - accuracy: 0.6263 - val_loss: 0.6449 - val_accuracy: 0.6094\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6453 - accuracy: 0.6109 - val_loss: 0.6314 - val_accuracy: 0.6300\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6329 - accuracy: 0.6250 - val_loss: 0.6222 - val_accuracy: 0.6377\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6289 - accuracy: 0.6301 - val_loss: 0.6617 - val_accuracy: 0.5980\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6296 - accuracy: 0.6302 - val_loss: 0.6263 - val_accuracy: 0.6343\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6617 - accuracy: 0.5820 - val_loss: 0.6928 - val_accuracy: 0.5257\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6774 - accuracy: 0.5692 - val_loss: 0.6738 - val_accuracy: 0.5772\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6618 - accuracy: 0.5915 - val_loss: 0.7328 - val_accuracy: 0.5129\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6881 - accuracy: 0.5376 - val_loss: 0.6809 - val_accuracy: 0.5547\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6627 - accuracy: 0.5845 - val_loss: 0.6514 - val_accuracy: 0.6049\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6517 - accuracy: 0.6025 - val_loss: 0.6421 - val_accuracy: 0.6178\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6458 - accuracy: 0.6105 - val_loss: 0.6386 - val_accuracy: 0.6180\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6821 - accuracy: 0.5422 - val_loss: 0.6945 - val_accuracy: 0.5078\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6938 - accuracy: 0.5073 - val_loss: 0.6934 - val_accuracy: 0.5090\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6936 - accuracy: 0.5096 - val_loss: 0.6931 - val_accuracy: 0.5114\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6937 - accuracy: 0.5103 - val_loss: 0.6927 - val_accuracy: 0.5125\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5169 - val_loss: 0.6910 - val_accuracy: 0.5273\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6884 - accuracy: 0.5351 - val_loss: 0.6875 - val_accuracy: 0.5426\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6777 - accuracy: 0.5590 - val_loss: 0.6766 - val_accuracy: 0.5608\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6661 - accuracy: 0.5786 - val_loss: 0.6736 - val_accuracy: 0.5668\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6877 - accuracy: 0.5309 - val_loss: 0.6950 - val_accuracy: 0.5034\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.5139 - val_loss: 0.6917 - val_accuracy: 0.5177\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6886 - accuracy: 0.5275 - val_loss: 0.6946 - val_accuracy: 0.4959\n",
      "1714/1714 [==============================] - 3s 1ms/step\n",
      "[[0.57860184]\n",
      " [0.4681773 ]\n",
      " [0.50782657]\n",
      " [0.35732043]\n",
      " [0.5037447 ]\n",
      " [0.44601753]\n",
      " [0.5309791 ]\n",
      " [0.407016  ]\n",
      " [0.44573385]\n",
      " [0.42590088]]\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.002, 'BATCH_SIZE': 1024, 'EPOCHS': 150, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.15, 'POST_PRUNE_EPOCHS': 50}\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 24)                96        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_16 (QActivati  (None, 24)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 12)                48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_17 (QActivati  (None, 12)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_16 is normal keras bn layer\n",
      "q_activation_16      quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_17 is normal keras bn layer\n",
      "q_activation_17      quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/150\n",
      "429/429 [==============================] - 6s 7ms/step - loss: 0.7413 - accuracy: 0.5034 - val_loss: 0.6978 - val_accuracy: 0.5070\n",
      "Epoch 2/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6958 - accuracy: 0.5070 - val_loss: 0.6949 - val_accuracy: 0.5107\n",
      "Epoch 3/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6941 - accuracy: 0.5098 - val_loss: 0.6945 - val_accuracy: 0.5095\n",
      "Epoch 4/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6934 - accuracy: 0.5113 - val_loss: 0.6939 - val_accuracy: 0.5100\n",
      "Epoch 5/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.5120 - val_loss: 0.6933 - val_accuracy: 0.5120\n",
      "Epoch 6/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6936 - accuracy: 0.5120 - val_loss: 0.6934 - val_accuracy: 0.5058\n",
      "Epoch 7/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6934 - accuracy: 0.5116 - val_loss: 0.6927 - val_accuracy: 0.5131\n",
      "Epoch 8/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6927 - accuracy: 0.5138 - val_loss: 0.6927 - val_accuracy: 0.5130\n",
      "Epoch 9/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6925 - accuracy: 0.5158 - val_loss: 0.6925 - val_accuracy: 0.5153\n",
      "Epoch 10/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5162 - val_loss: 0.6926 - val_accuracy: 0.5150\n",
      "Epoch 11/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6922 - val_accuracy: 0.5185\n",
      "Epoch 12/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6923 - val_accuracy: 0.5113\n",
      "Epoch 13/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6906 - accuracy: 0.5243 - val_loss: 0.6908 - val_accuracy: 0.5258\n",
      "Epoch 14/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6895 - accuracy: 0.5289 - val_loss: 0.6887 - val_accuracy: 0.5324\n",
      "Epoch 15/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6878 - accuracy: 0.5358 - val_loss: 0.6876 - val_accuracy: 0.5333\n",
      "Epoch 16/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6843 - accuracy: 0.5450 - val_loss: 0.6872 - val_accuracy: 0.5352\n",
      "Epoch 17/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6807 - accuracy: 0.5536 - val_loss: 0.6771 - val_accuracy: 0.5638\n",
      "Epoch 18/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6769 - accuracy: 0.5615 - val_loss: 0.6802 - val_accuracy: 0.5544\n",
      "Epoch 19/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6726 - accuracy: 0.5682 - val_loss: 0.6700 - val_accuracy: 0.5755\n",
      "Epoch 20/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6691 - accuracy: 0.5738 - val_loss: 0.6676 - val_accuracy: 0.5776\n",
      "Epoch 21/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6658 - accuracy: 0.5803 - val_loss: 0.6651 - val_accuracy: 0.5788\n",
      "Epoch 22/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6642 - accuracy: 0.5820 - val_loss: 0.6685 - val_accuracy: 0.5741\n",
      "Epoch 23/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6618 - accuracy: 0.5868 - val_loss: 0.6655 - val_accuracy: 0.5776\n",
      "Epoch 24/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6614 - accuracy: 0.5869 - val_loss: 0.6617 - val_accuracy: 0.5864\n",
      "Epoch 25/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6580 - accuracy: 0.5923 - val_loss: 0.6587 - val_accuracy: 0.5929\n",
      "Epoch 26/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6581 - accuracy: 0.5938 - val_loss: 0.6489 - val_accuracy: 0.6079\n",
      "Epoch 27/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6575 - accuracy: 0.5963 - val_loss: 0.6526 - val_accuracy: 0.6046\n",
      "Epoch 28/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6583 - accuracy: 0.5970 - val_loss: 0.6643 - val_accuracy: 0.5836\n",
      "Epoch 29/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6568 - accuracy: 0.5991 - val_loss: 0.6500 - val_accuracy: 0.6078\n",
      "Epoch 30/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6566 - accuracy: 0.5992 - val_loss: 0.6488 - val_accuracy: 0.6106\n",
      "Epoch 31/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6903 - accuracy: 0.5230 - val_loss: 0.6937 - val_accuracy: 0.5036\n",
      "Epoch 32/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5132 - val_loss: 0.6929 - val_accuracy: 0.5120\n",
      "Epoch 33/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6921 - val_accuracy: 0.5157\n",
      "Epoch 34/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6911 - accuracy: 0.5214 - val_loss: 0.6914 - val_accuracy: 0.5208\n",
      "Epoch 35/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6898 - accuracy: 0.5308 - val_loss: 0.6892 - val_accuracy: 0.5344\n",
      "Epoch 36/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6858 - accuracy: 0.5470 - val_loss: 0.6909 - val_accuracy: 0.5087\n",
      "Epoch 37/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6755 - accuracy: 0.5666 - val_loss: 0.6768 - val_accuracy: 0.5668\n",
      "Epoch 38/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6649 - accuracy: 0.5819 - val_loss: 0.6660 - val_accuracy: 0.5866\n",
      "Epoch 39/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6615 - accuracy: 0.5870 - val_loss: 0.6642 - val_accuracy: 0.5790\n",
      "Epoch 40/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6611 - accuracy: 0.5877 - val_loss: 0.6599 - val_accuracy: 0.5863\n",
      "Epoch 41/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6609 - accuracy: 0.5870 - val_loss: 0.6469 - val_accuracy: 0.6059\n",
      "Epoch 42/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6514 - accuracy: 0.5997 - val_loss: 0.6486 - val_accuracy: 0.6009\n",
      "Epoch 43/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6471 - accuracy: 0.6046 - val_loss: 0.6424 - val_accuracy: 0.6151\n",
      "Epoch 44/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6464 - accuracy: 0.6076 - val_loss: 0.6502 - val_accuracy: 0.6067\n",
      "Epoch 45/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6454 - accuracy: 0.6081 - val_loss: 0.6405 - val_accuracy: 0.6166\n",
      "Epoch 46/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6471 - accuracy: 0.6062 - val_loss: 0.6519 - val_accuracy: 0.5982\n",
      "Epoch 47/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6457 - accuracy: 0.6082 - val_loss: 0.6415 - val_accuracy: 0.6184\n",
      "Epoch 48/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6410 - accuracy: 0.6146 - val_loss: 0.6343 - val_accuracy: 0.6278\n",
      "Epoch 49/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6577 - accuracy: 0.5918 - val_loss: 0.7327 - val_accuracy: 0.4982\n",
      "Epoch 50/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6946 - accuracy: 0.5072 - val_loss: 0.6931 - val_accuracy: 0.5132\n",
      "Epoch 51/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6927 - accuracy: 0.5118 - val_loss: 0.6929 - val_accuracy: 0.5111\n",
      "Epoch 52/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6921 - accuracy: 0.5144 - val_loss: 0.6921 - val_accuracy: 0.5142\n",
      "Epoch 53/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6916 - accuracy: 0.5175 - val_loss: 0.6916 - val_accuracy: 0.5191\n",
      "Epoch 54/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6909 - accuracy: 0.5217 - val_loss: 0.6909 - val_accuracy: 0.5239\n",
      "Epoch 55/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6891 - accuracy: 0.5304 - val_loss: 0.6887 - val_accuracy: 0.5319\n",
      "Epoch 56/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6834 - accuracy: 0.5453 - val_loss: 0.6853 - val_accuracy: 0.5301\n",
      "Epoch 57/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6757 - accuracy: 0.5637 - val_loss: 0.6687 - val_accuracy: 0.5756\n",
      "Epoch 58/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6679 - accuracy: 0.5780 - val_loss: 0.6842 - val_accuracy: 0.5482\n",
      "Epoch 59/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6564 - accuracy: 0.5929 - val_loss: 0.6458 - val_accuracy: 0.6066\n",
      "Epoch 60/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6478 - accuracy: 0.6057 - val_loss: 0.6511 - val_accuracy: 0.5950\n",
      "Epoch 61/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6443 - accuracy: 0.6101 - val_loss: 0.6378 - val_accuracy: 0.6206\n",
      "Epoch 62/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6414 - accuracy: 0.6140 - val_loss: 0.6417 - val_accuracy: 0.6093\n",
      "Epoch 63/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6418 - accuracy: 0.6135 - val_loss: 0.6379 - val_accuracy: 0.6163\n",
      "Epoch 64/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6490 - accuracy: 0.6037 - val_loss: 0.6359 - val_accuracy: 0.6222\n",
      "Epoch 65/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6395 - accuracy: 0.6164 - val_loss: 0.6308 - val_accuracy: 0.6257\n",
      "Epoch 66/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6395 - accuracy: 0.6174 - val_loss: 0.6554 - val_accuracy: 0.6037\n",
      "Epoch 67/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6385 - accuracy: 0.6180 - val_loss: 0.6311 - val_accuracy: 0.6277\n",
      "Epoch 68/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6458 - accuracy: 0.6086 - val_loss: 0.7012 - val_accuracy: 0.5083\n",
      "Epoch 69/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6890 - accuracy: 0.5296 - val_loss: 0.6872 - val_accuracy: 0.5397\n",
      "Epoch 70/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6609 - accuracy: 0.5944 - val_loss: 0.6483 - val_accuracy: 0.6131\n",
      "Epoch 71/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6519 - accuracy: 0.6076 - val_loss: 0.6680 - val_accuracy: 0.5722\n",
      "Epoch 72/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6821 - accuracy: 0.5533 - val_loss: 0.6825 - val_accuracy: 0.5497\n",
      "Epoch 73/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6634 - accuracy: 0.5866 - val_loss: 0.6665 - val_accuracy: 0.5809\n",
      "Epoch 74/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6572 - accuracy: 0.5966 - val_loss: 0.6501 - val_accuracy: 0.6052\n",
      "Epoch 75/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6666 - accuracy: 0.5744 - val_loss: 0.6994 - val_accuracy: 0.5002\n",
      "Epoch 76/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5139 - val_loss: 0.6903 - val_accuracy: 0.5173\n",
      "Epoch 77/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6866 - accuracy: 0.5290 - val_loss: 0.6839 - val_accuracy: 0.5354\n",
      "Epoch 78/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6781 - accuracy: 0.5541 - val_loss: 0.6742 - val_accuracy: 0.5683\n",
      "Epoch 79/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6654 - accuracy: 0.5774 - val_loss: 0.6578 - val_accuracy: 0.5920\n",
      "Epoch 80/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6568 - accuracy: 0.5926 - val_loss: 0.6454 - val_accuracy: 0.6086\n",
      "Epoch 81/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6536 - accuracy: 0.5991 - val_loss: 0.6693 - val_accuracy: 0.5896\n",
      "Epoch 82/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6505 - accuracy: 0.6043 - val_loss: 0.6618 - val_accuracy: 0.5903\n",
      "Epoch 83/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6457 - accuracy: 0.6110 - val_loss: 0.6408 - val_accuracy: 0.6171\n",
      "Epoch 84/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6442 - accuracy: 0.6146 - val_loss: 0.6340 - val_accuracy: 0.6286\n",
      "Epoch 85/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6878 - accuracy: 0.5395 - val_loss: 0.6844 - val_accuracy: 0.5532\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_16\n",
      "cannot prune layer q_activation_16\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_17\n",
      "cannot prune layer q_activation_17\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 0.6388 - accuracy: 0.6187 - val_loss: 0.6367 - val_accuracy: 0.6193\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6361 - accuracy: 0.6218 - val_loss: 0.6340 - val_accuracy: 0.6254\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6362 - accuracy: 0.6217 - val_loss: 0.6314 - val_accuracy: 0.6273\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6347 - accuracy: 0.6236 - val_loss: 0.6433 - val_accuracy: 0.6122\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6349 - accuracy: 0.6236 - val_loss: 0.6316 - val_accuracy: 0.6209\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6637 - accuracy: 0.5744 - val_loss: 0.6949 - val_accuracy: 0.5022\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6918 - accuracy: 0.5203 - val_loss: 0.6906 - val_accuracy: 0.5265\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6836 - accuracy: 0.5481 - val_loss: 0.6760 - val_accuracy: 0.5696\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6809 - accuracy: 0.5529 - val_loss: 0.6891 - val_accuracy: 0.5236\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6784 - accuracy: 0.5598 - val_loss: 0.6721 - val_accuracy: 0.5735\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6663 - accuracy: 0.5841 - val_loss: 0.6639 - val_accuracy: 0.5869\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6601 - accuracy: 0.5948 - val_loss: 0.6733 - val_accuracy: 0.5761\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6636 - accuracy: 0.5938 - val_loss: 0.6612 - val_accuracy: 0.5852\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6721 - accuracy: 0.5730 - val_loss: 0.6719 - val_accuracy: 0.5776\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6763 - accuracy: 0.5566 - val_loss: 0.6947 - val_accuracy: 0.5055\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6935 - accuracy: 0.5059 - val_loss: 0.6930 - val_accuracy: 0.5069\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.5094 - val_loss: 0.6926 - val_accuracy: 0.5072\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5130 - val_loss: 0.6922 - val_accuracy: 0.5178\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6919 - accuracy: 0.5150 - val_loss: 0.6917 - val_accuracy: 0.5159\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6906 - accuracy: 0.5217 - val_loss: 0.6894 - val_accuracy: 0.5287\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6817 - accuracy: 0.5497 - val_loss: 0.6797 - val_accuracy: 0.5556\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6643 - accuracy: 0.5878 - val_loss: 0.6692 - val_accuracy: 0.5758\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6811 - accuracy: 0.5575 - val_loss: 0.6702 - val_accuracy: 0.5773\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6580 - accuracy: 0.5982 - val_loss: 0.7316 - val_accuracy: 0.5261\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6693 - accuracy: 0.5749 - val_loss: 0.6472 - val_accuracy: 0.6160\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6622 - accuracy: 0.5927 - val_loss: 0.6654 - val_accuracy: 0.5941\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6809 - accuracy: 0.5586 - val_loss: 0.6986 - val_accuracy: 0.5148\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6586 - accuracy: 0.5987 - val_loss: 0.7398 - val_accuracy: 0.5118\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6927 - accuracy: 0.5229 - val_loss: 0.6871 - val_accuracy: 0.5340\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6620 - accuracy: 0.5860 - val_loss: 0.6635 - val_accuracy: 0.5909\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6581 - accuracy: 0.5965 - val_loss: 0.6538 - val_accuracy: 0.6011\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6662 - accuracy: 0.5812 - val_loss: 0.6965 - val_accuracy: 0.5164\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6881 - accuracy: 0.5308 - val_loss: 0.6849 - val_accuracy: 0.5453\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6789 - accuracy: 0.5578 - val_loss: 0.6984 - val_accuracy: 0.5057\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6938 - accuracy: 0.5119 - val_loss: 0.6926 - val_accuracy: 0.5145\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6912 - accuracy: 0.5213 - val_loss: 0.6905 - val_accuracy: 0.5214\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6879 - accuracy: 0.5362 - val_loss: 0.6884 - val_accuracy: 0.5346\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6780 - accuracy: 0.5599 - val_loss: 0.6791 - val_accuracy: 0.5557\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6692 - accuracy: 0.5753 - val_loss: 0.6682 - val_accuracy: 0.5677\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6717 - accuracy: 0.5709 - val_loss: 0.6614 - val_accuracy: 0.5952\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6589 - accuracy: 0.5938 - val_loss: 0.6634 - val_accuracy: 0.5948\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6531 - accuracy: 0.6020 - val_loss: 0.6448 - val_accuracy: 0.6138\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6939 - accuracy: 0.5195 - val_loss: 0.6919 - val_accuracy: 0.5231\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6901 - accuracy: 0.5297 - val_loss: 0.6891 - val_accuracy: 0.5342\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6759 - accuracy: 0.5623 - val_loss: 0.6717 - val_accuracy: 0.5771\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6715 - accuracy: 0.5646 - val_loss: 0.6939 - val_accuracy: 0.5096\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6921 - accuracy: 0.5149 - val_loss: 0.6911 - val_accuracy: 0.5204\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6783 - accuracy: 0.5543 - val_loss: 0.6844 - val_accuracy: 0.5511\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6610 - accuracy: 0.5913 - val_loss: 0.6550 - val_accuracy: 0.6019\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6565 - accuracy: 0.5972 - val_loss: 0.6521 - val_accuracy: 0.6043\n",
      "1714/1714 [==============================] - 3s 2ms/step\n",
      "[[0.52129084]\n",
      " [0.6688272 ]\n",
      " [0.5304559 ]\n",
      " [0.60305125]\n",
      " [0.5601564 ]\n",
      " [0.5109614 ]\n",
      " [0.6675839 ]\n",
      " [0.28996265]\n",
      " [0.6721605 ]\n",
      " [0.4360184 ]]\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.001, 'BATCH_SIZE': 1024, 'EPOCHS': 100, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.15, 'POST_PRUNE_EPOCHS': 50}\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 24)                96        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_18 (QActivati  (None, 24)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 12)                48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_19 (QActivati  (None, 12)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_18 is normal keras bn layer\n",
      "q_activation_18      quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_19 is normal keras bn layer\n",
      "q_activation_19      quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/100\n",
      "429/429 [==============================] - 6s 7ms/step - loss: 3.2540 - accuracy: 0.5018 - val_loss: 1.1143 - val_accuracy: 0.4962\n",
      "Epoch 2/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7801 - accuracy: 0.5008 - val_loss: 0.7196 - val_accuracy: 0.5032\n",
      "Epoch 3/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7114 - accuracy: 0.5026 - val_loss: 0.7057 - val_accuracy: 0.5038\n",
      "Epoch 4/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7038 - accuracy: 0.5036 - val_loss: 0.7014 - val_accuracy: 0.5033\n",
      "Epoch 5/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7005 - accuracy: 0.5034 - val_loss: 0.6993 - val_accuracy: 0.5024\n",
      "Epoch 6/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6987 - accuracy: 0.5042 - val_loss: 0.6980 - val_accuracy: 0.5048\n",
      "Epoch 7/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6975 - accuracy: 0.5049 - val_loss: 0.6970 - val_accuracy: 0.5053\n",
      "Epoch 8/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6966 - accuracy: 0.5044 - val_loss: 0.6962 - val_accuracy: 0.5060\n",
      "Epoch 9/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6959 - accuracy: 0.5043 - val_loss: 0.6958 - val_accuracy: 0.5090\n",
      "Epoch 10/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6952 - accuracy: 0.5059 - val_loss: 0.6950 - val_accuracy: 0.5063\n",
      "Epoch 11/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6946 - accuracy: 0.5070 - val_loss: 0.6945 - val_accuracy: 0.5086\n",
      "Epoch 12/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6941 - accuracy: 0.5077 - val_loss: 0.6941 - val_accuracy: 0.5090\n",
      "Epoch 13/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6937 - accuracy: 0.5092 - val_loss: 0.6938 - val_accuracy: 0.5092\n",
      "Epoch 14/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6934 - accuracy: 0.5100 - val_loss: 0.6937 - val_accuracy: 0.5097\n",
      "Epoch 15/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6932 - accuracy: 0.5096 - val_loss: 0.6936 - val_accuracy: 0.5080\n",
      "Epoch 16/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6930 - accuracy: 0.5101 - val_loss: 0.6936 - val_accuracy: 0.5096\n",
      "Epoch 17/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.5116 - val_loss: 0.6931 - val_accuracy: 0.5129\n",
      "Epoch 18/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5117 - val_loss: 0.6933 - val_accuracy: 0.5115\n",
      "Epoch 19/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6925 - accuracy: 0.5127 - val_loss: 0.6931 - val_accuracy: 0.5154\n",
      "Epoch 20/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5129 - val_loss: 0.6931 - val_accuracy: 0.5101\n",
      "Epoch 21/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6922 - accuracy: 0.5138 - val_loss: 0.6928 - val_accuracy: 0.5133\n",
      "Epoch 22/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6920 - accuracy: 0.5154 - val_loss: 0.6925 - val_accuracy: 0.5133\n",
      "Epoch 23/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6918 - accuracy: 0.5173 - val_loss: 0.6925 - val_accuracy: 0.5160\n",
      "Epoch 24/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6912 - accuracy: 0.5229 - val_loss: 0.6916 - val_accuracy: 0.5264\n",
      "Epoch 25/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6905 - accuracy: 0.5270 - val_loss: 0.6905 - val_accuracy: 0.5317\n",
      "Epoch 26/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6896 - accuracy: 0.5300 - val_loss: 0.6904 - val_accuracy: 0.5303\n",
      "Epoch 27/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6886 - accuracy: 0.5343 - val_loss: 0.6884 - val_accuracy: 0.5354\n",
      "Epoch 28/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6870 - accuracy: 0.5400 - val_loss: 0.6867 - val_accuracy: 0.5418\n",
      "Epoch 29/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6850 - accuracy: 0.5463 - val_loss: 0.6839 - val_accuracy: 0.5523\n",
      "Epoch 30/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6827 - accuracy: 0.5518 - val_loss: 0.6819 - val_accuracy: 0.5584\n",
      "Epoch 31/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6800 - accuracy: 0.5591 - val_loss: 0.6808 - val_accuracy: 0.5555\n",
      "Epoch 32/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6781 - accuracy: 0.5634 - val_loss: 0.6789 - val_accuracy: 0.5613\n",
      "Epoch 33/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6758 - accuracy: 0.5677 - val_loss: 0.6743 - val_accuracy: 0.5727\n",
      "Epoch 34/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6738 - accuracy: 0.5722 - val_loss: 0.6742 - val_accuracy: 0.5685\n",
      "Epoch 35/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6714 - accuracy: 0.5769 - val_loss: 0.6720 - val_accuracy: 0.5751\n",
      "Epoch 36/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6700 - accuracy: 0.5783 - val_loss: 0.6715 - val_accuracy: 0.5781\n",
      "Epoch 37/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6674 - accuracy: 0.5831 - val_loss: 0.6680 - val_accuracy: 0.5799\n",
      "Epoch 38/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6663 - accuracy: 0.5859 - val_loss: 0.6672 - val_accuracy: 0.5818\n",
      "Epoch 39/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6645 - accuracy: 0.5876 - val_loss: 0.6615 - val_accuracy: 0.5982\n",
      "Epoch 40/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6636 - accuracy: 0.5888 - val_loss: 0.6609 - val_accuracy: 0.5952\n",
      "Epoch 41/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6619 - accuracy: 0.5920 - val_loss: 0.6616 - val_accuracy: 0.5928\n",
      "Epoch 42/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6597 - accuracy: 0.5951 - val_loss: 0.6707 - val_accuracy: 0.5812\n",
      "Epoch 43/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6581 - accuracy: 0.5971 - val_loss: 0.6722 - val_accuracy: 0.5749\n",
      "Epoch 44/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6560 - accuracy: 0.6003 - val_loss: 0.6587 - val_accuracy: 0.6030\n",
      "Epoch 45/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6554 - accuracy: 0.6017 - val_loss: 0.6594 - val_accuracy: 0.5993\n",
      "Epoch 46/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6550 - accuracy: 0.6008 - val_loss: 0.6563 - val_accuracy: 0.6054\n",
      "Epoch 47/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6617 - accuracy: 0.5947 - val_loss: 0.6608 - val_accuracy: 0.5968\n",
      "Epoch 48/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6581 - accuracy: 0.6006 - val_loss: 0.6569 - val_accuracy: 0.5980\n",
      "Epoch 49/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6607 - accuracy: 0.5980 - val_loss: 0.6649 - val_accuracy: 0.5873\n",
      "Epoch 50/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6590 - accuracy: 0.5995 - val_loss: 0.6682 - val_accuracy: 0.5953\n",
      "Epoch 51/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6834 - accuracy: 0.5591 - val_loss: 0.6759 - val_accuracy: 0.5671\n",
      "Epoch 52/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6590 - accuracy: 0.5992 - val_loss: 0.6818 - val_accuracy: 0.5948\n",
      "Epoch 53/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6809 - accuracy: 0.5536 - val_loss: 0.6955 - val_accuracy: 0.5162\n",
      "Epoch 54/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6846 - accuracy: 0.5465 - val_loss: 0.6787 - val_accuracy: 0.5653\n",
      "Epoch 55/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6682 - accuracy: 0.5841 - val_loss: 0.6656 - val_accuracy: 0.5852\n",
      "Epoch 56/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6585 - accuracy: 0.6028 - val_loss: 0.6531 - val_accuracy: 0.6064\n",
      "Epoch 57/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6555 - accuracy: 0.6066 - val_loss: 0.7182 - val_accuracy: 0.5443\n",
      "Epoch 58/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6606 - accuracy: 0.5974 - val_loss: 0.6506 - val_accuracy: 0.6151\n",
      "Epoch 59/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6575 - accuracy: 0.6039 - val_loss: 0.6518 - val_accuracy: 0.6116\n",
      "Epoch 60/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6638 - accuracy: 0.5910 - val_loss: 0.6693 - val_accuracy: 0.5802\n",
      "Epoch 61/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6587 - accuracy: 0.5992 - val_loss: 0.7037 - val_accuracy: 0.5442\n",
      "Epoch 62/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6649 - accuracy: 0.5920 - val_loss: 0.6592 - val_accuracy: 0.5997\n",
      "Epoch 63/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6580 - accuracy: 0.6023 - val_loss: 0.6609 - val_accuracy: 0.5932\n",
      "Epoch 64/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6644 - accuracy: 0.5915 - val_loss: 0.6586 - val_accuracy: 0.6016\n",
      "Epoch 65/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6622 - accuracy: 0.5924 - val_loss: 0.6655 - val_accuracy: 0.5910\n",
      "Epoch 66/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6586 - accuracy: 0.6011 - val_loss: 0.6536 - val_accuracy: 0.6103\n",
      "Epoch 67/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6557 - accuracy: 0.6047 - val_loss: 0.6495 - val_accuracy: 0.6178\n",
      "Epoch 68/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6498 - accuracy: 0.6150 - val_loss: 0.6485 - val_accuracy: 0.6162\n",
      "Epoch 69/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6523 - accuracy: 0.6119 - val_loss: 0.6576 - val_accuracy: 0.6045\n",
      "Epoch 70/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6494 - accuracy: 0.6136 - val_loss: 0.6475 - val_accuracy: 0.6179\n",
      "Epoch 71/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6455 - accuracy: 0.6176 - val_loss: 0.6464 - val_accuracy: 0.6209\n",
      "Epoch 72/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6455 - accuracy: 0.6178 - val_loss: 0.6446 - val_accuracy: 0.6216\n",
      "Epoch 73/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6444 - accuracy: 0.6192 - val_loss: 0.6537 - val_accuracy: 0.6097\n",
      "Epoch 74/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6456 - accuracy: 0.6165 - val_loss: 0.6485 - val_accuracy: 0.6202\n",
      "Epoch 75/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6556 - accuracy: 0.6010 - val_loss: 0.6953 - val_accuracy: 0.5387\n",
      "Epoch 76/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6572 - accuracy: 0.5988 - val_loss: 0.6433 - val_accuracy: 0.6215\n",
      "Epoch 77/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6508 - accuracy: 0.6090 - val_loss: 0.6672 - val_accuracy: 0.5854\n",
      "Epoch 78/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6483 - accuracy: 0.6124 - val_loss: 0.6416 - val_accuracy: 0.6230\n",
      "Epoch 79/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6390 - accuracy: 0.6232 - val_loss: 0.6337 - val_accuracy: 0.6310\n",
      "Epoch 80/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6375 - accuracy: 0.6253 - val_loss: 0.6386 - val_accuracy: 0.6253\n",
      "Epoch 81/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6392 - accuracy: 0.6242 - val_loss: 0.6381 - val_accuracy: 0.6264\n",
      "Epoch 82/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6368 - accuracy: 0.6260 - val_loss: 0.6431 - val_accuracy: 0.6300\n",
      "Epoch 83/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6387 - accuracy: 0.6255 - val_loss: 0.6362 - val_accuracy: 0.6282\n",
      "Epoch 84/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6436 - accuracy: 0.6193 - val_loss: 0.6450 - val_accuracy: 0.6187\n",
      "Epoch 85/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6376 - accuracy: 0.6251 - val_loss: 0.6328 - val_accuracy: 0.6321\n",
      "Epoch 86/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6341 - accuracy: 0.6288 - val_loss: 0.6315 - val_accuracy: 0.6366\n",
      "Epoch 87/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6343 - accuracy: 0.6292 - val_loss: 0.6331 - val_accuracy: 0.6332\n",
      "Epoch 88/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6332 - accuracy: 0.6302 - val_loss: 0.6310 - val_accuracy: 0.6322\n",
      "Epoch 89/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6334 - accuracy: 0.6298 - val_loss: 0.6463 - val_accuracy: 0.6117\n",
      "Epoch 90/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6425 - accuracy: 0.6181 - val_loss: 0.7318 - val_accuracy: 0.4949\n",
      "Epoch 91/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6941 - accuracy: 0.5145 - val_loss: 0.6921 - val_accuracy: 0.5222\n",
      "Epoch 92/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6855 - accuracy: 0.5406 - val_loss: 0.6845 - val_accuracy: 0.5459\n",
      "Epoch 93/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6596 - accuracy: 0.5951 - val_loss: 0.6519 - val_accuracy: 0.6082\n",
      "Epoch 94/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6647 - accuracy: 0.5892 - val_loss: 0.6796 - val_accuracy: 0.5571\n",
      "Epoch 95/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6523 - accuracy: 0.6080 - val_loss: 0.6454 - val_accuracy: 0.6216\n",
      "Epoch 96/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6445 - accuracy: 0.6198 - val_loss: 0.6489 - val_accuracy: 0.6185\n",
      "Epoch 97/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6414 - accuracy: 0.6251 - val_loss: 0.6431 - val_accuracy: 0.6192\n",
      "Epoch 98/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6839 - accuracy: 0.5360 - val_loss: 0.6939 - val_accuracy: 0.5065\n",
      "Epoch 99/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6916 - accuracy: 0.5174 - val_loss: 0.6912 - val_accuracy: 0.5199\n",
      "Epoch 100/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6881 - accuracy: 0.5345 - val_loss: 0.6874 - val_accuracy: 0.5356\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_18\n",
      "cannot prune layer q_activation_18\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_19\n",
      "cannot prune layer q_activation_19\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 0.6638 - accuracy: 0.5889 - val_loss: 0.6604 - val_accuracy: 0.5938\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6490 - accuracy: 0.6147 - val_loss: 0.6438 - val_accuracy: 0.6282\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6474 - accuracy: 0.6149 - val_loss: 0.6697 - val_accuracy: 0.5714\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6451 - accuracy: 0.6177 - val_loss: 0.6467 - val_accuracy: 0.6177\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6401 - accuracy: 0.6241 - val_loss: 0.6398 - val_accuracy: 0.6310\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6374 - accuracy: 0.6278 - val_loss: 0.6385 - val_accuracy: 0.6297\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6349 - accuracy: 0.6313 - val_loss: 0.6501 - val_accuracy: 0.6151\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6369 - accuracy: 0.6293 - val_loss: 0.6317 - val_accuracy: 0.6403\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6390 - accuracy: 0.6272 - val_loss: 0.6333 - val_accuracy: 0.6328\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6471 - accuracy: 0.6160 - val_loss: 0.6367 - val_accuracy: 0.6344\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6501 - accuracy: 0.6080 - val_loss: 0.6917 - val_accuracy: 0.5314\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6782 - accuracy: 0.5591 - val_loss: 0.6962 - val_accuracy: 0.5112\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6904 - accuracy: 0.5297 - val_loss: 0.6876 - val_accuracy: 0.5392\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6731 - accuracy: 0.5720 - val_loss: 0.6653 - val_accuracy: 0.5903\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6542 - accuracy: 0.6041 - val_loss: 0.7338 - val_accuracy: 0.5356\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6812 - accuracy: 0.5568 - val_loss: 0.6719 - val_accuracy: 0.5674\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6604 - accuracy: 0.5868 - val_loss: 0.6562 - val_accuracy: 0.5951\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6679 - accuracy: 0.5760 - val_loss: 0.6805 - val_accuracy: 0.5489\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6575 - accuracy: 0.5979 - val_loss: 0.6610 - val_accuracy: 0.5885\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6459 - accuracy: 0.6170 - val_loss: 0.6568 - val_accuracy: 0.5978\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6422 - accuracy: 0.6213 - val_loss: 0.6359 - val_accuracy: 0.6272\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6383 - accuracy: 0.6261 - val_loss: 0.6400 - val_accuracy: 0.6314\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6405 - accuracy: 0.6230 - val_loss: 0.6318 - val_accuracy: 0.6301\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6359 - accuracy: 0.6293 - val_loss: 0.6301 - val_accuracy: 0.6360\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6349 - accuracy: 0.6297 - val_loss: 0.6292 - val_accuracy: 0.6323\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6330 - accuracy: 0.6312 - val_loss: 0.6290 - val_accuracy: 0.6338\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6319 - accuracy: 0.6323 - val_loss: 0.6240 - val_accuracy: 0.6413\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6328 - accuracy: 0.6313 - val_loss: 0.6317 - val_accuracy: 0.6316\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6823 - accuracy: 0.5429 - val_loss: 0.6967 - val_accuracy: 0.5060\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6936 - accuracy: 0.5131 - val_loss: 0.6933 - val_accuracy: 0.5123\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6911 - accuracy: 0.5264 - val_loss: 0.6911 - val_accuracy: 0.5266\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6892 - accuracy: 0.5365 - val_loss: 0.6888 - val_accuracy: 0.5404\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6861 - accuracy: 0.5499 - val_loss: 0.6845 - val_accuracy: 0.5530\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6763 - accuracy: 0.5666 - val_loss: 0.6700 - val_accuracy: 0.5775\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6597 - accuracy: 0.5931 - val_loss: 0.6535 - val_accuracy: 0.6010\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6497 - accuracy: 0.6087 - val_loss: 0.6497 - val_accuracy: 0.6141\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6442 - accuracy: 0.6167 - val_loss: 0.6396 - val_accuracy: 0.6243\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6391 - accuracy: 0.6239 - val_loss: 0.6323 - val_accuracy: 0.6342\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6384 - accuracy: 0.6260 - val_loss: 0.6951 - val_accuracy: 0.5684\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6426 - accuracy: 0.6213 - val_loss: 0.6536 - val_accuracy: 0.6114\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6385 - accuracy: 0.6271 - val_loss: 0.6266 - val_accuracy: 0.6387\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6307 - accuracy: 0.6347 - val_loss: 0.6469 - val_accuracy: 0.6086\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6296 - accuracy: 0.6345 - val_loss: 0.6280 - val_accuracy: 0.6374\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6290 - accuracy: 0.6354 - val_loss: 0.6235 - val_accuracy: 0.6448\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6292 - accuracy: 0.6354 - val_loss: 0.6212 - val_accuracy: 0.6442\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6272 - accuracy: 0.6367 - val_loss: 0.6210 - val_accuracy: 0.6437\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6374 - accuracy: 0.6247 - val_loss: 0.6452 - val_accuracy: 0.6172\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6317 - accuracy: 0.6346 - val_loss: 0.6317 - val_accuracy: 0.6298\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6355 - accuracy: 0.6298 - val_loss: 0.6992 - val_accuracy: 0.5542\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6506 - accuracy: 0.6147 - val_loss: 0.6388 - val_accuracy: 0.6291\n",
      "1714/1714 [==============================] - 3s 1ms/step\n",
      "[[0.562911  ]\n",
      " [0.6092394 ]\n",
      " [0.6045996 ]\n",
      " [0.46003988]\n",
      " [0.4284698 ]\n",
      " [0.4491281 ]\n",
      " [0.5178977 ]\n",
      " [0.53560656]\n",
      " [0.5712998 ]\n",
      " [0.34540135]]\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.001, 'BATCH_SIZE': 1024, 'EPOCHS': 150, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.15, 'POST_PRUNE_EPOCHS': 50}\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 24)                96        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_20 (QActivati  (None, 24)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 12)                48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_21 (QActivati  (None, 12)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_20 is normal keras bn layer\n",
      "q_activation_20      quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_21 is normal keras bn layer\n",
      "q_activation_21      quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/150\n",
      "429/429 [==============================] - 6s 7ms/step - loss: 2.6639 - accuracy: 0.5011 - val_loss: 1.4314 - val_accuracy: 0.4994\n",
      "Epoch 2/150\n",
      "429/429 [==============================] - 3s 6ms/step - loss: 0.8836 - accuracy: 0.5015 - val_loss: 0.7197 - val_accuracy: 0.5023\n",
      "Epoch 3/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7131 - accuracy: 0.5019 - val_loss: 0.7094 - val_accuracy: 0.5019\n",
      "Epoch 4/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7058 - accuracy: 0.5022 - val_loss: 0.7039 - val_accuracy: 0.5024\n",
      "Epoch 5/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7021 - accuracy: 0.5024 - val_loss: 0.7012 - val_accuracy: 0.5033\n",
      "Epoch 6/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6998 - accuracy: 0.5029 - val_loss: 0.6993 - val_accuracy: 0.5019\n",
      "Epoch 7/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6981 - accuracy: 0.5039 - val_loss: 0.6978 - val_accuracy: 0.5023\n",
      "Epoch 8/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6969 - accuracy: 0.5046 - val_loss: 0.6967 - val_accuracy: 0.5043\n",
      "Epoch 9/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6960 - accuracy: 0.5046 - val_loss: 0.6958 - val_accuracy: 0.5039\n",
      "Epoch 10/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6953 - accuracy: 0.5060 - val_loss: 0.6952 - val_accuracy: 0.5047\n",
      "Epoch 11/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6946 - accuracy: 0.5072 - val_loss: 0.6948 - val_accuracy: 0.5061\n",
      "Epoch 12/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6942 - accuracy: 0.5078 - val_loss: 0.6946 - val_accuracy: 0.5065\n",
      "Epoch 13/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6939 - accuracy: 0.5079 - val_loss: 0.6943 - val_accuracy: 0.5068\n",
      "Epoch 14/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6936 - accuracy: 0.5086 - val_loss: 0.6940 - val_accuracy: 0.5068\n",
      "Epoch 15/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6934 - accuracy: 0.5095 - val_loss: 0.6939 - val_accuracy: 0.5083\n",
      "Epoch 16/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6932 - accuracy: 0.5093 - val_loss: 0.6937 - val_accuracy: 0.5060\n",
      "Epoch 17/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6931 - accuracy: 0.5094 - val_loss: 0.6937 - val_accuracy: 0.5059\n",
      "Epoch 18/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6929 - accuracy: 0.5109 - val_loss: 0.6937 - val_accuracy: 0.5046\n",
      "Epoch 19/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.5107 - val_loss: 0.6935 - val_accuracy: 0.5078\n",
      "Epoch 20/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6927 - accuracy: 0.5115 - val_loss: 0.6933 - val_accuracy: 0.5087\n",
      "Epoch 21/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6926 - accuracy: 0.5117 - val_loss: 0.6932 - val_accuracy: 0.5080\n",
      "Epoch 22/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6925 - accuracy: 0.5123 - val_loss: 0.6933 - val_accuracy: 0.5074\n",
      "Epoch 23/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6923 - accuracy: 0.5138 - val_loss: 0.6932 - val_accuracy: 0.5112\n",
      "Epoch 24/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5139 - val_loss: 0.6931 - val_accuracy: 0.5119\n",
      "Epoch 25/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6922 - accuracy: 0.5147 - val_loss: 0.6928 - val_accuracy: 0.5100\n",
      "Epoch 26/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6921 - accuracy: 0.5150 - val_loss: 0.6928 - val_accuracy: 0.5139\n",
      "Epoch 27/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6920 - accuracy: 0.5154 - val_loss: 0.6928 - val_accuracy: 0.5133\n",
      "Epoch 28/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6919 - accuracy: 0.5163 - val_loss: 0.7164 - val_accuracy: 0.4981\n",
      "Epoch 29/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6919 - accuracy: 0.5173 - val_loss: 0.6924 - val_accuracy: 0.5135\n",
      "Epoch 30/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5173 - val_loss: 0.6924 - val_accuracy: 0.5162\n",
      "Epoch 31/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6921 - accuracy: 0.5180 - val_loss: 0.6926 - val_accuracy: 0.5123\n",
      "Epoch 32/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5179 - val_loss: 0.7112 - val_accuracy: 0.4980\n",
      "Epoch 33/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6931 - accuracy: 0.5175 - val_loss: 0.6923 - val_accuracy: 0.5160\n",
      "Epoch 34/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6923 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5198\n",
      "Epoch 35/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6921 - accuracy: 0.5197 - val_loss: 0.6915 - val_accuracy: 0.5231\n",
      "Epoch 36/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6911 - accuracy: 0.5238 - val_loss: 0.6912 - val_accuracy: 0.5221\n",
      "Epoch 37/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6894 - accuracy: 0.5306 - val_loss: 0.6901 - val_accuracy: 0.5243\n",
      "Epoch 38/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6877 - accuracy: 0.5357 - val_loss: 0.6879 - val_accuracy: 0.5360\n",
      "Epoch 39/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6860 - accuracy: 0.5425 - val_loss: 0.6882 - val_accuracy: 0.5373\n",
      "Epoch 40/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6841 - accuracy: 0.5483 - val_loss: 0.6878 - val_accuracy: 0.5358\n",
      "Epoch 41/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6821 - accuracy: 0.5549 - val_loss: 0.6822 - val_accuracy: 0.5560\n",
      "Epoch 42/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6796 - accuracy: 0.5604 - val_loss: 0.6795 - val_accuracy: 0.5662\n",
      "Epoch 43/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6772 - accuracy: 0.5665 - val_loss: 0.6998 - val_accuracy: 0.5317\n",
      "Epoch 44/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6752 - accuracy: 0.5698 - val_loss: 0.6855 - val_accuracy: 0.5424\n",
      "Epoch 45/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6729 - accuracy: 0.5751 - val_loss: 0.6720 - val_accuracy: 0.5799\n",
      "Epoch 46/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6704 - accuracy: 0.5800 - val_loss: 0.6680 - val_accuracy: 0.5870\n",
      "Epoch 47/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6688 - accuracy: 0.5838 - val_loss: 0.6883 - val_accuracy: 0.5778\n",
      "Epoch 48/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6809 - accuracy: 0.5602 - val_loss: 0.6812 - val_accuracy: 0.5547\n",
      "Epoch 49/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6726 - accuracy: 0.5779 - val_loss: 0.6828 - val_accuracy: 0.5522\n",
      "Epoch 50/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6733 - accuracy: 0.5754 - val_loss: 0.6706 - val_accuracy: 0.5725\n",
      "Epoch 51/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6654 - accuracy: 0.5883 - val_loss: 0.6638 - val_accuracy: 0.5957\n",
      "Epoch 52/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6661 - accuracy: 0.5892 - val_loss: 0.6672 - val_accuracy: 0.5915\n",
      "Epoch 53/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6639 - accuracy: 0.5922 - val_loss: 0.6560 - val_accuracy: 0.6024\n",
      "Epoch 54/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6605 - accuracy: 0.5968 - val_loss: 0.6562 - val_accuracy: 0.6006\n",
      "Epoch 55/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6605 - accuracy: 0.5967 - val_loss: 0.6530 - val_accuracy: 0.6088\n",
      "Epoch 56/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6618 - accuracy: 0.5944 - val_loss: 0.6808 - val_accuracy: 0.5568\n",
      "Epoch 57/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6566 - accuracy: 0.6005 - val_loss: 0.6510 - val_accuracy: 0.6086\n",
      "Epoch 58/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6520 - accuracy: 0.6065 - val_loss: 0.6477 - val_accuracy: 0.6131\n",
      "Epoch 59/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6506 - accuracy: 0.6072 - val_loss: 0.6464 - val_accuracy: 0.6127\n",
      "Epoch 60/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6495 - accuracy: 0.6083 - val_loss: 0.6471 - val_accuracy: 0.6108\n",
      "Epoch 61/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6474 - accuracy: 0.6110 - val_loss: 0.6424 - val_accuracy: 0.6199\n",
      "Epoch 62/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6468 - accuracy: 0.6118 - val_loss: 0.6480 - val_accuracy: 0.6116\n",
      "Epoch 63/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6463 - accuracy: 0.6123 - val_loss: 0.6435 - val_accuracy: 0.6134\n",
      "Epoch 64/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6717 - accuracy: 0.5759 - val_loss: 0.6888 - val_accuracy: 0.5199\n",
      "Epoch 65/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6546 - accuracy: 0.6014 - val_loss: 0.6458 - val_accuracy: 0.6125\n",
      "Epoch 66/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6452 - accuracy: 0.6135 - val_loss: 0.6446 - val_accuracy: 0.6174\n",
      "Epoch 67/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6433 - accuracy: 0.6155 - val_loss: 0.6421 - val_accuracy: 0.6181\n",
      "Epoch 68/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6419 - accuracy: 0.6177 - val_loss: 0.6365 - val_accuracy: 0.6266\n",
      "Epoch 69/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6426 - accuracy: 0.6169 - val_loss: 0.6524 - val_accuracy: 0.6046\n",
      "Epoch 70/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6410 - accuracy: 0.6189 - val_loss: 0.6359 - val_accuracy: 0.6264\n",
      "Epoch 71/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6429 - accuracy: 0.6160 - val_loss: 0.6378 - val_accuracy: 0.6191\n",
      "Epoch 72/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6415 - accuracy: 0.6186 - val_loss: 0.6402 - val_accuracy: 0.6199\n",
      "Epoch 73/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6393 - accuracy: 0.6215 - val_loss: 0.6632 - val_accuracy: 0.5911\n",
      "Epoch 74/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6385 - accuracy: 0.6226 - val_loss: 0.6342 - val_accuracy: 0.6282\n",
      "Epoch 75/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6388 - accuracy: 0.6219 - val_loss: 0.6417 - val_accuracy: 0.6185\n",
      "Epoch 76/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6396 - accuracy: 0.6229 - val_loss: 0.6413 - val_accuracy: 0.6198\n",
      "Epoch 77/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6379 - accuracy: 0.6226 - val_loss: 0.6330 - val_accuracy: 0.6272\n",
      "Epoch 78/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6387 - accuracy: 0.6225 - val_loss: 0.6376 - val_accuracy: 0.6249\n",
      "Epoch 79/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6355 - accuracy: 0.6271 - val_loss: 0.6369 - val_accuracy: 0.6257\n",
      "Epoch 80/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6470 - accuracy: 0.6137 - val_loss: 0.6439 - val_accuracy: 0.6177\n",
      "Epoch 81/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6617 - accuracy: 0.5946 - val_loss: 0.6623 - val_accuracy: 0.5907\n",
      "Epoch 82/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6399 - accuracy: 0.6210 - val_loss: 0.6412 - val_accuracy: 0.6170\n",
      "Epoch 83/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6516 - accuracy: 0.6074 - val_loss: 0.6426 - val_accuracy: 0.6211\n",
      "Epoch 84/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6344 - accuracy: 0.6282 - val_loss: 0.6420 - val_accuracy: 0.6182\n",
      "Epoch 85/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6337 - accuracy: 0.6287 - val_loss: 0.6447 - val_accuracy: 0.6170\n",
      "Epoch 86/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6773 - accuracy: 0.5716 - val_loss: 0.6721 - val_accuracy: 0.5741\n",
      "Epoch 87/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6416 - accuracy: 0.6186 - val_loss: 0.6447 - val_accuracy: 0.6101\n",
      "Epoch 88/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6341 - accuracy: 0.6274 - val_loss: 0.6300 - val_accuracy: 0.6353\n",
      "Epoch 89/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6347 - accuracy: 0.6279 - val_loss: 0.6454 - val_accuracy: 0.6202\n",
      "Epoch 90/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6361 - accuracy: 0.6270 - val_loss: 0.6410 - val_accuracy: 0.6221\n",
      "Epoch 91/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6349 - accuracy: 0.6275 - val_loss: 0.6313 - val_accuracy: 0.6333\n",
      "Epoch 92/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6317 - accuracy: 0.6304 - val_loss: 0.6369 - val_accuracy: 0.6286\n",
      "Epoch 93/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6303 - accuracy: 0.6330 - val_loss: 0.6270 - val_accuracy: 0.6347\n",
      "Epoch 94/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6312 - accuracy: 0.6308 - val_loss: 0.6286 - val_accuracy: 0.6360\n",
      "Epoch 95/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6320 - accuracy: 0.6311 - val_loss: 0.6391 - val_accuracy: 0.6203\n",
      "Epoch 96/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6843 - accuracy: 0.5641 - val_loss: 0.7046 - val_accuracy: 0.5039\n",
      "Epoch 97/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6959 - accuracy: 0.5153 - val_loss: 0.6940 - val_accuracy: 0.5209\n",
      "Epoch 98/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6900 - accuracy: 0.5298 - val_loss: 0.6899 - val_accuracy: 0.5302\n",
      "Epoch 99/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6852 - accuracy: 0.5442 - val_loss: 0.6831 - val_accuracy: 0.5490\n",
      "Epoch 100/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6805 - accuracy: 0.5535 - val_loss: 0.6782 - val_accuracy: 0.5616\n",
      "Epoch 101/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6745 - accuracy: 0.5659 - val_loss: 0.6747 - val_accuracy: 0.5656\n",
      "Epoch 102/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6716 - accuracy: 0.5729 - val_loss: 0.6730 - val_accuracy: 0.5779\n",
      "Epoch 103/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6658 - accuracy: 0.5848 - val_loss: 0.6603 - val_accuracy: 0.5915\n",
      "Epoch 104/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6575 - accuracy: 0.5972 - val_loss: 0.6469 - val_accuracy: 0.6094\n",
      "Epoch 105/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6468 - accuracy: 0.6101 - val_loss: 0.6421 - val_accuracy: 0.6138\n",
      "Epoch 106/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6534 - accuracy: 0.6018 - val_loss: 0.6900 - val_accuracy: 0.5501\n",
      "Epoch 107/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6630 - accuracy: 0.5854 - val_loss: 0.6451 - val_accuracy: 0.6137\n",
      "Epoch 108/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6427 - accuracy: 0.6157 - val_loss: 0.6375 - val_accuracy: 0.6274\n",
      "Epoch 109/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6389 - accuracy: 0.6205 - val_loss: 0.6333 - val_accuracy: 0.6305\n",
      "Epoch 110/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6980 - accuracy: 0.5209 - val_loss: 0.6948 - val_accuracy: 0.4946\n",
      "Epoch 111/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6760 - accuracy: 0.5666 - val_loss: 0.6655 - val_accuracy: 0.5914\n",
      "Epoch 112/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6463 - accuracy: 0.6114 - val_loss: 0.6371 - val_accuracy: 0.6268\n",
      "Epoch 113/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6378 - accuracy: 0.6221 - val_loss: 0.6373 - val_accuracy: 0.6260\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_20\n",
      "cannot prune layer q_activation_20\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_21\n",
      "cannot prune layer q_activation_21\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 0.6340 - accuracy: 0.6290 - val_loss: 0.6356 - val_accuracy: 0.6223\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6330 - accuracy: 0.6295 - val_loss: 0.6428 - val_accuracy: 0.6208\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6296 - accuracy: 0.6339 - val_loss: 0.6357 - val_accuracy: 0.6259\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6316 - accuracy: 0.6318 - val_loss: 0.6273 - val_accuracy: 0.6384\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6289 - accuracy: 0.6354 - val_loss: 0.6323 - val_accuracy: 0.6300\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6320 - accuracy: 0.6313 - val_loss: 0.6256 - val_accuracy: 0.6411\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6293 - accuracy: 0.6344 - val_loss: 0.6271 - val_accuracy: 0.6383\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6324 - accuracy: 0.6301 - val_loss: 0.6248 - val_accuracy: 0.6380\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6404 - accuracy: 0.6230 - val_loss: 0.6278 - val_accuracy: 0.6355\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6294 - accuracy: 0.6344 - val_loss: 0.6397 - val_accuracy: 0.6253\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6268 - accuracy: 0.6368 - val_loss: 0.6230 - val_accuracy: 0.6425\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6481 - accuracy: 0.6162 - val_loss: 0.6604 - val_accuracy: 0.6022\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6351 - accuracy: 0.6299 - val_loss: 0.6283 - val_accuracy: 0.6371\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6287 - accuracy: 0.6359 - val_loss: 0.6210 - val_accuracy: 0.6439\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6962 - accuracy: 0.5176 - val_loss: 0.6928 - val_accuracy: 0.5117\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6903 - accuracy: 0.5239 - val_loss: 0.6874 - val_accuracy: 0.5332\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6827 - accuracy: 0.5517 - val_loss: 0.6796 - val_accuracy: 0.5624\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6631 - accuracy: 0.5988 - val_loss: 0.6516 - val_accuracy: 0.6162\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6393 - accuracy: 0.6276 - val_loss: 0.6310 - val_accuracy: 0.6359\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6562 - accuracy: 0.6037 - val_loss: 0.6485 - val_accuracy: 0.6147\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6403 - accuracy: 0.6205 - val_loss: 0.6310 - val_accuracy: 0.6352\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6306 - accuracy: 0.6328 - val_loss: 0.6247 - val_accuracy: 0.6419\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6352 - accuracy: 0.6277 - val_loss: 0.6255 - val_accuracy: 0.6405\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6277 - accuracy: 0.6356 - val_loss: 0.6214 - val_accuracy: 0.6467\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6274 - accuracy: 0.6361 - val_loss: 0.6238 - val_accuracy: 0.6434\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6303 - accuracy: 0.6329 - val_loss: 0.6277 - val_accuracy: 0.6338\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6273 - accuracy: 0.6357 - val_loss: 0.6228 - val_accuracy: 0.6418\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6423 - accuracy: 0.6193 - val_loss: 0.6606 - val_accuracy: 0.5904\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6317 - accuracy: 0.6283 - val_loss: 0.6218 - val_accuracy: 0.6473\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6366 - accuracy: 0.6292 - val_loss: 0.6444 - val_accuracy: 0.6143\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6266 - accuracy: 0.6382 - val_loss: 0.6254 - val_accuracy: 0.6464\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6413 - accuracy: 0.6224 - val_loss: 0.6420 - val_accuracy: 0.6213\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6279 - accuracy: 0.6370 - val_loss: 0.6238 - val_accuracy: 0.6410\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6240 - accuracy: 0.6407 - val_loss: 0.6288 - val_accuracy: 0.6398\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6244 - accuracy: 0.6401 - val_loss: 0.6240 - val_accuracy: 0.6398\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6252 - accuracy: 0.6394 - val_loss: 0.6301 - val_accuracy: 0.6360\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6240 - accuracy: 0.6404 - val_loss: 0.6217 - val_accuracy: 0.6432\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6651 - accuracy: 0.5881 - val_loss: 0.6941 - val_accuracy: 0.5397\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6786 - accuracy: 0.5671 - val_loss: 0.6711 - val_accuracy: 0.5841\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6522 - accuracy: 0.6110 - val_loss: 0.6336 - val_accuracy: 0.6312\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6446 - accuracy: 0.6189 - val_loss: 0.6368 - val_accuracy: 0.6254\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6325 - accuracy: 0.6310 - val_loss: 0.6664 - val_accuracy: 0.5861\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6302 - accuracy: 0.6340 - val_loss: 0.6234 - val_accuracy: 0.6414\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6283 - accuracy: 0.6364 - val_loss: 0.6472 - val_accuracy: 0.6157\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6287 - accuracy: 0.6356 - val_loss: 0.6293 - val_accuracy: 0.6376\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6499 - accuracy: 0.6112 - val_loss: 0.6419 - val_accuracy: 0.6182\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6319 - accuracy: 0.6310 - val_loss: 0.6232 - val_accuracy: 0.6429\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6264 - accuracy: 0.6384 - val_loss: 0.6231 - val_accuracy: 0.6461\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6715 - accuracy: 0.5817 - val_loss: 0.6701 - val_accuracy: 0.5780\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6431 - accuracy: 0.6182 - val_loss: 0.6316 - val_accuracy: 0.6353\n",
      "1714/1714 [==============================] - 3s 1ms/step\n",
      "[[0.509837  ]\n",
      " [0.74998677]\n",
      " [0.6697436 ]\n",
      " [0.573895  ]\n",
      " [0.5419041 ]\n",
      " [0.559422  ]\n",
      " [0.68276083]\n",
      " [0.6199392 ]\n",
      " [0.68034345]\n",
      " [0.27082103]]\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.0005, 'BATCH_SIZE': 1024, 'EPOCHS': 100, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.15, 'POST_PRUNE_EPOCHS': 50}\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 24)                96        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_22 (QActivati  (None, 24)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 12)                48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_23 (QActivati  (None, 12)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_22 is normal keras bn layer\n",
      "q_activation_22      quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_23 is normal keras bn layer\n",
      "q_activation_23      quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/100\n",
      "429/429 [==============================] - 6s 7ms/step - loss: 2.1997 - accuracy: 0.5024 - val_loss: 1.0680 - val_accuracy: 0.5024\n",
      "Epoch 2/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.8694 - accuracy: 0.5018 - val_loss: 0.8014 - val_accuracy: 0.5020\n",
      "Epoch 3/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7787 - accuracy: 0.5018 - val_loss: 0.7570 - val_accuracy: 0.5024\n",
      "Epoch 4/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7505 - accuracy: 0.5026 - val_loss: 0.7696 - val_accuracy: 0.5013\n",
      "Epoch 5/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7391 - accuracy: 0.5020 - val_loss: 0.7322 - val_accuracy: 0.5015\n",
      "Epoch 6/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7256 - accuracy: 0.5028 - val_loss: 0.7216 - val_accuracy: 0.4997\n",
      "Epoch 7/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7168 - accuracy: 0.5024 - val_loss: 0.7143 - val_accuracy: 0.4992\n",
      "Epoch 8/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7128 - accuracy: 0.5025 - val_loss: 0.7131 - val_accuracy: 0.4999\n",
      "Epoch 9/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7086 - accuracy: 0.5034 - val_loss: 0.7070 - val_accuracy: 0.5022\n",
      "Epoch 10/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7052 - accuracy: 0.5035 - val_loss: 0.7039 - val_accuracy: 0.5015\n",
      "Epoch 11/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7030 - accuracy: 0.5043 - val_loss: 0.7023 - val_accuracy: 0.5034\n",
      "Epoch 12/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7012 - accuracy: 0.5043 - val_loss: 0.7003 - val_accuracy: 0.5038\n",
      "Epoch 13/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6994 - accuracy: 0.5041 - val_loss: 0.6993 - val_accuracy: 0.5027\n",
      "Epoch 14/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6981 - accuracy: 0.5049 - val_loss: 0.6984 - val_accuracy: 0.5043\n",
      "Epoch 15/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6978 - accuracy: 0.5066 - val_loss: 0.6980 - val_accuracy: 0.5051\n",
      "Epoch 16/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6969 - accuracy: 0.5064 - val_loss: 0.6971 - val_accuracy: 0.5036\n",
      "Epoch 17/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6965 - accuracy: 0.5056 - val_loss: 0.6975 - val_accuracy: 0.5056\n",
      "Epoch 18/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6975 - accuracy: 0.5063 - val_loss: 0.6961 - val_accuracy: 0.5064\n",
      "Epoch 19/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6990 - accuracy: 0.5072 - val_loss: 0.6970 - val_accuracy: 0.5071\n",
      "Epoch 20/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7008 - accuracy: 0.5073 - val_loss: 0.6967 - val_accuracy: 0.5046\n",
      "Epoch 21/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7018 - accuracy: 0.5077 - val_loss: 0.6986 - val_accuracy: 0.5059\n",
      "Epoch 22/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7032 - accuracy: 0.5055 - val_loss: 0.6996 - val_accuracy: 0.5084\n",
      "Epoch 23/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7029 - accuracy: 0.5055 - val_loss: 0.6977 - val_accuracy: 0.5079\n",
      "Epoch 24/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7029 - accuracy: 0.5052 - val_loss: 0.7089 - val_accuracy: 0.4989\n",
      "Epoch 25/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7024 - accuracy: 0.5066 - val_loss: 0.7001 - val_accuracy: 0.5084\n",
      "Epoch 26/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7023 - accuracy: 0.5064 - val_loss: 0.7054 - val_accuracy: 0.4987\n",
      "Epoch 27/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7012 - accuracy: 0.5067 - val_loss: 0.7036 - val_accuracy: 0.5018\n",
      "Epoch 28/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7006 - accuracy: 0.5080 - val_loss: 0.7017 - val_accuracy: 0.5003\n",
      "Epoch 29/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7000 - accuracy: 0.5087 - val_loss: 0.6993 - val_accuracy: 0.5105\n",
      "Epoch 30/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6996 - accuracy: 0.5076 - val_loss: 0.7002 - val_accuracy: 0.5116\n",
      "Epoch 31/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6988 - accuracy: 0.5087 - val_loss: 0.7006 - val_accuracy: 0.5069\n",
      "Epoch 32/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6983 - accuracy: 0.5107 - val_loss: 0.6998 - val_accuracy: 0.5030\n",
      "Epoch 33/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6983 - accuracy: 0.5091 - val_loss: 0.6992 - val_accuracy: 0.5111\n",
      "Epoch 34/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6974 - accuracy: 0.5102 - val_loss: 0.7004 - val_accuracy: 0.5097\n",
      "Epoch 35/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6972 - accuracy: 0.5115 - val_loss: 0.6976 - val_accuracy: 0.5048\n",
      "Epoch 36/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6969 - accuracy: 0.5119 - val_loss: 0.6984 - val_accuracy: 0.5030\n",
      "Epoch 37/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6963 - accuracy: 0.5118 - val_loss: 0.6970 - val_accuracy: 0.5136\n",
      "Epoch 38/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6962 - accuracy: 0.5125 - val_loss: 0.6962 - val_accuracy: 0.5038\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_22\n",
      "cannot prune layer q_activation_22\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_23\n",
      "cannot prune layer q_activation_23\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 0.6989 - accuracy: 0.5073 - val_loss: 0.6965 - val_accuracy: 0.5049\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7000 - accuracy: 0.5059 - val_loss: 0.6976 - val_accuracy: 0.5084\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7014 - accuracy: 0.5065 - val_loss: 0.6962 - val_accuracy: 0.5078\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7014 - accuracy: 0.5059 - val_loss: 0.7097 - val_accuracy: 0.4997\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7007 - accuracy: 0.5070 - val_loss: 0.7116 - val_accuracy: 0.4999\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7004 - accuracy: 0.5073 - val_loss: 0.6975 - val_accuracy: 0.5126\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7003 - accuracy: 0.5066 - val_loss: 0.7038 - val_accuracy: 0.4985\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6996 - accuracy: 0.5092 - val_loss: 0.7006 - val_accuracy: 0.5081\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6993 - accuracy: 0.5084 - val_loss: 0.7011 - val_accuracy: 0.5002\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6990 - accuracy: 0.5089 - val_loss: 0.6987 - val_accuracy: 0.5045\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6985 - accuracy: 0.5094 - val_loss: 0.6994 - val_accuracy: 0.5014\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6981 - accuracy: 0.5098 - val_loss: 0.6993 - val_accuracy: 0.5033\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6982 - accuracy: 0.5100 - val_loss: 0.6997 - val_accuracy: 0.5115\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6974 - accuracy: 0.5106 - val_loss: 0.6972 - val_accuracy: 0.5035\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6969 - accuracy: 0.5110 - val_loss: 0.6990 - val_accuracy: 0.5153\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6967 - accuracy: 0.5109 - val_loss: 0.6961 - val_accuracy: 0.5079\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6963 - accuracy: 0.5115 - val_loss: 0.6983 - val_accuracy: 0.5160\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6963 - accuracy: 0.5131 - val_loss: 0.6968 - val_accuracy: 0.5035\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6958 - accuracy: 0.5130 - val_loss: 0.6967 - val_accuracy: 0.5034\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6956 - accuracy: 0.5129 - val_loss: 0.6969 - val_accuracy: 0.5147\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6951 - accuracy: 0.5144 - val_loss: 0.6957 - val_accuracy: 0.5075\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6949 - accuracy: 0.5147 - val_loss: 0.6971 - val_accuracy: 0.5137\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6946 - accuracy: 0.5148 - val_loss: 0.6947 - val_accuracy: 0.5135\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6942 - accuracy: 0.5167 - val_loss: 0.6943 - val_accuracy: 0.5105\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6939 - accuracy: 0.5161 - val_loss: 0.6976 - val_accuracy: 0.5164\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6936 - accuracy: 0.5164 - val_loss: 0.6932 - val_accuracy: 0.5126\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6932 - accuracy: 0.5182 - val_loss: 0.6964 - val_accuracy: 0.5169\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.5183 - val_loss: 0.6940 - val_accuracy: 0.5087\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6925 - accuracy: 0.5191 - val_loss: 0.6930 - val_accuracy: 0.5208\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6919 - accuracy: 0.5218 - val_loss: 0.6958 - val_accuracy: 0.5055\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6912 - accuracy: 0.5234 - val_loss: 0.6918 - val_accuracy: 0.5219\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6909 - accuracy: 0.5254 - val_loss: 0.6913 - val_accuracy: 0.5266\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6905 - accuracy: 0.5268 - val_loss: 0.6916 - val_accuracy: 0.5270\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6901 - accuracy: 0.5277 - val_loss: 0.6909 - val_accuracy: 0.5322\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6897 - accuracy: 0.5307 - val_loss: 0.6907 - val_accuracy: 0.5311\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6890 - accuracy: 0.5329 - val_loss: 0.6900 - val_accuracy: 0.5349\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6888 - accuracy: 0.5342 - val_loss: 0.6902 - val_accuracy: 0.5285\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6880 - accuracy: 0.5371 - val_loss: 0.6887 - val_accuracy: 0.5398\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6873 - accuracy: 0.5386 - val_loss: 0.6880 - val_accuracy: 0.5385\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6868 - accuracy: 0.5415 - val_loss: 0.6870 - val_accuracy: 0.5439\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6859 - accuracy: 0.5446 - val_loss: 0.6869 - val_accuracy: 0.5418\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6852 - accuracy: 0.5459 - val_loss: 0.6858 - val_accuracy: 0.5523\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6844 - accuracy: 0.5504 - val_loss: 0.6845 - val_accuracy: 0.5518\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6834 - accuracy: 0.5515 - val_loss: 0.6843 - val_accuracy: 0.5554\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6827 - accuracy: 0.5546 - val_loss: 0.6830 - val_accuracy: 0.5575\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6820 - accuracy: 0.5561 - val_loss: 0.6820 - val_accuracy: 0.5599\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6810 - accuracy: 0.5583 - val_loss: 0.6820 - val_accuracy: 0.5574\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6802 - accuracy: 0.5607 - val_loss: 0.6799 - val_accuracy: 0.5663\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6793 - accuracy: 0.5631 - val_loss: 0.6794 - val_accuracy: 0.5654\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6788 - accuracy: 0.5644 - val_loss: 0.6788 - val_accuracy: 0.5673\n",
      "1714/1714 [==============================] - 3s 1ms/step\n",
      "[[0.4950577 ]\n",
      " [0.45231962]\n",
      " [0.5806295 ]\n",
      " [0.5060985 ]\n",
      " [0.37364888]\n",
      " [0.3149808 ]\n",
      " [0.56620824]\n",
      " [0.4354608 ]\n",
      " [0.58136827]\n",
      " [0.5255733 ]]\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.0005, 'BATCH_SIZE': 1024, 'EPOCHS': 150, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.15, 'POST_PRUNE_EPOCHS': 50}\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_24 (Ba  (None, 24)                96        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_24 (QActivati  (None, 24)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 12)                48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_25 (QActivati  (None, 12)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_24 is normal keras bn layer\n",
      "q_activation_24      quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_25 is normal keras bn layer\n",
      "q_activation_25      quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/150\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 3.7707 - accuracy: 0.5001 - val_loss: 1.7927 - val_accuracy: 0.4986\n",
      "Epoch 2/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.9982 - accuracy: 0.4998 - val_loss: 0.7444 - val_accuracy: 0.5007\n",
      "Epoch 3/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7290 - accuracy: 0.5001 - val_loss: 0.7189 - val_accuracy: 0.5025\n",
      "Epoch 4/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7145 - accuracy: 0.5016 - val_loss: 0.7108 - val_accuracy: 0.5026\n",
      "Epoch 5/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7094 - accuracy: 0.5021 - val_loss: 0.7072 - val_accuracy: 0.5035\n",
      "Epoch 6/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7065 - accuracy: 0.5026 - val_loss: 0.7049 - val_accuracy: 0.5016\n",
      "Epoch 7/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7041 - accuracy: 0.5028 - val_loss: 0.7030 - val_accuracy: 0.5032\n",
      "Epoch 8/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7022 - accuracy: 0.5035 - val_loss: 0.7016 - val_accuracy: 0.5040\n",
      "Epoch 9/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7006 - accuracy: 0.5040 - val_loss: 0.7003 - val_accuracy: 0.5030\n",
      "Epoch 10/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6991 - accuracy: 0.5046 - val_loss: 0.6991 - val_accuracy: 0.5034\n",
      "Epoch 11/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6980 - accuracy: 0.5051 - val_loss: 0.6982 - val_accuracy: 0.5039\n",
      "Epoch 12/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6971 - accuracy: 0.5057 - val_loss: 0.6973 - val_accuracy: 0.5033\n",
      "Epoch 13/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6963 - accuracy: 0.5059 - val_loss: 0.6967 - val_accuracy: 0.5036\n",
      "Epoch 14/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6956 - accuracy: 0.5079 - val_loss: 0.6962 - val_accuracy: 0.5049\n",
      "Epoch 15/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6949 - accuracy: 0.5084 - val_loss: 0.6956 - val_accuracy: 0.5046\n",
      "Epoch 16/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6945 - accuracy: 0.5080 - val_loss: 0.6956 - val_accuracy: 0.5030\n",
      "Epoch 17/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6940 - accuracy: 0.5093 - val_loss: 0.6949 - val_accuracy: 0.5048\n",
      "Epoch 18/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6936 - accuracy: 0.5089 - val_loss: 0.6944 - val_accuracy: 0.5034\n",
      "Epoch 19/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6932 - accuracy: 0.5111 - val_loss: 0.6944 - val_accuracy: 0.5060\n",
      "Epoch 20/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6930 - accuracy: 0.5116 - val_loss: 0.6940 - val_accuracy: 0.5058\n",
      "Epoch 21/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5120 - val_loss: 0.6939 - val_accuracy: 0.5039\n",
      "Epoch 22/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5120 - val_loss: 0.6938 - val_accuracy: 0.5082\n",
      "Epoch 23/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5130 - val_loss: 0.6935 - val_accuracy: 0.5068\n",
      "Epoch 24/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6927 - accuracy: 0.5133 - val_loss: 0.6934 - val_accuracy: 0.5081\n",
      "Epoch 25/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.5128 - val_loss: 0.6989 - val_accuracy: 0.5010\n",
      "Epoch 26/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6936 - accuracy: 0.5119 - val_loss: 0.6982 - val_accuracy: 0.5001\n",
      "Epoch 27/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6933 - accuracy: 0.5130 - val_loss: 0.6934 - val_accuracy: 0.5095\n",
      "Epoch 28/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6933 - accuracy: 0.5129 - val_loss: 0.6942 - val_accuracy: 0.5075\n",
      "Epoch 29/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6935 - accuracy: 0.5118 - val_loss: 0.6935 - val_accuracy: 0.5093\n",
      "Epoch 30/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6930 - accuracy: 0.5142 - val_loss: 0.6967 - val_accuracy: 0.5035\n",
      "Epoch 31/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.5130 - val_loss: 0.6934 - val_accuracy: 0.5112\n",
      "Epoch 32/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6930 - accuracy: 0.5149 - val_loss: 0.6935 - val_accuracy: 0.5121\n",
      "Epoch 33/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6927 - accuracy: 0.5161 - val_loss: 0.6931 - val_accuracy: 0.5125\n",
      "Epoch 34/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5156 - val_loss: 0.6930 - val_accuracy: 0.5150\n",
      "Epoch 35/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5161 - val_loss: 0.6926 - val_accuracy: 0.5132\n",
      "Epoch 36/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5171 - val_loss: 0.6966 - val_accuracy: 0.5026\n",
      "Epoch 37/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6920 - accuracy: 0.5191 - val_loss: 0.6927 - val_accuracy: 0.5149\n",
      "Epoch 38/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6919 - accuracy: 0.5200 - val_loss: 0.6921 - val_accuracy: 0.5172\n",
      "Epoch 39/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6917 - accuracy: 0.5215 - val_loss: 0.6919 - val_accuracy: 0.5222\n",
      "Epoch 40/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6914 - accuracy: 0.5238 - val_loss: 0.6917 - val_accuracy: 0.5227\n",
      "Epoch 41/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6908 - accuracy: 0.5280 - val_loss: 0.6916 - val_accuracy: 0.5259\n",
      "Epoch 42/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6901 - accuracy: 0.5318 - val_loss: 0.6905 - val_accuracy: 0.5328\n",
      "Epoch 43/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6894 - accuracy: 0.5351 - val_loss: 0.6901 - val_accuracy: 0.5341\n",
      "Epoch 44/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6890 - accuracy: 0.5364 - val_loss: 0.6899 - val_accuracy: 0.5368\n",
      "Epoch 45/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6884 - accuracy: 0.5396 - val_loss: 0.6886 - val_accuracy: 0.5416\n",
      "Epoch 46/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6872 - accuracy: 0.5446 - val_loss: 0.6880 - val_accuracy: 0.5410\n",
      "Epoch 47/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6859 - accuracy: 0.5483 - val_loss: 0.6875 - val_accuracy: 0.5441\n",
      "Epoch 48/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6846 - accuracy: 0.5522 - val_loss: 0.6870 - val_accuracy: 0.5468\n",
      "Epoch 49/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6831 - accuracy: 0.5576 - val_loss: 0.6845 - val_accuracy: 0.5516\n",
      "Epoch 50/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6812 - accuracy: 0.5616 - val_loss: 0.6811 - val_accuracy: 0.5643\n",
      "Epoch 51/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6795 - accuracy: 0.5654 - val_loss: 0.6809 - val_accuracy: 0.5634\n",
      "Epoch 52/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6775 - accuracy: 0.5683 - val_loss: 0.6789 - val_accuracy: 0.5693\n",
      "Epoch 53/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6754 - accuracy: 0.5730 - val_loss: 0.6771 - val_accuracy: 0.5688\n",
      "Epoch 54/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6735 - accuracy: 0.5765 - val_loss: 0.6740 - val_accuracy: 0.5751\n",
      "Epoch 55/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6715 - accuracy: 0.5806 - val_loss: 0.6728 - val_accuracy: 0.5772\n",
      "Epoch 56/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6696 - accuracy: 0.5837 - val_loss: 0.6719 - val_accuracy: 0.5831\n",
      "Epoch 57/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6682 - accuracy: 0.5859 - val_loss: 0.6692 - val_accuracy: 0.5839\n",
      "Epoch 58/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6663 - accuracy: 0.5881 - val_loss: 0.6692 - val_accuracy: 0.5820\n",
      "Epoch 59/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6658 - accuracy: 0.5891 - val_loss: 0.6657 - val_accuracy: 0.5909\n",
      "Epoch 60/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6653 - accuracy: 0.5903 - val_loss: 0.6684 - val_accuracy: 0.5844\n",
      "Epoch 61/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6642 - accuracy: 0.5928 - val_loss: 0.6652 - val_accuracy: 0.5900\n",
      "Epoch 62/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6633 - accuracy: 0.5934 - val_loss: 0.6643 - val_accuracy: 0.5938\n",
      "Epoch 63/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6618 - accuracy: 0.5947 - val_loss: 0.6688 - val_accuracy: 0.5763\n",
      "Epoch 64/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6606 - accuracy: 0.5974 - val_loss: 0.6631 - val_accuracy: 0.5971\n",
      "Epoch 65/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6592 - accuracy: 0.5993 - val_loss: 0.6610 - val_accuracy: 0.5986\n",
      "Epoch 66/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6585 - accuracy: 0.6000 - val_loss: 0.6712 - val_accuracy: 0.5821\n",
      "Epoch 67/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6579 - accuracy: 0.6014 - val_loss: 0.6635 - val_accuracy: 0.5942\n",
      "Epoch 68/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6569 - accuracy: 0.6027 - val_loss: 0.6582 - val_accuracy: 0.5991\n",
      "Epoch 69/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6564 - accuracy: 0.6028 - val_loss: 0.6653 - val_accuracy: 0.5881\n",
      "Epoch 70/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6553 - accuracy: 0.6053 - val_loss: 0.6584 - val_accuracy: 0.5978\n",
      "Epoch 71/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6545 - accuracy: 0.6068 - val_loss: 0.6597 - val_accuracy: 0.6014\n",
      "Epoch 72/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6540 - accuracy: 0.6076 - val_loss: 0.6533 - val_accuracy: 0.6111\n",
      "Epoch 73/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6538 - accuracy: 0.6085 - val_loss: 0.6547 - val_accuracy: 0.6094\n",
      "Epoch 74/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6560 - accuracy: 0.6064 - val_loss: 0.6546 - val_accuracy: 0.6122\n",
      "Epoch 75/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6570 - accuracy: 0.6049 - val_loss: 0.6549 - val_accuracy: 0.6085\n",
      "Epoch 76/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6546 - accuracy: 0.6084 - val_loss: 0.6625 - val_accuracy: 0.6068\n",
      "Epoch 77/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6559 - accuracy: 0.6078 - val_loss: 0.6549 - val_accuracy: 0.6050\n",
      "Epoch 78/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6536 - accuracy: 0.6090 - val_loss: 0.6557 - val_accuracy: 0.6092\n",
      "Epoch 79/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6529 - accuracy: 0.6098 - val_loss: 0.6550 - val_accuracy: 0.6040\n",
      "Epoch 80/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6536 - accuracy: 0.6094 - val_loss: 0.6504 - val_accuracy: 0.6137\n",
      "Epoch 81/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6520 - accuracy: 0.6110 - val_loss: 0.6629 - val_accuracy: 0.5951\n",
      "Epoch 82/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6572 - accuracy: 0.6034 - val_loss: 0.6626 - val_accuracy: 0.5964\n",
      "Epoch 83/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6568 - accuracy: 0.6044 - val_loss: 0.6539 - val_accuracy: 0.6071\n",
      "Epoch 84/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6523 - accuracy: 0.6105 - val_loss: 0.6475 - val_accuracy: 0.6200\n",
      "Epoch 85/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6511 - accuracy: 0.6124 - val_loss: 0.6498 - val_accuracy: 0.6121\n",
      "Epoch 86/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6632 - accuracy: 0.5948 - val_loss: 0.6621 - val_accuracy: 0.5955\n",
      "Epoch 87/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6559 - accuracy: 0.6046 - val_loss: 0.6501 - val_accuracy: 0.6123\n",
      "Epoch 88/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6528 - accuracy: 0.6094 - val_loss: 0.6473 - val_accuracy: 0.6174\n",
      "Epoch 89/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6517 - accuracy: 0.6104 - val_loss: 0.6501 - val_accuracy: 0.6137\n",
      "Epoch 90/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6495 - accuracy: 0.6134 - val_loss: 0.6484 - val_accuracy: 0.6162\n",
      "Epoch 91/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6501 - accuracy: 0.6136 - val_loss: 0.7555 - val_accuracy: 0.5087\n",
      "Epoch 92/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6853 - accuracy: 0.5571 - val_loss: 0.6686 - val_accuracy: 0.5898\n",
      "Epoch 93/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6580 - accuracy: 0.5999 - val_loss: 0.6539 - val_accuracy: 0.6114\n",
      "Epoch 94/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6532 - accuracy: 0.6090 - val_loss: 0.6657 - val_accuracy: 0.5887\n",
      "Epoch 95/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6528 - accuracy: 0.6099 - val_loss: 0.6510 - val_accuracy: 0.6107\n",
      "Epoch 96/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6494 - accuracy: 0.6138 - val_loss: 0.6473 - val_accuracy: 0.6202\n",
      "Epoch 97/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6474 - accuracy: 0.6175 - val_loss: 0.6514 - val_accuracy: 0.6130\n",
      "Epoch 98/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6797 - accuracy: 0.5757 - val_loss: 0.6700 - val_accuracy: 0.5856\n",
      "Epoch 99/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6618 - accuracy: 0.5961 - val_loss: 0.6560 - val_accuracy: 0.6039\n",
      "Epoch 100/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6528 - accuracy: 0.6103 - val_loss: 0.6479 - val_accuracy: 0.6204\n",
      "Epoch 101/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6649 - accuracy: 0.5892 - val_loss: 0.6708 - val_accuracy: 0.5803\n",
      "Epoch 102/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6584 - accuracy: 0.6004 - val_loss: 0.6533 - val_accuracy: 0.6108\n",
      "Epoch 103/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6490 - accuracy: 0.6144 - val_loss: 0.6530 - val_accuracy: 0.6094\n",
      "Epoch 104/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6489 - accuracy: 0.6161 - val_loss: 0.6451 - val_accuracy: 0.6183\n",
      "Epoch 105/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6471 - accuracy: 0.6179 - val_loss: 0.6445 - val_accuracy: 0.6263\n",
      "Epoch 106/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6461 - accuracy: 0.6192 - val_loss: 0.6457 - val_accuracy: 0.6244\n",
      "Epoch 107/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6470 - accuracy: 0.6169 - val_loss: 0.6461 - val_accuracy: 0.6219\n",
      "Epoch 108/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6458 - accuracy: 0.6201 - val_loss: 0.6411 - val_accuracy: 0.6282\n",
      "Epoch 109/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6541 - accuracy: 0.6072 - val_loss: 0.6517 - val_accuracy: 0.6097\n",
      "Epoch 110/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6642 - accuracy: 0.5942 - val_loss: 0.7438 - val_accuracy: 0.5172\n",
      "Epoch 111/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6945 - accuracy: 0.5351 - val_loss: 0.6795 - val_accuracy: 0.5603\n",
      "Epoch 112/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6684 - accuracy: 0.5851 - val_loss: 0.6616 - val_accuracy: 0.6017\n",
      "Epoch 113/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6548 - accuracy: 0.6073 - val_loss: 0.6510 - val_accuracy: 0.6151\n",
      "Epoch 114/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6492 - accuracy: 0.6151 - val_loss: 0.6471 - val_accuracy: 0.6221\n",
      "Epoch 115/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6456 - accuracy: 0.6187 - val_loss: 0.6452 - val_accuracy: 0.6168\n",
      "Epoch 116/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6459 - accuracy: 0.6196 - val_loss: 0.6415 - val_accuracy: 0.6275\n",
      "Epoch 117/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6439 - accuracy: 0.6212 - val_loss: 0.6456 - val_accuracy: 0.6160\n",
      "Epoch 118/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6420 - accuracy: 0.6240 - val_loss: 0.6370 - val_accuracy: 0.6314\n",
      "Epoch 119/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6394 - accuracy: 0.6251 - val_loss: 0.6447 - val_accuracy: 0.6267\n",
      "Epoch 120/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6390 - accuracy: 0.6259 - val_loss: 0.6408 - val_accuracy: 0.6266\n",
      "Epoch 121/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6380 - accuracy: 0.6271 - val_loss: 0.6349 - val_accuracy: 0.6330\n",
      "Epoch 122/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6370 - accuracy: 0.6282 - val_loss: 0.6412 - val_accuracy: 0.6250\n",
      "Epoch 123/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6384 - accuracy: 0.6257 - val_loss: 0.6339 - val_accuracy: 0.6345\n",
      "Epoch 124/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6370 - accuracy: 0.6274 - val_loss: 0.6406 - val_accuracy: 0.6249\n",
      "Epoch 125/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6373 - accuracy: 0.6269 - val_loss: 0.6376 - val_accuracy: 0.6300\n",
      "Epoch 126/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6363 - accuracy: 0.6280 - val_loss: 0.6332 - val_accuracy: 0.6310\n",
      "Epoch 127/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6348 - accuracy: 0.6304 - val_loss: 0.6378 - val_accuracy: 0.6294\n",
      "Epoch 128/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6363 - accuracy: 0.6285 - val_loss: 0.6473 - val_accuracy: 0.6157\n",
      "Epoch 129/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6352 - accuracy: 0.6295 - val_loss: 0.6358 - val_accuracy: 0.6292\n",
      "Epoch 130/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6370 - accuracy: 0.6272 - val_loss: 0.6334 - val_accuracy: 0.6318\n",
      "Epoch 131/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6371 - accuracy: 0.6278 - val_loss: 0.6390 - val_accuracy: 0.6272\n",
      "Epoch 132/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6341 - accuracy: 0.6302 - val_loss: 0.6378 - val_accuracy: 0.6260\n",
      "Epoch 133/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6340 - accuracy: 0.6303 - val_loss: 0.6357 - val_accuracy: 0.6313\n",
      "Epoch 134/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6331 - accuracy: 0.6318 - val_loss: 0.6308 - val_accuracy: 0.6371\n",
      "Epoch 135/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6386 - accuracy: 0.6241 - val_loss: 0.6296 - val_accuracy: 0.6361\n",
      "Epoch 136/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6346 - accuracy: 0.6305 - val_loss: 0.6307 - val_accuracy: 0.6359\n",
      "Epoch 137/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6325 - accuracy: 0.6319 - val_loss: 0.6295 - val_accuracy: 0.6360\n",
      "Epoch 138/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6522 - accuracy: 0.6079 - val_loss: 0.6864 - val_accuracy: 0.5564\n",
      "Epoch 139/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6582 - accuracy: 0.5993 - val_loss: 0.6444 - val_accuracy: 0.6212\n",
      "Epoch 140/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6370 - accuracy: 0.6269 - val_loss: 0.6364 - val_accuracy: 0.6286\n",
      "Epoch 141/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6320 - accuracy: 0.6325 - val_loss: 0.6334 - val_accuracy: 0.6302\n",
      "Epoch 142/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6316 - accuracy: 0.6327 - val_loss: 0.6322 - val_accuracy: 0.6357\n",
      "Epoch 143/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6302 - accuracy: 0.6343 - val_loss: 0.6353 - val_accuracy: 0.6291\n",
      "Epoch 144/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6309 - accuracy: 0.6328 - val_loss: 0.6329 - val_accuracy: 0.6342\n",
      "Epoch 145/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6304 - accuracy: 0.6351 - val_loss: 0.6352 - val_accuracy: 0.6296\n",
      "Epoch 146/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6295 - accuracy: 0.6366 - val_loss: 0.6370 - val_accuracy: 0.6273\n",
      "Epoch 147/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6379 - accuracy: 0.6266 - val_loss: 0.6389 - val_accuracy: 0.6276\n",
      "Epoch 148/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6299 - accuracy: 0.6353 - val_loss: 0.6312 - val_accuracy: 0.6329\n",
      "Epoch 149/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7101 - accuracy: 0.5123 - val_loss: 0.6978 - val_accuracy: 0.5093\n",
      "Epoch 150/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6933 - accuracy: 0.5230 - val_loss: 0.6896 - val_accuracy: 0.5250\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_24\n",
      "cannot prune layer q_activation_24\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_25\n",
      "cannot prune layer q_activation_25\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 0.6548 - accuracy: 0.6007 - val_loss: 0.6523 - val_accuracy: 0.6102\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6344 - accuracy: 0.6303 - val_loss: 0.6393 - val_accuracy: 0.6215\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6331 - accuracy: 0.6321 - val_loss: 0.6465 - val_accuracy: 0.6137\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6713 - accuracy: 0.5825 - val_loss: 0.6578 - val_accuracy: 0.5916\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6360 - accuracy: 0.6296 - val_loss: 0.6378 - val_accuracy: 0.6257\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6304 - accuracy: 0.6348 - val_loss: 0.6416 - val_accuracy: 0.6205\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6304 - accuracy: 0.6354 - val_loss: 0.6276 - val_accuracy: 0.6382\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6286 - accuracy: 0.6372 - val_loss: 0.6274 - val_accuracy: 0.6423\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6288 - accuracy: 0.6368 - val_loss: 0.6316 - val_accuracy: 0.6374\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6288 - accuracy: 0.6370 - val_loss: 0.6256 - val_accuracy: 0.6419\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6274 - accuracy: 0.6390 - val_loss: 0.6252 - val_accuracy: 0.6419\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6715 - accuracy: 0.5848 - val_loss: 0.6984 - val_accuracy: 0.5389\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6894 - accuracy: 0.5473 - val_loss: 0.6851 - val_accuracy: 0.5526\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6829 - accuracy: 0.5571 - val_loss: 0.6804 - val_accuracy: 0.5635\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6783 - accuracy: 0.5659 - val_loss: 0.6766 - val_accuracy: 0.5716\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6743 - accuracy: 0.5739 - val_loss: 0.6723 - val_accuracy: 0.5813\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6690 - accuracy: 0.5843 - val_loss: 0.6660 - val_accuracy: 0.5906\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6626 - accuracy: 0.5935 - val_loss: 0.6598 - val_accuracy: 0.5981\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6569 - accuracy: 0.6027 - val_loss: 0.6537 - val_accuracy: 0.6061\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6531 - accuracy: 0.6080 - val_loss: 0.6496 - val_accuracy: 0.6128\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6490 - accuracy: 0.6137 - val_loss: 0.6498 - val_accuracy: 0.6139\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6454 - accuracy: 0.6181 - val_loss: 0.6452 - val_accuracy: 0.6182\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6418 - accuracy: 0.6230 - val_loss: 0.6402 - val_accuracy: 0.6261\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6381 - accuracy: 0.6265 - val_loss: 0.6367 - val_accuracy: 0.6305\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6353 - accuracy: 0.6303 - val_loss: 0.6353 - val_accuracy: 0.6331\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6333 - accuracy: 0.6316 - val_loss: 0.6303 - val_accuracy: 0.6394\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6318 - accuracy: 0.6339 - val_loss: 0.6292 - val_accuracy: 0.6374\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6772 - accuracy: 0.5956 - val_loss: 0.7385 - val_accuracy: 0.5254\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7094 - accuracy: 0.5379 - val_loss: 0.6961 - val_accuracy: 0.5495\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6894 - accuracy: 0.5550 - val_loss: 0.6850 - val_accuracy: 0.5614\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6752 - accuracy: 0.5730 - val_loss: 0.6663 - val_accuracy: 0.5869\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6531 - accuracy: 0.6061 - val_loss: 0.6453 - val_accuracy: 0.6201\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6418 - accuracy: 0.6211 - val_loss: 0.6359 - val_accuracy: 0.6299\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6363 - accuracy: 0.6278 - val_loss: 0.6320 - val_accuracy: 0.6371\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6486 - accuracy: 0.6118 - val_loss: 0.6481 - val_accuracy: 0.6185\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6403 - accuracy: 0.6239 - val_loss: 0.6360 - val_accuracy: 0.6299\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6332 - accuracy: 0.6329 - val_loss: 0.6308 - val_accuracy: 0.6389\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6313 - accuracy: 0.6348 - val_loss: 0.6312 - val_accuracy: 0.6333\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6327 - accuracy: 0.6335 - val_loss: 0.6341 - val_accuracy: 0.6312\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6300 - accuracy: 0.6359 - val_loss: 0.6269 - val_accuracy: 0.6442\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6294 - accuracy: 0.6365 - val_loss: 0.6244 - val_accuracy: 0.6444\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6295 - accuracy: 0.6361 - val_loss: 0.7389 - val_accuracy: 0.5463\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6367 - accuracy: 0.6286 - val_loss: 0.6268 - val_accuracy: 0.6417\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6290 - accuracy: 0.6372 - val_loss: 0.6275 - val_accuracy: 0.6408\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6274 - accuracy: 0.6388 - val_loss: 0.6330 - val_accuracy: 0.6326\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6268 - accuracy: 0.6395 - val_loss: 0.6273 - val_accuracy: 0.6459\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6268 - accuracy: 0.6404 - val_loss: 0.6293 - val_accuracy: 0.6367\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6260 - accuracy: 0.6402 - val_loss: 0.6263 - val_accuracy: 0.6404\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6279 - accuracy: 0.6380 - val_loss: 0.6253 - val_accuracy: 0.6448\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6266 - accuracy: 0.6391 - val_loss: 0.6279 - val_accuracy: 0.6392\n",
      "1714/1714 [==============================] - 3s 1ms/step\n",
      "[[0.423079  ]\n",
      " [0.60368705]\n",
      " [0.54961866]\n",
      " [0.52334636]\n",
      " [0.14553446]\n",
      " [0.4507345 ]\n",
      " [0.6248934 ]\n",
      " [0.63589364]\n",
      " [0.57060176]\n",
      " [0.5671425 ]]\n",
      "########### FOUND NEW BEST METRIC 0.3960911340806522 ##############\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.002, 'BATCH_SIZE': 1024, 'EPOCHS': 100, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.3, 'POST_PRUNE_EPOCHS': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sdf/home/a/alexyue/miniconda3/envs/SmartPixel/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 24)                96        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_26 (QActivati  (None, 24)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_27 (Ba  (None, 12)                48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_27 (QActivati  (None, 12)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_26 is normal keras bn layer\n",
      "q_activation_26      quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_27 is normal keras bn layer\n",
      "q_activation_27      quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/100\n",
      "429/429 [==============================] - 6s 7ms/step - loss: 1.5038 - accuracy: 0.4998 - val_loss: 0.9148 - val_accuracy: 0.5018\n",
      "Epoch 2/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7377 - accuracy: 0.5005 - val_loss: 0.7292 - val_accuracy: 0.5028\n",
      "Epoch 3/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7195 - accuracy: 0.5012 - val_loss: 0.7099 - val_accuracy: 0.5032\n",
      "Epoch 4/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7082 - accuracy: 0.5005 - val_loss: 0.7051 - val_accuracy: 0.5022\n",
      "Epoch 5/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7045 - accuracy: 0.5014 - val_loss: 0.7038 - val_accuracy: 0.5032\n",
      "Epoch 6/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7020 - accuracy: 0.5022 - val_loss: 0.7012 - val_accuracy: 0.5046\n",
      "Epoch 7/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7001 - accuracy: 0.5034 - val_loss: 0.6997 - val_accuracy: 0.5042\n",
      "Epoch 8/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6988 - accuracy: 0.5040 - val_loss: 0.6986 - val_accuracy: 0.5044\n",
      "Epoch 9/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6978 - accuracy: 0.5046 - val_loss: 0.6978 - val_accuracy: 0.5030\n",
      "Epoch 10/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6970 - accuracy: 0.5036 - val_loss: 0.6971 - val_accuracy: 0.5042\n",
      "Epoch 11/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6963 - accuracy: 0.5051 - val_loss: 0.6966 - val_accuracy: 0.5034\n",
      "Epoch 12/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6958 - accuracy: 0.5054 - val_loss: 0.6960 - val_accuracy: 0.5030\n",
      "Epoch 13/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6952 - accuracy: 0.5057 - val_loss: 0.6956 - val_accuracy: 0.5055\n",
      "Epoch 14/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6949 - accuracy: 0.5059 - val_loss: 0.6951 - val_accuracy: 0.5050\n",
      "Epoch 15/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6946 - accuracy: 0.5065 - val_loss: 0.6951 - val_accuracy: 0.5053\n",
      "Epoch 16/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6944 - accuracy: 0.5045 - val_loss: 0.6949 - val_accuracy: 0.5080\n",
      "Epoch 17/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6943 - accuracy: 0.5061 - val_loss: 0.6948 - val_accuracy: 0.5063\n",
      "Epoch 18/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6940 - accuracy: 0.5060 - val_loss: 0.6947 - val_accuracy: 0.5056\n",
      "Epoch 19/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6940 - accuracy: 0.5072 - val_loss: 0.6945 - val_accuracy: 0.5077\n",
      "Epoch 20/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6938 - accuracy: 0.5072 - val_loss: 0.6942 - val_accuracy: 0.5079\n",
      "Epoch 21/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6935 - accuracy: 0.5076 - val_loss: 0.6938 - val_accuracy: 0.5072\n",
      "Epoch 22/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6935 - accuracy: 0.5066 - val_loss: 0.6944 - val_accuracy: 0.5013\n",
      "Epoch 23/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.5085 - val_loss: 0.6939 - val_accuracy: 0.5081\n",
      "Epoch 24/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6931 - accuracy: 0.5092 - val_loss: 0.6939 - val_accuracy: 0.5075\n",
      "Epoch 25/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6931 - accuracy: 0.5091 - val_loss: 0.6935 - val_accuracy: 0.5046\n",
      "Epoch 26/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6930 - accuracy: 0.5084 - val_loss: 0.6936 - val_accuracy: 0.5070\n",
      "Epoch 27/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6929 - accuracy: 0.5093 - val_loss: 0.6938 - val_accuracy: 0.5076\n",
      "Epoch 28/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6929 - accuracy: 0.5078 - val_loss: 0.6935 - val_accuracy: 0.5093\n",
      "Epoch 29/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6929 - accuracy: 0.5091 - val_loss: 0.6936 - val_accuracy: 0.5072\n",
      "Epoch 30/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.5094 - val_loss: 0.6941 - val_accuracy: 0.5063\n",
      "Epoch 31/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5092 - val_loss: 0.6933 - val_accuracy: 0.5016\n",
      "Epoch 32/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6927 - accuracy: 0.5103 - val_loss: 0.6938 - val_accuracy: 0.5048\n",
      "Epoch 33/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6927 - accuracy: 0.5116 - val_loss: 0.6929 - val_accuracy: 0.5126\n",
      "Epoch 34/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6926 - accuracy: 0.5108 - val_loss: 0.6934 - val_accuracy: 0.5075\n",
      "Epoch 35/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5116 - val_loss: 0.6931 - val_accuracy: 0.5097\n",
      "Epoch 36/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6923 - accuracy: 0.5132 - val_loss: 0.6932 - val_accuracy: 0.5087\n",
      "Epoch 37/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6922 - accuracy: 0.5162 - val_loss: 0.6931 - val_accuracy: 0.5142\n",
      "Epoch 38/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6921 - accuracy: 0.5162 - val_loss: 0.6928 - val_accuracy: 0.5180\n",
      "Epoch 39/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5243\n",
      "Epoch 40/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6913 - accuracy: 0.5225 - val_loss: 0.6918 - val_accuracy: 0.5234\n",
      "Epoch 41/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6905 - accuracy: 0.5267 - val_loss: 0.6916 - val_accuracy: 0.5227\n",
      "Epoch 42/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6893 - accuracy: 0.5320 - val_loss: 0.6912 - val_accuracy: 0.5304\n",
      "Epoch 43/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6873 - accuracy: 0.5386 - val_loss: 0.6880 - val_accuracy: 0.5404\n",
      "Epoch 44/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6855 - accuracy: 0.5442 - val_loss: 0.6859 - val_accuracy: 0.5456\n",
      "Epoch 45/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6834 - accuracy: 0.5481 - val_loss: 0.6831 - val_accuracy: 0.5490\n",
      "Epoch 46/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6816 - accuracy: 0.5532 - val_loss: 0.6803 - val_accuracy: 0.5537\n",
      "Epoch 47/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6793 - accuracy: 0.5574 - val_loss: 0.6937 - val_accuracy: 0.5390\n",
      "Epoch 48/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6781 - accuracy: 0.5602 - val_loss: 0.6779 - val_accuracy: 0.5601\n",
      "Epoch 49/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6748 - accuracy: 0.5660 - val_loss: 0.6746 - val_accuracy: 0.5699\n",
      "Epoch 50/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6729 - accuracy: 0.5690 - val_loss: 0.6732 - val_accuracy: 0.5665\n",
      "Epoch 51/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6712 - accuracy: 0.5710 - val_loss: 0.6975 - val_accuracy: 0.5330\n",
      "Epoch 52/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6719 - accuracy: 0.5728 - val_loss: 0.6915 - val_accuracy: 0.5476\n",
      "Epoch 53/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6736 - accuracy: 0.5711 - val_loss: 0.6686 - val_accuracy: 0.5783\n",
      "Epoch 54/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6729 - accuracy: 0.5725 - val_loss: 0.6697 - val_accuracy: 0.5758\n",
      "Epoch 55/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6692 - accuracy: 0.5761 - val_loss: 0.6633 - val_accuracy: 0.5844\n",
      "Epoch 56/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6654 - accuracy: 0.5807 - val_loss: 0.6613 - val_accuracy: 0.5872\n",
      "Epoch 57/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6727 - accuracy: 0.5633 - val_loss: 0.6989 - val_accuracy: 0.5086\n",
      "Epoch 58/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6938 - accuracy: 0.5048 - val_loss: 0.6932 - val_accuracy: 0.5035\n",
      "Epoch 59/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6926 - accuracy: 0.5158 - val_loss: 0.6931 - val_accuracy: 0.5247\n",
      "Epoch 60/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6895 - accuracy: 0.5307 - val_loss: 0.6903 - val_accuracy: 0.5255\n",
      "Epoch 61/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6770 - accuracy: 0.5610 - val_loss: 0.6848 - val_accuracy: 0.5395\n",
      "Epoch 62/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6721 - accuracy: 0.5726 - val_loss: 0.6719 - val_accuracy: 0.5723\n",
      "Epoch 63/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6678 - accuracy: 0.5803 - val_loss: 0.6662 - val_accuracy: 0.5803\n",
      "Epoch 64/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6731 - accuracy: 0.5675 - val_loss: 0.6803 - val_accuracy: 0.5537\n",
      "Epoch 65/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6672 - accuracy: 0.5802 - val_loss: 0.6708 - val_accuracy: 0.5733\n",
      "Epoch 66/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6698 - accuracy: 0.5718 - val_loss: 0.6968 - val_accuracy: 0.5176\n",
      "Epoch 67/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6726 - accuracy: 0.5687 - val_loss: 0.6728 - val_accuracy: 0.5711\n",
      "Epoch 68/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6834 - accuracy: 0.5409 - val_loss: 0.6955 - val_accuracy: 0.5040\n",
      "Epoch 69/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6941 - accuracy: 0.5050 - val_loss: 0.6937 - val_accuracy: 0.5040\n",
      "Epoch 70/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6934 - accuracy: 0.5077 - val_loss: 0.6931 - val_accuracy: 0.5091\n",
      "Epoch 71/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6928 - val_accuracy: 0.5091\n",
      "Epoch 72/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5111 - val_loss: 0.6926 - val_accuracy: 0.5133\n",
      "Epoch 73/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6927 - accuracy: 0.5121 - val_loss: 0.6925 - val_accuracy: 0.5111\n",
      "Epoch 74/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6926 - accuracy: 0.5126 - val_loss: 0.6925 - val_accuracy: 0.5129\n",
      "Epoch 75/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6924 - accuracy: 0.5147 - val_loss: 0.6923 - val_accuracy: 0.5145\n",
      "Epoch 76/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6921 - accuracy: 0.5168 - val_loss: 0.6922 - val_accuracy: 0.5168\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_26\n",
      "cannot prune layer q_activation_26\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_27\n",
      "cannot prune layer q_activation_27\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 0.6729 - accuracy: 0.5695 - val_loss: 0.6783 - val_accuracy: 0.5581\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6624 - accuracy: 0.5851 - val_loss: 0.6659 - val_accuracy: 0.5840\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6603 - accuracy: 0.5889 - val_loss: 0.6645 - val_accuracy: 0.5815\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6597 - accuracy: 0.5897 - val_loss: 0.6600 - val_accuracy: 0.5868\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6869 - accuracy: 0.5434 - val_loss: 0.7024 - val_accuracy: 0.5001\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6959 - accuracy: 0.5030 - val_loss: 0.6946 - val_accuracy: 0.5067\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6939 - accuracy: 0.5072 - val_loss: 0.6942 - val_accuracy: 0.5071\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6933 - accuracy: 0.5094 - val_loss: 0.6936 - val_accuracy: 0.5092\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6930 - accuracy: 0.5114 - val_loss: 0.6931 - val_accuracy: 0.5124\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6927 - accuracy: 0.5136 - val_loss: 0.6930 - val_accuracy: 0.5136\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5155 - val_loss: 0.6928 - val_accuracy: 0.5136\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6920 - accuracy: 0.5189 - val_loss: 0.6922 - val_accuracy: 0.5195\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6916 - accuracy: 0.5218 - val_loss: 0.6922 - val_accuracy: 0.5150\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6909 - accuracy: 0.5258 - val_loss: 0.6910 - val_accuracy: 0.5232\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6899 - accuracy: 0.5298 - val_loss: 0.6894 - val_accuracy: 0.5314\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6886 - accuracy: 0.5335 - val_loss: 0.6876 - val_accuracy: 0.5386\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6868 - accuracy: 0.5390 - val_loss: 0.6866 - val_accuracy: 0.5369\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6846 - accuracy: 0.5465 - val_loss: 0.6859 - val_accuracy: 0.5440\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6815 - accuracy: 0.5546 - val_loss: 0.6793 - val_accuracy: 0.5594\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6787 - accuracy: 0.5605 - val_loss: 0.6793 - val_accuracy: 0.5560\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6761 - accuracy: 0.5659 - val_loss: 0.6746 - val_accuracy: 0.5739\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6736 - accuracy: 0.5719 - val_loss: 0.6735 - val_accuracy: 0.5705\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6787 - accuracy: 0.5594 - val_loss: 0.6804 - val_accuracy: 0.5568\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6737 - accuracy: 0.5679 - val_loss: 0.6695 - val_accuracy: 0.5744\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6732 - accuracy: 0.5696 - val_loss: 0.6836 - val_accuracy: 0.5473\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6720 - accuracy: 0.5732 - val_loss: 0.6671 - val_accuracy: 0.5843\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6672 - accuracy: 0.5833 - val_loss: 0.6712 - val_accuracy: 0.5718\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6667 - accuracy: 0.5834 - val_loss: 0.6657 - val_accuracy: 0.5827\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6639 - accuracy: 0.5868 - val_loss: 0.6603 - val_accuracy: 0.5916\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6639 - accuracy: 0.5888 - val_loss: 0.6629 - val_accuracy: 0.5870\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6626 - accuracy: 0.5898 - val_loss: 0.6599 - val_accuracy: 0.5937\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6615 - accuracy: 0.5910 - val_loss: 0.6649 - val_accuracy: 0.5835\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6609 - accuracy: 0.5915 - val_loss: 0.6610 - val_accuracy: 0.5917\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6599 - accuracy: 0.5933 - val_loss: 0.6570 - val_accuracy: 0.5978\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6602 - accuracy: 0.5931 - val_loss: 0.6570 - val_accuracy: 0.5985\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6591 - accuracy: 0.5949 - val_loss: 0.6589 - val_accuracy: 0.5947\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6606 - accuracy: 0.5924 - val_loss: 0.6582 - val_accuracy: 0.5972\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6584 - accuracy: 0.5956 - val_loss: 0.6556 - val_accuracy: 0.6023\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6629 - accuracy: 0.5917 - val_loss: 0.6625 - val_accuracy: 0.5868\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6676 - accuracy: 0.5835 - val_loss: 0.6989 - val_accuracy: 0.5165\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6748 - accuracy: 0.5650 - val_loss: 0.6737 - val_accuracy: 0.5779\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6612 - accuracy: 0.5919 - val_loss: 0.6693 - val_accuracy: 0.5783\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6585 - accuracy: 0.5955 - val_loss: 0.6560 - val_accuracy: 0.5989\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6751 - accuracy: 0.5732 - val_loss: 0.6725 - val_accuracy: 0.5751\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6640 - accuracy: 0.5892 - val_loss: 0.6579 - val_accuracy: 0.5994\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6587 - accuracy: 0.5966 - val_loss: 0.6568 - val_accuracy: 0.5970\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6581 - accuracy: 0.5965 - val_loss: 0.6604 - val_accuracy: 0.5935\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6571 - accuracy: 0.5984 - val_loss: 0.6560 - val_accuracy: 0.5988\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6577 - accuracy: 0.5971 - val_loss: 0.6572 - val_accuracy: 0.5972\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6552 - accuracy: 0.6010 - val_loss: 0.6560 - val_accuracy: 0.5988\n",
      "1714/1714 [==============================] - 4s 1ms/step\n",
      "[[0.48235464]\n",
      " [0.58553773]\n",
      " [0.5742767 ]\n",
      " [0.5329846 ]\n",
      " [0.62263685]\n",
      " [0.540028  ]\n",
      " [0.5881012 ]\n",
      " [0.54043263]\n",
      " [0.5953689 ]\n",
      " [0.4096765 ]]\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.002, 'BATCH_SIZE': 1024, 'EPOCHS': 150, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.3, 'POST_PRUNE_EPOCHS': 50}\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_28 (Ba  (None, 24)                96        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_28 (QActivati  (None, 24)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_29 (Ba  (None, 12)                48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_29 (QActivati  (None, 12)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_28 is normal keras bn layer\n",
      "q_activation_28      quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_29 is normal keras bn layer\n",
      "q_activation_29      quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/150\n",
      "429/429 [==============================] - 6s 7ms/step - loss: 0.7367 - accuracy: 0.4993 - val_loss: 0.7015 - val_accuracy: 0.5023\n",
      "Epoch 2/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6982 - accuracy: 0.5040 - val_loss: 0.6962 - val_accuracy: 0.5094\n",
      "Epoch 3/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6954 - accuracy: 0.5074 - val_loss: 0.6951 - val_accuracy: 0.5106\n",
      "Epoch 4/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6942 - accuracy: 0.5091 - val_loss: 0.6942 - val_accuracy: 0.5055\n",
      "Epoch 5/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6936 - accuracy: 0.5092 - val_loss: 0.6940 - val_accuracy: 0.5059\n",
      "Epoch 6/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6932 - accuracy: 0.5115 - val_loss: 0.6941 - val_accuracy: 0.5072\n",
      "Epoch 7/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6930 - accuracy: 0.5115 - val_loss: 0.6940 - val_accuracy: 0.5104\n",
      "Epoch 8/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.5117 - val_loss: 0.6937 - val_accuracy: 0.5120\n",
      "Epoch 9/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5127 - val_loss: 0.6937 - val_accuracy: 0.5102\n",
      "Epoch 10/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6925 - accuracy: 0.5132 - val_loss: 0.6930 - val_accuracy: 0.5126\n",
      "Epoch 11/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6922 - accuracy: 0.5157 - val_loss: 0.6926 - val_accuracy: 0.5158\n",
      "Epoch 12/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5155 - val_loss: 0.6928 - val_accuracy: 0.5115\n",
      "Epoch 13/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6932 - accuracy: 0.5145 - val_loss: 0.6973 - val_accuracy: 0.5114\n",
      "Epoch 14/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6929 - accuracy: 0.5155 - val_loss: 0.6925 - val_accuracy: 0.5175\n",
      "Epoch 15/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6918 - accuracy: 0.5206 - val_loss: 0.6927 - val_accuracy: 0.5136\n",
      "Epoch 16/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6910 - accuracy: 0.5241 - val_loss: 0.6919 - val_accuracy: 0.5214\n",
      "Epoch 17/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6903 - accuracy: 0.5287 - val_loss: 0.6904 - val_accuracy: 0.5337\n",
      "Epoch 18/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6892 - accuracy: 0.5334 - val_loss: 0.6900 - val_accuracy: 0.5337\n",
      "Epoch 19/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6876 - accuracy: 0.5399 - val_loss: 0.6892 - val_accuracy: 0.5216\n",
      "Epoch 20/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6863 - accuracy: 0.5439 - val_loss: 0.6866 - val_accuracy: 0.5475\n",
      "Epoch 21/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6843 - accuracy: 0.5491 - val_loss: 0.6827 - val_accuracy: 0.5537\n",
      "Epoch 22/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6802 - accuracy: 0.5579 - val_loss: 0.6782 - val_accuracy: 0.5585\n",
      "Epoch 23/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6757 - accuracy: 0.5658 - val_loss: 0.6781 - val_accuracy: 0.5653\n",
      "Epoch 24/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6741 - accuracy: 0.5690 - val_loss: 0.6802 - val_accuracy: 0.5544\n",
      "Epoch 25/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6726 - accuracy: 0.5707 - val_loss: 0.6723 - val_accuracy: 0.5724\n",
      "Epoch 26/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6720 - accuracy: 0.5720 - val_loss: 0.6773 - val_accuracy: 0.5574\n",
      "Epoch 27/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6654 - accuracy: 0.5816 - val_loss: 0.6640 - val_accuracy: 0.5824\n",
      "Epoch 28/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6613 - accuracy: 0.5865 - val_loss: 0.6633 - val_accuracy: 0.5840\n",
      "Epoch 29/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6602 - accuracy: 0.5896 - val_loss: 0.6692 - val_accuracy: 0.5804\n",
      "Epoch 30/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6578 - accuracy: 0.5914 - val_loss: 0.6582 - val_accuracy: 0.5906\n",
      "Epoch 31/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6551 - accuracy: 0.5947 - val_loss: 0.6504 - val_accuracy: 0.6018\n",
      "Epoch 32/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6943 - accuracy: 0.5248 - val_loss: 0.6947 - val_accuracy: 0.5036\n",
      "Epoch 33/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6929 - accuracy: 0.5141 - val_loss: 0.6927 - val_accuracy: 0.5191\n",
      "Epoch 34/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6909 - accuracy: 0.5234 - val_loss: 0.6902 - val_accuracy: 0.5243\n",
      "Epoch 35/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6840 - accuracy: 0.5467 - val_loss: 0.6805 - val_accuracy: 0.5576\n",
      "Epoch 36/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6674 - accuracy: 0.5797 - val_loss: 0.6840 - val_accuracy: 0.5505\n",
      "Epoch 37/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6548 - accuracy: 0.5970 - val_loss: 0.6668 - val_accuracy: 0.5887\n",
      "Epoch 38/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6538 - accuracy: 0.5988 - val_loss: 0.6593 - val_accuracy: 0.5897\n",
      "Epoch 39/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6611 - accuracy: 0.5871 - val_loss: 0.6631 - val_accuracy: 0.5882\n",
      "Epoch 40/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6539 - accuracy: 0.5982 - val_loss: 0.6761 - val_accuracy: 0.5827\n",
      "Epoch 41/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6492 - accuracy: 0.6037 - val_loss: 0.6581 - val_accuracy: 0.5896\n",
      "Epoch 42/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6499 - accuracy: 0.6022 - val_loss: 0.6493 - val_accuracy: 0.6077\n",
      "Epoch 43/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6490 - accuracy: 0.6046 - val_loss: 0.7102 - val_accuracy: 0.5396\n",
      "Epoch 44/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6685 - accuracy: 0.5738 - val_loss: 0.6944 - val_accuracy: 0.5214\n",
      "Epoch 45/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6806 - accuracy: 0.5534 - val_loss: 0.6711 - val_accuracy: 0.5793\n",
      "Epoch 46/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6595 - accuracy: 0.5899 - val_loss: 0.6552 - val_accuracy: 0.5982\n",
      "Epoch 47/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6547 - accuracy: 0.5951 - val_loss: 0.6525 - val_accuracy: 0.6007\n",
      "Epoch 48/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6520 - accuracy: 0.5989 - val_loss: 0.6489 - val_accuracy: 0.5967\n",
      "Epoch 49/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6506 - accuracy: 0.6027 - val_loss: 0.6598 - val_accuracy: 0.5842\n",
      "Epoch 50/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6476 - accuracy: 0.6050 - val_loss: 0.6420 - val_accuracy: 0.6193\n",
      "Epoch 51/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6469 - accuracy: 0.6070 - val_loss: 0.6404 - val_accuracy: 0.6210\n",
      "Epoch 52/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6446 - accuracy: 0.6104 - val_loss: 0.6488 - val_accuracy: 0.6012\n",
      "Epoch 53/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6646 - accuracy: 0.5765 - val_loss: 0.6969 - val_accuracy: 0.5104\n",
      "Epoch 54/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6921 - accuracy: 0.5208 - val_loss: 0.6906 - val_accuracy: 0.5315\n",
      "Epoch 55/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6855 - accuracy: 0.5444 - val_loss: 0.6985 - val_accuracy: 0.5217\n",
      "Epoch 56/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6554 - accuracy: 0.5971 - val_loss: 0.6468 - val_accuracy: 0.6146\n",
      "Epoch 57/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6500 - accuracy: 0.6050 - val_loss: 0.6461 - val_accuracy: 0.6116\n",
      "Epoch 58/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6483 - accuracy: 0.6062 - val_loss: 0.6463 - val_accuracy: 0.6134\n",
      "Epoch 59/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6733 - accuracy: 0.5626 - val_loss: 0.6976 - val_accuracy: 0.5013\n",
      "Epoch 60/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6935 - accuracy: 0.5080 - val_loss: 0.6932 - val_accuracy: 0.5104\n",
      "Epoch 61/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6927 - accuracy: 0.5119 - val_loss: 0.6926 - val_accuracy: 0.5118\n",
      "Epoch 62/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6924 - accuracy: 0.5142 - val_loss: 0.6922 - val_accuracy: 0.5156\n",
      "Epoch 63/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6920 - accuracy: 0.5171 - val_loss: 0.6921 - val_accuracy: 0.5167\n",
      "Epoch 64/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6915 - val_accuracy: 0.5183\n",
      "Epoch 65/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6908 - accuracy: 0.5226 - val_loss: 0.6906 - val_accuracy: 0.5225\n",
      "Epoch 66/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6896 - accuracy: 0.5289 - val_loss: 0.6903 - val_accuracy: 0.5267\n",
      "Epoch 67/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6880 - accuracy: 0.5356 - val_loss: 0.6875 - val_accuracy: 0.5332\n",
      "Epoch 68/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6849 - accuracy: 0.5430 - val_loss: 0.6836 - val_accuracy: 0.5463\n",
      "Epoch 69/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6802 - accuracy: 0.5526 - val_loss: 0.6777 - val_accuracy: 0.5530\n",
      "Epoch 70/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6712 - accuracy: 0.5706 - val_loss: 0.6791 - val_accuracy: 0.5612\n",
      "Epoch 71/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6624 - accuracy: 0.5861 - val_loss: 0.6636 - val_accuracy: 0.5833\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_28\n",
      "cannot prune layer q_activation_28\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_29\n",
      "cannot prune layer q_activation_29\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 0.6502 - accuracy: 0.6038 - val_loss: 0.6750 - val_accuracy: 0.5726\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6437 - accuracy: 0.6117 - val_loss: 0.6411 - val_accuracy: 0.6124\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6425 - accuracy: 0.6136 - val_loss: 0.6799 - val_accuracy: 0.5740\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6419 - accuracy: 0.6151 - val_loss: 0.6658 - val_accuracy: 0.5818\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6424 - accuracy: 0.6139 - val_loss: 0.6583 - val_accuracy: 0.6003\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6406 - accuracy: 0.6154 - val_loss: 0.6390 - val_accuracy: 0.6175\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6397 - accuracy: 0.6177 - val_loss: 0.6445 - val_accuracy: 0.6107\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6383 - accuracy: 0.6196 - val_loss: 0.6327 - val_accuracy: 0.6278\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6374 - accuracy: 0.6205 - val_loss: 0.6303 - val_accuracy: 0.6318\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6373 - accuracy: 0.6210 - val_loss: 0.6723 - val_accuracy: 0.5765\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6381 - accuracy: 0.6202 - val_loss: 0.6701 - val_accuracy: 0.5751\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6416 - accuracy: 0.6162 - val_loss: 0.6388 - val_accuracy: 0.6240\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6368 - accuracy: 0.6212 - val_loss: 0.6348 - val_accuracy: 0.6216\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6394 - accuracy: 0.6203 - val_loss: 0.6359 - val_accuracy: 0.6268\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6541 - accuracy: 0.6017 - val_loss: 0.6632 - val_accuracy: 0.5965\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6580 - accuracy: 0.5973 - val_loss: 0.6598 - val_accuracy: 0.6003\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6399 - accuracy: 0.6180 - val_loss: 0.6339 - val_accuracy: 0.6236\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6359 - accuracy: 0.6217 - val_loss: 0.6315 - val_accuracy: 0.6293\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6711 - accuracy: 0.5781 - val_loss: 0.6551 - val_accuracy: 0.6043\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6377 - accuracy: 0.6197 - val_loss: 0.6349 - val_accuracy: 0.6214\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6741 - accuracy: 0.5653 - val_loss: 0.6793 - val_accuracy: 0.5579\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6549 - accuracy: 0.6008 - val_loss: 0.6756 - val_accuracy: 0.5684\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6430 - accuracy: 0.6131 - val_loss: 0.6393 - val_accuracy: 0.6096\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6379 - accuracy: 0.6190 - val_loss: 0.6740 - val_accuracy: 0.5790\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6693 - accuracy: 0.5776 - val_loss: 0.6942 - val_accuracy: 0.5305\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6675 - accuracy: 0.5817 - val_loss: 0.6650 - val_accuracy: 0.5855\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6410 - accuracy: 0.6169 - val_loss: 0.6348 - val_accuracy: 0.6231\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6358 - accuracy: 0.6221 - val_loss: 0.6668 - val_accuracy: 0.5776\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6361 - accuracy: 0.6220 - val_loss: 0.6267 - val_accuracy: 0.6346\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6345 - accuracy: 0.6248 - val_loss: 0.6347 - val_accuracy: 0.6272\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6464 - accuracy: 0.6106 - val_loss: 0.6345 - val_accuracy: 0.6268\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6341 - accuracy: 0.6234 - val_loss: 0.6310 - val_accuracy: 0.6275\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6428 - accuracy: 0.6147 - val_loss: 0.6387 - val_accuracy: 0.6129\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6370 - accuracy: 0.6200 - val_loss: 0.6323 - val_accuracy: 0.6256\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6329 - accuracy: 0.6263 - val_loss: 0.6266 - val_accuracy: 0.6299\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6735 - accuracy: 0.5619 - val_loss: 0.6955 - val_accuracy: 0.5137\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5199 - val_loss: 0.6919 - val_accuracy: 0.5178\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6863 - accuracy: 0.5453 - val_loss: 0.6940 - val_accuracy: 0.5261\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6595 - accuracy: 0.5925 - val_loss: 0.6500 - val_accuracy: 0.6104\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6438 - accuracy: 0.6124 - val_loss: 0.6450 - val_accuracy: 0.6174\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6368 - accuracy: 0.6214 - val_loss: 0.6345 - val_accuracy: 0.6183\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6437 - accuracy: 0.6114 - val_loss: 0.6864 - val_accuracy: 0.5538\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6381 - accuracy: 0.6201 - val_loss: 0.6294 - val_accuracy: 0.6355\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6339 - accuracy: 0.6265 - val_loss: 0.6362 - val_accuracy: 0.6194\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6338 - accuracy: 0.6253 - val_loss: 0.6366 - val_accuracy: 0.6224\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6320 - accuracy: 0.6275 - val_loss: 0.6280 - val_accuracy: 0.6310\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6342 - accuracy: 0.6252 - val_loss: 0.6278 - val_accuracy: 0.6383\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6341 - accuracy: 0.6261 - val_loss: 0.6257 - val_accuracy: 0.6382\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6339 - accuracy: 0.6262 - val_loss: 0.6262 - val_accuracy: 0.6346\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6539 - accuracy: 0.6027 - val_loss: 0.6348 - val_accuracy: 0.6285\n",
      "1714/1714 [==============================] - 3s 1ms/step\n",
      "[[0.5875566 ]\n",
      " [0.69737273]\n",
      " [0.65545154]\n",
      " [0.48506677]\n",
      " [0.41130918]\n",
      " [0.5828571 ]\n",
      " [0.58446896]\n",
      " [0.5691482 ]\n",
      " [0.69341147]\n",
      " [0.5410796 ]]\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.001, 'BATCH_SIZE': 1024, 'EPOCHS': 100, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.3, 'POST_PRUNE_EPOCHS': 50}\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_30 (Ba  (None, 24)                96        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_30 (QActivati  (None, 24)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_31 (Ba  (None, 12)                48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_31 (QActivati  (None, 12)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_30 is normal keras bn layer\n",
      "q_activation_30      quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_31 is normal keras bn layer\n",
      "q_activation_31      quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/100\n",
      "429/429 [==============================] - 5s 7ms/step - loss: 1.2090 - accuracy: 0.4997 - val_loss: 0.8801 - val_accuracy: 0.5056\n",
      "Epoch 2/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7838 - accuracy: 0.5005 - val_loss: 0.7439 - val_accuracy: 0.5028\n",
      "Epoch 3/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7359 - accuracy: 0.5011 - val_loss: 0.7239 - val_accuracy: 0.5037\n",
      "Epoch 4/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7229 - accuracy: 0.5011 - val_loss: 0.7116 - val_accuracy: 0.5046\n",
      "Epoch 5/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7271 - accuracy: 0.5022 - val_loss: 0.7286 - val_accuracy: 0.5034\n",
      "Epoch 6/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7186 - accuracy: 0.5024 - val_loss: 0.7156 - val_accuracy: 0.5052\n",
      "Epoch 7/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7106 - accuracy: 0.5026 - val_loss: 0.7036 - val_accuracy: 0.5048\n",
      "Epoch 8/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7037 - accuracy: 0.5037 - val_loss: 0.7012 - val_accuracy: 0.5061\n",
      "Epoch 9/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7014 - accuracy: 0.5038 - val_loss: 0.6993 - val_accuracy: 0.5053\n",
      "Epoch 10/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6996 - accuracy: 0.5042 - val_loss: 0.6975 - val_accuracy: 0.5080\n",
      "Epoch 11/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6980 - accuracy: 0.5047 - val_loss: 0.6967 - val_accuracy: 0.5070\n",
      "Epoch 12/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6970 - accuracy: 0.5061 - val_loss: 0.6958 - val_accuracy: 0.5068\n",
      "Epoch 13/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6964 - accuracy: 0.5057 - val_loss: 0.6951 - val_accuracy: 0.5084\n",
      "Epoch 14/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6958 - accuracy: 0.5059 - val_loss: 0.6948 - val_accuracy: 0.5086\n",
      "Epoch 15/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6952 - accuracy: 0.5069 - val_loss: 0.6945 - val_accuracy: 0.5083\n",
      "Epoch 16/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6949 - accuracy: 0.5064 - val_loss: 0.6943 - val_accuracy: 0.5104\n",
      "Epoch 17/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6945 - accuracy: 0.5084 - val_loss: 0.6942 - val_accuracy: 0.5103\n",
      "Epoch 18/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6942 - accuracy: 0.5076 - val_loss: 0.6939 - val_accuracy: 0.5123\n",
      "Epoch 19/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6939 - accuracy: 0.5093 - val_loss: 0.6940 - val_accuracy: 0.5108\n",
      "Epoch 20/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6938 - accuracy: 0.5091 - val_loss: 0.6940 - val_accuracy: 0.5103\n",
      "Epoch 21/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6936 - accuracy: 0.5094 - val_loss: 0.6938 - val_accuracy: 0.5063\n",
      "Epoch 22/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6934 - accuracy: 0.5099 - val_loss: 0.6937 - val_accuracy: 0.5123\n",
      "Epoch 23/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.5107 - val_loss: 0.6943 - val_accuracy: 0.5040\n",
      "Epoch 24/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6931 - accuracy: 0.5116 - val_loss: 0.6934 - val_accuracy: 0.5089\n",
      "Epoch 25/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6930 - accuracy: 0.5124 - val_loss: 0.6932 - val_accuracy: 0.5118\n",
      "Epoch 26/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6931 - accuracy: 0.5103 - val_loss: 0.6934 - val_accuracy: 0.5136\n",
      "Epoch 27/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5122 - val_loss: 0.6929 - val_accuracy: 0.5103\n",
      "Epoch 28/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5118 - val_loss: 0.6931 - val_accuracy: 0.5114\n",
      "Epoch 29/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6927 - accuracy: 0.5127 - val_loss: 0.6930 - val_accuracy: 0.5099\n",
      "Epoch 30/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6927 - accuracy: 0.5124 - val_loss: 0.6930 - val_accuracy: 0.5078\n",
      "Epoch 31/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6925 - accuracy: 0.5139 - val_loss: 0.6929 - val_accuracy: 0.5123\n",
      "Epoch 32/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5146 - val_loss: 0.6953 - val_accuracy: 0.5030\n",
      "Epoch 33/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6924 - accuracy: 0.5144 - val_loss: 0.6928 - val_accuracy: 0.5137\n",
      "Epoch 34/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5153 - val_loss: 0.6928 - val_accuracy: 0.5151\n",
      "Epoch 35/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6922 - accuracy: 0.5157 - val_loss: 0.6931 - val_accuracy: 0.5125\n",
      "Epoch 36/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6921 - accuracy: 0.5160 - val_loss: 0.6929 - val_accuracy: 0.5169\n",
      "Epoch 37/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6920 - accuracy: 0.5168 - val_loss: 0.6928 - val_accuracy: 0.5121\n",
      "Epoch 38/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6919 - accuracy: 0.5184 - val_loss: 0.6925 - val_accuracy: 0.5209\n",
      "Epoch 39/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6937 - val_accuracy: 0.5139\n",
      "Epoch 40/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6914 - accuracy: 0.5217 - val_loss: 0.6936 - val_accuracy: 0.5158\n",
      "Epoch 41/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6912 - accuracy: 0.5238 - val_loss: 0.6944 - val_accuracy: 0.5077\n",
      "Epoch 42/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6908 - accuracy: 0.5268 - val_loss: 0.6915 - val_accuracy: 0.5245\n",
      "Epoch 43/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6902 - accuracy: 0.5298 - val_loss: 0.6907 - val_accuracy: 0.5334\n",
      "Epoch 44/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6897 - accuracy: 0.5319 - val_loss: 0.6903 - val_accuracy: 0.5305\n",
      "Epoch 45/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6893 - accuracy: 0.5339 - val_loss: 0.6895 - val_accuracy: 0.5333\n",
      "Epoch 46/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6889 - accuracy: 0.5352 - val_loss: 0.6888 - val_accuracy: 0.5351\n",
      "Epoch 47/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6884 - accuracy: 0.5368 - val_loss: 0.6896 - val_accuracy: 0.5357\n",
      "Epoch 48/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6878 - accuracy: 0.5387 - val_loss: 0.6892 - val_accuracy: 0.5351\n",
      "Epoch 49/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6872 - accuracy: 0.5401 - val_loss: 0.6870 - val_accuracy: 0.5441\n",
      "Epoch 50/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6869 - accuracy: 0.5420 - val_loss: 0.6898 - val_accuracy: 0.5371\n",
      "Epoch 51/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6865 - accuracy: 0.5441 - val_loss: 0.6884 - val_accuracy: 0.5374\n",
      "Epoch 52/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6857 - accuracy: 0.5454 - val_loss: 0.6854 - val_accuracy: 0.5475\n",
      "Epoch 53/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6852 - accuracy: 0.5478 - val_loss: 0.6851 - val_accuracy: 0.5466\n",
      "Epoch 54/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6846 - accuracy: 0.5478 - val_loss: 0.6858 - val_accuracy: 0.5436\n",
      "Epoch 55/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6838 - accuracy: 0.5505 - val_loss: 0.6837 - val_accuracy: 0.5518\n",
      "Epoch 56/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6833 - accuracy: 0.5523 - val_loss: 0.6854 - val_accuracy: 0.5432\n",
      "Epoch 57/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6824 - accuracy: 0.5536 - val_loss: 0.6839 - val_accuracy: 0.5473\n",
      "Epoch 58/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6819 - accuracy: 0.5543 - val_loss: 0.6821 - val_accuracy: 0.5532\n",
      "Epoch 59/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6814 - accuracy: 0.5553 - val_loss: 0.6828 - val_accuracy: 0.5484\n",
      "Epoch 60/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6805 - accuracy: 0.5570 - val_loss: 0.6824 - val_accuracy: 0.5528\n",
      "Epoch 61/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6792 - accuracy: 0.5598 - val_loss: 0.6815 - val_accuracy: 0.5510\n",
      "Epoch 62/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6789 - accuracy: 0.5592 - val_loss: 0.6768 - val_accuracy: 0.5660\n",
      "Epoch 63/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6773 - accuracy: 0.5622 - val_loss: 0.6791 - val_accuracy: 0.5608\n",
      "Epoch 64/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6760 - accuracy: 0.5636 - val_loss: 0.6764 - val_accuracy: 0.5634\n",
      "Epoch 65/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6763 - accuracy: 0.5634 - val_loss: 0.6838 - val_accuracy: 0.5376\n",
      "Epoch 66/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6747 - accuracy: 0.5645 - val_loss: 0.7184 - val_accuracy: 0.5117\n",
      "Epoch 67/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6747 - accuracy: 0.5644 - val_loss: 0.6933 - val_accuracy: 0.5130\n",
      "Epoch 68/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6723 - accuracy: 0.5689 - val_loss: 0.6695 - val_accuracy: 0.5742\n",
      "Epoch 69/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6691 - accuracy: 0.5742 - val_loss: 0.6719 - val_accuracy: 0.5629\n",
      "Epoch 70/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7016 - accuracy: 0.5134 - val_loss: 0.6997 - val_accuracy: 0.5069\n",
      "Epoch 71/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7005 - accuracy: 0.5072 - val_loss: 0.6989 - val_accuracy: 0.5075\n",
      "Epoch 72/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6999 - accuracy: 0.5072 - val_loss: 0.6998 - val_accuracy: 0.5037\n",
      "Epoch 73/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6992 - accuracy: 0.5075 - val_loss: 0.7001 - val_accuracy: 0.5063\n",
      "Epoch 74/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6992 - accuracy: 0.5074 - val_loss: 0.6999 - val_accuracy: 0.5113\n",
      "Epoch 75/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6986 - accuracy: 0.5084 - val_loss: 0.6996 - val_accuracy: 0.5061\n",
      "Epoch 76/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6979 - accuracy: 0.5107 - val_loss: 0.6952 - val_accuracy: 0.5180\n",
      "Epoch 77/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6968 - accuracy: 0.5130 - val_loss: 0.6947 - val_accuracy: 0.5198\n",
      "Epoch 78/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6966 - accuracy: 0.5125 - val_loss: 0.7008 - val_accuracy: 0.5149\n",
      "Epoch 79/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6946 - accuracy: 0.5172 - val_loss: 0.6931 - val_accuracy: 0.5140\n",
      "Epoch 80/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5236 - val_loss: 0.6916 - val_accuracy: 0.5130\n",
      "Epoch 81/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6853 - accuracy: 0.5463 - val_loss: 0.6856 - val_accuracy: 0.5401\n",
      "Epoch 82/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6794 - accuracy: 0.5629 - val_loss: 0.6878 - val_accuracy: 0.5576\n",
      "Epoch 83/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6789 - accuracy: 0.5649 - val_loss: 0.6874 - val_accuracy: 0.5422\n",
      "Epoch 84/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6734 - accuracy: 0.5726 - val_loss: 0.6784 - val_accuracy: 0.5686\n",
      "Epoch 85/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6706 - accuracy: 0.5763 - val_loss: 0.7192 - val_accuracy: 0.5148\n",
      "Epoch 86/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6727 - accuracy: 0.5721 - val_loss: 0.6639 - val_accuracy: 0.5845\n",
      "Epoch 87/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6677 - accuracy: 0.5802 - val_loss: 0.6675 - val_accuracy: 0.5805\n",
      "Epoch 88/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6663 - accuracy: 0.5816 - val_loss: 0.6638 - val_accuracy: 0.5907\n",
      "Epoch 89/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6631 - accuracy: 0.5851 - val_loss: 0.6674 - val_accuracy: 0.5760\n",
      "Epoch 90/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6601 - accuracy: 0.5889 - val_loss: 0.6621 - val_accuracy: 0.5884\n",
      "Epoch 91/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6588 - accuracy: 0.5921 - val_loss: 0.6556 - val_accuracy: 0.5940\n",
      "Epoch 92/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6598 - accuracy: 0.5894 - val_loss: 0.6610 - val_accuracy: 0.5910\n",
      "Epoch 93/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6618 - accuracy: 0.5878 - val_loss: 0.6791 - val_accuracy: 0.5652\n",
      "Epoch 94/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6596 - accuracy: 0.5904 - val_loss: 0.6534 - val_accuracy: 0.6033\n",
      "Epoch 95/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6556 - accuracy: 0.5959 - val_loss: 0.6516 - val_accuracy: 0.6009\n",
      "Epoch 96/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6567 - accuracy: 0.5937 - val_loss: 0.6642 - val_accuracy: 0.5875\n",
      "Epoch 97/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6727 - accuracy: 0.5690 - val_loss: 0.6574 - val_accuracy: 0.5919\n",
      "Epoch 98/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6555 - accuracy: 0.5957 - val_loss: 0.6570 - val_accuracy: 0.5934\n",
      "Epoch 99/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6547 - accuracy: 0.5970 - val_loss: 0.6488 - val_accuracy: 0.6058\n",
      "Epoch 100/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6819 - accuracy: 0.5469 - val_loss: 0.6965 - val_accuracy: 0.5096\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_30\n",
      "cannot prune layer q_activation_30\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_31\n",
      "cannot prune layer q_activation_31\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 8s 7ms/step - loss: 0.6816 - accuracy: 0.5459 - val_loss: 0.6884 - val_accuracy: 0.5373\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6630 - accuracy: 0.5819 - val_loss: 0.6881 - val_accuracy: 0.5294\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6613 - accuracy: 0.5860 - val_loss: 0.6741 - val_accuracy: 0.5654\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6584 - accuracy: 0.5900 - val_loss: 0.6867 - val_accuracy: 0.5706\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6581 - accuracy: 0.5903 - val_loss: 0.7160 - val_accuracy: 0.5282\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6711 - accuracy: 0.5716 - val_loss: 0.6866 - val_accuracy: 0.5587\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6602 - accuracy: 0.5871 - val_loss: 0.7054 - val_accuracy: 0.5544\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6558 - accuracy: 0.5942 - val_loss: 0.6518 - val_accuracy: 0.5996\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6546 - accuracy: 0.5960 - val_loss: 0.6530 - val_accuracy: 0.5976\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6537 - accuracy: 0.5966 - val_loss: 0.6494 - val_accuracy: 0.6026\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6927 - accuracy: 0.5311 - val_loss: 0.6823 - val_accuracy: 0.5466\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6626 - accuracy: 0.5850 - val_loss: 0.6539 - val_accuracy: 0.5990\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6533 - accuracy: 0.5978 - val_loss: 0.6518 - val_accuracy: 0.5983\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6521 - accuracy: 0.5990 - val_loss: 0.6543 - val_accuracy: 0.5928\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6518 - accuracy: 0.6001 - val_loss: 0.6487 - val_accuracy: 0.6001\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6689 - accuracy: 0.5710 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6712 - accuracy: 0.5672 - val_loss: 0.6638 - val_accuracy: 0.5825\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6535 - accuracy: 0.5977 - val_loss: 0.6502 - val_accuracy: 0.6015\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6513 - accuracy: 0.6013 - val_loss: 0.6525 - val_accuracy: 0.5991\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6506 - accuracy: 0.6022 - val_loss: 0.6489 - val_accuracy: 0.6023\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6514 - accuracy: 0.6014 - val_loss: 0.6545 - val_accuracy: 0.5934\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6494 - accuracy: 0.6037 - val_loss: 0.6444 - val_accuracy: 0.6102\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6510 - accuracy: 0.6022 - val_loss: 0.6470 - val_accuracy: 0.6115\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6490 - accuracy: 0.6047 - val_loss: 0.6454 - val_accuracy: 0.6081\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6606 - accuracy: 0.5907 - val_loss: 0.6574 - val_accuracy: 0.5951\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6508 - accuracy: 0.6025 - val_loss: 0.6445 - val_accuracy: 0.6100\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6480 - accuracy: 0.6076 - val_loss: 0.6436 - val_accuracy: 0.6135\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6476 - accuracy: 0.6067 - val_loss: 0.6432 - val_accuracy: 0.6139\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6756 - accuracy: 0.5632 - val_loss: 0.6985 - val_accuracy: 0.5106\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6940 - accuracy: 0.5140 - val_loss: 0.6933 - val_accuracy: 0.5144\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5186 - val_loss: 0.6929 - val_accuracy: 0.5172\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6918 - accuracy: 0.5207 - val_loss: 0.6918 - val_accuracy: 0.5205\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6908 - accuracy: 0.5262 - val_loss: 0.6907 - val_accuracy: 0.5277\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6883 - accuracy: 0.5360 - val_loss: 0.6955 - val_accuracy: 0.5144\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6651 - accuracy: 0.5857 - val_loss: 0.6611 - val_accuracy: 0.5814\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6502 - accuracy: 0.6055 - val_loss: 0.6453 - val_accuracy: 0.6114\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6483 - accuracy: 0.6073 - val_loss: 0.6591 - val_accuracy: 0.5899\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6478 - accuracy: 0.6083 - val_loss: 0.6529 - val_accuracy: 0.6085\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6470 - accuracy: 0.6090 - val_loss: 0.6428 - val_accuracy: 0.6131\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6464 - accuracy: 0.6095 - val_loss: 0.6451 - val_accuracy: 0.6081\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6464 - accuracy: 0.6095 - val_loss: 0.6401 - val_accuracy: 0.6196\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6454 - accuracy: 0.6116 - val_loss: 0.6445 - val_accuracy: 0.6130\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6446 - accuracy: 0.6119 - val_loss: 0.6398 - val_accuracy: 0.6178\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6483 - accuracy: 0.6086 - val_loss: 0.6641 - val_accuracy: 0.5705\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6496 - accuracy: 0.6080 - val_loss: 0.6646 - val_accuracy: 0.5835\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6470 - accuracy: 0.6101 - val_loss: 0.6431 - val_accuracy: 0.6159\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6460 - accuracy: 0.6118 - val_loss: 0.6398 - val_accuracy: 0.6203\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6429 - accuracy: 0.6149 - val_loss: 0.6421 - val_accuracy: 0.6140\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6433 - accuracy: 0.6150 - val_loss: 0.6407 - val_accuracy: 0.6158\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6449 - accuracy: 0.6129 - val_loss: 0.6437 - val_accuracy: 0.6140\n",
      "1714/1714 [==============================] - 3s 1ms/step\n",
      "[[0.49328315]\n",
      " [0.66843396]\n",
      " [0.62048703]\n",
      " [0.5466822 ]\n",
      " [0.5153217 ]\n",
      " [0.4304878 ]\n",
      " [0.64211905]\n",
      " [0.4411059 ]\n",
      " [0.6458488 ]\n",
      " [0.51557446]]\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.001, 'BATCH_SIZE': 1024, 'EPOCHS': 150, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.3, 'POST_PRUNE_EPOCHS': 50}\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_32 (Ba  (None, 24)                96        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_32 (QActivati  (None, 24)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_33 (Ba  (None, 12)                48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_33 (QActivati  (None, 12)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_32 is normal keras bn layer\n",
      "q_activation_32      quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_33 is normal keras bn layer\n",
      "q_activation_33      quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/150\n",
      "429/429 [==============================] - 6s 7ms/step - loss: 2.0706 - accuracy: 0.5011 - val_loss: 1.1122 - val_accuracy: 0.5024\n",
      "Epoch 2/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7446 - accuracy: 0.5012 - val_loss: 0.7215 - val_accuracy: 0.5040\n",
      "Epoch 3/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7160 - accuracy: 0.5033 - val_loss: 0.7187 - val_accuracy: 0.5028\n",
      "Epoch 4/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7054 - accuracy: 0.5039 - val_loss: 0.7002 - val_accuracy: 0.5027\n",
      "Epoch 5/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6987 - accuracy: 0.5039 - val_loss: 0.6979 - val_accuracy: 0.5022\n",
      "Epoch 6/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6972 - accuracy: 0.5048 - val_loss: 0.6970 - val_accuracy: 0.5025\n",
      "Epoch 7/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6962 - accuracy: 0.5055 - val_loss: 0.6963 - val_accuracy: 0.5023\n",
      "Epoch 8/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6955 - accuracy: 0.5067 - val_loss: 0.6959 - val_accuracy: 0.5010\n",
      "Epoch 9/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6948 - accuracy: 0.5080 - val_loss: 0.6953 - val_accuracy: 0.5034\n",
      "Epoch 10/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6942 - accuracy: 0.5086 - val_loss: 0.6950 - val_accuracy: 0.5018\n",
      "Epoch 11/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6938 - accuracy: 0.5093 - val_loss: 0.6949 - val_accuracy: 0.5024\n",
      "Epoch 12/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6936 - accuracy: 0.5110 - val_loss: 0.6947 - val_accuracy: 0.5061\n",
      "Epoch 13/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6933 - accuracy: 0.5103 - val_loss: 0.6942 - val_accuracy: 0.5046\n",
      "Epoch 14/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6931 - accuracy: 0.5113 - val_loss: 0.6943 - val_accuracy: 0.5064\n",
      "Epoch 15/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6930 - accuracy: 0.5113 - val_loss: 0.6940 - val_accuracy: 0.5068\n",
      "Epoch 16/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6929 - accuracy: 0.5109 - val_loss: 0.6937 - val_accuracy: 0.5091\n",
      "Epoch 17/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6927 - accuracy: 0.5123 - val_loss: 0.6934 - val_accuracy: 0.5089\n",
      "Epoch 18/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6926 - accuracy: 0.5122 - val_loss: 0.6936 - val_accuracy: 0.5098\n",
      "Epoch 19/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5136 - val_loss: 0.6938 - val_accuracy: 0.5075\n",
      "Epoch 20/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6924 - accuracy: 0.5128 - val_loss: 0.6936 - val_accuracy: 0.5116\n",
      "Epoch 21/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6924 - accuracy: 0.5135 - val_loss: 0.6929 - val_accuracy: 0.5138\n",
      "Epoch 22/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6922 - accuracy: 0.5147 - val_loss: 0.6929 - val_accuracy: 0.5143\n",
      "Epoch 23/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6921 - accuracy: 0.5144 - val_loss: 0.6931 - val_accuracy: 0.5114\n",
      "Epoch 24/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6920 - accuracy: 0.5154 - val_loss: 0.6933 - val_accuracy: 0.5115\n",
      "Epoch 25/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6919 - accuracy: 0.5150 - val_loss: 0.6926 - val_accuracy: 0.5144\n",
      "Epoch 26/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.5166 - val_loss: 0.6930 - val_accuracy: 0.5127\n",
      "Epoch 27/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.5152 - val_loss: 0.6930 - val_accuracy: 0.5118\n",
      "Epoch 28/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6928 - val_accuracy: 0.5168\n",
      "Epoch 29/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6915 - accuracy: 0.5176 - val_loss: 0.6930 - val_accuracy: 0.5149\n",
      "Epoch 30/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6926 - val_accuracy: 0.5176\n",
      "Epoch 31/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6913 - accuracy: 0.5191 - val_loss: 0.6923 - val_accuracy: 0.5175\n",
      "Epoch 32/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6913 - accuracy: 0.5194 - val_loss: 0.6928 - val_accuracy: 0.5127\n",
      "Epoch 33/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6911 - accuracy: 0.5193 - val_loss: 0.6926 - val_accuracy: 0.5134\n",
      "Epoch 34/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6909 - accuracy: 0.5223 - val_loss: 0.6928 - val_accuracy: 0.5177\n",
      "Epoch 35/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6908 - accuracy: 0.5215 - val_loss: 0.6924 - val_accuracy: 0.5086\n",
      "Epoch 36/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6905 - accuracy: 0.5232 - val_loss: 0.6922 - val_accuracy: 0.5236\n",
      "Epoch 37/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6903 - accuracy: 0.5237 - val_loss: 0.6919 - val_accuracy: 0.5216\n",
      "Epoch 38/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6899 - accuracy: 0.5261 - val_loss: 0.6906 - val_accuracy: 0.5303\n",
      "Epoch 39/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6894 - accuracy: 0.5274 - val_loss: 0.6902 - val_accuracy: 0.5205\n",
      "Epoch 40/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6884 - accuracy: 0.5314 - val_loss: 0.6899 - val_accuracy: 0.5268\n",
      "Epoch 41/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6872 - accuracy: 0.5360 - val_loss: 0.6892 - val_accuracy: 0.5283\n",
      "Epoch 42/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6858 - accuracy: 0.5406 - val_loss: 0.6915 - val_accuracy: 0.5205\n",
      "Epoch 43/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6838 - accuracy: 0.5462 - val_loss: 0.6900 - val_accuracy: 0.5329\n",
      "Epoch 44/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6815 - accuracy: 0.5531 - val_loss: 0.6821 - val_accuracy: 0.5512\n",
      "Epoch 45/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6794 - accuracy: 0.5577 - val_loss: 0.6816 - val_accuracy: 0.5509\n",
      "Epoch 46/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6776 - accuracy: 0.5618 - val_loss: 0.6766 - val_accuracy: 0.5669\n",
      "Epoch 47/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6759 - accuracy: 0.5641 - val_loss: 0.6793 - val_accuracy: 0.5594\n",
      "Epoch 48/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6740 - accuracy: 0.5674 - val_loss: 0.6708 - val_accuracy: 0.5761\n",
      "Epoch 49/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6708 - accuracy: 0.5731 - val_loss: 0.6750 - val_accuracy: 0.5717\n",
      "Epoch 50/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6684 - accuracy: 0.5771 - val_loss: 0.6698 - val_accuracy: 0.5707\n",
      "Epoch 51/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6663 - accuracy: 0.5796 - val_loss: 0.6716 - val_accuracy: 0.5748\n",
      "Epoch 52/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6639 - accuracy: 0.5837 - val_loss: 0.6655 - val_accuracy: 0.5779\n",
      "Epoch 53/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6635 - accuracy: 0.5849 - val_loss: 0.6613 - val_accuracy: 0.5854\n",
      "Epoch 54/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6630 - accuracy: 0.5860 - val_loss: 0.6610 - val_accuracy: 0.5886\n",
      "Epoch 55/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6590 - accuracy: 0.5919 - val_loss: 0.6628 - val_accuracy: 0.5883\n",
      "Epoch 56/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6600 - accuracy: 0.5905 - val_loss: 0.6610 - val_accuracy: 0.5862\n",
      "Epoch 57/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6592 - accuracy: 0.5905 - val_loss: 0.6724 - val_accuracy: 0.5729\n",
      "Epoch 58/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6564 - accuracy: 0.5954 - val_loss: 0.6522 - val_accuracy: 0.6028\n",
      "Epoch 59/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6557 - accuracy: 0.5966 - val_loss: 0.6647 - val_accuracy: 0.5853\n",
      "Epoch 60/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6521 - accuracy: 0.6014 - val_loss: 0.6485 - val_accuracy: 0.6071\n",
      "Epoch 61/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6500 - accuracy: 0.6045 - val_loss: 0.6502 - val_accuracy: 0.6055\n",
      "Epoch 62/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6490 - accuracy: 0.6062 - val_loss: 0.6446 - val_accuracy: 0.6104\n",
      "Epoch 63/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6643 - accuracy: 0.5857 - val_loss: 0.6684 - val_accuracy: 0.5717\n",
      "Epoch 64/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6474 - accuracy: 0.6087 - val_loss: 0.6423 - val_accuracy: 0.6159\n",
      "Epoch 65/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6452 - accuracy: 0.6113 - val_loss: 0.6409 - val_accuracy: 0.6177\n",
      "Epoch 66/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6444 - accuracy: 0.6115 - val_loss: 0.6532 - val_accuracy: 0.6042\n",
      "Epoch 67/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6446 - accuracy: 0.6121 - val_loss: 0.6377 - val_accuracy: 0.6189\n",
      "Epoch 68/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6442 - accuracy: 0.6128 - val_loss: 0.6409 - val_accuracy: 0.6177\n",
      "Epoch 69/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6427 - accuracy: 0.6144 - val_loss: 0.6459 - val_accuracy: 0.6099\n",
      "Epoch 70/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6403 - accuracy: 0.6172 - val_loss: 0.6395 - val_accuracy: 0.6195\n",
      "Epoch 71/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6407 - accuracy: 0.6169 - val_loss: 0.6400 - val_accuracy: 0.6224\n",
      "Epoch 72/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6397 - accuracy: 0.6180 - val_loss: 0.6425 - val_accuracy: 0.6098\n",
      "Epoch 73/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6397 - accuracy: 0.6176 - val_loss: 0.6356 - val_accuracy: 0.6195\n",
      "Epoch 74/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6689 - accuracy: 0.5752 - val_loss: 0.6847 - val_accuracy: 0.5458\n",
      "Epoch 75/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6631 - accuracy: 0.5876 - val_loss: 0.6571 - val_accuracy: 0.5980\n",
      "Epoch 76/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6398 - accuracy: 0.6189 - val_loss: 0.6407 - val_accuracy: 0.6176\n",
      "Epoch 77/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6704 - accuracy: 0.5767 - val_loss: 0.7014 - val_accuracy: 0.5095\n",
      "Epoch 78/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6949 - accuracy: 0.5123 - val_loss: 0.6935 - val_accuracy: 0.5163\n",
      "Epoch 79/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6920 - accuracy: 0.5203 - val_loss: 0.6915 - val_accuracy: 0.5241\n",
      "Epoch 80/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6864 - accuracy: 0.5391 - val_loss: 0.6823 - val_accuracy: 0.5460\n",
      "Epoch 81/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6678 - accuracy: 0.5845 - val_loss: 0.6640 - val_accuracy: 0.5925\n",
      "Epoch 82/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6534 - accuracy: 0.6063 - val_loss: 0.6516 - val_accuracy: 0.6126\n",
      "Epoch 83/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6454 - accuracy: 0.6139 - val_loss: 0.6458 - val_accuracy: 0.6089\n",
      "Epoch 84/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6803 - accuracy: 0.5577 - val_loss: 0.6843 - val_accuracy: 0.5430\n",
      "Epoch 85/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6548 - accuracy: 0.5983 - val_loss: 0.6406 - val_accuracy: 0.6187\n",
      "Epoch 86/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6414 - accuracy: 0.6161 - val_loss: 0.6374 - val_accuracy: 0.6239\n",
      "Epoch 87/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6380 - accuracy: 0.6197 - val_loss: 0.6304 - val_accuracy: 0.6325\n",
      "Epoch 88/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6367 - accuracy: 0.6225 - val_loss: 0.6518 - val_accuracy: 0.5976\n",
      "Epoch 89/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6382 - accuracy: 0.6213 - val_loss: 0.6326 - val_accuracy: 0.6249\n",
      "Epoch 90/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6361 - accuracy: 0.6244 - val_loss: 0.6263 - val_accuracy: 0.6367\n",
      "Epoch 91/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6332 - accuracy: 0.6271 - val_loss: 0.6375 - val_accuracy: 0.6198\n",
      "Epoch 92/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6334 - accuracy: 0.6267 - val_loss: 0.6279 - val_accuracy: 0.6329\n",
      "Epoch 93/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6327 - accuracy: 0.6277 - val_loss: 0.6324 - val_accuracy: 0.6285\n",
      "Epoch 94/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6505 - accuracy: 0.6036 - val_loss: 0.7128 - val_accuracy: 0.4987\n",
      "Epoch 95/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6967 - accuracy: 0.5092 - val_loss: 0.6941 - val_accuracy: 0.5182\n",
      "Epoch 96/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6929 - accuracy: 0.5176 - val_loss: 0.6913 - val_accuracy: 0.5240\n",
      "Epoch 97/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6906 - accuracy: 0.5265 - val_loss: 0.6892 - val_accuracy: 0.5351\n",
      "Epoch 98/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6871 - accuracy: 0.5390 - val_loss: 0.6872 - val_accuracy: 0.5365\n",
      "Epoch 99/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6711 - accuracy: 0.5741 - val_loss: 0.6888 - val_accuracy: 0.5532\n",
      "Epoch 100/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6490 - accuracy: 0.6088 - val_loss: 0.6496 - val_accuracy: 0.6072\n",
      "Epoch 101/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6395 - accuracy: 0.6212 - val_loss: 0.6526 - val_accuracy: 0.6093\n",
      "Epoch 102/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6348 - accuracy: 0.6266 - val_loss: 0.6277 - val_accuracy: 0.6365\n",
      "Epoch 103/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6342 - accuracy: 0.6265 - val_loss: 0.6303 - val_accuracy: 0.6330\n",
      "Epoch 104/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6480 - accuracy: 0.6071 - val_loss: 0.7152 - val_accuracy: 0.4967\n",
      "Epoch 105/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6955 - accuracy: 0.5057 - val_loss: 0.6936 - val_accuracy: 0.5132\n",
      "Epoch 106/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6927 - accuracy: 0.5128 - val_loss: 0.6925 - val_accuracy: 0.5106\n",
      "Epoch 107/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.5164 - val_loss: 0.6918 - val_accuracy: 0.5165\n",
      "Epoch 108/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6909 - accuracy: 0.5200 - val_loss: 0.6909 - val_accuracy: 0.5245\n",
      "Epoch 109/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6890 - accuracy: 0.5300 - val_loss: 0.6898 - val_accuracy: 0.5181\n",
      "Epoch 110/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6796 - accuracy: 0.5576 - val_loss: 0.6807 - val_accuracy: 0.5480\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_32\n",
      "cannot prune layer q_activation_32\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_33\n",
      "cannot prune layer q_activation_33\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 0.6525 - accuracy: 0.6028 - val_loss: 0.6735 - val_accuracy: 0.5756\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6466 - accuracy: 0.6109 - val_loss: 0.6929 - val_accuracy: 0.5632\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6359 - accuracy: 0.6246 - val_loss: 0.6944 - val_accuracy: 0.5617\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6385 - accuracy: 0.6211 - val_loss: 0.6651 - val_accuracy: 0.5946\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6336 - accuracy: 0.6277 - val_loss: 0.6733 - val_accuracy: 0.5842\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6328 - accuracy: 0.6285 - val_loss: 0.6757 - val_accuracy: 0.5920\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6327 - accuracy: 0.6276 - val_loss: 0.6364 - val_accuracy: 0.6218\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6326 - accuracy: 0.6285 - val_loss: 0.6345 - val_accuracy: 0.6318\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6349 - accuracy: 0.6252 - val_loss: 0.6268 - val_accuracy: 0.6379\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6308 - accuracy: 0.6301 - val_loss: 0.6262 - val_accuracy: 0.6374\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6305 - accuracy: 0.6310 - val_loss: 0.6240 - val_accuracy: 0.6366\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6301 - accuracy: 0.6310 - val_loss: 0.6226 - val_accuracy: 0.6424\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6297 - accuracy: 0.6315 - val_loss: 0.6242 - val_accuracy: 0.6391\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6304 - accuracy: 0.6321 - val_loss: 0.6244 - val_accuracy: 0.6408\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6293 - accuracy: 0.6331 - val_loss: 0.6222 - val_accuracy: 0.6417\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6280 - accuracy: 0.6339 - val_loss: 0.6222 - val_accuracy: 0.6417\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6382 - accuracy: 0.6232 - val_loss: 0.6552 - val_accuracy: 0.5992\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6364 - accuracy: 0.6245 - val_loss: 0.6267 - val_accuracy: 0.6384\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6326 - accuracy: 0.6283 - val_loss: 0.6259 - val_accuracy: 0.6389\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6445 - accuracy: 0.6128 - val_loss: 0.6564 - val_accuracy: 0.5964\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6308 - accuracy: 0.6310 - val_loss: 0.6332 - val_accuracy: 0.6312\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6307 - accuracy: 0.6314 - val_loss: 0.6239 - val_accuracy: 0.6385\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6268 - accuracy: 0.6353 - val_loss: 0.6281 - val_accuracy: 0.6325\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6379 - accuracy: 0.6245 - val_loss: 0.7952 - val_accuracy: 0.4940\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6640 - accuracy: 0.5868 - val_loss: 0.6554 - val_accuracy: 0.5991\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6307 - accuracy: 0.6323 - val_loss: 0.6276 - val_accuracy: 0.6362\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6270 - accuracy: 0.6356 - val_loss: 0.6218 - val_accuracy: 0.6406\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6268 - accuracy: 0.6366 - val_loss: 0.6215 - val_accuracy: 0.6435\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6267 - accuracy: 0.6370 - val_loss: 0.6250 - val_accuracy: 0.6370\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6258 - accuracy: 0.6362 - val_loss: 0.6276 - val_accuracy: 0.6331\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6459 - accuracy: 0.6126 - val_loss: 0.7081 - val_accuracy: 0.5316\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6832 - accuracy: 0.5490 - val_loss: 0.6743 - val_accuracy: 0.5619\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6629 - accuracy: 0.5837 - val_loss: 0.6607 - val_accuracy: 0.5864\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6444 - accuracy: 0.6152 - val_loss: 0.6352 - val_accuracy: 0.6306\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6369 - accuracy: 0.6246 - val_loss: 0.6321 - val_accuracy: 0.6335\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6353 - accuracy: 0.6269 - val_loss: 0.6270 - val_accuracy: 0.6376\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6319 - accuracy: 0.6305 - val_loss: 0.6256 - val_accuracy: 0.6420\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6289 - accuracy: 0.6344 - val_loss: 0.6226 - val_accuracy: 0.6427\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6265 - accuracy: 0.6370 - val_loss: 0.6303 - val_accuracy: 0.6337\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6254 - accuracy: 0.6374 - val_loss: 0.6230 - val_accuracy: 0.6431\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6261 - accuracy: 0.6365 - val_loss: 0.6224 - val_accuracy: 0.6400\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6320 - accuracy: 0.6296 - val_loss: 0.6352 - val_accuracy: 0.6251\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6268 - accuracy: 0.6366 - val_loss: 0.6240 - val_accuracy: 0.6384\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6245 - accuracy: 0.6388 - val_loss: 0.6168 - val_accuracy: 0.6475\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6255 - accuracy: 0.6377 - val_loss: 0.6160 - val_accuracy: 0.6510\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 6ms/step - loss: 0.6243 - accuracy: 0.6380 - val_loss: 0.6263 - val_accuracy: 0.6358\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6250 - accuracy: 0.6371 - val_loss: 0.6194 - val_accuracy: 0.6441\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6245 - accuracy: 0.6377 - val_loss: 0.6190 - val_accuracy: 0.6440\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6251 - accuracy: 0.6377 - val_loss: 0.6176 - val_accuracy: 0.6462\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6305 - accuracy: 0.6325 - val_loss: 0.6217 - val_accuracy: 0.6449\n",
      "1714/1714 [==============================] - 3s 1ms/step\n",
      "[[0.55482876]\n",
      " [0.59929675]\n",
      " [0.61627674]\n",
      " [0.64574015]\n",
      " [0.71000576]\n",
      " [0.4455624 ]\n",
      " [0.6686183 ]\n",
      " [0.4733197 ]\n",
      " [0.6041224 ]\n",
      " [0.22041702]]\n",
      "########### FOUND NEW BEST METRIC 0.4101397583345465 ##############\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.0005, 'BATCH_SIZE': 1024, 'EPOCHS': 100, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.3, 'POST_PRUNE_EPOCHS': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sdf/home/a/alexyue/miniconda3/envs/SmartPixel/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_34 (Ba  (None, 24)                96        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_34 (QActivati  (None, 24)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_35 (Ba  (None, 12)                48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_35 (QActivati  (None, 12)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_34 is normal keras bn layer\n",
      "q_activation_34      quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_35 is normal keras bn layer\n",
      "q_activation_35      quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/100\n",
      "429/429 [==============================] - 6s 7ms/step - loss: 1.2723 - accuracy: 0.5020 - val_loss: 0.8170 - val_accuracy: 0.5022\n",
      "Epoch 2/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7765 - accuracy: 0.5019 - val_loss: 0.7560 - val_accuracy: 0.5030\n",
      "Epoch 3/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7446 - accuracy: 0.5007 - val_loss: 0.7339 - val_accuracy: 0.5015\n",
      "Epoch 4/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7280 - accuracy: 0.5019 - val_loss: 0.7228 - val_accuracy: 0.5045\n",
      "Epoch 5/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7198 - accuracy: 0.5022 - val_loss: 0.7133 - val_accuracy: 0.5057\n",
      "Epoch 6/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7175 - accuracy: 0.5029 - val_loss: 0.7145 - val_accuracy: 0.5053\n",
      "Epoch 7/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7128 - accuracy: 0.5036 - val_loss: 0.7114 - val_accuracy: 0.5034\n",
      "Epoch 8/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7092 - accuracy: 0.5022 - val_loss: 0.7063 - val_accuracy: 0.5065\n",
      "Epoch 9/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7057 - accuracy: 0.5037 - val_loss: 0.7043 - val_accuracy: 0.5052\n",
      "Epoch 10/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7036 - accuracy: 0.5036 - val_loss: 0.7028 - val_accuracy: 0.5075\n",
      "Epoch 11/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7020 - accuracy: 0.5036 - val_loss: 0.7014 - val_accuracy: 0.5083\n",
      "Epoch 12/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7006 - accuracy: 0.5031 - val_loss: 0.7004 - val_accuracy: 0.5084\n",
      "Epoch 13/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6996 - accuracy: 0.5038 - val_loss: 0.6995 - val_accuracy: 0.5078\n",
      "Epoch 14/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6988 - accuracy: 0.5038 - val_loss: 0.6987 - val_accuracy: 0.5059\n",
      "Epoch 15/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6980 - accuracy: 0.5037 - val_loss: 0.6979 - val_accuracy: 0.5068\n",
      "Epoch 16/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6971 - accuracy: 0.5054 - val_loss: 0.6975 - val_accuracy: 0.5041\n",
      "Epoch 17/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6965 - accuracy: 0.5061 - val_loss: 0.6970 - val_accuracy: 0.5064\n",
      "Epoch 18/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6960 - accuracy: 0.5063 - val_loss: 0.6965 - val_accuracy: 0.5027\n",
      "Epoch 19/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6954 - accuracy: 0.5071 - val_loss: 0.6957 - val_accuracy: 0.5042\n",
      "Epoch 20/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6950 - accuracy: 0.5062 - val_loss: 0.6952 - val_accuracy: 0.5086\n",
      "Epoch 21/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6945 - accuracy: 0.5084 - val_loss: 0.6998 - val_accuracy: 0.5017\n",
      "Epoch 22/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6941 - accuracy: 0.5080 - val_loss: 0.6985 - val_accuracy: 0.5027\n",
      "Epoch 23/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6939 - accuracy: 0.5086 - val_loss: 0.6943 - val_accuracy: 0.5087\n",
      "Epoch 24/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6936 - accuracy: 0.5096 - val_loss: 0.6946 - val_accuracy: 0.5073\n",
      "Epoch 25/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6934 - accuracy: 0.5102 - val_loss: 0.6945 - val_accuracy: 0.5044\n",
      "Epoch 26/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.5109 - val_loss: 0.6939 - val_accuracy: 0.5080\n",
      "Epoch 27/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6930 - accuracy: 0.5110 - val_loss: 0.6940 - val_accuracy: 0.5098\n",
      "Epoch 28/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6929 - accuracy: 0.5111 - val_loss: 0.6936 - val_accuracy: 0.5094\n",
      "Epoch 29/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6927 - accuracy: 0.5125 - val_loss: 0.6939 - val_accuracy: 0.5045\n",
      "Epoch 30/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5118 - val_loss: 0.6939 - val_accuracy: 0.5046\n",
      "Epoch 31/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6925 - accuracy: 0.5128 - val_loss: 0.6934 - val_accuracy: 0.5132\n",
      "Epoch 32/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6924 - accuracy: 0.5129 - val_loss: 0.6934 - val_accuracy: 0.5097\n",
      "Epoch 33/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6922 - accuracy: 0.5146 - val_loss: 0.6936 - val_accuracy: 0.5042\n",
      "Epoch 34/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6922 - accuracy: 0.5134 - val_loss: 0.6933 - val_accuracy: 0.5061\n",
      "Epoch 35/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6920 - accuracy: 0.5144 - val_loss: 0.6933 - val_accuracy: 0.5078\n",
      "Epoch 36/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6920 - accuracy: 0.5151 - val_loss: 0.6934 - val_accuracy: 0.5060\n",
      "Epoch 37/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6919 - accuracy: 0.5159 - val_loss: 0.6932 - val_accuracy: 0.5084\n",
      "Epoch 38/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.5156 - val_loss: 0.6928 - val_accuracy: 0.5125\n",
      "Epoch 39/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6917 - accuracy: 0.5173 - val_loss: 0.6929 - val_accuracy: 0.5151\n",
      "Epoch 40/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6916 - accuracy: 0.5171 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 41/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6915 - accuracy: 0.5178 - val_loss: 0.6933 - val_accuracy: 0.5094\n",
      "Epoch 42/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6914 - accuracy: 0.5193 - val_loss: 0.6927 - val_accuracy: 0.5173\n",
      "Epoch 43/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6914 - accuracy: 0.5189 - val_loss: 0.6927 - val_accuracy: 0.5116\n",
      "Epoch 44/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6910 - accuracy: 0.5216 - val_loss: 0.6923 - val_accuracy: 0.5176\n",
      "Epoch 45/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6908 - accuracy: 0.5221 - val_loss: 0.6925 - val_accuracy: 0.5164\n",
      "Epoch 46/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6910 - accuracy: 0.5227 - val_loss: 0.6935 - val_accuracy: 0.5091\n",
      "Epoch 47/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6906 - accuracy: 0.5241 - val_loss: 0.6918 - val_accuracy: 0.5219\n",
      "Epoch 48/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6904 - accuracy: 0.5247 - val_loss: 0.6916 - val_accuracy: 0.5250\n",
      "Epoch 49/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6900 - accuracy: 0.5268 - val_loss: 0.6918 - val_accuracy: 0.5224\n",
      "Epoch 50/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6901 - accuracy: 0.5273 - val_loss: 0.6914 - val_accuracy: 0.5233\n",
      "Epoch 51/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6901 - accuracy: 0.5278 - val_loss: 0.6914 - val_accuracy: 0.5256\n",
      "Epoch 52/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6899 - accuracy: 0.5290 - val_loss: 0.6918 - val_accuracy: 0.5226\n",
      "Epoch 53/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6894 - accuracy: 0.5289 - val_loss: 0.6911 - val_accuracy: 0.5247\n",
      "Epoch 54/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6891 - accuracy: 0.5291 - val_loss: 0.6909 - val_accuracy: 0.5250\n",
      "Epoch 55/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6890 - accuracy: 0.5309 - val_loss: 0.6904 - val_accuracy: 0.5285\n",
      "Epoch 56/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6883 - accuracy: 0.5334 - val_loss: 0.6900 - val_accuracy: 0.5284\n",
      "Epoch 57/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6882 - accuracy: 0.5324 - val_loss: 0.6905 - val_accuracy: 0.5280\n",
      "Epoch 58/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6880 - accuracy: 0.5338 - val_loss: 0.6898 - val_accuracy: 0.5320\n",
      "Epoch 59/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6878 - accuracy: 0.5339 - val_loss: 0.7129 - val_accuracy: 0.5058\n",
      "Epoch 60/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6875 - accuracy: 0.5348 - val_loss: 0.6895 - val_accuracy: 0.5332\n",
      "Epoch 61/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6873 - accuracy: 0.5369 - val_loss: 0.6890 - val_accuracy: 0.5309\n",
      "Epoch 62/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6869 - accuracy: 0.5373 - val_loss: 0.6899 - val_accuracy: 0.5294\n",
      "Epoch 63/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6871 - accuracy: 0.5369 - val_loss: 0.6907 - val_accuracy: 0.5326\n",
      "Epoch 64/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6865 - accuracy: 0.5391 - val_loss: 0.6885 - val_accuracy: 0.5365\n",
      "Epoch 65/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6863 - accuracy: 0.5404 - val_loss: 0.6889 - val_accuracy: 0.5363\n",
      "Epoch 66/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6860 - accuracy: 0.5410 - val_loss: 0.6879 - val_accuracy: 0.5403\n",
      "Epoch 67/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6856 - accuracy: 0.5428 - val_loss: 0.6878 - val_accuracy: 0.5424\n",
      "Epoch 68/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6852 - accuracy: 0.5434 - val_loss: 0.6876 - val_accuracy: 0.5384\n",
      "Epoch 69/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6847 - accuracy: 0.5450 - val_loss: 0.6862 - val_accuracy: 0.5462\n",
      "Epoch 70/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6845 - accuracy: 0.5452 - val_loss: 0.6862 - val_accuracy: 0.5451\n",
      "Epoch 71/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6834 - accuracy: 0.5480 - val_loss: 0.6850 - val_accuracy: 0.5510\n",
      "Epoch 72/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6827 - accuracy: 0.5503 - val_loss: 0.6844 - val_accuracy: 0.5509\n",
      "Epoch 73/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6819 - accuracy: 0.5513 - val_loss: 0.6838 - val_accuracy: 0.5548\n",
      "Epoch 74/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6818 - accuracy: 0.5534 - val_loss: 0.6824 - val_accuracy: 0.5555\n",
      "Epoch 75/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6807 - accuracy: 0.5557 - val_loss: 0.6823 - val_accuracy: 0.5585\n",
      "Epoch 76/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6799 - accuracy: 0.5577 - val_loss: 0.6827 - val_accuracy: 0.5594\n",
      "Epoch 77/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6791 - accuracy: 0.5595 - val_loss: 0.6797 - val_accuracy: 0.5628\n",
      "Epoch 78/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6782 - accuracy: 0.5603 - val_loss: 0.6798 - val_accuracy: 0.5624\n",
      "Epoch 79/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6774 - accuracy: 0.5636 - val_loss: 0.6792 - val_accuracy: 0.5645\n",
      "Epoch 80/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6763 - accuracy: 0.5644 - val_loss: 0.6790 - val_accuracy: 0.5582\n",
      "Epoch 81/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6757 - accuracy: 0.5663 - val_loss: 0.6794 - val_accuracy: 0.5604\n",
      "Epoch 82/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6748 - accuracy: 0.5683 - val_loss: 0.6765 - val_accuracy: 0.5707\n",
      "Epoch 83/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6739 - accuracy: 0.5697 - val_loss: 0.6765 - val_accuracy: 0.5666\n",
      "Epoch 84/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6727 - accuracy: 0.5712 - val_loss: 0.6746 - val_accuracy: 0.5651\n",
      "Epoch 85/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6783 - accuracy: 0.5631 - val_loss: 0.6954 - val_accuracy: 0.5384\n",
      "Epoch 86/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6840 - accuracy: 0.5474 - val_loss: 0.6825 - val_accuracy: 0.5559\n",
      "Epoch 87/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6760 - accuracy: 0.5650 - val_loss: 0.6760 - val_accuracy: 0.5667\n",
      "Epoch 88/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6732 - accuracy: 0.5714 - val_loss: 0.6725 - val_accuracy: 0.5737\n",
      "Epoch 89/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6716 - accuracy: 0.5748 - val_loss: 0.6723 - val_accuracy: 0.5768\n",
      "Epoch 90/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6707 - accuracy: 0.5759 - val_loss: 0.6706 - val_accuracy: 0.5754\n",
      "Epoch 91/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6699 - accuracy: 0.5771 - val_loss: 0.6701 - val_accuracy: 0.5763\n",
      "Epoch 92/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6688 - accuracy: 0.5789 - val_loss: 0.6709 - val_accuracy: 0.5728\n",
      "Epoch 93/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6684 - accuracy: 0.5795 - val_loss: 0.6711 - val_accuracy: 0.5751\n",
      "Epoch 94/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6677 - accuracy: 0.5811 - val_loss: 0.6716 - val_accuracy: 0.5778\n",
      "Epoch 95/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6689 - accuracy: 0.5807 - val_loss: 0.7349 - val_accuracy: 0.5371\n",
      "Epoch 96/100\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6742 - accuracy: 0.5721 - val_loss: 0.6743 - val_accuracy: 0.5712\n",
      "Epoch 97/100\n",
      "429/429 [==============================] - 3s 7ms/step - loss: 0.6679 - accuracy: 0.5813 - val_loss: 0.6680 - val_accuracy: 0.5817\n",
      "Epoch 98/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6657 - accuracy: 0.5844 - val_loss: 0.6677 - val_accuracy: 0.5849\n",
      "Epoch 99/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6645 - accuracy: 0.5858 - val_loss: 0.6654 - val_accuracy: 0.5889\n",
      "Epoch 100/100\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6648 - accuracy: 0.5857 - val_loss: 0.6637 - val_accuracy: 0.5899\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_34\n",
      "cannot prune layer q_activation_34\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_35\n",
      "cannot prune layer q_activation_35\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 0.6640 - accuracy: 0.5873 - val_loss: 0.6750 - val_accuracy: 0.5726\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6669 - accuracy: 0.5825 - val_loss: 0.6997 - val_accuracy: 0.5376\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6656 - accuracy: 0.5836 - val_loss: 0.6820 - val_accuracy: 0.5627\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6648 - accuracy: 0.5854 - val_loss: 0.6970 - val_accuracy: 0.5412\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6654 - accuracy: 0.5864 - val_loss: 0.7010 - val_accuracy: 0.5315\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6647 - accuracy: 0.5868 - val_loss: 0.6798 - val_accuracy: 0.5589\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6645 - accuracy: 0.5874 - val_loss: 0.6798 - val_accuracy: 0.5751\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6667 - accuracy: 0.5840 - val_loss: 0.6841 - val_accuracy: 0.5691\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6663 - accuracy: 0.5854 - val_loss: 0.6641 - val_accuracy: 0.5862\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6631 - accuracy: 0.5896 - val_loss: 0.6616 - val_accuracy: 0.5901\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6623 - accuracy: 0.5909 - val_loss: 0.6622 - val_accuracy: 0.5911\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6619 - accuracy: 0.5914 - val_loss: 0.6639 - val_accuracy: 0.5891\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6604 - accuracy: 0.5940 - val_loss: 0.6590 - val_accuracy: 0.5958\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6602 - accuracy: 0.5943 - val_loss: 0.6589 - val_accuracy: 0.5949\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6598 - accuracy: 0.5944 - val_loss: 0.6582 - val_accuracy: 0.5969\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6594 - accuracy: 0.5935 - val_loss: 0.6578 - val_accuracy: 0.5970\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6587 - accuracy: 0.5958 - val_loss: 0.6569 - val_accuracy: 0.5991\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6577 - accuracy: 0.5962 - val_loss: 0.6585 - val_accuracy: 0.5974\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6570 - accuracy: 0.5982 - val_loss: 0.6594 - val_accuracy: 0.5935\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6569 - accuracy: 0.5975 - val_loss: 0.6549 - val_accuracy: 0.6013\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6556 - accuracy: 0.5991 - val_loss: 0.6595 - val_accuracy: 0.5962\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6551 - accuracy: 0.5997 - val_loss: 0.6562 - val_accuracy: 0.6020\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6549 - accuracy: 0.5999 - val_loss: 0.6564 - val_accuracy: 0.6002\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6550 - accuracy: 0.6002 - val_loss: 0.6532 - val_accuracy: 0.6043\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6548 - accuracy: 0.6006 - val_loss: 0.6547 - val_accuracy: 0.6016\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6541 - accuracy: 0.6024 - val_loss: 0.6531 - val_accuracy: 0.6097\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6548 - accuracy: 0.6016 - val_loss: 0.6509 - val_accuracy: 0.6097\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6528 - accuracy: 0.6037 - val_loss: 0.6516 - val_accuracy: 0.6069\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6525 - accuracy: 0.6043 - val_loss: 0.6534 - val_accuracy: 0.6049\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6521 - accuracy: 0.6053 - val_loss: 0.6508 - val_accuracy: 0.6098\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6518 - accuracy: 0.6054 - val_loss: 0.6508 - val_accuracy: 0.6121\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6539 - accuracy: 0.6026 - val_loss: 0.6522 - val_accuracy: 0.6089\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6512 - accuracy: 0.6060 - val_loss: 0.6497 - val_accuracy: 0.6115\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6511 - accuracy: 0.6070 - val_loss: 0.6507 - val_accuracy: 0.6140\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6504 - accuracy: 0.6073 - val_loss: 0.6519 - val_accuracy: 0.6087\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6508 - accuracy: 0.6076 - val_loss: 0.6499 - val_accuracy: 0.6138\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6498 - accuracy: 0.6074 - val_loss: 0.6490 - val_accuracy: 0.6130\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6503 - accuracy: 0.6072 - val_loss: 0.6492 - val_accuracy: 0.6094\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6497 - accuracy: 0.6081 - val_loss: 0.6467 - val_accuracy: 0.6144\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6493 - accuracy: 0.6084 - val_loss: 0.6487 - val_accuracy: 0.6132\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6485 - accuracy: 0.6092 - val_loss: 0.6468 - val_accuracy: 0.6161\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6483 - accuracy: 0.6099 - val_loss: 0.6485 - val_accuracy: 0.6128\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6482 - accuracy: 0.6102 - val_loss: 0.6532 - val_accuracy: 0.6077\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6484 - accuracy: 0.6095 - val_loss: 0.6460 - val_accuracy: 0.6180\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6481 - accuracy: 0.6107 - val_loss: 0.6459 - val_accuracy: 0.6183\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6480 - accuracy: 0.6104 - val_loss: 0.6497 - val_accuracy: 0.6125\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6471 - accuracy: 0.6118 - val_loss: 0.6486 - val_accuracy: 0.6165\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6479 - accuracy: 0.6107 - val_loss: 0.6456 - val_accuracy: 0.6185\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6468 - accuracy: 0.6120 - val_loss: 0.6446 - val_accuracy: 0.6219\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6462 - accuracy: 0.6127 - val_loss: 0.6450 - val_accuracy: 0.6195\n",
      "1714/1714 [==============================] - 3s 1ms/step\n",
      "[[0.55878615]\n",
      " [0.5112261 ]\n",
      " [0.5230509 ]\n",
      " [0.56041914]\n",
      " [0.7452102 ]\n",
      " [0.3879968 ]\n",
      " [0.51623297]\n",
      " [0.6167935 ]\n",
      " [0.53936476]\n",
      " [0.4704292 ]]\n",
      "Testing hyperparameters: {'MODEL_TYPE': 'DNN', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'DNN_LAYERS': [24, 12], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'CONV_LAYER_STRIDES': [(1, 1), (1, 1)], 'FLATTENED_LAYERS': [7], 'MAX_POOLING_SIZE': (2, 2), 'OUTPUT': 'SINGLE', 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.0005, 'BATCH_SIZE': 1024, 'EPOCHS': 150, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.3, 'POST_PRUNE_EPOCHS': 50}\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_36 (Ba  (None, 24)                96        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_36 (QActivati  (None, 24)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_37 (Ba  (None, 12)                48        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " q_activation_37 (QActivati  (None, 12)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_36 is normal keras bn layer\n",
      "q_activation_36      quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_37 is normal keras bn layer\n",
      "q_activation_37      quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [1 1 1 0]\n",
      "Epoch 1/150\n",
      "429/429 [==============================] - 6s 7ms/step - loss: 4.8034 - accuracy: 0.5000 - val_loss: 3.8401 - val_accuracy: 0.4980\n",
      "Epoch 2/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 2.6192 - accuracy: 0.5009 - val_loss: 2.2006 - val_accuracy: 0.4958\n",
      "Epoch 3/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 2.0608 - accuracy: 0.5009 - val_loss: 1.7311 - val_accuracy: 0.4998\n",
      "Epoch 4/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 1.6456 - accuracy: 0.5011 - val_loss: 1.4628 - val_accuracy: 0.5035\n",
      "Epoch 5/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 1.3038 - accuracy: 0.5008 - val_loss: 1.1323 - val_accuracy: 0.5030\n",
      "Epoch 6/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 1.0082 - accuracy: 0.5020 - val_loss: 0.8865 - val_accuracy: 0.5038\n",
      "Epoch 7/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7786 - accuracy: 0.5027 - val_loss: 0.7358 - val_accuracy: 0.5027\n",
      "Epoch 8/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7274 - accuracy: 0.5026 - val_loss: 0.7202 - val_accuracy: 0.5027\n",
      "Epoch 9/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7147 - accuracy: 0.5029 - val_loss: 0.7083 - val_accuracy: 0.5046\n",
      "Epoch 10/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.7059 - accuracy: 0.5038 - val_loss: 0.7045 - val_accuracy: 0.5072\n",
      "Epoch 11/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7027 - accuracy: 0.5038 - val_loss: 0.7023 - val_accuracy: 0.5062\n",
      "Epoch 12/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.7006 - accuracy: 0.5049 - val_loss: 0.7000 - val_accuracy: 0.5059\n",
      "Epoch 13/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6989 - accuracy: 0.5056 - val_loss: 0.6985 - val_accuracy: 0.5058\n",
      "Epoch 14/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6977 - accuracy: 0.5057 - val_loss: 0.6976 - val_accuracy: 0.5062\n",
      "Epoch 15/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6967 - accuracy: 0.5055 - val_loss: 0.6967 - val_accuracy: 0.5055\n",
      "Epoch 16/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6958 - accuracy: 0.5070 - val_loss: 0.6960 - val_accuracy: 0.5055\n",
      "Epoch 17/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6952 - accuracy: 0.5075 - val_loss: 0.6955 - val_accuracy: 0.5062\n",
      "Epoch 18/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6946 - accuracy: 0.5076 - val_loss: 0.6951 - val_accuracy: 0.5063\n",
      "Epoch 19/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6943 - accuracy: 0.5090 - val_loss: 0.6949 - val_accuracy: 0.5068\n",
      "Epoch 20/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6940 - accuracy: 0.5082 - val_loss: 0.6946 - val_accuracy: 0.5050\n",
      "Epoch 21/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6937 - accuracy: 0.5093 - val_loss: 0.6945 - val_accuracy: 0.5063\n",
      "Epoch 22/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6934 - accuracy: 0.5093 - val_loss: 0.6941 - val_accuracy: 0.5075\n",
      "Epoch 23/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6942 - val_accuracy: 0.5070\n",
      "Epoch 24/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6931 - accuracy: 0.5110 - val_loss: 0.6938 - val_accuracy: 0.5071\n",
      "Epoch 25/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6930 - accuracy: 0.5097 - val_loss: 0.6933 - val_accuracy: 0.5083\n",
      "Epoch 26/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5101 - val_loss: 0.6940 - val_accuracy: 0.5044\n",
      "Epoch 27/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6926 - accuracy: 0.5121 - val_loss: 0.6929 - val_accuracy: 0.5109\n",
      "Epoch 28/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6924 - accuracy: 0.5126 - val_loss: 0.6928 - val_accuracy: 0.5123\n",
      "Epoch 29/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6922 - accuracy: 0.5145 - val_loss: 0.6926 - val_accuracy: 0.5153\n",
      "Epoch 30/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6921 - accuracy: 0.5147 - val_loss: 0.6927 - val_accuracy: 0.5117\n",
      "Epoch 31/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6920 - accuracy: 0.5161 - val_loss: 0.6928 - val_accuracy: 0.5133\n",
      "Epoch 32/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6918 - accuracy: 0.5177 - val_loss: 0.6924 - val_accuracy: 0.5148\n",
      "Epoch 33/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6915 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5203\n",
      "Epoch 34/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6911 - accuracy: 0.5234 - val_loss: 0.6922 - val_accuracy: 0.5221\n",
      "Epoch 35/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6905 - accuracy: 0.5277 - val_loss: 0.6912 - val_accuracy: 0.5266\n",
      "Epoch 36/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6897 - accuracy: 0.5308 - val_loss: 0.6909 - val_accuracy: 0.5291\n",
      "Epoch 37/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6887 - accuracy: 0.5357 - val_loss: 0.6894 - val_accuracy: 0.5322\n",
      "Epoch 38/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6878 - accuracy: 0.5381 - val_loss: 0.6887 - val_accuracy: 0.5359\n",
      "Epoch 39/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6864 - accuracy: 0.5425 - val_loss: 0.6875 - val_accuracy: 0.5409\n",
      "Epoch 40/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6852 - accuracy: 0.5460 - val_loss: 0.6861 - val_accuracy: 0.5443\n",
      "Epoch 41/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6840 - accuracy: 0.5481 - val_loss: 0.6846 - val_accuracy: 0.5496\n",
      "Epoch 42/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6831 - accuracy: 0.5512 - val_loss: 0.6842 - val_accuracy: 0.5474\n",
      "Epoch 43/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6817 - accuracy: 0.5530 - val_loss: 0.6824 - val_accuracy: 0.5518\n",
      "Epoch 44/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6808 - accuracy: 0.5555 - val_loss: 0.6811 - val_accuracy: 0.5559\n",
      "Epoch 45/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6794 - accuracy: 0.5586 - val_loss: 0.6797 - val_accuracy: 0.5613\n",
      "Epoch 46/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6777 - accuracy: 0.5620 - val_loss: 0.6801 - val_accuracy: 0.5563\n",
      "Epoch 47/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6771 - accuracy: 0.5642 - val_loss: 0.6773 - val_accuracy: 0.5617\n",
      "Epoch 48/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6764 - accuracy: 0.5648 - val_loss: 0.6771 - val_accuracy: 0.5585\n",
      "Epoch 49/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6754 - accuracy: 0.5675 - val_loss: 0.6819 - val_accuracy: 0.5509\n",
      "Epoch 50/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6756 - accuracy: 0.5667 - val_loss: 0.6794 - val_accuracy: 0.5622\n",
      "Epoch 51/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6741 - accuracy: 0.5683 - val_loss: 0.6757 - val_accuracy: 0.5699\n",
      "Epoch 52/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6727 - accuracy: 0.5729 - val_loss: 0.6777 - val_accuracy: 0.5616\n",
      "Epoch 53/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6711 - accuracy: 0.5748 - val_loss: 0.6753 - val_accuracy: 0.5647\n",
      "Epoch 54/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6727 - accuracy: 0.5723 - val_loss: 0.6743 - val_accuracy: 0.5728\n",
      "Epoch 55/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6699 - accuracy: 0.5773 - val_loss: 0.6748 - val_accuracy: 0.5728\n",
      "Epoch 56/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6673 - accuracy: 0.5814 - val_loss: 0.6684 - val_accuracy: 0.5835\n",
      "Epoch 57/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6667 - accuracy: 0.5821 - val_loss: 0.6728 - val_accuracy: 0.5660\n",
      "Epoch 58/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6656 - accuracy: 0.5844 - val_loss: 0.6708 - val_accuracy: 0.5765\n",
      "Epoch 59/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6686 - accuracy: 0.5810 - val_loss: 0.6747 - val_accuracy: 0.5628\n",
      "Epoch 60/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6647 - accuracy: 0.5856 - val_loss: 0.6662 - val_accuracy: 0.5823\n",
      "Epoch 61/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6634 - accuracy: 0.5884 - val_loss: 0.6776 - val_accuracy: 0.5910\n",
      "Epoch 62/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6644 - accuracy: 0.5895 - val_loss: 0.6693 - val_accuracy: 0.5758\n",
      "Epoch 63/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6675 - accuracy: 0.5832 - val_loss: 0.6698 - val_accuracy: 0.5672\n",
      "Epoch 64/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6651 - accuracy: 0.5875 - val_loss: 0.6676 - val_accuracy: 0.5822\n",
      "Epoch 65/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6621 - accuracy: 0.5899 - val_loss: 0.6615 - val_accuracy: 0.5887\n",
      "Epoch 66/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6681 - accuracy: 0.5812 - val_loss: 0.6635 - val_accuracy: 0.5947\n",
      "Epoch 67/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6649 - accuracy: 0.5875 - val_loss: 0.6638 - val_accuracy: 0.5927\n",
      "Epoch 68/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6642 - accuracy: 0.5877 - val_loss: 0.6707 - val_accuracy: 0.5754\n",
      "Epoch 69/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6619 - accuracy: 0.5921 - val_loss: 0.6662 - val_accuracy: 0.5863\n",
      "Epoch 70/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6711 - accuracy: 0.5762 - val_loss: 0.6666 - val_accuracy: 0.5872\n",
      "Epoch 71/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6619 - accuracy: 0.5914 - val_loss: 0.6597 - val_accuracy: 0.5927\n",
      "Epoch 72/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6605 - accuracy: 0.5938 - val_loss: 0.6602 - val_accuracy: 0.5913\n",
      "Epoch 73/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6620 - accuracy: 0.5899 - val_loss: 0.6693 - val_accuracy: 0.5823\n",
      "Epoch 74/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6601 - accuracy: 0.5941 - val_loss: 0.6607 - val_accuracy: 0.5920\n",
      "Epoch 75/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6628 - accuracy: 0.5891 - val_loss: 0.6665 - val_accuracy: 0.5832\n",
      "Epoch 76/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6731 - accuracy: 0.5712 - val_loss: 0.6658 - val_accuracy: 0.5875\n",
      "Epoch 77/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6651 - accuracy: 0.5854 - val_loss: 0.6639 - val_accuracy: 0.5901\n",
      "Epoch 78/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6590 - accuracy: 0.5959 - val_loss: 0.6639 - val_accuracy: 0.5965\n",
      "Epoch 79/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6604 - accuracy: 0.5929 - val_loss: 0.6612 - val_accuracy: 0.5939\n",
      "Epoch 80/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6625 - accuracy: 0.5910 - val_loss: 0.7660 - val_accuracy: 0.5094\n",
      "Epoch 81/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6799 - accuracy: 0.5566 - val_loss: 0.6715 - val_accuracy: 0.5731\n",
      "Epoch 82/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6627 - accuracy: 0.5889 - val_loss: 0.6583 - val_accuracy: 0.5996\n",
      "Epoch 83/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6591 - accuracy: 0.5968 - val_loss: 0.6558 - val_accuracy: 0.6006\n",
      "Epoch 84/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6614 - accuracy: 0.5916 - val_loss: 0.6619 - val_accuracy: 0.5971\n",
      "Epoch 85/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6567 - accuracy: 0.6000 - val_loss: 0.6532 - val_accuracy: 0.6043\n",
      "Epoch 86/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6572 - accuracy: 0.5986 - val_loss: 0.6580 - val_accuracy: 0.6019\n",
      "Epoch 87/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6583 - accuracy: 0.5962 - val_loss: 0.6605 - val_accuracy: 0.6023\n",
      "Epoch 88/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6544 - accuracy: 0.6034 - val_loss: 0.6568 - val_accuracy: 0.5967\n",
      "Epoch 89/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6569 - accuracy: 0.5981 - val_loss: 0.6537 - val_accuracy: 0.6052\n",
      "Epoch 90/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6552 - accuracy: 0.6021 - val_loss: 0.6556 - val_accuracy: 0.5984\n",
      "Epoch 91/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6662 - accuracy: 0.5858 - val_loss: 0.6653 - val_accuracy: 0.5811\n",
      "Epoch 92/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6560 - accuracy: 0.6014 - val_loss: 0.6520 - val_accuracy: 0.6056\n",
      "Epoch 93/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6580 - accuracy: 0.5981 - val_loss: 0.6674 - val_accuracy: 0.5851\n",
      "Epoch 94/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6543 - accuracy: 0.6039 - val_loss: 0.6501 - val_accuracy: 0.6091\n",
      "Epoch 95/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6532 - accuracy: 0.6056 - val_loss: 0.6535 - val_accuracy: 0.6030\n",
      "Epoch 96/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6527 - accuracy: 0.6057 - val_loss: 0.6494 - val_accuracy: 0.6092\n",
      "Epoch 97/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6531 - accuracy: 0.6052 - val_loss: 0.6497 - val_accuracy: 0.6117\n",
      "Epoch 98/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6514 - accuracy: 0.6077 - val_loss: 0.6761 - val_accuracy: 0.5707\n",
      "Epoch 99/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6843 - accuracy: 0.5565 - val_loss: 0.6981 - val_accuracy: 0.5150\n",
      "Epoch 100/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6842 - accuracy: 0.5470 - val_loss: 0.6792 - val_accuracy: 0.5649\n",
      "Epoch 101/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6589 - accuracy: 0.5965 - val_loss: 0.6547 - val_accuracy: 0.6062\n",
      "Epoch 102/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6510 - accuracy: 0.6071 - val_loss: 0.6554 - val_accuracy: 0.6043\n",
      "Epoch 103/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6542 - accuracy: 0.6048 - val_loss: 0.6568 - val_accuracy: 0.5986\n",
      "Epoch 104/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6516 - accuracy: 0.6070 - val_loss: 0.6506 - val_accuracy: 0.6112\n",
      "Epoch 105/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6527 - accuracy: 0.6082 - val_loss: 0.6534 - val_accuracy: 0.6069\n",
      "Epoch 106/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6517 - accuracy: 0.6073 - val_loss: 0.6569 - val_accuracy: 0.6105\n",
      "Epoch 107/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6501 - accuracy: 0.6087 - val_loss: 0.6475 - val_accuracy: 0.6142\n",
      "Epoch 108/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6612 - accuracy: 0.5942 - val_loss: 0.6552 - val_accuracy: 0.6030\n",
      "Epoch 109/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6694 - accuracy: 0.5828 - val_loss: 0.6790 - val_accuracy: 0.5577\n",
      "Epoch 110/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6557 - accuracy: 0.6015 - val_loss: 0.6564 - val_accuracy: 0.6083\n",
      "Epoch 111/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6635 - accuracy: 0.5922 - val_loss: 0.7221 - val_accuracy: 0.5194\n",
      "Epoch 112/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6960 - accuracy: 0.5224 - val_loss: 0.6907 - val_accuracy: 0.5322\n",
      "Epoch 113/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6876 - accuracy: 0.5369 - val_loss: 0.6857 - val_accuracy: 0.5422\n",
      "Epoch 114/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6824 - accuracy: 0.5495 - val_loss: 0.6804 - val_accuracy: 0.5554\n",
      "Epoch 115/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6770 - accuracy: 0.5615 - val_loss: 0.6756 - val_accuracy: 0.5633\n",
      "Epoch 116/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6712 - accuracy: 0.5718 - val_loss: 0.6691 - val_accuracy: 0.5743\n",
      "Epoch 117/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6662 - accuracy: 0.5837 - val_loss: 0.6640 - val_accuracy: 0.5855\n",
      "Epoch 118/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6601 - accuracy: 0.5930 - val_loss: 0.6580 - val_accuracy: 0.5962\n",
      "Epoch 119/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6559 - accuracy: 0.5990 - val_loss: 0.6573 - val_accuracy: 0.5959\n",
      "Epoch 120/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6660 - accuracy: 0.5845 - val_loss: 0.6543 - val_accuracy: 0.6038\n",
      "Epoch 121/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6554 - accuracy: 0.6013 - val_loss: 0.6569 - val_accuracy: 0.6027\n",
      "Epoch 122/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6519 - accuracy: 0.6060 - val_loss: 0.6486 - val_accuracy: 0.6120\n",
      "Epoch 123/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6511 - accuracy: 0.6071 - val_loss: 0.6500 - val_accuracy: 0.6097\n",
      "Epoch 124/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6496 - accuracy: 0.6094 - val_loss: 0.6464 - val_accuracy: 0.6142\n",
      "Epoch 125/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6510 - accuracy: 0.6088 - val_loss: 0.6491 - val_accuracy: 0.6105\n",
      "Epoch 126/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6543 - accuracy: 0.6023 - val_loss: 0.6517 - val_accuracy: 0.6094\n",
      "Epoch 127/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6482 - accuracy: 0.6107 - val_loss: 0.6488 - val_accuracy: 0.6043\n",
      "Epoch 128/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6769 - accuracy: 0.5651 - val_loss: 0.6866 - val_accuracy: 0.5473\n",
      "Epoch 129/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6753 - accuracy: 0.5621 - val_loss: 0.6713 - val_accuracy: 0.5722\n",
      "Epoch 130/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6598 - accuracy: 0.5909 - val_loss: 0.6540 - val_accuracy: 0.6048\n",
      "Epoch 131/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6524 - accuracy: 0.6042 - val_loss: 0.6535 - val_accuracy: 0.6047\n",
      "Epoch 132/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6513 - accuracy: 0.6072 - val_loss: 0.6464 - val_accuracy: 0.6138\n",
      "Epoch 133/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6482 - accuracy: 0.6112 - val_loss: 0.6446 - val_accuracy: 0.6116\n",
      "Epoch 134/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6503 - accuracy: 0.6095 - val_loss: 0.6457 - val_accuracy: 0.6175\n",
      "Epoch 135/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6487 - accuracy: 0.6112 - val_loss: 0.6427 - val_accuracy: 0.6195\n",
      "Epoch 136/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6476 - accuracy: 0.6120 - val_loss: 0.6493 - val_accuracy: 0.6108\n",
      "Epoch 137/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6627 - accuracy: 0.5891 - val_loss: 0.7030 - val_accuracy: 0.5215\n",
      "Epoch 138/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6925 - accuracy: 0.5264 - val_loss: 0.6884 - val_accuracy: 0.5390\n",
      "Epoch 139/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6805 - accuracy: 0.5534 - val_loss: 0.6760 - val_accuracy: 0.5653\n",
      "Epoch 140/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6665 - accuracy: 0.5796 - val_loss: 0.6626 - val_accuracy: 0.5844\n",
      "Epoch 141/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6613 - accuracy: 0.5919 - val_loss: 0.6691 - val_accuracy: 0.5712\n",
      "Epoch 142/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6598 - accuracy: 0.5927 - val_loss: 0.6555 - val_accuracy: 0.6036\n",
      "Epoch 143/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6517 - accuracy: 0.6061 - val_loss: 0.6499 - val_accuracy: 0.6096\n",
      "Epoch 144/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6470 - accuracy: 0.6118 - val_loss: 0.6458 - val_accuracy: 0.6142\n",
      "Epoch 145/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6457 - accuracy: 0.6126 - val_loss: 0.6472 - val_accuracy: 0.6148\n",
      "Epoch 146/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6441 - accuracy: 0.6142 - val_loss: 0.6449 - val_accuracy: 0.6160\n",
      "Epoch 147/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6426 - accuracy: 0.6159 - val_loss: 0.6391 - val_accuracy: 0.6231\n",
      "Epoch 148/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6422 - accuracy: 0.6168 - val_loss: 0.6397 - val_accuracy: 0.6233\n",
      "Epoch 149/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6407 - accuracy: 0.6184 - val_loss: 0.6416 - val_accuracy: 0.6213\n",
      "Epoch 150/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6406 - accuracy: 0.6192 - val_loss: 0.6451 - val_accuracy: 0.6121\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_36\n",
      "cannot prune layer q_activation_36\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_37\n",
      "cannot prune layer q_activation_37\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 7ms/step - loss: 0.6664 - accuracy: 0.5914 - val_loss: 0.6997 - val_accuracy: 0.5453\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6849 - accuracy: 0.5582 - val_loss: 0.6910 - val_accuracy: 0.5454\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6630 - accuracy: 0.5842 - val_loss: 0.7006 - val_accuracy: 0.5480\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6573 - accuracy: 0.5940 - val_loss: 0.7091 - val_accuracy: 0.5437\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6627 - accuracy: 0.5850 - val_loss: 0.6785 - val_accuracy: 0.5743\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6546 - accuracy: 0.5971 - val_loss: 0.6680 - val_accuracy: 0.5871\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6538 - accuracy: 0.6030 - val_loss: 0.6867 - val_accuracy: 0.5640\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6578 - accuracy: 0.5991 - val_loss: 0.6627 - val_accuracy: 0.5905\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6537 - accuracy: 0.6043 - val_loss: 0.6500 - val_accuracy: 0.6100\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6499 - accuracy: 0.6098 - val_loss: 0.6468 - val_accuracy: 0.6148\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6493 - accuracy: 0.6106 - val_loss: 0.6496 - val_accuracy: 0.6101\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6490 - accuracy: 0.6116 - val_loss: 0.6504 - val_accuracy: 0.6108\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6479 - accuracy: 0.6128 - val_loss: 0.6441 - val_accuracy: 0.6191\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6484 - accuracy: 0.6118 - val_loss: 0.6495 - val_accuracy: 0.6115\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6509 - accuracy: 0.6077 - val_loss: 0.6477 - val_accuracy: 0.6114\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6476 - accuracy: 0.6124 - val_loss: 0.6478 - val_accuracy: 0.6110\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6482 - accuracy: 0.6121 - val_loss: 0.6499 - val_accuracy: 0.6087\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6797 - accuracy: 0.5616 - val_loss: 0.6865 - val_accuracy: 0.5402\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6558 - accuracy: 0.6006 - val_loss: 0.6477 - val_accuracy: 0.6131\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6472 - accuracy: 0.6134 - val_loss: 0.6652 - val_accuracy: 0.5874\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6480 - accuracy: 0.6098 - val_loss: 0.6529 - val_accuracy: 0.6046\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6489 - accuracy: 0.6104 - val_loss: 0.6640 - val_accuracy: 0.5837\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6467 - accuracy: 0.6136 - val_loss: 0.6422 - val_accuracy: 0.6235\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6440 - accuracy: 0.6173 - val_loss: 0.6401 - val_accuracy: 0.6231\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6590 - accuracy: 0.5984 - val_loss: 0.6527 - val_accuracy: 0.6022\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6457 - accuracy: 0.6148 - val_loss: 0.6489 - val_accuracy: 0.6108\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6560 - accuracy: 0.6005 - val_loss: 0.6439 - val_accuracy: 0.6224\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6441 - accuracy: 0.6164 - val_loss: 0.6416 - val_accuracy: 0.6197\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6436 - accuracy: 0.6177 - val_loss: 0.6400 - val_accuracy: 0.6259\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6430 - accuracy: 0.6189 - val_loss: 0.6418 - val_accuracy: 0.6222\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6436 - accuracy: 0.6169 - val_loss: 0.6429 - val_accuracy: 0.6190\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6578 - accuracy: 0.5993 - val_loss: 0.6492 - val_accuracy: 0.6132\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6437 - accuracy: 0.6158 - val_loss: 0.6462 - val_accuracy: 0.6158\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6429 - accuracy: 0.6185 - val_loss: 0.6410 - val_accuracy: 0.6229\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6416 - accuracy: 0.6203 - val_loss: 0.6428 - val_accuracy: 0.6181\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6423 - accuracy: 0.6188 - val_loss: 0.6375 - val_accuracy: 0.6260\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6446 - accuracy: 0.6178 - val_loss: 0.6409 - val_accuracy: 0.6232\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6413 - accuracy: 0.6206 - val_loss: 0.6377 - val_accuracy: 0.6271\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6737 - accuracy: 0.5710 - val_loss: 0.6994 - val_accuracy: 0.5185\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6893 - accuracy: 0.5407 - val_loss: 0.6878 - val_accuracy: 0.5431\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6520 - accuracy: 0.6044 - val_loss: 0.6463 - val_accuracy: 0.6097\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6436 - accuracy: 0.6154 - val_loss: 0.6400 - val_accuracy: 0.6213\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6412 - accuracy: 0.6176 - val_loss: 0.6387 - val_accuracy: 0.6222\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6402 - accuracy: 0.6194 - val_loss: 0.6383 - val_accuracy: 0.6226\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6409 - accuracy: 0.6203 - val_loss: 0.6382 - val_accuracy: 0.6215\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6458 - accuracy: 0.6168 - val_loss: 0.6439 - val_accuracy: 0.6150\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6436 - accuracy: 0.6186 - val_loss: 0.6395 - val_accuracy: 0.6222\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6459 - accuracy: 0.6138 - val_loss: 0.6417 - val_accuracy: 0.6224\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6426 - accuracy: 0.6201 - val_loss: 0.6393 - val_accuracy: 0.6264\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6436 - accuracy: 0.6184 - val_loss: 0.6497 - val_accuracy: 0.6181\n",
      "1714/1714 [==============================] - 3s 1ms/step\n",
      "[[0.59087723]\n",
      " [0.69222325]\n",
      " [0.5334515 ]\n",
      " [0.6547705 ]\n",
      " [0.504764  ]\n",
      " [0.3894515 ]\n",
      " [0.6053732 ]\n",
      " [0.3910995 ]\n",
      " [0.4196989 ]\n",
      " [0.69702196]]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    results = hyperparameter_search(data, HYPERPARAMETERS, param_grid, result_file=SAVE_FILE)\n",
    "    send_email_notification(\"All done with hyperparameter search\", 'Done!')\n",
    "except Exception as e:\n",
    "    print(\"Error encountered:\", e)\n",
    "    send_email_notification(\"Hyperparameter search ran into an error\", 'Go fix it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE REFORMATTING\n",
    "# (RUN LATER WHEN THEY ARENT BEING WRITTEN TO)\n",
    "\n",
    "def reformat_hyperparameter_results(input_file, output_file):\n",
    "    # Read the original JSON file\n",
    "    with open(input_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Process and format the metrics\n",
    "    for key, value in data.items():\n",
    "        if \"metrics\" in value:\n",
    "            value[\"metrics\"] = format_metrics(value[\"metrics\"])\n",
    "\n",
    "    # Write the updated data to the new JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "# Define input and output file names\n",
    "input_file = 'one_layerDNN_results.json'\n",
    "output_file = 'one_layerDNN_results.json'\n",
    "\n",
    "# Call the function to reformat the JSON data\n",
    "reformat_hyperparameter_results(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Model Read / Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  [(None, 105)]             0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 24)                96        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " q_activation_4 (QActivatio  (None, 24)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 12)                48        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " q_activation_5 (QActivatio  (None, 12)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3001 (11.72 KB)\n",
      "Trainable params: 2929 (11.44 KB)\n",
      "Non-trainable params: 72 (288.00 Byte)\n",
      "_________________________________________________________________\n",
      "dense1               u=24 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_4 is normal keras bn layer\n",
      "q_activation_4       quantized_relu(15,0)\n",
      "dense2               u=12 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "batch_normalization_5 is normal keras bn layer\n",
      "q_activation_5       quantized_relu(15,0)\n",
      "dense_output         u=1 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "shape 12323 is  (438739,) data is like [0 1 0 0]\n",
      "Epoch 1/150\n",
      "429/429 [==============================] - 6s 7ms/step - loss: 1.7775 - accuracy: 0.5017 - val_loss: 0.7032 - val_accuracy: 0.5022\n",
      "Epoch 2/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6981 - accuracy: 0.5032 - val_loss: 0.6957 - val_accuracy: 0.5011\n",
      "Epoch 3/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6952 - accuracy: 0.5055 - val_loss: 0.6945 - val_accuracy: 0.5044\n",
      "Epoch 4/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6939 - accuracy: 0.5066 - val_loss: 0.6941 - val_accuracy: 0.5027\n",
      "Epoch 5/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6935 - accuracy: 0.5080 - val_loss: 0.6938 - val_accuracy: 0.5040\n",
      "Epoch 6/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6932 - accuracy: 0.5081 - val_loss: 0.6934 - val_accuracy: 0.5039\n",
      "Epoch 7/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6930 - accuracy: 0.5089 - val_loss: 0.6934 - val_accuracy: 0.5035\n",
      "Epoch 8/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.5095 - val_loss: 0.6932 - val_accuracy: 0.5037\n",
      "Epoch 9/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6928 - accuracy: 0.5095 - val_loss: 0.6932 - val_accuracy: 0.5048\n",
      "Epoch 10/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5113 - val_loss: 0.6930 - val_accuracy: 0.5056\n",
      "Epoch 11/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6925 - accuracy: 0.5118 - val_loss: 0.6931 - val_accuracy: 0.5054\n",
      "Epoch 12/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6925 - accuracy: 0.5126 - val_loss: 0.6932 - val_accuracy: 0.5053\n",
      "Epoch 13/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6925 - accuracy: 0.5125 - val_loss: 0.6929 - val_accuracy: 0.5081\n",
      "Epoch 14/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6923 - accuracy: 0.5132 - val_loss: 0.6929 - val_accuracy: 0.5066\n",
      "Epoch 15/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6922 - accuracy: 0.5146 - val_loss: 0.6930 - val_accuracy: 0.5087\n",
      "Epoch 16/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6928 - val_accuracy: 0.5119\n",
      "Epoch 17/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6918 - accuracy: 0.5197 - val_loss: 0.6922 - val_accuracy: 0.5179\n",
      "Epoch 18/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6913 - accuracy: 0.5237 - val_loss: 0.6929 - val_accuracy: 0.5125\n",
      "Epoch 19/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6905 - accuracy: 0.5283 - val_loss: 0.6916 - val_accuracy: 0.5213\n",
      "Epoch 20/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6893 - accuracy: 0.5337 - val_loss: 0.6891 - val_accuracy: 0.5335\n",
      "Epoch 21/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6869 - accuracy: 0.5414 - val_loss: 0.6910 - val_accuracy: 0.5259\n",
      "Epoch 22/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6841 - accuracy: 0.5487 - val_loss: 0.6839 - val_accuracy: 0.5493\n",
      "Epoch 23/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6801 - accuracy: 0.5557 - val_loss: 0.6798 - val_accuracy: 0.5554\n",
      "Epoch 24/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6776 - accuracy: 0.5604 - val_loss: 0.6774 - val_accuracy: 0.5568\n",
      "Epoch 25/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6739 - accuracy: 0.5662 - val_loss: 0.6771 - val_accuracy: 0.5611\n",
      "Epoch 26/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6721 - accuracy: 0.5698 - val_loss: 0.6748 - val_accuracy: 0.5670\n",
      "Epoch 27/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6696 - accuracy: 0.5732 - val_loss: 0.6814 - val_accuracy: 0.5527\n",
      "Epoch 28/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6666 - accuracy: 0.5789 - val_loss: 0.6653 - val_accuracy: 0.5805\n",
      "Epoch 29/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6642 - accuracy: 0.5817 - val_loss: 0.6641 - val_accuracy: 0.5804\n",
      "Epoch 30/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6628 - accuracy: 0.5839 - val_loss: 0.6816 - val_accuracy: 0.5592\n",
      "Epoch 31/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6611 - accuracy: 0.5860 - val_loss: 0.6585 - val_accuracy: 0.5866\n",
      "Epoch 32/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6591 - accuracy: 0.5885 - val_loss: 0.6521 - val_accuracy: 0.5953\n",
      "Epoch 33/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6576 - accuracy: 0.5915 - val_loss: 0.6563 - val_accuracy: 0.5918\n",
      "Epoch 34/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6558 - accuracy: 0.5936 - val_loss: 0.6528 - val_accuracy: 0.5999\n",
      "Epoch 35/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6641 - accuracy: 0.5754 - val_loss: 0.6919 - val_accuracy: 0.5160\n",
      "Epoch 36/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6721 - accuracy: 0.5635 - val_loss: 0.6626 - val_accuracy: 0.5817\n",
      "Epoch 37/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6527 - accuracy: 0.5991 - val_loss: 0.6538 - val_accuracy: 0.5970\n",
      "Epoch 38/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6535 - accuracy: 0.5975 - val_loss: 0.6470 - val_accuracy: 0.6047\n",
      "Epoch 39/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6497 - accuracy: 0.6022 - val_loss: 0.6469 - val_accuracy: 0.6072\n",
      "Epoch 40/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6496 - accuracy: 0.6021 - val_loss: 0.6453 - val_accuracy: 0.6061\n",
      "Epoch 41/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6545 - accuracy: 0.5973 - val_loss: 0.6579 - val_accuracy: 0.5914\n",
      "Epoch 42/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6482 - accuracy: 0.6046 - val_loss: 0.6677 - val_accuracy: 0.5503\n",
      "Epoch 43/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6476 - accuracy: 0.6050 - val_loss: 0.6480 - val_accuracy: 0.6039\n",
      "Epoch 44/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6458 - accuracy: 0.6074 - val_loss: 0.6390 - val_accuracy: 0.6163\n",
      "Epoch 45/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6449 - accuracy: 0.6084 - val_loss: 0.6454 - val_accuracy: 0.6050\n",
      "Epoch 46/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6450 - accuracy: 0.6084 - val_loss: 0.6356 - val_accuracy: 0.6194\n",
      "Epoch 47/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6429 - accuracy: 0.6114 - val_loss: 0.6349 - val_accuracy: 0.6229\n",
      "Epoch 48/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6456 - accuracy: 0.6083 - val_loss: 0.6760 - val_accuracy: 0.5729\n",
      "Epoch 49/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6427 - accuracy: 0.6110 - val_loss: 0.6346 - val_accuracy: 0.6187\n",
      "Epoch 50/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6409 - accuracy: 0.6149 - val_loss: 0.6345 - val_accuracy: 0.6205\n",
      "Epoch 51/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6410 - accuracy: 0.6135 - val_loss: 0.6336 - val_accuracy: 0.6213\n",
      "Epoch 52/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6404 - accuracy: 0.6159 - val_loss: 0.6368 - val_accuracy: 0.6178\n",
      "Epoch 53/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6385 - accuracy: 0.6172 - val_loss: 0.6333 - val_accuracy: 0.6207\n",
      "Epoch 54/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6387 - accuracy: 0.6176 - val_loss: 0.6320 - val_accuracy: 0.6247\n",
      "Epoch 55/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6365 - accuracy: 0.6194 - val_loss: 0.6408 - val_accuracy: 0.6156\n",
      "Epoch 56/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6360 - accuracy: 0.6214 - val_loss: 0.6370 - val_accuracy: 0.6211\n",
      "Epoch 57/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6358 - accuracy: 0.6223 - val_loss: 0.6330 - val_accuracy: 0.6243\n",
      "Epoch 58/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6395 - accuracy: 0.6199 - val_loss: 0.6383 - val_accuracy: 0.6186\n",
      "Epoch 59/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6364 - accuracy: 0.6230 - val_loss: 0.6407 - val_accuracy: 0.6161\n",
      "Epoch 60/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6359 - accuracy: 0.6219 - val_loss: 0.6451 - val_accuracy: 0.6135\n",
      "Epoch 61/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6577 - accuracy: 0.5890 - val_loss: 0.6390 - val_accuracy: 0.6236\n",
      "Epoch 62/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6345 - accuracy: 0.6228 - val_loss: 0.6360 - val_accuracy: 0.6190\n",
      "Epoch 63/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6345 - accuracy: 0.6228 - val_loss: 0.6244 - val_accuracy: 0.6350\n",
      "Epoch 64/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6327 - accuracy: 0.6248 - val_loss: 0.6349 - val_accuracy: 0.6175\n",
      "Epoch 65/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6327 - accuracy: 0.6243 - val_loss: 0.6293 - val_accuracy: 0.6317\n",
      "Epoch 66/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6332 - accuracy: 0.6245 - val_loss: 0.6242 - val_accuracy: 0.6391\n",
      "Epoch 67/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6316 - accuracy: 0.6256 - val_loss: 0.6222 - val_accuracy: 0.6356\n",
      "Epoch 68/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6314 - accuracy: 0.6266 - val_loss: 0.6615 - val_accuracy: 0.5901\n",
      "Epoch 69/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6330 - accuracy: 0.6249 - val_loss: 0.6277 - val_accuracy: 0.6320\n",
      "Epoch 70/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6449 - accuracy: 0.6095 - val_loss: 0.7222 - val_accuracy: 0.5085\n",
      "Epoch 71/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6948 - accuracy: 0.5104 - val_loss: 0.6937 - val_accuracy: 0.5113\n",
      "Epoch 72/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6923 - accuracy: 0.5177 - val_loss: 0.6932 - val_accuracy: 0.5180\n",
      "Epoch 73/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6901 - accuracy: 0.5288 - val_loss: 0.6892 - val_accuracy: 0.5306\n",
      "Epoch 74/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6802 - accuracy: 0.5600 - val_loss: 0.6746 - val_accuracy: 0.5692\n",
      "Epoch 75/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6661 - accuracy: 0.5834 - val_loss: 0.6623 - val_accuracy: 0.5905\n",
      "Epoch 76/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6553 - accuracy: 0.5969 - val_loss: 0.6532 - val_accuracy: 0.6009\n",
      "Epoch 77/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6486 - accuracy: 0.6053 - val_loss: 0.6389 - val_accuracy: 0.6156\n",
      "Epoch 78/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6478 - accuracy: 0.6057 - val_loss: 0.6411 - val_accuracy: 0.6112\n",
      "Epoch 79/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6414 - accuracy: 0.6154 - val_loss: 0.6419 - val_accuracy: 0.6119\n",
      "Epoch 80/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6409 - accuracy: 0.6159 - val_loss: 0.6367 - val_accuracy: 0.6199\n",
      "Epoch 81/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6825 - accuracy: 0.5502 - val_loss: 0.6866 - val_accuracy: 0.5451\n",
      "Epoch 82/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6522 - accuracy: 0.6000 - val_loss: 0.6546 - val_accuracy: 0.6007\n",
      "Epoch 83/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6399 - accuracy: 0.6165 - val_loss: 0.6411 - val_accuracy: 0.6182\n",
      "Epoch 84/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6396 - accuracy: 0.6182 - val_loss: 0.6493 - val_accuracy: 0.6042\n",
      "Epoch 85/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6629 - accuracy: 0.5796 - val_loss: 0.6971 - val_accuracy: 0.5070\n",
      "Epoch 86/150\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6832 - accuracy: 0.5505 - val_loss: 0.6813 - val_accuracy: 0.5550\n",
      "Epoch 87/150\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6708 - accuracy: 0.5651 - val_loss: 0.6951 - val_accuracy: 0.5046\n",
      "pruning layer dense1\n",
      "cannot prune layer batch_normalization_4\n",
      "cannot prune layer q_activation_4\n",
      "pruning layer dense2\n",
      "cannot prune layer batch_normalization_5\n",
      "cannot prune layer q_activation_5\n",
      "pruning layer dense_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 7s 8ms/step - loss: 0.6339 - accuracy: 0.6228 - val_loss: 0.6230 - val_accuracy: 0.6356\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6447 - accuracy: 0.6128 - val_loss: 0.6378 - val_accuracy: 0.6206\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6330 - accuracy: 0.6262 - val_loss: 0.6361 - val_accuracy: 0.6195\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6307 - accuracy: 0.6287 - val_loss: 0.6252 - val_accuracy: 0.6354\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6307 - accuracy: 0.6280 - val_loss: 0.6382 - val_accuracy: 0.6091\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6890 - accuracy: 0.5304 - val_loss: 0.6993 - val_accuracy: 0.5013\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6966 - accuracy: 0.5020 - val_loss: 0.6957 - val_accuracy: 0.4996\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6948 - accuracy: 0.5032 - val_loss: 0.6946 - val_accuracy: 0.5007\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6940 - accuracy: 0.5036 - val_loss: 0.6940 - val_accuracy: 0.5008\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6935 - accuracy: 0.5059 - val_loss: 0.6935 - val_accuracy: 0.5046\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6933 - accuracy: 0.5060 - val_loss: 0.6934 - val_accuracy: 0.5041\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6931 - accuracy: 0.5068 - val_loss: 0.6933 - val_accuracy: 0.5055\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6930 - accuracy: 0.5072 - val_loss: 0.6934 - val_accuracy: 0.5065\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6930 - accuracy: 0.5070 - val_loss: 0.6931 - val_accuracy: 0.5056\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6929 - accuracy: 0.5084 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6929 - accuracy: 0.5084 - val_loss: 0.6932 - val_accuracy: 0.5049\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.5086 - val_loss: 0.6931 - val_accuracy: 0.5091\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6928 - accuracy: 0.5091 - val_loss: 0.6930 - val_accuracy: 0.5069\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6927 - accuracy: 0.5099 - val_loss: 0.6931 - val_accuracy: 0.5095\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6927 - accuracy: 0.5098 - val_loss: 0.6929 - val_accuracy: 0.5087\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5113 - val_loss: 0.6932 - val_accuracy: 0.5036\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6926 - accuracy: 0.5117 - val_loss: 0.6930 - val_accuracy: 0.5075\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5129 - val_loss: 0.6927 - val_accuracy: 0.5135\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6923 - accuracy: 0.5141 - val_loss: 0.6922 - val_accuracy: 0.5166\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6920 - accuracy: 0.5167 - val_loss: 0.6922 - val_accuracy: 0.5195\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6908 - accuracy: 0.5249 - val_loss: 0.6897 - val_accuracy: 0.5329\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6872 - accuracy: 0.5405 - val_loss: 0.6876 - val_accuracy: 0.5362\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6804 - accuracy: 0.5550 - val_loss: 0.6841 - val_accuracy: 0.5433\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6722 - accuracy: 0.5722 - val_loss: 0.6808 - val_accuracy: 0.5568\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6667 - accuracy: 0.5829 - val_loss: 0.6560 - val_accuracy: 0.5983\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6764 - accuracy: 0.5587 - val_loss: 0.6952 - val_accuracy: 0.5060\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6924 - accuracy: 0.5171 - val_loss: 0.6914 - val_accuracy: 0.5190\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6894 - accuracy: 0.5296 - val_loss: 0.6880 - val_accuracy: 0.5366\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6827 - accuracy: 0.5525 - val_loss: 0.6820 - val_accuracy: 0.5519\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6759 - accuracy: 0.5629 - val_loss: 0.6839 - val_accuracy: 0.5444\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6841 - accuracy: 0.5409 - val_loss: 0.6924 - val_accuracy: 0.5114\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6855 - accuracy: 0.5411 - val_loss: 0.6804 - val_accuracy: 0.5562\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6719 - accuracy: 0.5725 - val_loss: 0.6651 - val_accuracy: 0.5829\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6632 - accuracy: 0.5852 - val_loss: 0.6566 - val_accuracy: 0.5945\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6923 - accuracy: 0.5153 - val_loss: 0.6939 - val_accuracy: 0.5072\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6933 - accuracy: 0.5077 - val_loss: 0.6933 - val_accuracy: 0.5053\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6930 - accuracy: 0.5089 - val_loss: 0.6931 - val_accuracy: 0.5059\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6925 - accuracy: 0.5112 - val_loss: 0.6927 - val_accuracy: 0.5084\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6921 - accuracy: 0.5141 - val_loss: 0.6922 - val_accuracy: 0.5131\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6916 - accuracy: 0.5169 - val_loss: 0.6916 - val_accuracy: 0.5150\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6901 - accuracy: 0.5239 - val_loss: 0.6901 - val_accuracy: 0.5257\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6842 - accuracy: 0.5445 - val_loss: 0.6811 - val_accuracy: 0.5559\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6733 - accuracy: 0.5704 - val_loss: 0.6738 - val_accuracy: 0.5727\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6651 - accuracy: 0.5833 - val_loss: 0.6526 - val_accuracy: 0.5995\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 2s 5ms/step - loss: 0.6695 - accuracy: 0.5730 - val_loss: 0.6608 - val_accuracy: 0.5896\n"
     ]
    }
   ],
   "source": [
    "model, train_metrics = train_model(data, HYPERPARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1714/1714 [==============================] - 3s 2ms/step\n",
      "[[0.657699  ]\n",
      " [0.51863325]\n",
      " [0.55201584]\n",
      " [0.3855904 ]\n",
      " [0.49306977]\n",
      " [0.61651945]\n",
      " [0.5650373 ]\n",
      " [0.41414428]\n",
      " [0.47818124]\n",
      " [0.53208697]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIhCAYAAAB5deq6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3GklEQVR4nO3dd1yV5f/H8fdhgyiuFBy5N5or9ygVZ1pmPys1d2VmrpZlDtS2iZWZfctRObKhfsuRopbbUsHMkZojU0FzoqLIuH9/+D3EERBuOIdzgNfz8eDx8Nxc131/Dl4gH6/r+lwWwzAMAQAAAADS5ebsAAAAAADA1ZE4AQAAAEAGSJwAAAAAIAMkTgAAAACQARInAAAAAMgAiRMAAAAAZIDECQAAAAAyQOIEAAAAABkgcQIAAACADJA4AciWefPmyWKx2Hzcdddduu+++7R8+XKHPvu+++5TcHCwQ5/hysqXL6/+/ftn2O72v59ChQqpWbNmWrRokcOfnVUzZ87UvHnzUl0/fvy4LBZLmp/Lq3755Rd1795dd999t7y9vVWyZEk1bdpUzz//vE27++67T/fdd59zgkxDZuO57777Uo1R60f58uVt2q5bt04NGzZUgQIFZLFYtGzZMknS4sWLVatWLfn6+spisWj37t2aOHGiLBaL6bj79++f6rkAIEkezg4AQN4wd+5cVa9eXYZhKDo6WjNmzFDXrl31/fffq2vXrs4OL9975JFH9Pzzz8swDB07dkxvvPGGevXqJcMw1KtXL9P3W7p0qQoVKuSASG+ZOXOmihcvnio5CwoK0rZt21SpUiWHPduVrFixQt26ddN9992nd955R0FBQYqKitLOnTv11Vdf6b333ktuO3PmTCdGmj0VK1bUggULUl339vZO/rNhGOrZs6eqVq2q77//XgUKFFC1atX0zz//6IknnlDHjh01c+ZMeXt7q2rVqho8eLA6duxoOpZx48ZpxIgR2Xo/APImEicAdhEcHKyGDRsmv+7YsaOKFCmiRYsW5erEKTY2Vn5+fs4OI9tKliypJk2aSJKaNm2q5s2bq3z58vrkk0+ylDjVq1fP3iFmire3d/L7yA/eeecdVahQQatXr5aHx7//ZD/22GN65513bNrWrFkzp8OzG19f3wz/Xk+fPq0LFy6oe/fuatu2bfL1LVu2KD4+Xn369FHr1q2Tr/v5+alMmTKmY8kvSTkA81iqB8AhfHx85OXlJU9PT5vroaGhaty4sYoWLapChQqpfv36mj17tgzDSHWPhQsXqmnTpvL395e/v7/q1q2r2bNn3/G5S5culZ+fnwYPHqyEhARJ0qVLlzRo0CAVLVpU/v7+6tKli44ePSqLxaKJEycm97Uu7YmIiNAjjzyiIkWKJP8SdePGDb3yyiuqUKGCvLy8VLp0aT377LO6dOmSzfNvv6fV7UvbrEscf/rpJz3zzDMqXry4ihUrpocfflinT5+26RsfH6+XXnpJgYGB8vPzU4sWLfTrr7/e8euQkXLlyumuu+7SmTNnbK7HxMTohRdesHmfI0eO1LVr1+74fsz0TUpK0ocffqi6devK19dXhQsXVpMmTfT9998n33vfvn3asGFDqiVb6S3V27x5s9q2bauCBQvKz89PzZo104oVK2zamPma32769OmyWCz6888/U33u5ZdflpeXl86dOydJioyM1AMPPKASJUrI29tbpUqVUpcuXXTy5Mk7PiMt58+fV/HixW2SJis3N9t/wtNaGnfy5Ek98sgjKliwoAoXLqzevXtrx44dqb6G/fv3l7+/v/7880917txZ/v7+Klu2rJ5//nnFxcXZ3NPM97C9TJw4MTkJevnll5PHRP/+/dWiRQtJ0qOPPiqLxZL8NUhvqV5GP1fSWqpnGIZmzpyZPGaLFCmiRx55REePHrVpZ10+vGPHDrVs2VJ+fn6qWLGi3nrrLSUlJdm0vXTpkp5//nlVrFhR3t7eKlGihDp37qw//vhDhmGoSpUq6tChQ6r4r169qoCAAD377LOmv44AsofECYBdJCYmKiEhQfHx8Tp58mTyL8y3z2YcP35cTz/9tL7++mstWbJEDz/8sJ577jlNnjzZpt348ePVu3dvlSpVSvPmzdPSpUvVr18//fXXX+nGEBYWpv/7v//Tq6++qs8++0weHh5KSkpS165dtXDhQr388staunSpGjdufMclPA8//LAqV66sb775RrNmzZJhGHrooYc0depUPfHEE1qxYoVGjx6tzz//XG3atEn1i6UZgwcPlqenpxYuXKh33nlHP//8s/r06WPT5sknn9TUqVPVt29f/fe//1WPHj308MMP6+LFi1l+7uXLl3XhwgVVrVo1+VpsbKxat26tzz//XMOHD9eqVav08ssva968eerWrdsdfzE207d///4aMWKE7r33Xi1evFhfffWVunXrpuPHj0u6lfxWrFhR9erV07Zt27Rt2zYtXbo03Wdv2LBBbdq00eXLlzV79mwtWrRIBQsWVNeuXbV48eJU7TPzNb9dnz595OXllSphS0xM1Pz589W1a1cVL15c165dU0hIiM6cOaOPPvpI4eHhmj59uu6++25duXLljs9IS9OmTfXLL79o+PDh+uWXXxQfH5/pvteuXdP999+vn376SW+//ba+/vprlSxZUo8++mia7ePj49WtWze1bdtW//3vfzVw4ECFhYXp7bfftmmX2e9hsxISElJ9WJONwYMHa8mSJZKk5557LnlMjBs3Th999JEk6Y033tC2bdvuuGQxKz9XJOnpp5/WyJEj1a5dOy1btkwzZ87Uvn371KxZs1T/+RAdHa3evXurT58++v7779WpUye98sormj9/fnKbK1euqEWLFvrkk080YMAA/fDDD5o1a5aqVq2qqKgoWSwWPffccwoPD9fhw4dt7v/FF18oJiaGxAlwBgMAsmHu3LmGpFQf3t7exsyZM+/YNzEx0YiPjzcmTZpkFCtWzEhKSjIMwzCOHj1quLu7G717975j/9atWxu1atUyEhMTjWHDhhleXl7G/PnzbdqsWLHCkGR8/PHHNtfffPNNQ5IxYcKE5GsTJkwwJBnjx4+3afvjjz8akox33nnH5vrixYsNScZ//vOf5Gu339OqXLlyRr9+/ZJfW79uQ4cOtWn3zjvvGJKMqKgowzAM48CBA4YkY9SoUTbtFixYYEiyuWd6rM+Jj483bt68aRw6dMjo1q2bUbBgQWPnzp02XxM3Nzdjx44dNv2//fZbQ5KxcuXKdN9PZvtu3LjRkGSMHTv2jjHXqlXLaN26darrx44dMyQZc+fOTb7WpEkTo0SJEsaVK1eSryUkJBjBwcFGmTJlksdVZr/m6Xn44YeNMmXKGImJicnXVq5caUgyfvjhB8MwDGPnzp2GJGPZsmV3vFdmnTt3zmjRokXy95Wnp6fRrFkz480337R5v4Zx6/sh5dfso48+MiQZq1atsmn39NNPp/oa9uvXz5BkfP311zZtO3fubFSrVi3d+NL7Hk4rnvS0bt06zZ8hkoxBgwYlt7P+3b/77rs2/X/66SdDkvHNN9/YXLd+P1tl9udKv379jHLlyiW/3rZtmyHJeO+992za/f3334avr6/x0ksvpXovv/zyi03bmjVrGh06dEh+PWnSJEOSER4enm4cMTExRsGCBY0RI0akutf9999/x/cAwDGYcQJgF1988YV27NihHTt2aNWqVerXr5+effZZzZgxw6bd+vXr1a5dOwUEBMjd3V2enp4aP368zp8/r7Nnz0qSwsPDlZiYmKn/Ub1x44YeeughLViwQGvWrFHv3r1tPr9hwwZJUs+ePW2uP/744+nes0ePHqlilpRqadr//d//qUCBAlq3bl2GcaanW7duNq/r1KkjScn/A/7TTz9JUqr31bNnzzSXb6Vn5syZ8vT0lJeXl6pWrapVq1Zp0aJFatCgQXKb5cuXKzg4WHXr1rX5X/8OHTrIYrHo559/Tvf+me27atUqSbLb/5Zfu3ZNv/zyix555BH5+/snX3d3d9cTTzyhkydP6uDBgzZ9Mvqap2fAgAE6efKk1q5dm3xt7ty5CgwMVKdOnSRJlStXVpEiRfTyyy9r1qxZ2r9/f7beX7FixbRp0ybt2LFDb731lh588EEdOnRIr7zyimrXrp28PDAtGzZsUMGCBVPNrqY39i0WS6r9iHXq1En1dcnM97BZlSpVSv75kfJj3LhxWbpfWsz8XElp+fLlslgs6tOnj83YDgwM1D333JPq+yIwMFCNGjWyuXb713HVqlWqWrWq2rVrl+5zCxYsqAEDBmjevHnJy13Xr1+v/fv3a9iwYabeAwD7IHECYBc1atRQw4YN1bBhQ3Xs2FGffPKJ2rdvr5deeil5H9Cvv/6q9u3bS5I+/fRTbdmyRTt27NDYsWMlSdevX5ck/fPPP5KUqY3dZ8+e1erVq9W0aVM1a9Ys1efPnz8vDw8PFS1a1OZ6yZIl071nUFBQmve46667bK5bLBYFBgbq/PnzGcaZnmLFitm8tlYRs34trPcODAy0aefh4ZGq75307NlTO3bs0NatW/XJJ5+oYMGCeuyxx2yWAZ05c0Z79uyRp6enzUfBggVlGMYdf0nPbN9//vlH7u7uqd5PVl28eFGGYaT6O5OkUqVKSVKqv5+Mvubp6dSpk4KCgjR37tzkZ3///ffq27ev3N3dJUkBAQHasGGD6tatq1dffVW1atVSqVKlNGHCBFPL7G7XsGFDvfzyy/rmm290+vRpjRo1SsePH09VICKl8+fPpznO0xv7fn5+8vHxsbnm7e2tGzduJL/O7PewWT4+Psk/P1J+lCtXLkv3S4uZnyspnTlzRoZhqGTJkqnG9/bt21N9X6T1fent7W3ztfnnn38yFcdzzz2nK1euJFccnDFjhsqUKaMHH3zQ1HsAYB9U1QPgMHXq1NHq1at16NAhNWrUSF999ZU8PT21fPlym1/QrGexWFkTlJMnT6ps2bJ3fMbdd9+tadOmqXv37nr44Yf1zTff2Ny7WLFiSkhI0IULF2ySp+jo6HTvefuGcus9/vnnH5vkyfhf6fV77703+Zq3t3eae56ymlxZfwmLjo5W6dKlk68nJCSYuuddd92VXPWwadOmqlGjhlq3bq1Ro0Yln7dVvHhx+fr6as6cOWneo3jx4uneP7N977rrLiUmJio6OjrNZMesIkWKyM3NTVFRUak+Zy34cKe4zbDOYn3wwQe6dOmSFi5cqLi4OA0YMMCmXe3atfXVV1/JMAzt2bNH8+bN06RJk+Tr66sxY8ZkOw5PT09NmDBBYWFh2rt3b7rtihUrlmYRkTuN/Yxk9nvYFZn5uZJS8eLFZbFYtGnTJpvy6FZpXctMLJkpFlK5cmV16tRJH330kTp16qTvv/9eoaGhyYk6gJzFjBMAh9m9e7ekf39hsVgs8vDwsPlH//r16/ryyy9t+rVv317u7u76+OOPM/Wc9u3ba/Xq1dq4caMeeOABmypu1vLEtxcJ+OqrrzL9Pqylj1Nu7pak7777TteuXbMpjVy+fHnt2bPHpt369et19erVTD8vJWuFsNvPuPn666+TqwZmRcuWLdW3b1+tWLFC27ZtkyQ98MADOnLkiIoVK5bm//7f6VDQzPa1LmnL6O/29v+hT0+BAgXUuHFjLVmyxKZ9UlKS5s+frzJlytgUwMiuAQMG6MaNG1q0aJHmzZunpk2bqnr16mm2tVgsuueeexQWFqbChQsrIiLC9PPSSggl6cCBA5L+nVVLS+vWrXXlypXk5ZFWZsb+7TL7PeyKzP5csXrggQdkGIZOnTqV5tiuXbu26Vg6deqkQ4cOJS8DvpMRI0Zoz5496tevn9zd3fXkk0+afh4A+2DGCYBd7N27N/kX+fPnz2vJkiUKDw9X9+7dVaFCBUlSly5dNG3aNPXq1UtPPfWUzp8/r6lTp6b6H9vy5cvr1Vdf1eTJk3X9+nU9/vjjCggI0P79+3Xu3DmFhoamen6LFi20bt06dezYUe3bt9fKlSsVEBCgjh07qnnz5nr++ecVExOjBg0aaNu2bfriiy8kpS7pnJaQkBB16NBBL7/8smJiYtS8eXPt2bNHEyZMUL169fTEE08kt33iiSc0btw4jR8/Xq1bt9b+/fs1Y8YMBQQEZOnrWqNGDfXp00fTp0+Xp6en2rVrp71792rq1KnZPoB28uTJWrx4scaNG6e1a9dq5MiR+u6779SqVSuNGjVKderUUVJSkk6cOKE1a9bo+eefV+PGjdO8V2b7tmzZUk888YSmTJmiM2fO6IEHHpC3t7ciIyPl5+en5557TtK/szaLFy9WxYoV5ePjk+4vqG+++aZCQkJ0//3364UXXpCXl5dmzpypvXv3atGiRWmWpM6q6tWrq2nTpnrzzTf1999/6z//+Y/N55cvX66ZM2fqoYceUsWKFWUYhpYsWaJLly4pJCQkuV3btm21YcOGDJPfDh06qEyZMuratauqV6+upKQk7d69W++99578/f3veFBrv379FBYWpj59+mjKlCmqXLmyVq1apdWrV0vK3Ni/XWa/h826fv26tm/fnubn7HVuV1Z+rkhS8+bN9dRTT2nAgAHauXOnWrVqpQIFCigqKkqbN29W7dq19cwzz5iKZeTIkVq8eLEefPBBjRkzRo0aNdL169e1YcMGPfDAA7r//vuT24aEhKhmzZr66aef1KdPH5UoUSJbXwcA2eC8uhQA8oK0quoFBAQYdevWNaZNm2bcuHHDpv2cOXOMatWqGd7e3kbFihWNN99805g9e7YhyTh27JhN2y+++MK49957DR8fH8Pf39+oV6+eTSUwa1W9lPbu3WsEBgYa9evXN/755x/DMAzjwoULxoABA4zChQsbfn5+RkhIiLF9+3ZDkvH+++8n97VW4bL2S+n69evGyy+/bJQrV87w9PQ0goKCjGeeeca4ePGiTbu4uDjjpZdeMsqWLWv4+voarVu3Nnbv3p1uVb3bq9BZK4T99NNPNvd8/vnnjRIlShg+Pj5GkyZNjG3btqW6Z3okGc8++2yan3vxxRcNScaGDRsMwzCMq1evGq+99ppRrVo1w8vLywgICDBq165tjBo1yoiOjk7uV65cOaN///4298ps38TERCMsLMwIDg5Obte0adPkynSGYRjHjx832rdvbxQsWNCQlFzlLK2qeoZhGJs2bTLatGljFChQwPD19TWaNGlicz/DMPc1v5P//Oc/hiTD19fXuHz5ss3n/vjjD+Pxxx83KlWqZPj6+hoBAQFGo0aNjHnz5tm0s1Zfy8jixYuNXr16GVWqVDH8/f0NT09P4+677zaeeOIJY//+/anueXsVuxMnThgPP/yw4e/vbxQsWNDo0aNHciXA//73v8nt+vXrZxQoUCDV82+vTGcYmf8etkdVPUlGfHy8YRjZr6pnldHPldur6qV8340bN04eY5UqVTL69u1rU5kyrZ9J6d3z4sWLxogRI4y7777b8PT0NEqUKGF06dLF+OOPP1L1nzhxoiHJ2L59e6rPAcg5FsNw4Il1AOCiFi5cqN69e2vLli1pFpXAnRUtWlQDBw7U1KlTnR0KTHrjjTf02muv6cSJE6YLJcA5GjZsKIvFoh07djg7FCBfY6kegDxv0aJFOnXqlGrXri03Nzdt375d7777rlq1akXSZNKePXu0cuVKXbx4UU2bNnV2OMiA9TiA6tWrKz4+XuvXr9cHH3ygPn36kDS5uJiYGO3du1fLly/Xrl277ngINICcQeIEIM8rWLCgvvrqK02ZMkXXrl1TUFCQ+vfvrylTpjg7tFxnxIgR+uOPP/TCCy/o4YcfdnY4yICfn5/CwsJ0/PhxxcXF6e6779bLL7+s1157zdmhIQMRERG6//77VaxYMU2YMEEPPfSQs0MC8j2W6gEAAABABihHDgAAAAAZIHECAAAAgAyQOAEAAABABvJdcYikpCSdPn1aBQsWtOuhiAAAAAByF8MwdOXKFZUqVSrDg8HzXeJ0+vRplS1b1tlhAAAAAHARf//9d4bHNOS7xKlgwYKSbn1xChUq5ORopPj4eK1Zs0bt27eXp6ens8NBLsCYgRmMF5jFmIFZjBmY5UpjJiYmRmXLlk3OEe4k3yVO1uV5hQoVcpnEyc/PT4UKFXL6wEHuwJiBGYwXmMWYgVmMGZjlimMmM1t4KA4BAAAAABkgcQIAAACADJA4AQAAAEAGSJwAAAAAIAMkTgAAAACQARInAAAAAMgAiRMAAAAAZIDECQAAAAAyQOIEAAAAABkgcQIAAACADJA4AQAAAEAGSJwAAAAAIAMkTgAAAACQAQ9nB5CflR+z4n9/ctOIbWskSdvHtFVgYR/nBQUAAAAgFafOOG3cuFFdu3ZVqVKlZLFYtGzZsgz7bNiwQQ0aNJCPj48qVqyoWbNmOT5QB/g3aZJS/jU0eWudyo9ZoVeW/KbrNxNzPjAAAAAAqTg1cbp27ZruuecezZgxI1Ptjx07ps6dO6tly5aKjIzUq6++quHDh+u7775zcKT2ZZs0pW3RrydVY/yPav3uem05fE6JSUYORAYAAAAgLU5dqtepUyd16tQp0+1nzZqlu+++W9OnT5ck1ahRQzt37tTUqVPVo0cPB0VpX5lJmlL66/x19Z79izzdLWpTvYT6NimvJpWKyd3N4qAIAQAAANwuV+1x2rZtm9q3b29zrUOHDpo9e7bi4+Pl6emZqk9cXJzi4uKSX8fExEiS4uPjFR8f79iA7Sg+0dDqfWe0et8ZebpbdH+14urT6G41qlCUJCqfsY7b3DR+4TyMF5jFmIFZjBmY5UpjxkwMuSpxio6OVsmSJW2ulSxZUgkJCTp37pyCgoJS9XnzzTcVGhqa6vqaNWvk5+fnsFjT56bsrpCMTzS0Zv8/WrP/H7lbDNUqnKQWgVKVAEPkUPlHeHi4s0NALsJ4gVmMGZjFmIFZrjBmYmNjM902VyVOkmSx2GYGhmGked3qlVde0ejRo5Nfx8TEqGzZsmrfvr0KFSrkuEDTYa2eZy+JhkV7Lrprz0XJx9NNjzYsrZAaJdWwXBFmovKo+Ph4hYeHKyQkJM1ZViAlxgvMYszALMYMzHKlMWNdjZYZuSpxCgwMVHR0tM21s2fPysPDQ8WKFUuzj7e3t7y9vVNd9/T0dPpflL3diE/S59v+1ufb/lZBHw89Ur+02tcKYjlfHpUXxzAch/ECsxgzMIsxA7NcYcyYeX6uOgC3adOmqab01qxZo4YNGzr9i55Zx9/qkiPPuXIjQXO3/qXHP92uupPWKPT7vdp25DzV+QAAAIAscGridPXqVe3evVu7d++WdKvc+O7du3XixAlJt5bZ9e3bN7n9kCFD9Ndff2n06NE6cOCA5syZo9mzZ+uFF15wRvhZllPJkxVJFAAAAJA9Tk2cdu7cqXr16qlevXqSpNGjR6tevXoaP368JCkqKio5iZKkChUqaOXKlfr5559Vt25dTZ48WR988EGuKUWeUk4nT1Ypk6gGk8P1/trDJFAAAABABpy6x+m+++5LLu6Qlnnz5qW61rp1a0VERDgwqpxz/K0uunY9Ti/PWa3IKwV0JuaGEpJy7vmXrscrbO0hfbLxiDoHB6p55eIKDPBlTxQAAABwm1xVHCIv8vJwU0gZQ2GdW8nT01M3E5L0ypLf9N/I00rIoYmg2JuJ+jbilL6NOCVJKuzrqQHNK2hYm8okUAAAAIBInFyOl4eb3utZT+88Ulfbj57X1iPn9OuxC4r862KOJVLMRAEAAAC2SJxclLubRc0rF1fzysUlSYlJhrYfPa8vtx3XugNnFJ8DS/qYiQIAAABuIXHKJVImUimTqJ8P/aMbOZFFyXYm6qmWFXVv+aI6dy1OJQr6MBsFAACAPI3EKRe6PYn69dgFrdkXpW8jTurKjUSHPz/2ZqKmrztsc43ZKAAAAORlJE65nLubRU0rFVPTSsX02gO1cjyJsko5G/V0q0okUAAAAMhTSJzyEFdIomJvJips7SF9uumoejYso5CagSzjAwAAQK5H4pRHpZVERcfc0JbD/2jF71G67uB9UVfjEjRny3HN2XKcZXwAAADI9dycHQAcz5pEda9XWlN71tXe0I4a1a6KCvt65sjzrcv4ak9crffXHlZiUg7VVQcAAADshBmnfMjdzaIR7apqWJsqOToTxTI+AAAA5FYkTvmYdSZKkrrXK623H7lHM9Yf1twtx3XperzDnnv7Mr7+zcpT2hwAAAAujcQJyZwxE3XpejylzQEAAODySJyQirNmoqyse6JY0gcAAABXQeKEDN0+E3X2yg0V9/fWr8fO69NNxxR70zGlzlMu6StawEsP1S1FEgUAAACnIHFCpqWciZKk5pWLa3jbqjkyG3Xh2k3KmwMAAMBpKEeObLHORu0aF6JFTzbRoOblVcDb3aHPtC7lazAlXD/ujXLoswAAAACJxAl2Yp2NGte1lvZM6KBR7arIz8vBCVRsvIbMj+BsKAAAADgciRPszjoL9fvEDjly0G7Y2kNqOCVck37Yp21HzpNEAQAAwO7Y4wSHub2oxNr90fpq59+6Fmf/YhIXY+PZAwUAAACHIXGCw1mX8TWtVEyvdqnp8GIS1j1Qc7cc04DmFVS+uB8H6wIAACBbSJyQo+5U2vzzrX/ZNZmyJlBWlDQHAABAVpE4wSnSK21uXdK3dPcpXbhm3xmplCXNSaIAAABgBokTXMbtS/ocuS+KJAoAAABmkDjBJaW1L2rOluO67IB9USRRAAAAyAiJE1xeyn1RM9YfVtjaww57FkkUAAAA0kLihFzDmkBVCyyo0B/2K+ryDYc+jyQKAAAAViROyHU6BgcppGagw8+GSillEhVYyEePN7qbMucAAAD5CIkTcqWcPhsqpeiYG5Q5BwAAyGdInJDrpXU21PFz17To1xOKjolz+PNZ0gcAAJD3kTghz7j9bChrIuWoc6HSkjKJCgrw0YSuNdUxOMjhzwUAAIBjuTk7AMBRrInUuK61tGNsiBY92USDmpdX0QKeOfL8qMs3NGR+hN5fe1iJSUaOPBMAAACOwYwT8oX0DtfNiZmosLWHNG/rMXWvV5olfAAAALkUiRPyHWckURdj49kHBQAAkIuROCFfc0YSRWlzAACA3IfECfgfZyRRt5c2p6AEAACAayJxAtKQVhKVE2XOrQUlRrWrqmFtKjP7BAAA4CJInIAMOKPMedjaQ1r4y1/q1bgcy/gAAABcAIkTYFJ6S/qWRJ7SxVj7JVFnrsTZLOOzFpVoU624qG4OAACQs0icgGy4PYmasf6wwtYedsizUhaV8Pdw12+WP9QhuBQzUQAAADmAA3ABO3F3s2hEu6qa1ae+ggJ8HPqsqwkWzdt2Qo9/ul0t3l6vH/dGOfR5AAAA+R2JE2BnHYODtPnlNlr0ZBMNal5eRQt4OvR51oIS7689rETW8AEAADgES/UAB3BGaXMKSgAAADgOiRPgYHcqbb7wlxM6c8V+pc3TKygRUjOQJAoAACAbSJyAHJRWafOcKigRWMhHjze6m9koAACALCBxApzIWlCiWmBBhf6wX1GXbzjsWdExN2xmo4ICfDSha011DA5y2DMBAADyChInwAV0DA5SSM1Am2V8i349oegY+y3ju130/4pKDGxenqV8AAAAGSBxAlxEWsv4HFlUwlp/z7qUj/1QAAAA6SNxAlxUepX5lkSe0sVY+1fmYz8UAABA+kicgFwgZRL1YvsqGvXpj1p10t1hz0trP9S4LjVVpICXzl65QTIFAADyHRInIJdxd7OoY1lDXVrco9dXHXRoQQmrqMs3NHRhhM01iksAAID8hMQJyKU61CqpTnVK52hBiZSi/ldcYlS7qhrWpjKzTwAAIE8jcQJysZwuKJGWsLWHNG/rMXWvV5rCEgAAIM8icQLykLQKSuTEbNTF2HgKSwAAgDyNxAnIo+40GzV7y3GHPZeDdgEAQF7k5uwAAOQMayI1rmstzepTX0EBPjnyXOteqPfXHlZikpFxBwAAABfEjBOQD3UMDlJIzcAc3Q8VtvaQFv7yl3o1LscyPgAAkOuQOAH5lDP2Q525EmezjK9oAS89VLcURSUAAIDLI3ECkO5+KOthtxevxWnS8gOKjrHvmVEXrt1MLirBXigAAODKSJwApHJ7IiVJHYKDNGP9YYWtPeyQZ1r3Qg1sXp4ZKAAA4HJInABkirubRSPaVVW1wIIK/WG/oi7bd/bJyjoDxTI+AADgSkicAJiSU4UlUi7jI4kCAADORuIEwLQ7FZZY+MsJnbli38ISJFEAAMDZSJwAZEtahSUcuReKghIAAMAZOAAXgF1Z90LlxCG7HK4LAAByCjNOABwi5V4oR58PFbb2kOZtPabu9UqzhA8AADgEiRMAh0nvfChHFJW4GBvPPigAAOAwJE4AckxaRSXW7o/W7C3H7foc9kEBAAB7Y48TAKewJlHjutZy6H4o9kEBAAB7YMYJgNPlxNlQ7IMCAADZQeIEwCWkt4zPnkkU+6AAAEBWkTgBcDnpJVFLIk/pYqx9kigO1QUAAGaQOAFwabcnUY44XJckCgAAZITiEAByjZw4XNeaRD3+6Xa1eHu9ftwb5ZDnAACA3MXpidPMmTNVoUIF+fj4qEGDBtq0adMd2y9YsED33HOP/Pz8FBQUpAEDBuj8+fM5FC0AV9AxOEibX26jRU820aDm5VW0gKdDnkNFPgAAYOXUxGnx4sUaOXKkxo4dq8jISLVs2VKdOnXSiRMn0my/efNm9e3bV4MGDdK+ffv0zTffaMeOHRo8eHAORw7A2VKWM98xNiQ5iSriZ/8kKmztITWcEq5JP+zTtiPnSaIAAMiHnJo4TZs2TYMGDdLgwYNVo0YNTZ8+XWXLltXHH3+cZvvt27erfPnyGj58uCpUqKAWLVro6aef1s6dO3M4cgCuJGUStfO1EI1qV8Xuz7BW5Hv80+1qMDmcWSgAAPIZpxWHuHnzpnbt2qUxY8bYXG/fvr22bt2aZp9mzZpp7NixWrlypTp16qSzZ8/q22+/VZcuXdJ9TlxcnOLi4pJfx8TESJLi4+MVH2/fc2KywhqDK8SC3IExk7GhrSuoUnE/TVn5h6Jj4jLuYNKl6/EKW3tIn248okcalFa7GiXUsFwRlywkwXiBWYwZmMWYgVmuNGbMxGAxDMMp/2V6+vRplS5dWlu2bFGzZs2Sr7/xxhv6/PPPdfDgwTT7ffvttxowYIBu3LihhIQEdevWTd9++608PdNenjNx4kSFhoamur5w4UL5+fnZ580AcElJhnQkxqLfL1i085xF1xIcl9gU9jL0cPkk3VOMWSgAAHKL2NhY9erVS5cvX1ahQoXu2Nbp5cgtFttfZAzDSHXNav/+/Ro+fLjGjx+vDh06KCoqSi+++KKGDBmi2bNnp9nnlVde0ejRo5Nfx8TEqGzZsmrfvn2GX5ycEB8fr/DwcIWEhKSb/AEpMWayJjHJ0M6/LmrtgbP6729RdjsPyurSTYvmHHLXB4/WUafgQLveOzsYLzCLMQOzGDMwy5XGjHU1WmY4LXEqXry43N3dFR0dbXP97NmzKlmyZJp93nzzTTVv3lwvvviiJKlOnToqUKCAWrZsqSlTpigoKChVH29vb3l7e6e67unp6fS/qJRcLR64PsaMOZ6SWlQtqRZVS2pc1+DkQ3WX7j6lC9fsl0SN+HqPIv6+rA61glzqHCjGC8xizMAsxgzMcoUxY+b5TisO4eXlpQYNGig8PNzmenh4uM3SvZRiY2Pl5mYbsru7u6RbM1UAkBmOrMhnGNK8rX9RRAIAgDzGqVX1Ro8erc8++0xz5szRgQMHNGrUKJ04cUJDhgyRdGuZXd++fZPbd+3aVUuWLNHHH3+so0ePasuWLRo+fLgaNWqkUqVKOettAMjFHFmRz1pE4p7QNZQyBwAgl3PqHqdHH31U58+f16RJkxQVFaXg4GCtXLlS5cqVkyRFRUXZnOnUv39/XblyRTNmzNDzzz+vwoULq02bNnr77bed9RYA5CHubhaNaFdV1QILKvSH/Yq6fMMu970al6A5W45rzpbjKlrASw/VLaWQmoEutZQPAADcmdOLQwwdOlRDhw5N83Pz5s1Lde25557Tc8895+CoAORnHYODFFIzMHkf1Fc7/9a1uES73PvCtZvJSVRQgI8mdK2pjsGp92cCAADX4tSlegDgqlIu4dszoYNGtauiwr723cAadfmGhsyP0Mo9UXa9LwAAsD8SJwDIgHUJ365xtwpJDGhWXvZcYPfsoghN/H4ve6AAAHBhTl+qBwC5hXUWqmmlYrq3fBENXRhpl/taK/HN2/oXe6AAAHBRzDgBQBZ0rlNKs/rUV1CAj13va90DRTlzAABcCzNOAJBFjiwiIf1bzvzTTUfVs2EZZqEAAHAiZpwAIBtyooiEtZz5459uV4u31+vHvRSTAAAgp5E4AYCd3F5EYlDz8ipawDGV+FjCBwBAzmKpHgDYWcoiEq92qalfj13Qmn3Rmrf1uOyV6oStPaQ5m49qYIuKGtamMsv3AABwMBInAHAgR1Xik6TLNxLYAwUAQA5hqR4A5BBHVeJLuQeKSnwAADgGM04AkINur8S3dPcpXbgWb7f7316Jr0214iKHAgAg+0icACCHpbUHyt7lzK2zUHO2HJe/h7t+s/yhDsGlWMoHAEAWkTgBgBPdnkTNWH9Yc7cc16Xr9puFuppg0bxtJzRv2wkV9vXUgOYVKCgBAIBJ7HECABeRVjnzIn72LWduXcrXYEo450EBAGACiRMAuJiUh+rufC1Eo9pVsfszLsXGa8j8CE36YZ+2HTlPMQkAADLAUj0AcGHWWahqgQU1ZsnvuhRrvyV8kpL3QbGEDwCAO2PGCQBygY7BQdr1v9mnwr72Xb4n/buEr/bE1ZQzBwAgDcw4AUAuYZ19GtamikMq8UlS7M1EDtUFACANzDgBQC6Tcg/UngkdHDILlfJQ3RZvr6eQBAAg3yNxAoBcLK1KfEUL2DeJirp8Q0PmR7CEDwCQr7FUDwDygHQP1d3xt67dtM9SvrC1hzRv6zF1r1eaJXwAgHyHGScAyGNSLuXbNbaNOpVJVICvff6f7GJsPEv4AAD5EokTAORh7m4WdSxr6Jcx9ycv5bMX6xI+zoICAOQHLNUDgHwg5VK+eysUteuZUNazoIoW8NJDdUuxjA8AkCcx4wQA+UzKM6H8vNztdt8L126yjA8AkGeROAFAPmStxvf7RMeUM6cSHwAgr2GpHgDkY2kdqrsk8pQu2mkZH5X4AAB5BTNOAACbSnw7/7eMz16oxAcAyAtInAAANqyzULP61FdQgI9d700lPgBAbsVSPQBAmjoGBymkZmDyEr6lu0/pwjUq8QEA8icSJwBAulKWMX+1S83kJGr2luN2ub+1Et+cLccVFOCjCV1rqmNwkF3uDQCAPbFUDwCQKSn3QTlyGR+V+AAArojECQBgWsfgIG1+uY0WPdlEg5qXVxE/+5UzD1t7SM3fWkcRCQCASyFxAgBkiSMr8UXHxFFEAgDgUkicAADZ5qhKfJQxBwC4CopDAADsxlGV+KL/t/9pYPPyVOADADgFiRMAwK4cUYnPulCPCnwAAGdhqR4AwGEcVYmPCnwAgJzGjBMAIEfcvoxvSeQpXYzN3jK+sLWHtPCXv9SrcTmVL+6nEgV9WMYHAHAIEicAQI65fRnfjPWHFbb2cLbueeZKnMLWHkp+zTI+AIAjsFQPAOAUjqrEF335hp6ZH0EVPgCAXTHjBABwqtuX8GWniIT0byGJMUt+V0FvTzWpVIylewCAbGPGCQDgdI4oInEpNl69Z//CGVAAALtgxgkA4FLsPQPFGVAAAHsgcQIAuJyURSTurVBUE7/fr+iYG1m6F2dAAQDswfRSvWvXrmncuHFq1qyZKleurIoVK9p8AABgTx2Dg7RlTBuNalfFLvejeAQAICtMzzgNHjxYGzZs0BNPPKGgoCBZLCx3AAA4lrUCX7XAggr9Yb+iLmdt9km6NQNlkTR26V5dv5mowABflu8BADJkOnFatWqVVqxYoebNmzsiHgAA0pVy/9PZKzd0/Nw1Lfr1hKJj4kzdx5B0/tpNjfr6N0mc/QQAyJjpxKlIkSIqWrSoI2IBACBD1v1PVsPaVNH2o+f17IIIXboen6V7WpfvfdynPskTACBNpvc4TZ48WePHj1dsbKwj4gEAwBR3N4uaVy6ut3rUlkW3luGZZS0gMXbpXi2NOKltR84rMcm4Yx8AQP5iesbpvffe05EjR1SyZEmVL19enp6eNp+PiIiwW3AAAGRWx+Agfdynfpb3QLF8DwBwJ6YTp4ceesgBYQAAkH32PAOK5XsAgJRMJ04TJkxwRBwAANjF7WdAZWcGyiIp9If9KujtqXPX4lSioA8V+AAgn8ryAbi7du3SgQMHZLFYVLNmTdWrV8+ecQEAkG0pZ6CiY25o8vJ9unAt8wUkDElRl2+o9+xfkq+xhA8A8ifTidPZs2f12GOP6eeff1bhwoVlGIYuX76s+++/X1999ZXuuusuR8QJAECWpKzC5+vppmfm39qLm9XSDyzhA4D8yXRVveeee04xMTHat2+fLly4oIsXL2rv3r2KiYnR8OHDHREjAAB2YS0gERjgk+V7WBOu0B/262ZCkrYdOa//7j5FJT4AyONMzzj9+OOPWrt2rWrUqJF8rWbNmvroo4/Uvn17uwYHAIC9ZXf5nvTvEr4mb6616csyPgDIu0zPOCUlJaUqQS5Jnp6eSkpKsktQAAA4knX5Xvd6pfVG96yf/3R7wmVdxvfj3ii7xAkAcB2mE6c2bdpoxIgROn36dPK1U6dOadSoUWrbtq1dgwMAwNHssXzPimV8AJB3mV6qN2PGDD344IMqX768ypYtK4vFohMnTqh27dqaP3++I2IEAMChUi7fO3vlhor7e+v5r3frTEyc6SISLOMDgLzJdOJUtmxZRUREKDw8XH/88YcMw1DNmjXVrl07R8QHAECOSFl9T5ImdqulZ+ZHyKKsVeBLbxkf1fgAIHfK8jlOISEhCgkJsWcsAAC4DOsSvtsP0C1WwEvnr900fb+UB+qG1AzkEF0AyGUylTh98MEHeuqpp+Tj46MPPvjgjm0pSQ4AyCtuX8JXoqCPGpQrotbv/qToyzeyvIzv12MXbGa3AACuL1OJU1hYmHr37i0fHx+FhYWl285isZA4AQDylNuX8EnShK41s7WM7+yVG0pMMmwSskYVijILBQAuLFOJ07Fjx9L8MwAA+VF2l/Edir6iFqvW2/SleAQAuDbT5cgnTZqk2NjYVNevX7+uSZMm2SUoAABcXcfgIG1+uY0WPdlE7z9WV4uebKJtr7RVUIBPhmdCffTzEZukSeIMKABwdaYTp9DQUF29ejXV9djYWIWGhtolKAAAcgPrMr4H65ZW00rF5OXhpglda0pKfaCu9XV6q/FSngHFmU8A4HpMJ06GYchiSf1T/7ffflPRokXtEhQAALlVegfqBgb4aFS7qrpTTpSyeERiksEBugDgQjJdjrxIkSKyWCyyWCyqWrWqTfKUmJioq1evasiQIQ4JEgCA3CStanyNKhTV8j2nM9V/7f5ojf56N3ugAMCFZDpxmj59ugzD0MCBAxUaGqqAgIDkz3l5eal8+fJq2rSpQ4IEACC3SasaX4mCPum0tjV7y/FU1zhAFwCcK9OJU79+/SRJFSpUUPPmzeXhkeWzcwEAyJcaVSiqoACfLJ8BxQG6AOA8pvc4Xbt2TevWrUt1ffXq1Vq1apVdggIAIC9yd7NkWDziTlLugQIA5CzTidOYMWOUmJiY6rphGBozZoxdggIAIK+6U/GIgc3LZ+oe1gN0KR4BADnH9Hq7w4cPq2bNmqmuV69eXX/++afpAGbOnKl3331XUVFRqlWrlqZPn66WLVum2z4uLk6TJk3S/PnzFR0drTJlymjs2LEaOHCg6WcDAOAM6RWP+PXYBc1JY3/T7Y6fu6YWb3OALgDkJNOJU0BAgI4ePary5cvbXP/zzz9VoEABU/davHixRo4cqZkzZ6p58+b65JNP1KlTJ+3fv1933313mn169uypM2fOaPbs2apcubLOnj2rhIQEs28DAACnSqt4RGb3QIWtPZzqGsUjAMCxTC/V69atm0aOHKkjR44kX/vzzz/1/PPPq1u3bqbuNW3aNA0aNEiDBw9WjRo1NH36dJUtW1Yff/xxmu1//PFHbdiwQStXrlS7du1Uvnx5NWrUSM2aNTP7NgAAcDl32gOVEQ7QBQDHMj3j9O6776pjx46qXr26ypQpI0k6efKkWrZsqalTp2b6Pjdv3tSuXbtS7Ytq3769tm7dmmaf77//Xg0bNtQ777yjL7/8UgUKFFC3bt00efJk+fr6ptknLi5OcXFxya9jYmIkSfHx8YqPj890vI5ijcEVYkHuwJiBGYyX3KdtteL68LF7NGXlH4qO+fffr6AAb/VsUEbvrz+Sbl9r8YjNh87I3c2is1fiVKKgtxqWK5LpKnyMGZjFmIFZrjRmzMSQpaV6W7duVXh4uH777Tf5+vqqTp06atWqlan7nDt3TomJiSpZsqTN9ZIlSyo6OjrNPkePHtXmzZvl4+OjpUuX6ty5cxo6dKguXLigOXPmpNnnzTffVGhoaKrra9askZ+fn6mYHSk8PNzZISCXYczADMZL7vNyTelIjEUx8VIhT6lSoWuK/PuQJPcM+z7z5U7FJv6bKBX2MvRw+STdUyzzM1GMGZjFmIFZrjBmYmNjM93WYhhGlufzb9y4IW9vb1ks5s+SOH36tEqXLq2tW7faHJz7+uuv68svv9Qff/yRqk/79u21adMmRUdHJx/Au2TJEj3yyCO6du1amrNOac04lS1bVufOnVOhQoVMx21v8fHxCg8PV0hIiDw9PZ0dDnIBxgzMYLzkLb8cu6A+c3aa7mf9V/rDx+5Rh1ol79iWMQOzGDMwy5XGTExMjIoXL67Lly9nmBuYnnFKSkrS66+/rlmzZunMmTM6dOiQKlasqHHjxql8+fIaNGhQpu5TvHhxubu7p5pdOnv2bKpZKKugoCCVLl06OWmSpBo1asgwDJ08eVJVqlRJ1cfb21ve3t6prnt6ejr9LyolV4sHro8xAzMYL3lD08olsnSArvXw3NdXHVSnOqUztWyPMQOzGDMwyxXGjJnnmy4OMWXKFM2bN0/vvPOOvLy8kq/Xrl1bn332Wabv4+XlpQYNGqSaogsPD0+32EPz5s11+vRpXb16NfnaoUOH5ObmlrzfCgCAvCq7xSM4PBcAss504vTFF1/oP//5j3r37i1393/XWdepUyfN5XV3Mnr0aH322WeaM2eODhw4oFGjRunEiRMaMmSIJOmVV15R3759k9v36tVLxYoV04ABA7R//35t3LhRL774ogYOHJhucQgAAPKS9A7QLeyXuf81PXvl1tlPHKALAOaYXqp36tQpVa5cOdX1pKQk05UxHn30UZ0/f16TJk1SVFSUgoODtXLlSpUrV06SFBUVpRMnTiS39/f3V3h4uJ577jk1bNhQxYoVU8+ePTVlyhSzbwMAgFwrrQN0k5IM9Z79S4Z9vdzd9OPeKIX+sD/NA3TbVivuyNABINcynTjVqlVLmzZtSk5urL755hvVq1fPdABDhw7V0KFD0/zcvHnzUl2rXr26S1TgAADAmW4/QDcxycjU/qdhCyOUmEYD6wG6Hz52j/2DBYA8wHTiNGHCBD3xxBM6deqUkpKStGTJEh08eFBffPGFli9f7ogYAQBABqz7n56ZHyGLZJM8WV9XLO6no+fSLr37bwGJP/RSDYeHCwC5juk9Tl27dtXixYu1cuVKWSwWjR8/XgcOHNAPP/ygkJAQR8QIAAAyIb39T4EBPprVp75e717njv1vFZCI05EYC3ugAOA2pmecJKlDhw7q0KGDvWMBAADZlNb+p0YVisrdzaL/7j6VqXv8fsGi+97bqOiYf89BtO6B6hgc5KjQAcClZSlxAgAAruv2/U9WJQr6pNE6tQ3RFklxNtese6A+7lOf5AlAvpSppXpFixbVuXPnJElFihRR0aJF0/24++671alTJ+3Zs8ehgQMAAHMaVSiqoACfTJwBlbqFdaFe6A/7WbYHIF/K1IxTWFiYChYsKEmaPn36HdvGxcVp5cqVGjBggHbt2pXtAAEAgH1kpoDEnVgP0d1+9LzcLJZUSwEBIC/LVOLUr1+/NP+cnk6dOqlBgwZZjwoAADiEtYDE7ec4BQb4qFNwoOZsOZ7hPZ5dEKFL1/89u5H9TwDygyztcbp06ZK+/fZbHTlyRC+++KKKFi2qiIgIlSxZUqVLl1bZsmV19uxZe8cKAADsIL0CEr8eu5CpxCll0iSx/wlA/mA6cdqzZ4/atWungIAAHT9+XE8++aSKFi2qpUuX6q+//tIXX3zhiDgBAIAdpVVAolGFogos5K3omBtKa59TeqxnQIX+sF8hNQNZtgcgTzJ9jtPo0aPVv39/HT58WD4+/1bn6dSpkzZu3GjX4AAAQM5xd7Potc7VJZlJm25Juf+J858A5EWmZ5x27NihTz75JNX10qVLKzo62i5BAQAA5+hQq6QGVk3Symg/m3OcCvt56lJs/B163sL+JwB5lenEycfHRzExMamuHzx4UHfddZddggIAAM5zTzFDL/VupciTV5L3QCUlGeo9+5cM+7L/CUBeZXqp3oMPPqhJkyYpPv7WD0aLxaITJ05ozJgx6tGjh90DBAAAOc+6B+rBuqXVtFIxNalULJNnQNni/CcAeYXpxGnq1Kn6559/VKJECV2/fl2tW7dW5cqV5e/vr9dff90RMQIAACezngElZX3/06/HLtg9LgDIKaaX6hUqVEibN2/W+vXrFRERoaSkJNWvX1/t2rVzRHwAAMBFpHcGVGb3P0XH3NC2I+c5OBdArpSlc5wkqU2bNmrTpk3y64iICI0fP17Lly+3S2AAAMD1pHUGVGb3P01evk8XrlE4AkDuZGqpXnh4uF588UW9+uqrOnr0qCTpjz/+0EMPPaR7771XCQkJDgkSAAC4jqzuf0qZNEn/Fo74cW+U44IFADvJdOL0+eefq0OHDpo7d67eeustNWnSRPPnz1ejRo1UpEgR/fbbb/rxxx8dGSsAAHBBWd3/ROEIALlJphOnsLAwvfHGGzp37py++uornTt3TmFhYYqMjNTcuXMVHBzsyDgBAIALs+5/CgzwsblerIDXHftZC0fM23KMQ3MBuLRM73E6cuSIHn30UUnSI488Ind3d02bNk2VKlVyWHAAACD3SGv/U/Tl6xr19W8Z9p284kDyn9n7BMAVZXrG6dq1aypQoMCtTm5u8vHxUdmyZR0WGAAAyH1u3/8UGOBr+h7sfQLgikxV1Vu9erUCAgIkSUlJSVq3bp327t1r06Zbt272iw4AAORqjSoUVVCAj6Iv31BmF+AZurVXKvSH/QqpGUjJcgAuwVTi1K9fP5vXTz/9tM1ri8WixMTE7EcFAADyBGvhiGfmR8gimUqeoi7f0Paj5+VmsXD2EwCny3TilJSU5Mg4AABAHpXewbmZ8eyCCF26ztlPAJwvywfgAgAAZNbthSPOXYmzKQiRnpRJk/Tv/qeP+9QneQKQo0icAABAjrAWjpCkxCRDn20+Zmrvk/Tv/qexS/fq+s1EBQb4snwPQI7IdFU9AAAAe8nqobnSreTp/LWbGvX1b3r80+1q8fZ6KvABcDgSJwAA4BTpHZpb2M/T1H0oXw4gJ7BUDwAAOE1ah+YmJRnqPfuXTN+D8uUAcgKJEwAAcKqUe5+kW/ufsnL2U9TlG5q35ZiKF/SmdDkAu8tU4lSkSBFZLJn7wXPhwoVsBQQAAPK3rJ79JMmmUh+lywHYU6YSp+nTpyf/+fz585oyZYo6dOigpk2bSpK2bdum1atXa9y4cQ4JEgAA5C/ZOfvJitLlAOwpU4lTv379kv/co0cPTZo0ScOGDUu+Nnz4cM2YMUNr167VqFGj7B8lAADId1Luf4qOuaHJy/fpwrX4jDv+T8q9TwW9PXXuWhxL+ABkmek9TqtXr9bbb7+d6nqHDh00ZswYuwQFAAAg2e5/8vV00zPzIyRlfvmede9TymITLOEDkBWmy5EXK1ZMS5cuTXV92bJlKlasWBo9AAAAsi+98uVmUb4cQFaYnnEKDQ3VoEGD9PPPPyfvcdq+fbt+/PFHffbZZ3YPEAAAwOr28uXnrsTZFITIDOts1Zglv6ugt6eaVCrG0j0AGTKdOPXv3181atTQBx98oCVLlsgwDNWsWVNbtmxR48aNHREjAABAspTL9xKTDH22+Zip0uVWl2Lj1Xv2LyzdA5ApWTrHqXHjxlqwYIG9YwEAADAlO6XLrai+ByAzspQ4JSUl6c8//9TZs2eVlJRk87lWrVrZJTAAAIDMyG7pcmv1vbFL9+r6zUQFBvhSeQ9AKqYTp+3bt6tXr17666+/ZBi2/69jsViUmJhot+AAAAAy4/a9T8X9vfX817t1JiYuU7NQhqTz125q1Ne/SaLyHoDUTFfVGzJkiBo2bKi9e/fqwoULunjxYvLHhQsXHBEjAABAhqx7nx6sW1rNKxfXxG61JN2aTTKLynsAbmd6xunw4cP69ttvVblyZUfEAwAAYBfZWcLH8j0AtzOdODVu3Fh//vkniRMAAHB51iV824+e17MLInTpenym+7J8D0BKphOn5557Ts8//7yio6NVu3ZteXp62ny+Tp06dgsOAAAgu9zdLGpeubje6lFbz8yPkJS96nsj21VV+eJ+KlHQh1koIB8xnTj16NFDkjRw4MDkaxaLRYZhUBwCAAC4LHtU35OksLWHkq8xCwXkH6YTp2PHjjkiDgAAAIdLWX0vOuaGJi/fpwvXMr9873acAQXkH6YTp3LlyjkiDgAAgBxhrb4nSb6ebtlavkcRCSD/MJ04ffHFF3f8fN++fbMcDAAAQE7K7vI9iSISQH5hOnEaMWKEzev4+HjFxsbKy8tLfn5+JE4AACBXcdTyPYpIAHmL6cTp4sWLqa4dPnxYzzzzjF588UW7BAUAAJCT7L18T6KIBJDXuNnjJlWqVNFbb72VajYKAAAgt7Eu3wsM8LHbPaMv39CQ+RGa9MM+bTtyXolJWUnJADiT6Rmn9Li7u+v06dP2uh0AAIDTpFy+d/bKDR0/d01haw/LouzNQs3ZclxzthxnBgrIhUwnTt9//73Na8MwFBUVpRkzZqh58+Z2CwwAAMCZUi7fk6RqgQWzVUQiJesM1MDm5RVSM5A9UEAuYDpxeuihh2xeWywW3XXXXWrTpo3ee+89e8UFAADgUuxZRIIZKCD3MZ04JSUlOSIOAAAAl2fPIhIpcZAu4PqyVRzCMAwZBpsbAQBA/mPPIhLG/z7GLPldWw6fo3gE4IKylDh98cUXql27tnx9feXr66s6deroyy+/tHdsAAAALq1jcJA2v9xGi55sovcfq6tR7apIkrK6W+lSbLx6z/5FLd5erx/3RtkvUADZZnqp3rRp0zRu3DgNGzZMzZs3l2EY2rJli4YMGaJz585p1KhRjogTAADAJTmiiATFIwDXYzpx+vDDD/Xxxx+rb9++ydcefPBB1apVSxMnTiRxAgAA+VrKIhJr90dr9pbjpu9B8QjA9ZheqhcVFaVmzZqlut6sWTNFRTGlDAAAYJ2FGte1lmb1qa+gbO6DivrfDNT7aw+z/wlwEtOJU+XKlfX111+nur548WJVqVLFLkEBAADkFSn3QQ1qXj5b9wpbe0jN31rH/ifACUwv1QsNDdWjjz6qjRs3qnnz5rJYLNq8ebPWrVuXZkIFAACQ31lnoJpWKqZ7KxTN1h6o6Jg4DZkfoVHtqmpYm8rsfQJyiOkZpx49eujXX39V8eLFtWzZMi1ZskTFixfXr7/+qu7duzsiRgAAgDzDOgO1YHBjFfb1zPJ9mH0CcpapGaf4+Hg99dRTGjdunObPn++omAAAAPI0dzeLmlcurrd61M7WIbrW2Seq7wGOZ2rGydPTU0uXLnVULAAAAPmKvQ7RnbPluB7/dDvnPwEOZHqpXvfu3bVs2TIHhAIAAJD/2LN4BNX3AMcxXRyicuXKmjx5srZu3aoGDRqoQIECNp8fPny43YIDAADID24vHjHx+/2Kjsn6Abphaw9p0a9/aWK3Wpz9BNiJ6cTps88+U+HChbVr1y7t2rXL5nMWi4XECQAAIBusB+jOWH9YYWsPZ/k+1v1PM3vVV+c6JE9AdplOnI4dO+aIOAAAAPA/7m4WjWhXVdUCC2Z79mnYogg9d6aKKt5VQCUK+lBAAsgi04kTAAAAcoY9Zp+SDOn9df/2DQrw0YSuNVnCB5hkOnEaPXp0mtctFot8fHxUuXJlPfjggypatGi2gwMAAMjvUs4+ZefgXCtrAQmW8AHmmE6cIiMjFRERocTERFWrVk2GYejw4cNyd3dX9erVNXPmTD3//PPavHmzatas6YiYAQAA8h3r7NOvxy5o7f5ozd5yPFv3e3ZhhIafqaLhbauwdA/IBNPlyB988EG1a9dOp0+f1q5duxQREaFTp04pJCREjz/+uE6dOqVWrVpp1KhRjogXAAAg37JW3xvXtZZm9amvwEJZP//J0K0lfPeErtGkH/Zp25HzlDAH7sB04vTuu+9q8uTJKlSoUPK1QoUKaeLEiXrnnXfk5+en8ePHp6q4l56ZM2eqQoUK8vHxUYMGDbRp06ZM9duyZYs8PDxUt25ds28BAAAg1+sYHKQtY9poVLsq2brP1bgEDtAFMsF04nT58mWdPXs21fV//vlHMTExkqTChQvr5s2bGd5r8eLFGjlypMaOHavIyEi1bNlSnTp10okTJzKMoW/fvmrbtq3Z8AEAAPIM6/6nmb3qyx6r7ThAF0hflpbqDRw4UEuXLtXJkyd16tQpLV26VIMGDdJDDz0kSfr1119VtWrVDO81bdo0DRo0SIMHD1aNGjU0ffp0lS1bVh9//PEd+z399NPq1auXmjZtajZ8AACAPKdznSDNeLye3e4XtvaQ6k9aQwIFpGC6OMQnn3yiUaNG6bHHHlNCQsKtm3h4qF+/fpo2bZokqXr16vrss8/ueJ+bN29q165dGjNmjM319u3ba+vWren2mzt3ro4cOaL58+drypQpGcYbFxenuLi45NfWWbH4+HjFx8dn2N/RrDG4QizIHRgzMIPxArMYM7lXSI27NOOxezRl5R+KjonLuEMGLt9IUNjaQ5q75aimPFhLHWqVTLMdYwZmudKYMRODxTCMLP03wtWrV3X06FEZhqFKlSrJ39/fVP/Tp0+rdOnS2rJli5o1a5Z8/Y033tDnn3+ugwcPpupz+PBhtWjRQps2bVLVqlU1ceJELVu2TLt37073ORMnTlRoaGiq6wsXLpSfn5+pmAEAAFxdkiEdibEoJl46e1368aSbpOys47v1q+KAqkmqW4zZJ+QtsbGx6tWrly5fvmxTwyEtpmec1q1bp7Zt28rf31916tSx+dyMGTM0bNgwU/ezWGy/kQ3DSHVNkhITE9WrVy+FhoZmahmg1SuvvGJz9lRMTIzKli2r9u3bZ/jFyQnx8fEKDw9XSEiIPD09nR0OcgHGDMxgvMAsxkzes+r3aA3/ek827nDr97J5h9w17P6Keva+SjblyxkzMMuVxox1NVpmmE6cevToofDwcN17770216dPn67x48dnOnEqXry43N3dFR0dbXP97NmzKlky9VTwlStXtHPnTkVGRiY/IykpSYZhyMPDQ2vWrFGbNm1S9fP29pa3t3eq656enk7/i0rJ1eKB62PMwAzGC8xizOQd3eqXlZeXh8Ys+V2XYrO+NMqQ9OFPRzV36wn1bFhGITUD1ahCUVlHCWMGZrnCmDHzfNOJU1hYmDp37qwNGzYkH3A7depUTZ48WStWrMj0fby8vNSgQQOFh4ere/fuydfDw8P14IMPpmpfqFAh/f777zbXZs6cqfXr1+vbb79VhQoVzL4VAACAfMF6eO6M9Yc1d8txXbqe9QTKWr58zpbjKuzrqX5N71Z5VvAhHzCdOA0YMEDnz59X+/bttXnzZi1evFhvvPGGVq1aZbNXKTNGjx6tJ554Qg0bNlTTpk31n//8RydOnNCQIUMk3Vpmd+rUKX3xxRdyc3NTcHCwTf8SJUrIx8cn1XUAAADYspYuH9amin49dkFr90drSeQpXczGLNSl6/F6f/0R+bi5y71ctLrVK2vHiAHXYjpxkqQXXnhB58+fV8OGDZWYmKg1a9aocePGpu/z6KOP6vz585o0aZKioqIUHByslStXqly5cpKkqKioDM90AgAAQOa5u1nUtFIxNa1UTK92qakZ6w8rbO3hbN3zRpJFwxfv0b6oK3qlc007RQq4lkwlTh988EGqa0FBQfLz81OrVq30yy+/6JdffpEkDR8+3FQAQ4cO1dChQ9P83Lx58+7Yd+LEiZo4caKp5wEAAOAW6yxUtcCC2d4DJUmfbDym2qUK64G6pewUIeA6MpU4hYWFpXnd3d1dW7Zs0ZYtWyTdqpBnNnECAACAc1n3QH247rDeX3dY2dmyNOyrSB3+56qGt61iU30PyO0ylTgdO3bM0XEAAADAidzdLBoZUlVVS/pr6MLIbN3r/XWH9emmo3q6VSUNa1OZBAp5gpuzAwAAAIDr6FynlGb1qa/CftkrEx17M1Fhaw+p1vgf9cz8ndpy+JwSkyi/h9zLdOL0yCOP6K233kp1/d1339X//d//2SUoAAAAOE/H4CDtei1Eo9pVUWHf7CVQNxKStGrvGfWe/YtqT1yt99ceJoFCrmQ6cdqwYYO6dOmS6nrHjh21ceNGuwQFAAAA57IWjtg1LkSLnmyiQc3Lq4C3e7buaZ2Fuid0jVbuibJTpEDOMJ04Xb16VV5eXqmue3p6KiYmxi5BAQAAwDVYy5eP61pLeyZ0UNc6gdm+59W4BA1dGKFhCyOYfUKuYTpxCg4O1uLFi1Nd/+qrr1SzJnX7AQAA8ip3N4s+7NVAMx6rJ3uUe1i+J0p1Jq5m9gm5gukDcMeNG6cePXroyJEjatOmjSRp3bp1WrRokb755hu7BwgAAADX8kDdUnJzU7ar70nStZuJGrowQk/+XUFju/Cf8HBdphOnbt26admyZXrjjTf07bffytfXV3Xq1NHatWvVunVrR8QIAAAAF9O5TinNcrNozHe/69L17B2cK0mfbjqmJMPQuAdq2SE6wP5MJ06S1KVLlzQLRAAAACD/6BgcpPuqFNOoT3/UhjNeio1PzNb9Zm8+rujLN/TB4/U5+wkuh3OcAAAAkGXubhZ1LGso4rU2GtWuivy8sld5b8Xv0ao5bpWmhx+icARciunEKTExUVOnTlWjRo0UGBiookWL2nwAAAAg/7GWL/99YodsJ1BxiYamrzusGuN/5NwnuAzTiVNoaKimTZumnj176vLlyxo9erQefvhhubm5aeLEiQ4IEQAAALlFygRqweDGql82IMv3upmQxLlPcBmmE6cFCxbo008/1QsvvCAPDw89/vjj+uyzzzR+/Hht377dETECAAAgl3F3s6h55eJa8mwLzexVL1uH5yaf+7SAc5/gPKYTp+joaNWuXVuS5O/vr8uXL0uSHnjgAa1YscK+0QEAACDX61ynlPZM6KAutbN3eO7y36NUc9wqZp/gFKYTpzJlyigq6tZgrVy5stasWSNJ2rFjh7y9ve0bHQAAAPIEdzeLPurdQINalM/WfeISDQ1dGKHXV+y3T2BAJplOnLp3765169ZJkkaMGKFx48apSpUq6tu3rwYOHGj3AAEAAJB3jHuglp5sWT7b9/l00zFNXr4v+wEBmWT6HKe33nor+c+PPPKIypQpo61bt6py5crq1q2bXYMDAABA3jO2Sy3VK1tEL363R9fisn720+zNxxV96YY+6MW5T3C8bJ/j1KRJE40ePZqkCQAAAJlm3ffUtU729j2t2BvNvifkCNOJ0/nz55P//Pfff2v8+PF68cUXtWnTJrsGBgAAgLzN3c2iD3s1yHbVPeu+p8c/2aabCUl2jBD4V6YTp99//13ly5dXiRIlVL16de3evVv33nuvwsLC9J///Ef333+/li1b5sBQAQAAkBdZZ58WDG6sutk492nbsQuq+toqypbDITKdOL300kuqXbu2NmzYoPvuu08PPPCAOnfurMuXL+vixYt6+umnbfY/AQAAAJllPfdp2bMtsl08YvnvUar+Gsv3YF+ZTpx27Nih119/XS1atNDUqVN1+vRpDR06VG5ubnJzc9Nzzz2nP/74w5GxAgAAIB8Y26WWZvaqJx+PrG/Hj0+6tXxv2EJmn2AfmR6NFy5cUGDgrc17/v7+KlCggIoWLZr8+SJFiujKlSv2jxAAAAD5Tuc6pbRvUkd1Di6Zrfss3xOlOhNXM/uEbDOVxlsslju+BgAAAOzF3c2imX0aZvvQ3Gs3Ezk0F9lm6hyn/v37y9vbW5J048YNDRkyRAUKFJAkxcXF2T86AAAA5HvjHqglN4v06abj2brPp5uOKckwNO6BWvYJDPlKphOnfv362bzu06dPqjZ9+/bNfkQAAADAbayH5o7++jfdyEbJcQ7NRVZlOnGaO3euI+MAAAAA7qhznVLqEBykD9cd0kc/HVF8Fos+rNgbrdWvrVTYo/XU9Z5Sdo4SeVXWS5UAAAAAOczdzaKRIdX0x5ROalCucJbvk5AkPbcoUoM/32G/4JCnkTgBAAAg13F3s+i7Z5prxmN15ZmNJXdrD5zVwx9tpmQ5MkTiBAAAgFzrgbql9ceUThp+f+Us3yPi78uqOnalfvjttB0jQ15D4gQAAIBczd3NotEdqmlmr3pZvkeiwdI93BmJEwAAAPKEznVKaVaf+vLzzPqvuCzdQ3pInAAAAJBndAwO0u+hHdU5uGSW7xHx92VVfXWlpocfIoFCMhInAAAA5CnubhbN7NNQT7Ysn+V7JEqavu6wao3/USv3RNktNuReJE4AAADIk8Z2qaWZveplq+rejYQkDV0YoWELIph9yudInAAAAJBnda5TSn9M6aT6ZQOydZ/lv0ep5rhVzD7lYyROAAAAyNPc3Sxa8mwLDWpRLlv3iUs0mH3Kx0icAAAAkC+MeyA420v3JGaf8isSJwAAAOQb9lq6Z519en3FfjtFBldH4gQAAIB8xV5L9yTp003HFPrDPjtEBVdH4gQAAIB8ybp0z8cje78Sz91ynENz8wESJwAAAORbneuU0r5JHTWybeVs7X2K+Puyqo1dyb6nPIzECQAAAPmau5tFI0Oq6Y8pndQ5uGSW75NgSEMXRmjycvY95UUkTgAAAIBuJVAz+zTUky3LZ+s+szcf08C5v9onKLgMEicAAAAghbFdamlmr3ryds/60r31B//R/e+uZ99THkLiBAAAANymc51S2j+5k4bfXznL9zh2/rqqvbZSP+5l31NeQOIEAAAApMHdzaLRHappZq96Wb5HQpI0ZH4EyVMeQOIEAAAA3EHnOqU0q099eWVj6d6whRG6mZBkx6iQ00icAAAAgAx0DA7SgcmdVL9sQJb6JyRJNcavYuYpFyNxAgAAADLB3c2iJc+20KAW5bLUP/F/y/Y46yl3InECAAAATBj3QLBm9qonjyz+Jj10YYSW7z5t36DgcCROAAAAgEmd65TSwSmdVaGYb5b6D/sqUsMWRFCuPBchcQIAAACywN3Nop9ebKM21Ypnqf/y36MUPOFH9j3lEiROAAAAQDbMGdBY/Zplbd/T9fgkypXnEiROAAAAQDaFdgtW2+p3Zbn/8EWRLNtzcSROAAAAgB3M7t8oy8nTzURDbd/7yc4RwZ5InAAAAAA7md2/UZaX7R0/f12Np4RzUK6LInECAAAA7Ci0W7Da1cjazNOZqzdV9bVVmrx8v52jQnaROAEAAAB29lm/RhrUonyW+8/efExtpv7EvicXQuIEAAAAOMC4B2ppxmN1s9z/6LlYVXttJRX3XASJEwAAAOAgD9QtrVl96svPM2u/dickiXLlLoLECQAAAHCgjsFB+j20o+qVDcjyPShX7nwkTgAAAICDubtZtPTZFgouVTBL/W8mGmr6Rrido4IZJE4AAABADlk+vJWCg/yz1Pfs1Xg98P4GO0eEzCJxAgAAAHLQ8hGt1bZ68Sz13Rt1VRO+/93OESEzSJwAAACAHDa7f2PNeKxuln4Z/3zrCYX+sM/uMeHOSJwAAAAAJ3igbmkdfqOz6pUtZLrv3C3HNXDurw6ICukhcQIAAACc5FbRiJbq16yc6b7rD/6jBz7Y6ICokBYSJwAAAMDJQrsF6/5q5vc97T19RZ0pGJEjSJwAAAAAFzB3QGOV8Pc03W9/1FW1eGutAyJCSiROAAAAgIvY9mqILFnod/JSHMmTg5E4AQAAAC7C3c2ij3rVz1Lfk5fi1GX6z/YNCMmcnjjNnDlTFSpUkI+Pjxo0aKBNmzal23bJkiUKCQnRXXfdpUKFCqlp06ZavXp1DkYLAAAAOFbnOkF6smWFLPXdF31NA+f+YueIIDk5cVq8eLFGjhypsWPHKjIyUi1btlSnTp104sSJNNtv3LhRISEhWrlypXbt2qX7779fXbt2VWRkZA5HDgAAADjO2C419WTL8lnqu/7gOYX+sNe+AcG5idO0adM0aNAgDR48WDVq1ND06dNVtmxZffzxx2m2nz59ul566SXde++9qlKlit544w1VqVJFP/zwQw5HDgAAADjW2C61NLNXvSz9wj53y1+avJxDcu3Jw1kPvnnzpnbt2qUxY8bYXG/fvr22bt2aqXskJSXpypUrKlq0aLpt4uLiFBcXl/w6JiZGkhQfH6/4+PgsRG5f1hhcIRbkDowZmMF4gVmMGZjFmHGskBp3aX9oiDpM36S/Lt4w1Xf25uNKSkrSq52qOyi6rHGlMWMmBqclTufOnVNiYqJKlixpc71kyZKKjo7O1D3ee+89Xbt2TT179ky3zZtvvqnQ0NBU19esWSM/Pz9zQTtQeHi4s0NALsOYgRmMF5jFmIFZjBnHGl1dmrjDoosJbpKJuntzt/6lY0ePqXsFw3HBZZErjJnY2NhMt3Va4mRlsdj+xRuGkepaWhYtWqSJEyfqv//9r0qUKJFuu1deeUWjR49Ofh0TE6OyZcuqffv2KlSoUNYDt5P4+HiFh4crJCREnp7m6/Yj/2HMwAzGC8xizMAsxkzO6dxZavrmep2LTTDRy6Kfo91VseLdesVFZp5cacxYV6NlhtMSp+LFi8vd3T3V7NLZs2dTzULdbvHixRo0aJC++eYbtWvX7o5tvb295e3tneq6p6en0/+iUnK1eOD6GDMwg/ECsxgzMIsxkzN+ea29Kr260nS/OVtPqP7dxfRA3VIOiCprXGHMmHm+04pDeHl5qUGDBqmm6MLDw9WsWbN0+y1atEj9+/fXwoUL1aVLF0eHCQAAALgMdzeLZmbxnKdhX0Vq5Z7Tdo4o/3BqVb3Ro0frs88+05w5c3TgwAGNGjVKJ06c0JAhQyTdWmbXt2/f5PaLFi1S37599d5776lJkyaKjo5WdHS0Ll++7Ky3AAAAAOSoznWCNKhF1s55GrowUiv3RNk5ovzBqYnTo48+qunTp2vSpEmqW7euNm7cqJUrV6pcuXKSpKioKJsznT755BMlJCTo2WefVVBQUPLHiBEjnPUWAAAAgBw37oGaalv9riz1HbowgpmnLHB6cYihQ4dq6NChaX5u3rx5Nq9//vlnxwcEAAAA5AKz+zfSwLm/av3Bf0z3HbowUrPcLOoYHOSAyPImp844AQAAAMi6OQMaqU214lnq++yCCCUmuV6ZcldF4gQAAADkYnMGNFabauaX7SUaUtup6x0QUd5E4gQAAADkcnMGNNL9Vc3PPB2/cEOD5v3igIjyHhInAAAAIA+YO7CxgksVNN1v3R/ntHz3KQdElLeQOAEAAAB5xPLhrVQryN90v+GLd7PfKQMkTgAAAEAesmJEa9PJU5Ih/d/Hmx0UUd5A4gQAAADkMStGtFa5Ij6m+kT8HaPXV+xzUES5H4kTAAAAkAetf7GNLCb7fLrpuG4mJDkkntyOxAkAAADIg9zdLPqoV33T/bq8v8EB0eR+JE4AAABAHtW5TpA6Bwea6nP4n1h9H0GVvduROAEAAAB52Ie96svD5Jq94V/v1vLdpx0TUC5F4gQAAADkYe5uFn3wuPkle8O+itSbK/c7IKLcicQJAAAAyOOysmRPkj7ZeEwr9zDzJJE4AQAAAPnCh73qy81smT1Jzy2K5HBckTgBAAAA+YK7m0XvP1bPdL9EQ3o//KADIspdSJwAAACAfKLrPaXUtnoJ0/0++OlIvp91InECAAAA8pHZ/e9VrVIFTfdr/PoaB0STe5A4AQAAAPnMiuGtVKawt6k+564lKPSH3x0UkesjcQIAAADyoc1j2qmQt7l0YO6WE7qZkOSgiFwbiRMAAACQT+0c18F0n5Zvr3VAJK6PxAkAAADIp7w83DSweXlTfc5cidfk5XsdE5ALI3ECAAAA8rHxXWuphL+XqT6zN/+V75bskTgBAAAA+dy2V9uZ7tPynfy1ZI/ECQAAAMjn3N0seu6+Sqb6nInJX0v2SJwAAAAAaGT7anKzmOuTn5bskTgBAAAAkLubRe8/Vs90v87vb3BANK6HxAkAAACAJKnrPaVUv2xhU33+/CdW128mOiYgF0LiBAAAACDZN880k8kVe2r2RrhDYnElJE4AAAAAkrm7WfTB4+aW7F28kajvI046KCLXQOIEAAAAwEbXe0qpTfW7TPUZ/vVvSkwyHBSR85E4AQAAAEhlTv9G8nY3t2hv+pqDDorG+UicAAAAAKRp17j2ptp/+PORPDvrROIEAAAAIE3+Ph4q6udpqs+zC3c6KBrnInECAAAAkK4tY9qaav/j3rN58lBcEicAAAAA6fL1clfpAB9TfRpOWe2gaJyHxAkAAADAHa19/j5T7WNuJGnZzr8dE4yTkDgBAAAAuCNfL3fVKxtgqs/Ib/fkqUIRJE4AAAAAMvTtM81N99l8+B8HROIcJE4AAAAAMuTuZlFYz7qm+jz5xQ7HBOMEJE4AAAAAMqV7/dLy88p8CnEzUbocG+/AiHIOiRMAAACATNv1mrlDcRu/Hu6gSHIWiRMAAACATPP1clcxE4fi3kg0dPVGggMjyhkkTgAAAABM2fBSG1PtO72/wUGR5BwSJwAAAACm+Pt4yN/EXqe/L97QzYQkB0bkeCROAAAAAEzb/mqIqfadpv/smEByCIkTAAAAANP8fTzkYSKbOHLuuq7fTHRcQA5G4gQAAAAgS0aFVDHV/snPc++5TiROAAAAALLkyZaVTbXffOS8EpMMB0XjWCROAAAAALLEy8NNA5qVN9Vny5/nHROMg5E4AQAAAMiyCd1qyWKi/Vs/HnRYLI5E4gQAAAAgW3reWzrTbQ//c025cbUeiRMAAACAbJnYtbap9gcumpmjcg0kTgAAAACyxdfLXR4mcqEVJ0icAAAAAORD3RuUynTbU9cdGIiDkDgBAAAAyLZJ3eqYaG3JdYfhkjgBAAAAyDZfL3cTyYVFU1YccGA09kfiBAAAAMAu7qtaLNNtl0SedmAk9kfiBAAAAMAuPujVMNNtEwzlquV6JE4AAAAA7MLfx8PUYbiTftjnsFjsjcQJAAAAgN3cV6Voptv+dPCsAyOxLxInAAAAAHbzYe97M932/NU4B0ZiXyROAAAAAOzG38cj023jk6TEJMOB0dgPiRMAAAAAuyrknfk0Y/PhfxwYif2QOAEAAACwq5pBhTLddtaGIw6MxH5InAAAAADY1TOtq2S67R/RVxwYif2QOAEAAACwqxbV7sp029ibCQ6MxH5InAAAAADYlbubRe6ZPNApLoHiEAAAAADyKS/3zLe9mZDkuEDshMQJAAAAgN0V9vPMdNtPfnb9AhEkTgAAAADsrmG5oplu++lmEicAAAAA+VDPhuUy3TbmRqIDI7EPEicAAAAAdtesSnFnh2BXJE4AAAAA7M7dLZNl9f7n4GnXPs/J6YnTzJkzVaFCBfn4+KhBgwbatGnTHdtv2LBBDRo0kI+PjypWrKhZs2blUKQAAAAAHKXTBxudHcIdOTVxWrx4sUaOHKmxY8cqMjJSLVu2VKdOnXTixIk02x87dkydO3dWy5YtFRkZqVdffVXDhw/Xd999l8ORAwAAAMiIh4m2rl6Q3KmJ07Rp0zRo0CANHjxYNWrU0PTp01W2bFl9/PHHabafNWuW7r77bk2fPl01atTQ4MGDNXDgQE2dOjWHIwcAAACQkfUv3O/sEOzGTBJoVzdv3tSuXbs0ZswYm+vt27fX1q1b0+yzbds2tW/f3uZahw4dNHv2bMXHx8vTM3Wt+Li4OMXFxSW/jomJkSTFx8crPj4+u28j26wxuEIsyB0YMzCD8QKzGDMwizGDOwkKyPxZTlLOjyMzz3Na4nTu3DklJiaqZMmSNtdLliyp6OjoNPtER0en2T4hIUHnzp1TUFBQqj5vvvmmQkNDU11fs2aN/Pz8svEO7Cs8PNzZISCXYczADMYLzGLMwCzGDNLnpswtdEvSypUrHR2MjdjY2Ey3dVriZGWx2FbbMAwj1bWM2qd13eqVV17R6NGjk1/HxMSobNmyat++vQoVKpTVsO0mPj5e4eHhCgkJSXPGDLgdYwZmMF5gFmMGZjFmkJER29ZksqWbOnfu6NBYbmddjZYZTkucihcvLnd391SzS2fPnk01q2QVGBiYZnsPDw8VK1YszT7e3t7y9vZOdd3T09OlvrldLR64PsYMzGC8wCzGDMxizCA9Y9qW11vrjmeqXU6PITPPc1pxCC8vLzVo0CDVtG54eLiaNWuWZp+mTZumar9mzRo1bNiQb1QAAADABQ0JqWXXds7i1Kp6o0eP1meffaY5c+bowIEDGjVqlE6cOKEhQ4ZIurXMrm/fvsnthwwZor/++kujR4/WgQMHNGfOHM2ePVsvvPCCs94CAAAAgAwcf6tLtj7vCpy6x+nRRx/V+fPnNWnSJEVFRSk4OFgrV65UuXLlJElRUVE2ZzpVqFBBK1eu1KhRo/TRRx+pVKlS+uCDD9SjRw9nvQUAAAAAmXD8rS6aFb7vf8v2kiS5aUzb8i4/02Tl9OIQQ4cO1dChQ9P83Lx581Jda926tSIiIhwcFQAAAAB7GxJSS4Puq6qVK1eqc+eOuWq7jVOX6gEAAABAbkDiBAAAAAAZIHECAAAAgAyQOAEAAABABkicAAAAACADJE4AAAAAkAESJwAAAADIAIkTAAAAAGSAxAkAAAAAMkDiBAAAAAAZIHECAAAAgAyQOAEAAABABkicAAAAACADHs4OIKcZhiFJiomJcXIkt8THxys2NlYxMTHy9PR0djjIBRgzMIPxArMYMzCLMQOzXGnMWHMCa45wJ/kucbpy5YokqWzZsk6OBAAAAIAruHLligICAu7YxmJkJr3KQ5KSknT69GkVLFhQFovF2eEoJiZGZcuW1d9//61ChQo5OxzkAowZmMF4gVmMGZjFmIFZrjRmDMPQlStXVKpUKbm53XkXU76bcXJzc1OZMmWcHUYqhQoVcvrAQe7CmIEZjBeYxZiBWYwZmOUqYyajmSYrikMAAAAAQAZInAAAAAAgAyROTubt7a0JEybI29vb2aEgl2DMwAzGC8xizMAsxgzMyq1jJt8VhwAAAAAAs5hxAgAAAIAMkDgBAAAAQAZInAAAAAAgAyROAAAAAJABEicHmzlzpipUqCAfHx81aNBAmzZtumP7DRs2qEGDBvLx8VHFihU1a9asHIoUrsLMmFmyZIlCQkJ01113qVChQmratKlWr16dg9HCFZj9OWO1ZcsWeXh4qG7duo4NEC7H7JiJi4vT2LFjVa5cOXl7e6tSpUqaM2dODkULV2B2zCxYsED33HOP/Pz8FBQUpAEDBuj8+fM5FC2cbePGjeratatKlSoli8WiZcuWZdgnN/wOTOLkQIsXL9bIkSM1duxYRUZGqmXLlurUqZNOnDiRZvtjx46pc+fOatmypSIjI/Xqq69q+PDh+u6773I4cjiL2TGzceNGhYSEaOXKldq1a5fuv/9+de3aVZGRkTkcOZzF7Jixunz5svr27au2bdvmUKRwFVkZMz179tS6des0e/ZsHTx4UIsWLVL16tVzMGo4k9kxs3nzZvXt21eDBg3Svn379M0332jHjh0aPHhwDkcOZ7l27ZruuecezZgxI1Ptc83vwAYcplGjRsaQIUNsrlWvXt0YM2ZMmu1feuklo3r16jbXnn76aaNJkyYOixGuxeyYSUvNmjWN0NBQe4cGF5XVMfPoo48ar732mjFhwgTjnnvucWCEcDVmx8yqVauMgIAA4/z58zkRHlyQ2THz7rvvGhUrVrS59sEHHxhlypRxWIxwXZKMpUuX3rFNbvkdmBknB7l586Z27dql9u3b21xv3769tm7dmmafbdu2pWrfoUMH7dy5U/Hx8Q6LFa4hK2PmdklJSbpy5YqKFi3qiBDhYrI6ZubOnasjR45owoQJjg4RLiYrY+b7779Xw4YN9c4776h06dKqWrWqXnjhBV2/fj0nQoaTZWXMNGvWTCdPntTKlStlGIbOnDmjb7/9Vl26dMmJkJEL5ZbfgT2cHUBede7cOSUmJqpkyZI210uWLKno6Og0+0RHR6fZPiEhQefOnVNQUJDD4oXzZWXM3O69997TtWvX1LNnT0eECBeTlTFz+PBhjRkzRps2bZKHB/8E5DdZGTNHjx7V5s2b5ePjo6VLl+rcuXMaOnSoLly4wD6nfCArY6ZZs2ZasGCBHn30Ud24cUMJCQnq1q2bPvzww5wIGblQbvkdmBknB7NYLDavDcNIdS2j9mldR95ldsxYLVq0SBMnTtTixYtVokQJR4UHF5TZMZOYmKhevXopNDRUVatWzanw4ILM/JxJSkqSxWLRggUL1KhRI3Xu3FnTpk3TvHnzmHXKR8yMmf3792v48OEaP368du3apR9//FHHjh3TkCFDciJU5FK54Xdg/rvRQYoXLy53d/dU/xtz9uzZVBm1VWBgYJrtPTw8VKxYMYfFCteQlTFjtXjxYg0aNEjffPON2rVr58gw4ULMjpkrV65o586dioyM1LBhwyTd+qXYMAx5eHhozZo1atOmTY7EDufIys+ZoKAglS5dWgEBAcnXatSoIcMwdPLkSVWpUsWhMcO5sjJm3nzzTTVv3lwvvviiJKlOnToqUKCAWrZsqSlTprjM7AFcR275HZgZJwfx8vJSgwYNFB4ebnM9PDxczZo1S7NP06ZNU7Vfs2aNGjZsKE9PT4fFCteQlTEj3Zpp6t+/vxYuXMj68XzG7JgpVKiQfv/9d+3evTv5Y8iQIapWrZp2796txo0b51TocJKs/Jxp3ry5Tp8+ratXryZfO3TokNzc3FSmTBmHxgvny8qYiY2NlZub7a+Y7u7ukv6dRQBSyjW/AzupKEW+8NVXXxmenp7G7Nmzjf379xsjR440ChQoYBw/ftwwDMMYM2aM8cQTTyS3P3r0qOHn52eMGjXK2L9/vzF79mzD09PT+Pbbb531FpDDzI6ZhQsXGh4eHsZHH31kREVFJX9cunTJWW8BOczsmLkdVfXyH7Nj5sqVK0aZMmWMRx55xNi3b5+xYcMGo0qVKsbgwYOd9RaQw8yOmblz5xoeHh7GzJkzjSNHjhibN282GjZsaDRq1MhZbwE57MqVK0ZkZKQRGRlpSDKmTZtmREZGGn/99ZdhGLn3d2ASJwf76KOPjHLlyhleXl5G/fr1jQ0bNiR/rl+/fkbr1q1t2v/8889GvXr1DC8vL6N8+fLGxx9/nMMRw9nMjJnWrVsbklJ99OvXL+cDh9OY/TmTEolT/mR2zBw4cMBo166d4evra5QpU8YYPXq0ERsbm8NRw5nMjpkPPvjAqFmzpuHr62sEBQUZvXv3Nk6ePJnDUcNZfvrppzv+fpJbfwe2GAZzpgAAAABwJ+xxAgAAAIAMkDgBAAAAQAZInAAAAAAgAyROAAAAAJABEicAAAAAyACJEwAAAABkgMQJAAAAADJA4gQAAAAAGSBxAgBki8Vi0bJly3L8ueXLl9f06dOzdY/Y2Fj16NFDhQoVksVi0aVLl9K8ZuZZ8+bNU+HChbMVFwDA9ZA4AQDSdfbsWT399NO6++675e3trcDAQHXo0EHbtm1LbhMVFaVOnTo5Mcq0TZw4URaLJdVH9erVk9t8/vnn2rRpk7Zu3aqoqCgFBASkeW3Hjh166qmnMvXcRx99VIcOHXLU2wIAOImHswMAALiuHj16KD4+Xp9//rkqVqyoM2fOaN26dbpw4UJym8DAQCdGeGe1atXS2rVrba55ePz7T9+RI0dUo0YNBQcH3/HaXXfdleln+vr6ytfXNxtRAwBcETNOAIA0Xbp0SZs3b9bbb7+t+++/X+XKlVOjRo30yiuvqEuXLsntbl+qt3XrVtWtW1c+Pj5q2LChli1bJovFot27d0uSfv75Z1ksFq1bt04NGzaUn5+fmjVrpoMHDybf48iRI3rwwQdVsmRJ+fv76957702VAGWGh4eHAgMDbT6KFy8uSbrvvvv03nvvaePGjbJYLLrvvvvSvCalXhZ46dIlPfXUUypZsqR8fHwUHBys5cuXS0p7qd4PP/ygBg0ayMfHRxUrVlRoaKgSEhJsvoafffaZunfvLj8/P1WpUkXff/+9zT327dunLl26qFChQipYsKBatmypI0eOaOPGjfL09FR0dLRN++eff16tWrUy/TUDAKSNxAkAkCZ/f3/5+/tr2bJliouLy1SfK1euqGvXrqpdu7YiIiI0efJkvfzyy2m2HTt2rN577z3t3LlTHh4eGjhwYPLnrl69qs6dO2vt2rWKjIxUhw4d1LVrV504ccIu702SlixZoieffFJNmzZVVFSUlixZkua12yUlJalTp07aunWr5s+fr/379+utt96Su7t7ms9ZvXq1+vTpo+HDh2v//v365JNPNG/ePL3++us27UJDQ9WzZ0/t2bNHnTt3Vu/evZNn9k6dOqVWrVrJx8dH69ev165duzRw4EAlJCSoVatWqlixor788svkeyUkJGj+/PkaMGCA3b5eAJDvGQAApOPbb781ihQpYvj4+BjNmjUzXnnlFeO3336zaSPJWLp0qWEYhvHxxx8bxYoVM65fv578+U8//dSQZERGRhqGYRg//fSTIclYu3ZtcpsVK1YYkmz63a5mzZrGhx9+mPy6XLlyRlhYWLrtJ0yYYLi5uRkFChSw+Rg0aFBymxEjRhitW7e26ZfWtZTPWr16teHm5mYcPHgwzefOnTvXCAgISH7dsmVL44033rBp8+WXXxpBQUHJryUZr732WvLrq1evGhaLxVi1apVhGIbxyiuvGBUqVDBu3ryZ5jPffvtto0aNGsmvly1bZvj7+xtXr15Nsz0AwDxmnAAA6erRo4dOnz6t77//Xh06dNDPP/+s+vXra968eWm2P3jwoOrUqSMfH5/ka40aNUqzbZ06dZL/HBQUJOlWMQpJunbtml566SXVrFlThQsXlr+/v/744w/TM07VqlXT7t27bT5un+kxa/fu3SpTpoyqVq2aqfa7du3SpEmTkmfw/P399eSTTyoqKkqxsbHJ7VJ+PQoUKKCCBQsmfz12796tli1bytPTM81n9O/fX3/++ae2b98uSZozZ4569uypAgUKZPVtAgBuQ3EIAMAd+fj4KCQkRCEhIRo/frwGDx6sCRMmqH///qnaGoYhi8WS6lpaUiYB1j5JSUmSpBdffFGrV6/W1KlTVblyZfn6+uqRRx7RzZs3TcXu5eWlypUrm+qTEbOFH5KSkhQaGqqHH3441edSJpi3J0UWiyX565HRM0uUKKGuXbtq7ty5qlixolauXKmff/7ZVJwAgDsjcQIAmFKzZs10z22qXr26FixYoLi4OHl7e0uSdu7cafoZmzZtUv/+/dW9e3dJt/Y8HT9+PKsh21WdOnV08uRJHTp0KFOzTvXr19fBgwezlcDVqVNHn3/+ueLj49OddRo8eLAee+wxlSlTRpUqVVLz5s2z/DwAQGos1QMApOn8+fNq06aN5s+frz179ujYsWP65ptv9M477+jBBx9Ms0+vXr2UlJSkp556SgcOHEieNZKUaibqTipXrqwlS5Zo9+7d+u2335Lva1ZCQoKio6NtPs6cOWP6Pim1bt1arVq1Uo8ePRQeHq5jx45p1apV+vHHH9NsP378eH3xxReaOHGi9u3bpwMHDmjx4sV67bXXMv3MYcOGKSYmRo899ph27typw4cP68svv7SpRNihQwcFBARoypQpFIUAAAcgcQIApMnf31+NGzdWWFiYWrVqpeDgYI0bN05PPvmkZsyYkWafQoUK6YcfftDu3btVt25djR07VuPHj5dkuywtI2FhYSpSpIiaNWumrl27qkOHDqpfv77p97Bv3z4FBQXZfJQrV870fW733Xff6d5779Xjjz+umjVr6qWXXlJiYmKabTt06KDly5crPDxc9957r5o0aaJp06aZiqNYsWJav369rl69qtatW6tBgwb69NNPbWaf3Nzc1L9/fyUmJqpv377Zfo8AAFsWI73F5wAA2MGCBQs0YMAAXb58mYNhHezJJ5/UmTNnUp0BBQDIPvY4AQDs6osvvlDFihVVunRp/fbbb3r55ZfVs2dPkiYHunz5snbs2KEFCxbov//9r7PDAYA8icQJAGBX0dHRGj9+vKKjoxUUFKT/+7//y3YJcNzZgw8+qF9//VVPP/20QkJCnB0OAORJLNUDAAAAgAxQHAIAAAAAMkDiBAAAAAAZIHECAAAAgAyQOAEAAABABkicAAAAACADJE4AAAAAkAESJwAAAADIAIkTAAAAAGTg/wG4l3zD4SilOgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.8725768838361755, 0.2938063432972006), (0.9003789535053199, 0.2574546516296215), (0.929857163678764, 0.21175955326836746), (0.960246319778458, 0.15204934486660096), (0.980141378807754, 0.1017190408409066), (0.990016032648302, 0.0677396985291434), (0.995008016324151, 0.0405489251432534), (0.9990161783996502, 0.007810504032993905)]\n"
     ]
    }
   ],
   "source": [
    "test_results = test_model(data, model, HYPERPARAMETERS)\n",
    "metrics = getTargetMetrics(test_results)\n",
    "displayPerformance(data, test_results, metrics, HYPERPARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_batch_norm(dense_layer, bn_layer):\n",
    "    W, b = dense_layer.get_weights()\n",
    "    gamma, beta, moving_mean, moving_var = bn_layer.get_weights()\n",
    "\n",
    "    epsilon = bn_layer.epsilon\n",
    "    std = np.sqrt(moving_var + epsilon)\n",
    "    new_W = gamma / std * W\n",
    "    new_b = gamma / std * (b - moving_mean) + beta\n",
    "\n",
    "    return new_W, new_b\n",
    "\n",
    "def create_folded_model(original_model): # Fold batch normalization layers into dense layers\n",
    "    inputs = original_model.input\n",
    "    x = inputs\n",
    "    new_layers = []\n",
    "\n",
    "    for layer in original_model.layers:\n",
    "        if isinstance(layer, QDense):\n",
    "            next_layer = new_layers[-1] if new_layers else inputs\n",
    "            if isinstance(next_layer, BatchNormalization):\n",
    "                # Fold the BatchNormalization into the previous Dense layer\n",
    "                new_W, new_b = fold_batch_norm(layer, next_layer)\n",
    "                x = QDense(layer.units, weights=[new_W, new_b], kernel_quantizer=layer.kernel_quantizer, bias_quantizer=layer.bias_quantizer)(x)\n",
    "                new_layers.pop()  # Remove the BatchNormalization layer\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        elif not isinstance(layer, BatchNormalization):\n",
    "            x = layer(x)\n",
    "        new_layers.append(x)\n",
    "\n",
    "    outputs = x\n",
    "\n",
    "    new_model = Model(inputs, outputs)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def showDone():\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(6, 6)\n",
    "    square = plt.Rectangle((0, 0), 1, 1, color='green')\n",
    "    ax.add_patch(square)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    plt.title(\"DONE\", fontsize=20)\n",
    "\n",
    "showDone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Functional model inputs must come from `tf.keras.Input` (thus holding past layer metadata). They cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model_1\" was not an Input tensor, it was generated by layer \"y_timed_input\".\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: KerasTensor(type_spec=TensorSpec(shape=(None, 105), dtype=tf.float32, name='y_timed_input'), name='y_timed_input', description=\"created by layer 'y_timed_input'\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Functional model inputs must come from `tf.keras.Input` (thus holding past layer metadata). They cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model_1\" was not an Input tensor, it was generated by layer \"y_timed_input\".\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: KerasTensor(type_spec=TensorSpec(shape=(None, 105), dtype=tf.float32, name='y_timed_input'), name='y_timed_input', description=\"created by layer 'y_timed_input'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " y_timed_input (InputLayer)  multiple                     0         ['y_timed_input[0][0]']       \n",
      "                                                                                                  \n",
      " dense1 (QDense)             (None, 24)                   2544      ['y_timed_input[1][0]']       \n",
      "                                                                                                  \n",
      " q_activation_32 (QActivati  (None, 24)                   0         ['dense1[1][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " dense2 (QDense)             (None, 12)                   300       ['q_activation_32[1][0]']     \n",
      "                                                                                                  \n",
      " q_activation_33 (QActivati  (None, 12)                   0         ['dense2[1][0]']              \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " dense_output (QDense)       (None, 1)                    13        ['q_activation_33[1][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2857 (11.16 KB)\n",
      "Trainable params: 2857 (11.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sdf/home/a/alexyue/miniconda3/envs/SmartPixel/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Create the folded model\n",
    "new_model = create_folded_model(loaded_model)\n",
    "\n",
    "# Verify the new model\n",
    "new_model.summary()\n",
    "\n",
    "new_model.save(f'./DNN_L2_S24_best_performance_single_quant_10_15new_folded.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1714/1714 [==============================] - 3s 2ms/step\n",
      "[[0.30105942]\n",
      " [0.44341695]\n",
      " [0.41784704]\n",
      " [0.34261703]\n",
      " [0.39480978]\n",
      " [0.0527426 ]\n",
      " [0.48433354]\n",
      " [0.10639128]\n",
      " [0.33765462]\n",
      " [0.42171764]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIhCAYAAAB5deq6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACCbUlEQVR4nO3dd1jV5f/H8dc5hyUO3IIjRdEUkVyZI7VURHA07Gul5kj9Zua2oblH2bchVmY2HJUjG2qpOFDLbQ40c5thpoImpDiR8fn94e+QCArncNjPx3VxXZ37fD73eR+8OfHmvu/3bTIMwxAAAAAA4K7MOR0AAAAAAOR2JE4AAAAAkA4SJwAAAABIB4kTAAAAAKSDxAkAAAAA0kHiBAAAAADpIHECAAAAgHSQOAEAAABAOkicAAAAACAdJE4AMmXevHkymUwpvsqUKaNHHnlEK1asyNLXfuSRR+Tn55elr5GbValSRb169Ur3ujv/fYoVK6amTZtq0aJFWf7a9po5c6bmzZuXqv3kyZMymUxpPpdf/fLLL3riiSd03333ydXVVeXKlVOTJk00YsSIFNc98sgjeuSRR3ImyDRkNJ5HHnkk1Ri1flWpUiXFtevXr1fDhg1VuHBhmUwmLVu2TJK0ePFi1a5dW4UKFZLJZNK+ffs0YcIEmUwmm+Pu1atXqtcFAElyyukAAOQPc+fOVc2aNWUYhqKiojRjxgx17NhRP/74ozp27JjT4RV4Tz31lEaMGCHDMBQREaE333xTXbt2lWEY6tq1q839LV26VMWKFcuCSG+ZOXOmSpcunSo58/Ly0vbt21WtWrUse+3cZOXKlerUqZMeeeQRvf322/Ly8lJkZKR2796tr7/+Wu+9917ytTNnzszBSDOnatWqWrBgQap2V1fX5P82DENdunRRjRo19OOPP6pw4cK6//779ffff+u5555Tu3btNHPmTLm6uqpGjRrq27ev2rVrZ3MsY8eO1ZAhQzL1fgDkTyROABzCz89PDRs2TH7crl07lShRQosWLcrTidO1a9fk7u6e02FkWrly5dS4cWNJUpMmTdSsWTNVqVJFn3zyiV2JU7169RwdYoa4uromv4+C4O2335a3t7fWrFkjJ6d//5f9zDPP6O23305xra+vb3aH5zCFChVK99/17NmziomJ0RNPPKHWrVsnt2/dulXx8fHq3r27WrZsmdzu7u6uihUr2hxLQUnKAdiOpXoAsoSbm5tcXFzk7Oycon3ixIl66KGHVLJkSRUrVkz169fX7NmzZRhGqj4WLlyoJk2aqEiRIipSpIjq1q2r2bNn3/N1ly5dKnd3d/Xt21cJCQmSpIsXL6pPnz4qWbKkihQpovbt2+uPP/6QyWTShAkTku+1Lu0JDw/XU089pRIlSiT/EnXjxg2NGjVK3t7ecnFxUYUKFfTSSy/p4sWLKV7/zj6t7lzaZl3i+NNPP+nFF19U6dKlVapUKT355JM6e/Zsinvj4+P16quvytPTU+7u7nr44Ye1c+fOe34f0lO5cmWVKVNG586dS9EeGxurl19+OcX7HDp0qK5evXrP92PLvUlJSfrwww9Vt25dFSpUSMWLF1fjxo31448/Jvd98OBBbdy4MdWSrbst1duyZYtat26tokWLyt3dXU2bNtXKlStTXGPL9/xO06dPl8lk0u+//57quddee00uLi66cOGCJGnv3r3q0KGDypYtK1dXV5UvX17t27fX6dOn7/kaaYmOjlbp0qVTJE1WZnPK/4WntTTu9OnTeuqpp1S0aFEVL15c3bp1065du1J9D3v16qUiRYro999/V3BwsIoUKaJKlSppxIgRiouLS9GnLT/DjjJhwoTkJOi1115LHhO9evXSww8/LEl6+umnZTKZkr8Hd1uql97nSlpL9QzD0MyZM5PHbIkSJfTUU0/pjz/+SHGddfnwrl271Lx5c7m7u6tq1ap66623lJSUlOLaixcvasSIEapatapcXV1VtmxZBQcH68iRIzIMQ9WrV1dgYGCq+K9cuSIPDw+99NJLNn8fAWQOiRMAh0hMTFRCQoLi4+N1+vTp5F+Y75zNOHnypF544QV98803WrJkiZ588kkNGjRIkydPTnHduHHj1K1bN5UvX17z5s3T0qVL1bNnT/355593jSEkJET/+c9/9Prrr+vzzz+Xk5OTkpKS1LFjRy1cuFCvvfaali5dqoceeuieS3iefPJJ+fj46Ntvv9WsWbNkGIYef/xxvfvuu3ruuee0cuVKDR8+XF988YVatWqV6hdLW/Tt21fOzs5auHCh3n77bf3888/q3r17imv69eund999Vz169NAPP/ygzp0768knn9Q///xj9+teunRJMTExqlGjRnLbtWvX1LJlS33xxRcaPHiwVq1apddee03z5s1Tp06d7vmLsS339urVS0OGDNGDDz6oxYsX6+uvv1anTp108uRJSbeS36pVq6pevXravn27tm/frqVLl971tTdu3KhWrVrp0qVLmj17thYtWqSiRYuqY8eOWrx4carrM/I9v1P37t3l4uKSKmFLTEzU/Pnz1bFjR5UuXVpXr15VQECAzp07p48++khhYWGaPn267rvvPl2+fPmer5GWJk2a6JdfftHgwYP1yy+/KD4+PsP3Xr16VY8++qh++ukn/e9//9M333yjcuXK6emnn07z+vj4eHXq1EmtW7fWDz/8oOeff14hISH63//+l+K6jP4M2yohISHVlzXZ6Nu3r5YsWSJJGjRoUPKYGDt2rD766CNJ0ptvvqnt27ffc8miPZ8rkvTCCy9o6NChatOmjZYtW6aZM2fq4MGDatq0aao/PkRFRalbt27q3r27fvzxRwUFBWnUqFGaP39+8jWXL1/Www8/rE8++US9e/fW8uXLNWvWLNWoUUORkZEymUwaNGiQwsLCdPz48RT9f/nll4qNjSVxAnKCAQCZMHfuXENSqi9XV1dj5syZ97w3MTHRiI+PNyZNmmSUKlXKSEpKMgzDMP744w/DYrEY3bp1u+f9LVu2NGrXrm0kJiYaAwcONFxcXIz58+enuGblypWGJOPjjz9O0T516lRDkjF+/PjktvHjxxuSjHHjxqW4dvXq1YYk4+23307RvnjxYkOS8emnnya33dmnVeXKlY2ePXsmP7Z+3wYMGJDiurffftuQZERGRhqGYRiHDx82JBnDhg1Lcd2CBQsMSSn6vBvr68THxxs3b940jh07ZnTq1MkoWrSosXv37hTfE7PZbOzatSvF/d99950hyQgNDb3r+8novZs2bTIkGaNHj75nzLVr1zZatmyZqj0iIsKQZMydOze5rXHjxkbZsmWNy5cvJ7clJCQYfn5+RsWKFZPHVUa/53fz5JNPGhUrVjQSExOT20JDQw1JxvLlyw3DMIzdu3cbkoxly5bds6+MunDhgvHwww8n/1w5OzsbTZs2NaZOnZri/RrGrZ+H279nH330kSHJWLVqVYrrXnjhhVTfw549exqSjG+++SbFtcHBwcb9999/1/ju9jOcVjx307JlyzQ/QyQZffr0Sb7O+m//zjvvpLj/p59+MiQZ3377bYp268+zVUY/V3r27GlUrlw5+fH27dsNScZ7772X4rq//vrLKFSokPHqq6+mei+//PJLimt9fX2NwMDA5MeTJk0yJBlhYWF3jSM2NtYoWrSoMWTIkFR9Pfroo/d8DwCyBjNOABziyy+/1K5du7Rr1y6tWrVKPXv21EsvvaQZM2akuG7Dhg1q06aNPDw8ZLFY5OzsrHHjxik6Olrnz5+XJIWFhSkxMTFDf1G9ceOGHn/8cS1YsEBr165Vt27dUjy/ceNGSVKXLl1StD/77LN37bNz586pYpaUamnaf/7zHxUuXFjr169PN8676dSpU4rH/v7+kpT8F/CffvpJklK9ry5duqS5fOtuZs6cKWdnZ7m4uKhGjRpatWqVFi1apAYNGiRfs2LFCvn5+alu3bop/uofGBgok8mkn3/++a79Z/TeVatWSZLD/lp+9epV/fLLL3rqqadUpEiR5HaLxaLnnntOp0+f1tGjR1Pck973/G569+6t06dPa926dcltc+fOlaenp4KCgiRJPj4+KlGihF577TXNmjVLhw4dytT7K1WqlDZv3qxdu3bprbfe0mOPPaZjx45p1KhRqlOnTvLywLRs3LhRRYsWTTW7erexbzKZUu1H9Pf3T/V9ycjPsK2qVauW/Plx+9fYsWPt6i8ttnyu3G7FihUymUzq3r17irHt6empBx54INXPhaenpxo1apSi7c7v46pVq1SjRg21adPmrq9btGhR9e7dW/PmzUte7rphwwYdOnRIAwcOtOk9AHAMEicADlGrVi01bNhQDRs2VLt27fTJJ5+obdu2evXVV5P3Ae3cuVNt27aVJH322WfaunWrdu3apdGjR0uSrl+/Lkn6+++/JSlDG7vPnz+vNWvWqEmTJmratGmq56Ojo+Xk5KSSJUumaC9Xrtxd+/Ty8kqzjzJlyqRoN5lM8vT0VHR0dLpx3k2pUqVSPLZWEbN+L6x9e3p6prjOyckp1b330qVLF+3atUvbtm3TJ598oqJFi+qZZ55JsQzo3Llz2r9/v5ydnVN8FS1aVIZh3POX9Ize+/fff8tisaR6P/b6559/ZBhGqn8zSSpfvrwkpfr3Se97fjdBQUHy8vLS3Llzk1/7xx9/VI8ePWSxWCRJHh4e2rhxo+rWravXX39dtWvXVvny5TV+/HibltndqWHDhnrttdf07bff6uzZsxo2bJhOnjyZqkDE7aKjo9Mc53cb++7u7nJzc0vR5urqqhs3biQ/zujPsK3c3NySPz9u/6pcubJd/aXFls+V2507d06GYahcuXKpxveOHTtS/Vyk9XPp6uqa4nvz999/ZyiOQYMG6fLly8kVB2fMmKGKFSvqscces+k9AHAMquoByDL+/v5as2aNjh07pkaNGunrr7+Ws7OzVqxYkeIXNOtZLFbWBOX06dOqVKnSPV/jvvvu07Rp0/TEE0/oySef1Lfffpui71KlSikhIUExMTEpkqeoqKi79nnnhnJrH3///XeK5Mn4/9LrDz74YHKbq6trmnue7E2urL+ERUVFqUKFCsntCQkJNvVZpkyZ5KqHTZo0Ua1atdSyZUsNGzYs+byt0qVLq1ChQpozZ06afZQuXfqu/Wf03jJlyigxMVFRUVFpJju2KlGihMxmsyIjI1M9Zy34cK+4bWGdxfrggw908eJFLVy4UHFxcerdu3eK6+rUqaOvv/5ahmFo//79mjdvniZNmqRChQpp5MiRmY7D2dlZ48ePV0hIiA4cOHDX60qVKpVmEZF7jf30ZPRnODey5XPldqVLl5bJZNLmzZtTlEe3SqstI7FkpFiIj4+PgoKC9NFHHykoKEg//vijJk6cmJyoA8hezDgByDL79u2T9O8vLCaTSU5OTin+p3/9+nV99dVXKe5r27atLBaLPv744wy9Ttu2bbVmzRpt2rRJHTp0SFHFzVqe+M4iAV9//XWG34e19PHtm7sl6fvvv9fVq1dTlEauUqWK9u/fn+K6DRs26MqVKxl+vdtZK4TdecbNN998k1w10B7NmzdXjx49tHLlSm3fvl2S1KFDB504cUKlSpVK86//9zoUNKP3Wpe0pfdve+df6O+mcOHCeuihh7RkyZIU1yclJWn+/PmqWLFiigIYmdW7d2/duHFDixYt0rx589SkSRPVrFkzzWtNJpMeeOABhYSEqHjx4goPD7f59dJKCCXp8OHDkv6dVUtLy5Ytdfny5eTlkVa2jP07ZfRnODey9XPFqkOHDjIMQ2fOnElzbNepU8fmWIKCgnTs2LHkZcD3MmTIEO3fv189e/aUxWJRv379bH49AI7BjBMAhzhw4EDyL/LR0dFasmSJwsLC9MQTT8jb21uS1L59e02bNk1du3bVf//7X0VHR+vdd99N9RfbKlWq6PXXX9fkyZN1/fp1Pfvss/Lw8NChQ4d04cIFTZw4MdXrP/zww1q/fr3atWuntm3bKjQ0VB4eHmrXrp2aNWumESNGKDY2Vg0aNND27dv15ZdfSkpd0jktAQEBCgwM1GuvvabY2Fg1a9ZM+/fv1/jx41WvXj0999xzydc+99xzGjt2rMaNG6eWLVvq0KFDmjFjhjw8POz6vtaqVUvdu3fX9OnT5ezsrDZt2ujAgQN69913M30A7eTJk7V48WKNHTtW69at09ChQ/X999+rRYsWGjZsmPz9/ZWUlKRTp05p7dq1GjFihB566KE0+8rovc2bN9dzzz2nKVOm6Ny5c+rQoYNcXV21d+9eubu7a9CgQZL+nbVZvHixqlatKjc3t7v+gjp16lQFBATo0Ucf1csvvywXFxfNnDlTBw4c0KJFi9IsSW2vmjVrqkmTJpo6dar++usvffrppymeX7FihWbOnKnHH39cVatWlWEYWrJkiS5evKiAgIDk61q3bq2NGzemm/wGBgaqYsWK6tixo2rWrKmkpCTt27dP7733nooUKXLPg1p79uypkJAQde/eXVOmTJGPj49WrVqlNWvWSMrY2L9TRn+GbXX9+nXt2LEjzeccdW6XPZ8rktSsWTP997//Ve/evbV79261aNFChQsXVmRkpLZs2aI6deroxRdftCmWoUOHavHixXrsscc0cuRINWrUSNevX9fGjRvVoUMHPfroo8nXBgQEyNfXVz/99JO6d++usmXLZur7ACATcq4uBYD8IK2qeh4eHkbdunWNadOmGTdu3Ehx/Zw5c4z777/fcHV1NapWrWpMnTrVmD17tiHJiIiISHHtl19+aTz44IOGm5ubUaRIEaNevXopKoFZq+rd7sCBA4anp6dRv3594++//zYMwzBiYmKM3r17G8WLFzfc3d2NgIAAY8eOHYYk4/3330++11qFy3rf7a5fv2689tprRuXKlQ1nZ2fDy8vLePHFF41//vknxXVxcXHGq6++alSqVMkoVKiQ0bJlS2Pfvn13rap3ZxU6a4Wwn376KUWfI0aMMMqWLWu4ubkZjRs3NrZv356qz7uRZLz00ktpPvfKK68YkoyNGzcahmEYV65cMcaMGWPcf//9houLi+Hh4WHUqVPHGDZsmBEVFZV8X+XKlY1evXql6Cuj9yYmJhohISGGn59f8nVNmjRJrkxnGIZx8uRJo23btkbRokUNSclVztKqqmcYhrF582ajVatWRuHChY1ChQoZjRs3TtGfYdj2Pb+XTz/91JBkFCpUyLh06VKK544cOWI8++yzRrVq1YxChQoZHh4eRqNGjYx58+aluM5afS09ixcvNrp27WpUr17dKFKkiOHs7Gzcd999xnPPPWccOnQoVZ93VrE7deqU8eSTTxpFihQxihYtanTu3Dm5EuAPP/yQfF3Pnj2NwoULp3r9OyvTGUbGf4YdUVVPkhEfH28YRuar6lml97lyZ1W929/3Qw89lDzGqlWrZvTo0SNFZcq0PpPu1uc///xjDBkyxLjvvvsMZ2dno2zZskb79u2NI0eOpLp/woQJhiRjx44dqZ4DkH1MhpGFJ9YBQC61cOFCdevWTVu3bk2zqATurWTJknr++ef17rvv5nQosNGbb76pMWPG6NSpUzYXSkDOaNiwoUwmk3bt2pXToQAFGkv1AOR7ixYt0pkzZ1SnTh2ZzWbt2LFD77zzjlq0aEHSZKP9+/crNDRU//zzj5o0aZLT4SAd1uMAatasqfj4eG3YsEEffPCBunfvTtKUy8XGxurAgQNasWKF9uzZc89DoAFkDxInAPle0aJF9fXXX2vKlCm6evWqvLy81KtXL02ZMiWnQ8tzhgwZoiNHjujll1/Wk08+mdPhIB3u7u4KCQnRyZMnFRcXp/vuu0+vvfaaxowZk9OhIR3h4eF69NFHVapUKY0fP16PP/54TocEFHgs1QMAAACAdFCOHAAAAADSQeIEAAAAAOkgcQIAAACAdBS44hBJSUk6e/asihYt6tBDEQEAAADkLYZh6PLlyypfvny6B4MXuMTp7NmzqlSpUk6HAQAAACCX+Ouvv9I9pqHAJU5FixaVdOubU6xYsRyORoqPj9fatWvVtm1bOTs753Q4yCMYN7AVYwb2YNzAHowb2COnxk1sbKwqVaqUnCPcS4FLnKzL84oVK5ZrEid3d3cVK1aMDxdkGOMGtmLMwB6MG9iDcQN75PS4ycgWHopDAAAAAEA6SJwAAAAAIB0kTgAAAACQDhInAAAAAEgHiRMAAAAApIPECQAAAADSQeIEAAAAAOkgcQIAAACAdJA4AQAAAEA6SJwAAAAAIB0kTgAAAACQDhInAAAAAEgHiRMAAAAApMMppwMoyKqMXPn//2XWkO1rJUnhYwJUsohLzgUFAAAAIJUcnXHatGmTOnbsqPLly8tkMmnZsmXp3rNx40Y1aNBAbm5uqlq1qmbNmpX1gWaBf5Mm6fZ/hvpTwvTglLDsDwgAAADAXeVo4nT16lU98MADmjFjRoauj4iIUHBwsJo3b669e/fq9ddf1+DBg/X9999ncaSOlTJpSu3vKzdJngAAAIBcJEeX6gUFBSkoKCjD18+aNUv33Xefpk+fLkmqVauWdu/erXfffVedO3fOoigdK72kyervKzcVc+Umy/YAAACAXCBP7XHavn272rZtm6ItMDBQs2fPVnx8vJydnVPdExcXp7i4uOTHsbGxkqT4+HjFx8dnbcCZ9J9ZW7V6yMM5HQZyIevYze1jGLkHYwb2YNzAHowb2COnxo0tr5enEqeoqCiVK1cuRVu5cuWUkJCgCxcuyMvLK9U9U6dO1cSJE1O1r127Vu7u7lkW692ZldEVkicvXNGKlaE6etGkDWdNup4oVSps6IkqhlwsWRsl8oawMJZ0wjaMGdiDcQN7MG5gj+weN9euXcvwtXkqcZIkk8mU4rFhGGm2W40aNUrDhw9PfhwbG6tKlSqpbdu2KlasWNYFehfW6nkZYTabNXK3k+ISkpLb/roqbTsvPVChmBb/9yFZzGm/b+Rv8fHxCgsLU0BAQJozrcCdGDOwB+MG9mDcwB45NW6sq9EyIk8lTp6enoqKikrRdv78eTk5OalUqVJp3uPq6ipXV9dU7c7Ozrn+hzk+SVJSUprP/XomVjXHh+l/T/rr6UaVsjcw5Bp5YRwjd2HMwB6MG9iDcQN7ZPe4seW18tQBuE2aNEk1fbd27Vo1bNgwz/xgnnyrvUP7e23Jfvm8vlI3E9JOsAAAAABkXo4mTleuXNG+ffu0b98+SbfKje/bt0+nTp2SdGuZXY8ePZKv79+/v/78808NHz5chw8f1pw5czR79my9/PLLORG+3RydPCUkSTXGrNKLX+1WYpLh0L4BAAAA5HDitHv3btWrV0/16tWTJA0fPlz16tXTuHHjJEmRkZHJSZQkeXt7KzQ0VD///LPq1q2ryZMn64MPPsgzpchvd6/kya+CfXuvVh08p2qvh+qdVUdIoAAAAAAHytE9To888khycYe0zJs3L1Vby5YtFR4enoVRZZ+Tb7VX7NUbevHTtVKRMqpapoheD/bVvr8u6tnPdtjd70cbT+ijjScU0qWunqhfwYERAwAAAAVTnioOkR8VcrGoS1VDwcH/7tNq5F1Srk7mFNX07DHsm32aFnZUm19r5YhQAQAAgAIrTxWHKCgsZpPeetLfIX399c91eY9cqSs3EhzSHwAAAFAQkTjlUk/Ur6DKpQo5pC9Dkt+ENXr0nZ/Y+wQAAADYgcQpF9v4SivVqVDUYf1FRF+Tz+uhWn0g0mF9AgAAAAUBiVMut3xQCx2YECg/ryIO6c+Q1H9+OMkTAAAAYAMSpzygiJuTVgxpqRNvBjusz/E/HNDNhCRtPxGtH/ad0fYT0SzjAwAAAO6Cqnp5iMVs0sm32mvU0r1a9MvZTPV17vJNNZ66TjFX45PbvDzcNL6jr9r5eWU2VAAAACBfYcYpD5r6RD0dmxKkckWdM9XP7UmTJEVduqEXWcYHAAAApELilEe5OJn1y+i2OjAhUEWcHfPPaF2oN3H5IZbtAQAAALchccrjirg56cDkIIclUIakyEs3tDMiJvPBAQAAAPkEiVM+cXsC5YgJqPOXb2S+EwAAACCfIHHKZ4q4Oen4m+3Vs2mlNJ93c8rYP3nZom6SpMQkQ1t/v6B31xzVu2uOaOvxCyzjAwAAQIFDVb18amInf40O9tMX205q18kYubtY1LleRT1UrZRavvOToi7d0N3SH5OkA2cvKeZqnEYvO6CL1/4tIjHjpxNyczKrf8tqGtS6uixmU7a8HwAAACAnkTjlYy5OZvVrUVX9WlRN0T6+o69enB8uk5Rm8mRIemPl4bv2eyMhSdPXH9enm//QtC4PUL4cAAAA+R5L9Qqgdn5e+rh7fXl6uKVo9/Jw08yu9fXGE37KyDzStZuJ6k/5cgAAABQAzDgVUO38vBTg66mdETE6f/mGyhZ1UyPvkrKYTdp+Ivquy/jSMmzxPv0Vc009m3rLJYN7qAAAAIC8hMSpALOYTWpSrVSqdlsr6l2PT9IboUf0ZugRta/jpfefrcfeJwAAAOQrTA8gFWtFPVsZklb8Fqkao0M1PewY1fcAAACQb5A4IZVG3iXlWcy+5EmSEg1p+vrjqjNhDfufAAAAkC+QOCEVi9mkCZ18M92PtXhE6H6SJwAAAORtJE5IUzs/L83qXl+FXSyZ7mvAwnCFsHQPAAAAeRiJE+6qnZ+X9k8I1NDWPnJ1ylyxh/fXH1eDKWEs3QMAAECeROKEe7KYTRoacL8OTQrSgr4PaUDLanb3dfFaPOc+AQAAIE8icUKGWMwmNfMprVeDaqpfc+9M9TVx+SGW7QEAACBP4Rwn2Gx0e1+djL6qsEPn7bo/8tINzdsaoZJFXBVzJU4lC7vI06NQ8gG8AAAAQG5D4gS7fNbjQa3Yd0bDvvlV8XbMHk1eeThVWxFXi/o+XFWDWlcngQIAAECuwlI92K1D3Qo6MiVI7euUc0h/V+ISNX39cdUet5oS5gAAAMhVSJyQKRazSR91a6iZXeupsItjhtONhCQNWBiugQvC2QsFAACAXIHECQ4R7F9e+ye007A21eXugLOfJGnFb5HyHbuK2ScAAADkOBInOIzFbNKQNjX024RADWtTXcULOWe6z7hEQwMWhmtq6CEHRAgAAADYh+IQcDhrAjWwVXXtjIjR+cs3dOFyXJoFITLqk00ReqBicQX7l3dgpAAAAEDGkDghy1jMJjWpVkqSlJhk6PMtEYq6dEP27loa88MBBfp5UXEPAAAA2Y6lesgWFrNJ4zv6ZqqPmKvx2hkRo8QkQ9tPROuHfWe0/UQ0BSQAAACQ5ZhxQrZp5+elj7vX18TlhxR56YZdfaw7FKXh3+xLcb+Xh5vGd/RVOz8vR4UKAAAApEDihGzVzs9LAb6e2hkRo7UHIzV/xymbDtCdvfVkqraoSzf04vxwDW1TQ1VKu6tsUTc18i7Jkj4AAAA4DIkTsp1171OTaqU0pkNtDV60Ryt/O2d3f9a0K2TdseQ2ZqEAAADgSOxxQo66/QBdNyfHDUfrLNTqA5wBBQAAgMwjcUKuEOxfXgcntdPQ1j4q7JryAF0vDzc936yKTf1ZZ6EmLj+krccvUEgCAAAAmcJSPeQaFrNJQwPu16DWNZLPf7LuV9oZEaM5aexvuhdDUuSlG+o2+5fktpKFXTTlMT8F+7OEDwAAABlH4oRc5/bzn6waeZeUl4dbps6BkqSYqzc1YGG4+v3lrdHtM1ceHQAAAAUHS/WQJ9x+DpQjauV9tjlCL83fw9I9AAAAZAiJE/IM6zlQnh5uDulv5YEo+Y5dpdD9FJAAAADAvbFUD3nK7edAnb98QycvXFXIuuMySXYt4YtLNFi6BwAAgHSROCHPuXMP1P2eRTVx+SFFXrphd5+fbY5QkmFobIfajggRAAAA+QyJE/K8O2ehShdx1cCF4frnWrxN/czeclJ7TsbolcBaalytlCxmR+ymAgAAQH7AHifkC9ZZqMfqVlAzn9J64/E6dvWz73Ssus3+RQ9MXMveJwAAACQjcUK+FOzvpX7Nve2+/0pcggYsDNfU0EMOjAoAAAB5FYkT8q3R7X3V5+Eqmerjk00RCt1/1jEBAQAAIM9ijxPytbEdastskj7bfNLuPkYu+U1xCUny9CikRt4l2fsEAABQAJE4Id8b3b626lUqoeHf/KobCUk23x97I0HDvvlVklTE1aK+D1fVoNbVSaAAAAAKEJbqoUAI9i+vg5PaKdivXKb6uRKXqOnrj6vWuNV6f91xJSbZc3oUAAAA8hoSJxQYFrNJM7s3VL/mVTLd182EJIWsO0b1PQAAgAKCxAkFzuj2tTWzaz0VdrVkui9r9b2BC8OZfQIAAMjHSJxQIAX7l9f+8YEa1qa6XC2Z36u0Yn+k6k9eq9UHmH0CAADIj0icUGBZzCYNaVNDhyYHaWhrn0zPQF26nqD+88NJngAAAPIhEicUeBazSUMD7tf+8YFa1K+xQp6uq6Ju9hecnLj8EMv2AAAA8hnKkQP/z2I2qUm1UpIkV4tZAxaG29VP5KUb2hkRk9wXAAAA8j5mnIA0BPt76YUW3nbff/7yDQdGAwAAgJxG4gTcxahgX7ur77lY+NECAADIT1iqB9xDsH95Bfp5accf0XpvzRGF/3UpQ/e9/O2vOnPxuno2rSJni1mJSYZ2RsTo/OUbKlvUTY28S8piznw1PwAAAGQPEicgHRazSc18SquZz8MK3X9Wr3y/X1fjElNdZ5JkSKpcyl1/Rl/TlJWH9c3uv9S+Tnl9veuUIi/9u3yvZGEXPV63vAJ8PUmiAAAA8gASJ8AG1hmoGRuOa+7Wk7p4PT75OU8PN43v6Ku2vp76ds9f+t/qozp27oqOnTuWqp+Yqzc1Z+tJzdl6Ul7/f187P6/sfCsAAACwAYkTYCPr+U8DW1W/6/K7px+8T21qlVPzt3/StZupZ6duF3nphvrPD9fMrvUV7E/yBAAAkBuROAF2ur18eVqOnbuSbtJ0u5cWhavnycoKrO3F8j0AAIBchsQJyCK2liQ3DGnetj81b9ufLN8DAADIZaiZDGSRskXd7L438tINvTg/XKsPRDowIgAAANiLGScgizTyLikvDzdFXbohw477DUkvf7tf128mytOjEMv3AAAAchAzTkAWsZhNGt/RV9KtUuX2uBKXoGHf/KpnP9uhh/+3gRkoAACAHELiBGShdn5e+rh7fXl62L9sz8pafS90P8kTAABAdmOpHpDF2vl5KcDXUzsjYrT2YJTmbTtp19I9q4GLwjX9P/4Oiw8AAADpY8YJyAbW0uXjO9XWR13rZaqvJEMa/M1+7YtmvxMAAEB2IXECslmwf3nN6l5fXplcvjfvmFmTVx7W9hPRSkzKzBwWAAAA0sNSPSAHWJfv7fgjWv2+3G3TQblWhkz6csdf+nLHXypZ2EVTHvNTsD/nPgEAAGSFHJ9xmjlzpry9veXm5qYGDRpo8+bN97x+wYIFeuCBB+Tu7i4vLy/17t1b0dHR2RQt4DgWs0nNfEprWpcHMt1XzNWbGrAwXAMXhjP7BAAAkAVyNHFavHixhg4dqtGjR2vv3r1q3ry5goKCdOrUqTSv37Jli3r06KE+ffro4MGD+vbbb7Vr1y717ds3myMHHKedn5dDlu5J0or9kfIbv1rvrztOAgUAAOBAOZo4TZs2TX369FHfvn1Vq1YtTZ8+XZUqVdLHH3+c5vU7duxQlSpVNHjwYHl7e+vhhx/WCy+8oN27d2dz5IBjtfPz0pbXWmlRv8Z6/5m6Gtq6ut1nP12PT1LIumOqM2ENCRQAAICD5Ngep5s3b2rPnj0aOXJkiva2bdtq27Ztad7TtGlTjR49WqGhoQoKCtL58+f13XffqX379nd9nbi4OMXFxSU/jo2NlSTFx8crPj7eAe8kc6wx5IZYkPMa3ldMUjFJUtVShTT4m/1293XtZqJC1h3TJ5tOqN/DVfRiy6qymKnEV1DxWQN7MG5gD8YN7JFT48aW1zMZhpEjf44+e/asKlSooK1bt6pp06bJ7W+++aa++OILHT16NM37vvvuO/Xu3Vs3btxQQkKCOnXqpO+++07Ozs5pXj9hwgRNnDgxVfvChQvl7u7umDcDZJF90SbNO2aWYff8079czIZal09S24qGyJ8AAACka9euqWvXrrp06ZKKFSt2z2tzvKqeyZTyNzjDMFK1WR06dEiDBw/WuHHjFBgYqMjISL3yyivq37+/Zs+eneY9o0aN0vDhw5Mfx8bGqlKlSmrbtm2635zsEB8fr7CwMAUEBNw1+UPBFSyp3m9RmZp5srqZZNKq0xZtj3bSlMdqK7B2ucwHiDyDzxrYg3EDezBuYI+cGjfW1WgZkWOJU+nSpWWxWBQVFZWi/fz58ypXLu1f6KZOnapmzZrplVdekST5+/urcOHCat68uaZMmSIvr9SlmF1dXeXq6pqq3dnZOVf9MOe2eJB7dKpfSS4uTpq4/JAiL93IdH8Xrydo4Ne/alb3+mrnR/nygobPGtiDcQN7MG5gj+weN7a8Vo4Vh3BxcVGDBg0UFhaWoj0sLCzF0r3bXbt2TWZzypAtFoukWzNVQH51e/GI1jXLOKTPicsPUTgCAAAgg3K0qt7w4cP1+eefa86cOTp8+LCGDRumU6dOqX///pJuLbPr0aNH8vUdO3bUkiVL9PHHH+uPP/7Q1q1bNXjwYDVq1Ejly5fPqbcBZAuL2aQm1Uppdq9G+qCLv1zNmUt6Ii/d0M6IGAdFBwAAkL/l6B6np59+WtHR0Zo0aZIiIyPl5+en0NBQVa5cWZIUGRmZ4kynXr166fLly5oxY4ZGjBih4sWLq1WrVvrf//6XU28ByBFBdTyVeCpcEYXu1+dbT+razUS7+jl/OfNL/wAAAAqCHC8OMWDAAA0YMCDN5+bNm5eqbdCgQRo0aFAWRwXkfmaTNKhVNQ0JuF8zNhzXJ5v+sDmBKuqa4x8BAAAAeUKOLtUDkHkWs0lD2tTQbxMCNaxNdbm7WDJ878vf/qovt59UfGJSFkYIAACQ95E4AflERhMoa7H/ckVdFXMtXuN+OKi2IZu06rfIFEVWEpMMbT8RrR/2ndH2E9EUkgAAAAUa63SAfMaaQA1sVV0zNhzX3K0ndfH6v6die3q4aXxHX7WuVU5f7/pL7687pogLV/XignDVv6+4Xg+upQtX4lKVP/f6//soYQ4AAAoiEicgn7o9gdoZEaPzl2+obFE3NfIuKYv51rzTc40r64l6FfTppj/02aY/FH7qop6atT3N/qIu3dCL88P1Mec/AQCAAojECcjnrGXM76aIq5OGB9RQ94fu03thx7R4119pXmfo1jK/icsPqVXNctrz5z9pJmMAAAD5EYkTAElS2WJuerxuhbsmTtKt5Cny0g01nrpOMVf/Xf7HMj4AAJDfURwCQLKMnut0e9Ik3Uqm+s8PV+j+yKwICwAAIMeROAFIVraoW6buf2lhuELCjlGBDwAA5DskTgCSNfIuKS8PN9m7W8mQ9P7643pg4lpNWn6QMuYAACDfIHECkMxiNml8R19Jsjt5kqQrcQmas/Wknv1shxpMDtP7646TQAEAgDyNxAlACu38vPRx9/ry9Ei5bK9UYRe7+rt4PV4h646pwZQwrT7AHigAAJA3UVUPQCrt/LwU4OuZ4vynBpVLqOU7P6U4FNcWF6/Fq//8cM3sWl/B/lTfAwAAeQszTgDSZD3/6bG6FdSkWim5OJmTl/FlBgUkAABAXkTiBCDD2vl5aWbX+srMWbcUkAAAAHkRiRMAmwT7e2nGs/Uy3c/tBSQe/t8G9j8BAIBcjcQJgM2C/ctrVvf6Ku7u7JD+OEAXAADkdiROAOzSzs9Le8YEaFib6ipeyDEJFPufAABAbkXiBMBuFrNJQ9rU0J6xAVrUr7H6NKuiwq4Wu/uz7n+idDkAAMhtSJwAZJq1At/YjrW1f3yghraunqkDdK2ly1m6BwAAcgsSJwAOZTGbNDSghj7qmvkCEizdAwAAuQWJE4As4YgCEizdAwAAuQWJE4As46gCEtaleyRPAAAgpzjldAAA8jdrAYmBraprZ0SM1h6M0rxtJ2XP4ruRS35TUVdnNa5WSpbMnMILAABgIxInANnCWkCiSbVSerBKCQ1YuNfmPi5ei1e32b+oZGEXPV63vAJ8PdXIuyRJFAAAyHIs1QOQ7TK7/ynm6k3N2XpSz362Qw//bwNL+AAAQJYjcQKQI6z7nzJbujzy0g1KlwMAgCxH4gQgxziydPnAReEK3X/WAVEBAACkRuIEIMc5onR5kiENWLiXZXsAACBLUBwCQK7Qzs9LAb6emrHhuOZuPamL1+Pt6mf00gO6fjNRnh6FKBwBAAAchsQJQK5xe+nyHX9E66UF4TYnUNFXb2rYN79KkooXclbvZt4a2MqHBAoAAGQKS/UA5DoWs0nNfErrrc51ZJLsLh5x8Xq8QtYd0wMT12rS8oPafiJaiUn2nCAFAAAKOhInALlWOz8vfdy9vjw93DLVz5W4BMqXAwCATCFxApCrtfPz0pbXWmlRv8bq3bRKpkqXS7fKl784P5zkCQAA2IQ9TgByPYvZpCbVSqlJtVJ6sEoJDVi4N1P9GZJGLvlNRV2d1bhaKfY/AQCAdDHjBCBPsZYu98rk8r2L1+LVbfYvajA5TO+vO87eJwAAcE/MOAHIc6yly3dGxCgq9oYmrziomKv2lS+3FpD4ZNMJvdCiGhX4AABAmphxApAnWZfvPVGvgt58ok6m9z5du5mokHXHVGfCGmagAABAKiROAPI8a/W94u7Ome7LmkA1mBJGAQkAAJCMxAlAvtDOz0t7xgRoWJvqKl4o8wnUxWvx6j8/XKH7SZ4AAACJE4B8xGI2aUibGtozNkCL+jVWn2ZVVLJw5pKolxaGKyTsGEv3AAAo4EicAOQ71v1PYzvW1q7RAVrQ9yG7Z6EMSe+vP87eJwAACjgSJwD5msVsUjOf0nqrc+YKSFA8AgCAgo3ECUCB4KgCEiRQAAAUTCROAAqM2wtIuLtYMtUXCRQAAAULiROAAsVaQOK3CYEOTaAoXw4AQP5mc+J09epVjR07Vk2bNpWPj4+qVq2a4gsA8oLbE6ihratn+gBdypcDAJC/Odl6Q9++fbVx40Y999xz8vLyksmU2V83ACDnWMwmDQ2ooRrlimjAwr2Z7u+lReH6MKmeOtQt74DoAABAbmFz4rRq1SqtXLlSzZo1y4p4ACBHBPuX1yyzSSOX/KaL1+Lt7scwpIFf79WSfafVr3k1NfIuKYuZPzABAJDX2Zw4lShRQiVLlsyKWAAgR7Xz81KAr6dmbDiuTzb9oWs3E+3ua8ORv7XhyN8qXshZvZt5a2ArHxIoAADyMJv3OE2ePFnjxo3TtWvXsiIeAMhRji4ecfF6PNX3AADIB2yecXrvvfd04sQJlStXTlWqVJGzc8ozUcLDwx0WHADkFGsCNbBVdYfMQFmr783dFqG3nqyjdn5eDowWAABkNZsTp8cffzwLwgCA3MnRCZS1+t6s7vVJngAAyENsTpzGjx+fFXEAQK52ewL14frjmr7+eKb6G730gK7fTJSnRyEKSAAAkAfYnDhZ7dmzR4cPH5bJZJKvr6/q1avnyLgAIFeyli/3KVNEA7+2v3x59NWbGvbNr5IkLw83je/oywwUAAC5mM2J0/nz5/XMM8/o559/VvHixWUYhi5duqRHH31UX3/9tcqUKZMVcQJArtKhbnn9dvaiPtkUkem+Ii/dUP/54ZrZtb6C/UmeAADIjWyuqjdo0CDFxsbq4MGDiomJ0T///KMDBw4oNjZWgwcPzooYASBXGhXsq5ld66lkYef0L86AlxaGKyTsGJX3AADIhWyecVq9erXWrVunWrVqJbf5+vrqo48+Utu2bR0aHADkdsH+5RXo56WdETFadyhKX+/+S1fj7CseYUh6f/1xzd4SoS4NKyrA15P9TwAA5BI2J05JSUmpSpBLkrOzs5KSkhwSFADkJRazSU2qlVKTaqX0envfTFffuxKXoDlbT2rO1pMcoAsAQC5h81K9Vq1aaciQITp79mxy25kzZzRs2DC1bt3aocEBQF5z5wG6xQtlbhmf9QDdBlPCtPpApIOiBAAAtrI5cZoxY4YuX76sKlWqqFq1avLx8ZG3t7cuX76sDz/8MCtiBIA8x5pA7RkboEX9Givk6bqZ2gtlPf8pdD/JEwAAOcHmpXqVKlVSeHi4wsLCdOTIERmGIV9fX7Vp0yYr4gOAPM26jE+SCjmb1X9+eKb6e2lhuAafq67BrauzdA8AgGxk9zlOAQEBCggIcGQsAJCvtfPz0syu9TVwUbjsLZxnLSDxxfaTeuvJOpz9BABANslQ4vTBBx/ov//9r9zc3PTBBx/c81pKkgPA3QX7e2mG6mnAQvsPz5X+XbrH2U8AAGSPDCVOISEh6tatm9zc3BQSEnLX60wmE4kTAKQj2L+8ZplNGrnkN128Fp+pvli6BwBA9shQ4hQREZHmfwMA7NPOz0sBvp6aseG45m49qYvX7UugWLoHAED2sLmq3qRJk3Tt2rVU7devX9ekSZMcEhQAFAR3Vt7r06yKCrta7OrLunSPkuUAAGQNmxOniRMn6sqVK6nar127pokTJzokKAAoSKyV98Z2rK394wM1tHV12bvobuLyQ0q0t/IEAAC4K5sTJ8MwZDKl/l/6r7/+qpIlSzokKAAoqCxmk4YG1NBHXevZdX/kpRvaGRHj4KgAAECGy5GXKFFCJpNJJpNJNWrUSJE8JSYm6sqVK+rfv3+WBAkABU1mCkicv3wji6ICAKDgynDiNH36dBmGoeeff14TJ06Uh4dH8nMuLi6qUqWKmjRpkiVBAkBBZC0g8eH643p//XFldAFe2aJuWRoXAAAFUYYTp549e0qSvL291axZMzk52X12LgAgg6xL92qUK5Khs5/MJik+IUmSlJhkaGdEjM5fvqFS7k52H7oLAABsSJysrl69qvXr1yswMDBF+5o1a5SUlKSgoCCHBQcAuCWjS/eSDKnH3J1qU6usDpy5pKjYuOTnirtY5FzlnDrUrZgdIQMAkK/YXBxi5MiRSkxMTNVuGIZGjhzpkKAAAKm18/PSnjEBGtamuooXck7xnJeHm95/pq66PXSfJGnd4fMpkiZJunhTGvj1r3p/3XEq7wEAYCObZ5yOHz8uX1/fVO01a9bU77//7pCgAABps579NLBV9eRleGWLuqmRd0lZzCZ18C+v0N8i9U+as1K3ivqErDumRTv/1IROtTkwFwCADLJ5xsnDw0N//PFHqvbff/9dhQsXtjmAmTNnytvbW25ubmrQoIE2b958z+vj4uI0evRoVa5cWa6urqpWrZrmzJlj8+sCQF5mPfvpsboV1KRaKVnMt5KinRExd0maUoqKjVP/+eHMPgEAkEE2J06dOnXS0KFDdeLEieS233//XSNGjFCnTp1s6mvx4sUaOnSoRo8erb1796p58+YKCgrSqVOn7npPly5dtH79es2ePVtHjx7VokWLVLNmTVvfBgDkS7aWIg9Zd0z1J60lgQIAIB02J07vvPOOChcurJo1a8rb21ve3t6qVauWSpUqpXfffdemvqZNm6Y+ffqob9++qlWrlqZPn65KlSrp448/TvP61atXa+PGjQoNDVWbNm1UpUoVNWrUSE2bNrX1bQBAvmRPKfJLNxIUsu6YHpi4VqH7I7MgKgAA8j6b9zh5eHho27ZtCgsL06+//qpChQrJ399fLVq0sKmfmzdvas+ePakKSrRt21bbtm1L854ff/xRDRs21Ntvv62vvvpKhQsXVqdOnTR58mQVKlQozXvi4uIUF/fvBunY2FhJUnx8vOLjbTtUMitYY8gNsSDvYNzgbupVLCrPYq46FxuX4XOfrK7EJWjAwnC1319O7/3HP3n5HwouPmtgD8YN7JFT48aW17PrMCaTyaS2bduqRYsWcnV1lclk+/9cL1y4oMTERJUrVy5Fe7ly5RQVFZXmPX/88Ye2bNkiNzc3LV26VBcuXNCAAQMUExNz131OU6dO1cSJE1O1r127Vu7u7jbHnVXCwsJyOgTkQYwbpCXY06Q5sdYFBbZ/Pq88cE5rD65VmwpJalvREPkT+KyBPRg3sEd2j5tr165l+FqbE6ekpCS98cYbmjVrls6dO6djx46patWqGjt2rKpUqaI+ffrY1N+dSZdhGHdNxJKSkmQymbRgwQJ5eHhIurXc76mnntJHH32U5qzTqFGjNHz48OTHsbGxqlSpktq2batixYrZFGtWiI+PV1hYmAICAuTs7Jz+DYAYN7i3YEn1D57TlNAjqUqSZ1S8YdKq0xZtPG9Rv4er6MWWVZmBKoD4rIE9GDewR06NG+tqtIywOXGaMmWKvvjiC7399tvq169fcnudOnUUEhKS4cSpdOnSslgsqWaXzp8/n2oWysrLy0sVKlRITpokqVatWjIMQ6dPn1b16tVT3ePq6ipXV9dU7c7Ozrnqhzm3xYO8gXGDu+lQt6KC/CtoxobjCll33O5+rt1M1PsbTuiLHaf01pN1KF9eQPFZA3swbmCP7B43tryWzcUhvvzyS3366afq1q2bLBZLcru/v7+OHDmS4X5cXFzUoEGDVNNxYWFhdy320KxZM509e1ZXrlxJbjt27JjMZrMqVqxo4zsBgPzNeubTrO715Vks9R+QbHHxWrz6zw+neAQAoMCyOXE6c+aMfHx8UrUnJSXZvJlr+PDh+vzzzzVnzhwdPnxYw4YN06lTp9S/f39Jt5bZ9ejRI/n6rl27qlSpUurdu7cOHTqkTZs26ZVXXtHzzz9/1+IQAFDQtfPz0s8jWiioYmKm+xq4KFyh+886ICoAAPIWmxOn2rVrp3lI7bfffqt69erZ1NfTTz+t6dOna9KkSapbt642bdqk0NBQVa5cWZIUGRmZ4kynIkWKKCwsTBcvXlTDhg3VrVs3dezYUR988IGtbwMAChSL2aR2lQzNeOYBFXe3fwlEkiENWLhXk5Yf1PYT0Zz9BAAoMGze4zR+/Hg999xzOnPmjJKSkrRkyRIdPXpUX375pVasWGFzAAMGDNCAAQPSfG7evHmp2mrWrEmVFgCwU2Dtcgryr6ChX4dr+f60K5hmxJytJzVn60kVL+Ss3s28NbCVD8UjAAD5ms0zTh07dtTixYsVGhoqk8mkcePG6fDhw1q+fLkCAgKyIkYAgANZzCZ92LWBZnatp8KulvRvuIeL1+MVsu6Y6kxYo/fXHWcGCgCQb9l1jlNgYKACAwMdHQsAIBsF+5dXoJ+XZmw4rk82/aFrN+3fA3XtZqJC1h3T3G0RVN8DAORLNs84AQDyD2vlvd8mBGpYm+pyd8nkDBTV9wAA+VSGEqeSJUvqwoULkqQSJUqoZMmSd/267777FBQUpP3792dp4AAAx7k9gRrauroyu1vppYXhCgk7xtI9AEC+kaGleiEhISpatKgkafr06fe8Ni4uTqGhoerdu7f27NmT6QABANnHYjZpaEAN1ShXRAMW7rW7H0PS++uP67PNf+iFFtUoHgEAyPMylDj17Nkzzf++m6CgIDVo0MD+qAAAOSrYv7xmmU2auPyQIi/dsLsf696nTzadIIECAORpdu1xunjxoj7//HONGjVKMTExkqTw8HCdOXNGklSpUiWdP3/ecVECALJdOz8vbXmtlRb1a6w+zapkqi9rAtVgSphWH2D/EwAg77E5cdq/f79q1Kih//3vf3r33Xd18eJFSdLSpUs1atQoR8cHAMhBFrNJTaqV0tiOtTWre/1MHZ4rUTwCAJB32Zw4DR8+XL169dLx48fl5uaW3B4UFKRNmzY5NDgAQO7Rzs9Le8YEOKT6HsUjAAB5jc2J065du/TCCy+kaq9QoYKiouw/hR4AkPs5qvqetXgES/cAAHmFzYmTm5ubYmNjU7UfPXpUZcqUcUhQAIDczVp976Ou9TLVD0v3AAB5hc2J02OPPaZJkyYpPj5ekmQymXTq1CmNHDlSnTt3dniAAIDcK9i/vEP2Pr20KFwTfjyg7SeiWb4HAMiVbE6c3n33Xf39998qW7asrl+/rpYtW8rHx0dFihTRG2+8kRUxAgByMUfsfTIMad62P/XsZzv08P82sHwPAJDrZOgcp9sVK1ZMW7Zs0YYNGxQeHq6kpCTVr19fbdq0yYr4AAB5gHXv08BW1TVjw3F9sukPXbuZaFdfkZdu6MX54fq4e3218/NycKQAANjH5sTJqlWrVmrVqlXy4/DwcI0bN04rVqxwSGAAgLzn9gTqw/XH9f7647J34d3E5YcU4OvJgbkAgFzBpqV6YWFheuWVV/T666/rjz/+kCQdOXJEjz/+uB588EElJCRkSZAAgLwls8UjDN2aedoZEePYwAAAsFOGE6cvvvhCgYGBmjt3rt566y01btxY8+fPV6NGjVSiRAn9+uuvWr16dVbGCgDIYzJbPOL85RsOjggAAPtkOHEKCQnRm2++qQsXLujrr7/WhQsXFBISor1792ru3Lny8/PLyjgBAHmUtXiEPec+lSnimiUxAQBgqwwnTidOnNDTTz8tSXrqqadksVg0bdo0VatWLcuCAwDkD/Yu3Xtr1WH9+tfFrAkKAAAbZDhxunr1qgoXLnzrJrNZbm5uqlSpUpYFBgDIf6xL97w83O56jXVWys3JrP1nYvX4zK0atWS/Yq7ezJ4gAQBIg01V9dasWSMPDw9JUlJSktavX68DBw6kuKZTp06Oiw4AkO+08/NSgK+ndkbEaN2hKC3dd0YxV+OTn/f0cNP4jr6qf18JTV11REv3ntGinX9p1YEovdz2fj3b6D4q7QEAsp1NiVPPnj1TPH7hhRdSPDaZTEpMtO/cDgBAwWExm9SkWik1qVZKr7f31c6IGJ2/fENli7qpkXfJ5MQo5Om6erbRfRr3wwEdibqsMcsOaPGuvzTpsdqqd18JSVJiknHX+wEAcJQMJ05JSUlZGQcAoICyJlF308i7pFYMelhf7fhT09Ye029nLumJmdvUpWFFPVilpKaFHVPkpX+r7xUv5Kzezbw1sJUPCRQAwGFsOscJAICc4GQxq3czb214+RF1rl9RkvTN7tN65bv9KZImSbp4PV4h646pwZQwrT4QmRPhAgDyIRInAECeUaaoq97r8oC+eaGxnNKZTbp4LV7954fr/XXHlZhkZFOEAID8isQJAJDnJCZJCRlMhkLWHVOzt9Yz+wQAyBQSJwBAnnP+8o30L7pNVGyc+s8P16TlB7X9RDQzUAAAm9lUVQ8AgNygbNG7nwN1L3O2ntScrScpIAEAsBkzTgCAPKeRd8l7HqKbHgpIAABslaEZpxIlSshkythf5GJiYjIVEAAA6bGYTRrf0Vcvzg9XZhbdWQtIDGtTg9knAMA9ZShxmj59evJ/R0dHa8qUKQoMDFSTJk0kSdu3b9eaNWs0duzYLAkSAIA7tfPz0sfd62vkkt908Vp8pvoKWXdMc7b8oecfrkoCBQBIU4YSp549eyb/d+fOnTVp0iQNHDgwuW3w4MGaMWOG1q1bp2HDhjk+SgAA0tDOz0sBvp6aseG45mw9qUvX7U+gLt1IUMi6Y/pk0wm90KIaCRQAIAWb9zitWbNG7dq1S9UeGBiodevWOSQoAAAyymI2aUibGgofG6Bhbapnur9rNxMVsu6Y6kxYwxlQAIBkNidOpUqV0tKlS1O1L1u2TKVKlXJIUAAA2MqaQM3qXj9ThSOsrAkUBSQAAJId5cgnTpyoPn366Oeff07e47Rjxw6tXr1an3/+ucMDBADAFtblezsjYrTuUJRmbz2Zqf6sBSRmdq2vYH8vxwQJAMhzbJ5x6tWrl7Zt26bixYtryZIl+v777+Xh4aGtW7eqV69eWRAiAAC2sZhNalKtlMZ2rK1Z3euruLtzpvscuChcofvPOiA6AEBeZNcBuA899JAWLFjg6FgAAHA4RxWQSDKkAQv3atj5qxSOAIACyK7EKSkpSb///rvOnz+vpKSkFM+1aNHCIYEBAOAo1v1PA1tV14wNxxWy7rjdfVG6HAAKJpsTpx07dqhr1676888/ZRgpKw2ZTCYlJiY6LDgAABzJmkDd71k0U+c/UbocAAoem/c49e/fXw0bNtSBAwcUExOjf/75J/krJiYmK2IEAMCh2vl5ac+YW+XL3V0sdvdjrbz3wMS1Ct1P5T0AyM9snnE6fvy4vvvuO/n4+GRFPAAAZIs7l+99sukPXbtp36qJK3EJGrAwXC+c9taoYF8HRwoAyA1snnF66KGH9Pvvv2dFLAAAZDtrAvXbhEANbV1dmVlw98mmCCrvAUA+ZfOM06BBgzRixAhFRUWpTp06cnZOWeLV39/fYcEBAJBdLGaThgbUUI1yRTRg4V67+xm55De18fWUi5PNf5sEAORiNidOnTt3liQ9//zzyW0mk0mGYVAcAgCQ5wX7l9css0kTfjykqNgbNt8feyNBjaeu05tP1FE7Pw7MBYD8wubEKSIiIiviAAAg17j97Cd7SpfHXI1X//nher5ZFQX4eqqRd0mq7gFAHmdz4lS5cuWsiAMAgFzFEaXL52w9qTlbT8rLw03jO/oyAwUAeZjNidOXX355z+d79OhhdzAAAOQ2t88+2Vt5L/LSDfWfH65hbWpw5hMA5FE2J05DhgxJ8Tg+Pl7Xrl2Ti4uL3N3dSZwAAPnO7aXLh34druX7o+zqJ2TdMc3Z8oeef7gqCRQA5DE2l/y5/cDbf/75R1euXNHRo0f18MMPa9GiRVkRIwAAuYLFbNKHXRtoZtd6Kupm898eJUmXbiRwaC4A5EEOqZVavXp1vfXWW6lmowAAyI+C/ctrz5gAlSzsnP7Fd2E9NHfgwnAlJhkOjA4AkBUcdsiExWLR2bMc+gcAKBhcnMx684k6MkmZOjR3xf5I+Y1frffXHSeBAoBczOZ1Bj/++GOKx4ZhKDIyUjNmzFCzZs0cFhgAALldOz8vfdy9viYuP6TIS7af+WR1PT5JIeuOae62CL31JOc/AUBuZHPi9Pjjj6d4bDKZVKZMGbVq1Urvvfeeo+ICACBPsFbd2xkRo3WHojR760m7+7p4LZ7qewCQS9mcOCUlJWVFHAAA5FkWs0lNqpVSk2ql9KB3SU348ZCiYu2fgaL6HgDkPpna42QYhgyD9dgAAFi18/PS1pGtNKxN9Uz1Y62+12BKmFYfoPoeAOQ0uxKnL7/8UnXq1FGhQoVUqFAh+fv766uvvnJ0bAAA5EnWc59mda+v4u72V96T/l2+N2n5QW0/EU0BCQDIITYv1Zs2bZrGjh2rgQMHqlmzZjIMQ1u3blX//v114cIFDRs2LCviBAAgz7Huf8rMoblWc7ae1JytJ+Xl4abxHX0pIAEA2czmxOnDDz/Uxx9/rB49eiS3PfbYY6pdu7YmTJhA4gQAwG2sh+YG+Z3VK9/v19W4xEz1F3nphl6cH66Pu9cneQKAbGTzUr3IyEg1bdo0VXvTpk0VGckabAAA0hLsX177xwdqWJvqcnexZKovQ9KIb37V1uMXWLoHANnE5sTJx8dH33zzTar2xYsXq3r1zG2EBQAgP7Puffptwq0EyqOQ/fufrt5MVLfZv+jBN9YpdD9/uASArGbzUr2JEyfq6aef1qZNm9SsWTOZTCZt2bJF69evTzOhAgAAKVkTqIGtqmvGhuMKWXfc7r5irt7UgIXheuG0t0YF+zowSgDA7WyecercubN27typ0qVLa9myZVqyZIlKly6tnTt36oknnsiKGAEAyJccWX3vk00RCt1/1kGRAQDuZNOMU3x8vP773/9q7Nixmj9/flbFBABAgWKtvjdjw3HN3XpSF6/H29XPmB8OKNDPiwNzASAL2DTj5OzsrKVLl2ZVLAAAFFjW2ac9YwO0qF9jBfl52txHzNV47YyIyYLoAAA2L9V74okntGzZsiwIBQAAWMwmNalWSjO62rd87/zlG0pMMrT9RLR+2HeGQ3MBwEFsLg7h4+OjyZMna9u2bWrQoIEKFy6c4vnBgwc7LDgAAAoqi9mkt56so/7zw22679e/LuqtVUcUeelGclvJwi56vG55Bfh6qpF3SZbyAYAdbE6cPv/8cxUvXlx79uzRnj17UjxnMplInAAAcJB2fl6a1b2+Ji4/lCIRupc5W0+maou5elNztp7UnK0n5eXhpvEdfTk8FwBsZHPiFBERkRVxAACANFgLR+yMiNHnm09o/ZG/73qtk9mkhHSW5UVeuqH+88M1rE0NDWzlw+wTAGSQzXucAABA9rLue5rdq5Fmdq2nkoVT7n3y8nDTsDY10k2abhey7pjqT1qr99cdZw8UAGSAzTNOw4cPT7PdZDLJzc1NPj4+euyxx1SyZMlMBwcAAFIK9i+vQD8v7YyI0fnLN1S2qJsaeZfUCjvOcLp0I0Eh647ps81/6O3O/gr2Z/keANyNzYnT3r17FR4ersTERN1///0yDEPHjx+XxWJRzZo1NXPmTI0YMUJbtmyRry8nmAMA4GjWGajblS3qZnd/V+ISNGBhuDoc8NL7z9Rj+R4ApMHmpXqPPfaY2rRpo7Nnz2rPnj0KDw/XmTNnFBAQoGeffVZnzpxRixYtNGzYsKyIFwAApKGRd0l5ebgpMynPiv2R8p+wRqH7Ix0WFwDkFzYnTu+8844mT56sYsWKJbcVK1ZMEyZM0Ntvvy13d3eNGzcuVcU9AACQdSxmk8Z3vLXSIzPJ09WbiRqwMFzPz9upXyJixPYnALjF5sTp0qVLOn/+fKr2v//+W7GxsZKk4sWL6+bNm5mPDgAAZFg7Py993L2+PD3sX7ZnteHI3+o+Z7cmhlu05uA5B0QHAHmbXUv1nn/+eS1dulSnT5/WmTNntHTpUvXp00ePP/64JGnnzp2qUaNGhvqbOXOmvL295ebmpgYNGmjz5s0Zum/r1q1ycnJS3bp1bX0LAADkW+38vLTltVZa1K+x+jSrohLuzunfdA8Xb0oDv/6V5XsACjybE6dPPvlErVu31jPPPKPKlSvrvvvu0zPPPKPWrVvr448/liTVrFlTn3/+ebp9LV68WEOHDtXo0aO1d+9eNW/eXEFBQTp16tQ977t06ZJ69Oih1q1b2xo+AAD5nrV4xNiOtbV7TICGtameid5uLfwbuChcoXZU7gOA/MLmxKlIkSL67LPPFB0dnVxhLzo6Wp9++qmKFCkiSapbt26GZoKmTZumPn36qG/fvqpVq5amT5+uSpUqJSdgd/PCCy+oa9euatKkia3hAwBQoFjMJg1pU0OzutdX8UzMPiUZ0oCFe7X6ADNPAAomm8uRr1+/Xq1bt1aRIkXk7++f4rkZM2Zo4MCBGern5s2b2rNnj0aOHJmivW3bttq2bdtd75s7d65OnDih+fPna8qUKem+TlxcnOLi4pIfW/dhxcfHKz4+PkOxZiVrDLkhFuQdjBvYijGD1veX1o7XHtHwb/cr9ID9e5ZeX/Kb9p2KkdlkUmPvkmrkXZLy5UiBzxvYI6fGjS2vZ3Pi1LlzZ4WFhenBBx9M0T59+nSNGzcuw4nThQsXlJiYqHLlyqVoL1eunKKiotK85/jx4xo5cqQ2b94sJ6eMhT516lRNnDgxVfvatWvl7u6eoT6yQ1hYWE6HgDyIcQNbMWYQWFQqW92kRSfMikuyPeGJuRavWZtOSpJmboyQi9lQ6/JJalvREPkTbsfnDeyR3ePm2rVrGb7W5sQpJCREwcHB2rhxY/IBt++++64mT56slStX2tqdTKaUn7KGYaRqk6TExER17dpVEydOzHDhCUkaNWqUhg8fnvw4NjZWlSpVUtu2bVOUVM8p8fHxCgsLU0BAgJydM7eBFwUH4wa2YszgdsGSRiYZmZ59kqSbSSatOm3RxvMW9Xu4il5sWZUZqAKOzxvYI6fGjXU1WkbYnDj17t1b0dHRatu2rbZs2aLFixfrzTff1KpVq9S0adMM91O6dGlZLJZUs0vnz59PNQslSZcvX9bu3bu1d+/e5FmtpKQkGYYhJycnrV27Vq1atUp1n6urq1xdXVO1Ozs756of5twWD/IGxg1sxZiBlbOkmd0bKnT/WY354YBirmZuecy1m4l6f8MJzd76p97u7K9gfy/HBIo8i88b2CO7x40tr2Vz4iRJL7/8sqKjo9WwYUMlJiZq7dq1euihh2zqw8XFRQ0aNFBYWJieeOKJ5PawsDA99thjqa4vVqyYfvvttxRtM2fO1IYNG/Tdd9/J29vbnrcCAECBFuxfXoF+XtoZEaO1B6M0b9tJZebM2ytxCRqwMFz9/vLW6Pa+DosTAHJahhKnDz74IFWbl5eX3N3d1aJFC/3yyy/65ZdfJEmDBw/O8IsPHz5czz33nBo2bKgmTZro008/1alTp9S/f39Jt5bZnTlzRl9++aXMZrP8/PxS3F+2bFm5ubmlagcAABlnLV/epFopPVilhAYs3JvpPj/bHKFdEdF6JbCWGlcrxfI9AHlehhKnkJCQNNstFou2bt2qrVu3Srq1X8mWxOnpp59WdHS0Jk2apMjISPn5+Sk0NFSVK1eWJEVGRqZ7phMAAHCcYP/ymmU2aeLyQ4q8dCNTfe07Hatus39REVcnlu8ByPMylDhFRERkWQADBgzQgAED0nxu3rx597x3woQJmjBhguODAgCgAGvn56UAX09t//281mz6RSvOuumfa/bvgWL5HoD8wOYDcAEAQP5nMZv0kHdJNSxjaHInxyQ7n22O0Evz9ygxKTO7qAAgZ9icOD311FN66623UrW/8847+s9//uOQoAAAQO4RWLucZnWvr+Luma90tfJAlHzHrlLo/kgHRAYA2cfmxGnjxo1q3759qvZ27dpp06ZNDgkKAADkLu38vLRnTIAW9H1IQX6ecnWyf9FKXKKhAQvDNXBhOLNPAPIMmz/1rly5IhcXl1Ttzs7ONh0gBQAA8haL2aRmPqX1cfcGOjSpndrX8cxUfyv2R8p/whpmnwDkCTYnTn5+flq8eHGq9q+//lq+vmz4BACgILCYTfqoWwP1a14lU/1cvZnI7BOAPMHmA3DHjh2rzp0768SJE2rVqpUkaf369Vq0aJG+/fZbhwcIAAByr9Hta6tepRJ65fv9uhqXaHc/K/ZH6qcj5/XOUw9QthxArmTzjFOnTp20bNky/f777xowYIBGjBih06dPa926dXr88cezIEQAAJCbBfuX1/7xgRrWprpcLfYfdGudfeo9d6e2n4hmBgpArmLzjJMktW/fPs0CEQAAoGCymE0a0qaGBraqrkEL9yj0wDm7+/rp6N/66ejf8vJw0/iOvmrnxwwUgJzHOU4AAMBhLGaTZnZvmOm9T5IUeemGXpwfrtUHKB4BIOfZnDglJibq3XffVaNGjeTp6amSJUum+AIAABjdvrZmdq0nt0yULZckQ9LIJb9p6/ELLN0DkKNs/jSbOHGipk2bpi5duujSpUsaPny4nnzySZnNZk2YMCELQgQAAHlRsH95HZzUTkNb+8jVyf69Txevxavb7F/04BvrKF0OIMfYnDgtWLBAn332mV5++WU5OTnp2Wef1eeff65x48Zpx44dWREjAADIoyxmk4YG3K9Dk4LU0T9z5z7FXL2pAQvD9cbKQw6KDgAyzubEKSoqSnXq1JEkFSlSRJcuXZIkdejQQStXrnRsdAAAIF+wmE36sGsDzexaT4VdLZnq67PNEXppwR6W7gHIVjYnThUrVlRk5K1pch8fH61du1aStGvXLrm6ujo2OgAAkK9YS5e3r5O52aeVv0XJb/xqvb/uOAkUgGxhc+L0xBNPaP369ZKkIUOGaOzYsapevbp69Oih559/3uEBAgCA/MViNumjbg0yXXnvenySQtYdU+1xqzU97BgJFIAsZfM5Tm+99Vbyfz/11FOqWLGitm3bJh8fH3Xq1MmhwQEAgPxrdPvaqlephMb8cEAxV+Pt7udGQpKmrz+umRtP6KVHfDSwlY8sZvuLUQBAWuw6APd2jRs3VuPGjR0RCwAAKGCC/csr0M9LOyNiFBV7Qxcuxylk3VFdu5lkc183E27NQH22+Q+93dlfwf4cnAvAcWxOnKKjo1WqVClJ0l9//aXPPvtM169fV6dOndS8eXOHBwgAAPI3i9mkJtVKJT+uULyQBiwMt7u/K3EJGrAwXP3+8tbo9r6OCBEAMr7H6bffflOVKlVUtmxZ1axZU/v27dODDz6okJAQffrpp3r00Ue1bNmyLAwVAAAUBMH+XurX3DvT/Xy2OUKTVxx0QEQAYEPi9Oqrr6pOnTrauHGjHnnkEXXo0EHBwcG6dOmS/vnnH73wwgsp9j8BAADYa3R730wXj5Ck2VtO6vEZW/TumiPaevwCBSQA2C3DS/V27dqlDRs2yN/fX3Xr1tWnn36qAQMGyGy+lXsNGjSIvU4AAMBhrMUjXvl+v67GJdrdz77Tl7Tv9CXN+OmEirg6sf8JgF0yPOMUExMjT89bZy4UKVJEhQsXVsmSJZOfL1GihC5fvuz4CAEAQIFlPfdpWJvqcnfJ3MG50r/7nwYuDGf2CYBNbDrHyWQy3fMxAACAo1nMJg1pU0O/TQhUR//MHZxrtWJ/pHzHruL8JwAZZlNVvV69esnV1VWSdOPGDfXv31+FCxeWJMXFxTk+OgAAgP9nMZv0YdcGCvI7m+nle5IUl2ho+vrjmrXxhKZ1qcvyPQD3lOHEqWfPniked+/ePdU1PXr0yHxEAAAA92A9+2nHH9F6Z80R7fvrUqb6u5GQRPlyAOnKcOI0d+7crIwDAAAgwyxmk5r5lFYzn4c1ecVBzd5yMtN9frY5QmcvXtcHz9aXxcx2BAAp2bTHCQAAILcZ26G2Q0qXS9LK36LkP2GNQvdHOqQ/APkHiRMAAMjzRrevrZld66lkYedM93X1ZiKV9wCkYlNxCAAAgNzKuvdpZ0SM1h2K0oJfTulGQpLd/a3YH6mwg1F68REfDWpdneV7QAHHjBMAAMg3LGaTmlQrpbEda+vgpHYa2tpHrk72JzzWyns1x1C6HCjoSJwAAEC+ZDGbNDTgfh2aFJTp85/ik0iggIKOxAkAAORr1vOfZnatJzenzP3qY02gao9bTQEJoIAhcQIAAAVCsH95HZzUTu3rlMt0X9aznwYuoIAEUFCQOAEAgALDYjbpo24NNbNrPRV2tWS6vxW/Rer+0aEs3wMKABInAABQ4AT7l9f+8YGZ3vskSQmGWL4HFAAkTgAAoEC6fe+TI2afrMv3nv1ku25mogw6gNyJxAkAABRojpx9kqTtETGqMWaVpoYeckh/AHIHEicAAFDgObLyntUnmyL0xEdbtPX4BfY/AfkAiRMAAMD/s1beG9raR85m+w/Otdr71yV1m/2Lao9bTQEJII8jcQIAALiN9eDcI1OCHJZA3UhI0vT1x1VnwhqtPkABCSAvInECAABIw+0JlCPOfpKkazcT1X9+uJb/etYh/QHIPiROAAAA93D72U+O2v80aNFevTR/D0v3gDyExAkAACADHL3/aeWBKFUfHaoXvtpNAQkgDyBxAgAAyCBH739KMqQ1B89RQALIA0icAAAAbHR7AtXR31OZn3/6t4BE7XGrFbqfAhJAbkPiBAAAYCfr+U9HpwTpqfoVHNLnjYQkDVgYrsc5AwrIVUicAAAAMsnFyax3u9TVrO71VdjF4pA+9/3/GVAPTFzLDBSQC5A4AQAAOEg7Py/tnxDosPLlknQlLkEDFoZr8opDDusTgO1InAAAABzo9vLlrhZH7H66ZfaWCAW897NuJiQ5rE8AGUfiBAAAkAWC/cvr0OQgNahc3GF9Hv/7qmqMWaVnPtlOAgVkMxInAACALGIxm/T9i80045m6Djn7yWpHRIxqjFmlgQvCKR4BZBMSJwAAgCzWoW6F5LOfXJ0cl0Ct+C1S949ZpffXHSeBArIYiRMAAEA2sJ79dGhSkBb0fUh1KxVzSL8JSYZC1h1T7fGrtfzXsw7pE0BqJE4AAADZyGI2qZlPaS17qblDC0jciE/SoEV71XbaRvY/AVmAxAkAACCHWAtIDG3t47A9UMfOX1GNMas0NZTy5YAjkTgBAADkIOsSPuseKEfVkPhkUwTJE+BAJE4AAAC5gDWBOv5GsOrf5+GQPj/ZFKE3Qw9q6/ELFI8AMonECQAAIBexmE1aMuBhzXimrhyx/enTTSfVbfYvFI8AMonECQAAIBfqULeCjr0RrMGPVpMjVu9Zi0d0nrmV2SfADiROAAAAuZTFbNLwwJr6/c1gBfuVc0ife05d1P2jQxW6P9Ih/QEFBYkTAABALmcxmzSze0PN7FpPJdydM91fgiENWBiugQvCmX0CMojECQAAII8I9i+v3WMCtKhfY/mVL5rp/lb8Fqn7x4Sy9wnIABInAACAPMRiNqlJtVJaMbiFZjxTN9PnPyUkib1PQAaQOAEAAORRHepW0JEpQfqi94NydcpcArXn1EX5vB6qaWuOkkABaSBxAgAAyMMsZpNa3l9W7z9TL9N9GZI++Ol31WD5HpAKiRMAAEA+0M7PS7O611dxBxSPSGT5HpAKiRMAAEA+0c7PS3vGBGhoax+H9EfpcuBfJE4AAAD5iMVs0tCA+zWre30Vc7Nkuj9r6fLJKw45IDog7yJxAgAAyIfa+Xlp77hAh80+zd4SoYD3ftbNhCSH9AfkNSROAAAA+dTts08ehZwy3d/xv6+qxphVevyjLdp6/AL7n1CgZP4nCAAAALlaOz8vBfh6ascf0Rq9dL9ORl/PVH/7/rqkbrN/kauTWS+2rKZBravLksnzpIDcjhknAACAAsBiNqmZT2n9/EorzXimriwOyHPiEpI0ff1x1Ry7ivLlyPdInAAAAAqYDnUr6NgbwWpfp5xD+otPNDRo0V49P2+nQ/oDcqMcT5xmzpwpb29vubm5qUGDBtq8efNdr12yZIkCAgJUpkwZFStWTE2aNNGaNWuyMVoAAID8wWI26aNuDXVsSpCqlynskD43HPlbDd9YL+pHID/K0cRp8eLFGjp0qEaPHq29e/eqefPmCgoK0qlTp9K8ftOmTQoICFBoaKj27NmjRx99VB07dtTevXuzOXIAAID8wcXJrLARj6jPw5Ud0t+lG4ka8YtF3WbvpAIf8pUcTZymTZumPn36qG/fvqpVq5amT5+uSpUq6eOPP07z+unTp+vVV1/Vgw8+qOrVq+vNN99U9erVtXz58myOHAAAIH8Z28FPM7vWk5NDfjs0aefJi6oxZpUGzN9D9T3kCzlWVe/mzZvas2ePRo4cmaK9bdu22rZtW4b6SEpK0uXLl1WyZMm7XhMXF6e4uLjkx7GxsZKk+Ph4xcfH2xG5Y1ljyA2xIO9g3MBWjBnYg3FT8ATUKqMD4wP07Oe/aO9fsQ7pM/RAlFa/HqppXfzVvo6nQ/pE/pNTnze2vF6OJU4XLlxQYmKiypVLuSmxXLlyioqKylAf7733nq5evaouXbrc9ZqpU6dq4sSJqdrXrl0rd3d324LOQmFhYTkdAvIgxg1sxZiBPRg3BU+vilIdV5O++t0sQ5kvv5ckaeg3v2rqj3v16gOGg2a1kB9l9+fNtWvXMnxtjp/jZDKl/GE0DCNVW1oWLVqkCRMm6IcfflDZsmXvet2oUaM0fPjw5MexsbGqVKmS2rZtq2LFitkfuIPEx8crLCxMAQEBcnZ2zulwkEcwbmArxgzswbgp2IIlvZ5k6MP1v2vW5gglZnq1nUnnblg04hepUZXimtuzoVzIoPD/curzxroaLSNyLHEqXbq0LBZLqtml8+fPp5qFutPixYvVp08fffvtt2rTps09r3V1dZWrq2uqdmdn51z1P4HcFg/yBsYNbMWYgT0YNwWXs6RXgn01vF0tfbj+mD7++YTiMp9BaefJi6o9cZ2C/Tz1Ydf6HJ6LZNn9eWPLa+VYmu/i4qIGDRqkmo4LCwtT06ZN73rfokWL1KtXLy1cuFDt27fP6jABAAAKPIvZpKEB9+vQ5CAt6PuQirlaHNJv6IEo+bweqmlrjlJAArlejs6PDh8+XJ9//rnmzJmjw4cPa9iwYTp16pT69+8v6dYyux49eiRfv2jRIvXo0UPvvfeeGjdurKioKEVFRenSpUs59RYAAAAKDIvZpGY+pbV/Yjv5lS/ikD4NSR/89LuqjyaBQu6Wo4nT008/renTp2vSpEmqW7euNm3apNDQUFWufOscgcjIyBRnOn3yySdKSEjQSy+9JC8vr+SvIUOG5NRbAAAAKJBWDG6pD7o84IDSEbckGbcSqJpjVil0f6SDegUcJ8eLQwwYMEADBgxI87l58+alePzzzz9nfUAAAADIkE71K6p93QoatHCPQg+cc0if8UmGBiwMV/B+9j8hd6GUCQAAAOxmMZs0s3tDHZsSpOplHHfUS+iBKFUfHarlv551WJ9AZpA4AQAAINNcnMwKG/Gopj9VRyY5Zp9SkiENWrRXT360lb1PyHEkTgAAAHCY9g94aVrjRL3Uwtth+5/C/7qoalTfQw4jcQIAAIBDmU3S0IDq+v3NYAX73ft8Tlt88NPvqjVutVYfoHgEsh+JEwAAALJEVux/upmQpP7zw9n7hGxH4gQAAIAsZd3/NOOZunJUkbxBi/bqxa92s3QP2YbECQAAANmiQ90KOv5GsAY/Ws0h/a06eE4+7H1CNiFxAgAAQLaxmE0aHlhTJxy0/8nQrb1P1UeTQCFrkTgBAAAg292+/8mzmEum+0sy/k2gpocdI4GCw5E4AQAAIMe4OJm14/UA9Xm4skP6SzKk6euPq8YYZqDgWCROAAAAyHFjO/g5tPpeYhIzUHAsEicAAADkCrdX33PU4bnWGajqo0P13uojJFCwG4kTAAAAcpUOdSvo9zeDVaWUm8P6TDKkD38+oRqjQxW6nwN0YTsSJwAAAOQ6FrNJP7/S2mF7n6wSDWnAwnA99EaYPtn4u24mJDm0f+RfJE4AAADItRy998nq3OWbmrrqqGqMWaUB8/ewhA/pInECAABArnb73iezozY/3Sb0QJSqvR6qoV+HMwOFuyJxAgAAQJ7QoW4FHX8jWIMfreaw4hG3W7YvUjXGrNLTn2wjgUIqJE4AAADIMyxmk4YH1tTvb95KoCxZkEH9EvGPaoxZpckrDjm+c+RZJE4AAADIc6wJ1LE3gjW0tU+WzEDN3hKhJm+uY/YJkkicAAAAkIdZzCYNDbhfv78ZrGC/cg7vPzI2TjXGrNLABeEUkCjgSJwAAACQ51nMJs3s3lDHpgSpc/3yDu9/xW+R8nk9VMMX72UGqoAicQIAAEC+4eJk1ntd6unEm8Ea9Ihji0gYkpbsPasaY1Zp0vKDDuwZeQGJEwAAAPIdi9mkEe1uFZEY2tpHzg6uYz5n60nVnbiG2acChMQJAAAA+ZZ1D9SRKUH66vlG8izq4rC+L15PYPapACFxAgAAQL5nMZvUvEYZ7Rgd4PCDdJl9KhhInAAAAFCgWA/S/aL3gypfzNUhfVpnn95YydlP+RWJEwAAAAoci9mklveX1bbX2+jYlCCVK+bskH4/2xyhfl/uckhfyF1InAAAAFCguTiZ9cvrbdXn4coO6S/s0Hmt2HfGIX0h9yBxAgAAACSN7eCnY1OC9FCVEpnua+TS3zgwN58hcQIAAAD+n4uTWYv7N9XMrvXklInflK/EJWpnRIzjAkOOI3ECAAAA7hDsX15HpwRr8KPV7O7j/OUbDowIOY3ECQAAAEiDxWzS8MCaOvFmsOpVKmbz/Ul3LNVLTDK0/US0fth3RttPRLOUL49xyukAAAAAgNzMYjZp6UvNtWLfGQ38el+G73vlu191OOqyBrby0bbfL2ji8kOKvPTvLJST2aQO/p56+6m6csnMukBkCxInAAAAIAM61K2gIP/yav3uBp2MufcyPF+vYjoUGatPN/2hRTtP6fKNhFTXJCQZWrYvUsv2RSrYz1Mfdq0viyNP5oVDkdoCAAAAGWQxm/Tzq631QZcH5JzGb9LF3Z01q3t9hQ5prrm9HpR3afc0k6Y7hR6IUvXRoVr+69ksiBqOwIwTAAAAYKNO9Suqfd0K2vFHtLafiJZkqEnV0mpcrVTyrNGjNcvK2WJS99k7M9RnkiENWrRXU1Ye1Lud66pp9dLMQOUiJE4AAACAHSxmk5r5lFYzn9J3vSb66k2b+z0Xe1PPzd0pZ4tJ07rUVccHymcmTDgIS/UAAACALFK2qJvd98YnGhq0aK8Cpv2smwlJDowK9iBxAgAAALJII++ScnexZKqP4+evqsaYVXr6k20kUDmIxAkAAADIIhazSVOfrOOQvn6J+Ec1xqzSf2ZtJYHKASROAAAAQBZ6rG4F+Ve0/QDdu9l18qJqjFmlF7/azSG62YjECQAAAMhiPw5srja1yji0z1UHz8nndUqYZxcSJwAAACAbfN6zkQ5PaqcS7pnb83Q7Q7dKmPeem7GS57AfiRMAAACQTQq5WLR3XDv1ebiyQ/v96ejfqj56pa7fTHRov/gXiRMAAACQzcZ28NOxKUF6qEoJh/UZnyjVGrea2acsQuIEAAAA5AAXJ7MW92/q8ATqp6N/q+rIlbp0Ld5hfYLECQAAAMhRtydQ1cu4O6TPJEkPTFqrlu9scEh/IHECAAAAcgUXJ7PCRjyqGc/UlZPJMX3+GX2d5MlBSJwAAACAXKRD3Qo6+kawvnq+kQo5Zz6D+jP6Osv2HIDECQAAAMhlLGaTmtcoo8OTgzX9Kf9M9/f8PApGZBaJEwAAAJCLPd6wkk68GazShZ3s7uPspRsOjKhgInECAAAAcjmL2aTdYwPVu9l9dt1f3sNNkpSYZGj7iWj9sO+Mtp+IVmKS4cgw8zX701YAAAAA2Wp8xzoaFVRbtceuUrwNOU/z+0tp5f6zmrLysCJvm30q4mpR34eralDr6rKYHVSRIp9ixgkAAADIQ1yczDo+tb0eqZ7xs5+mh53QSwv3pkiaJOlKXKKmrz+u2uNWK3R/pKNDzVdInAAAAIA8aF6fpprxTN17XlO5ZCG99WQdpTeXdCMhSQMWhmvgwnCW790FS/UAAACAPKpD3QoK8i+vn46c16QVB3Xmn+uSpNqehfVVv2bycHfW9hPRymgqtGJ/pMIORunFR3xYvncHEicAAAAgD7OYTWrjW05tfMul+fz5y7ZV1ItLNDR9/XF9+NNxtalVTj0aV1HjaqUKfBJF4gQAAADkY2WLutl1X2KStObgOa05eE5uTmb1b1mtQM9CsccJAAAAyMcaeZdUycIumerjRkKSpq8/rppjVml62LECuQ+KxAkAAADIxyxmk6Y85ueQvuKTjAJbhY/ECQAAAMjngv299EILb4f1Z63CN2D+ngIz+0TiBAAAABQAo4J9NbNrPbk5OS4FCD0QpeqvhxaI5XskTgAAAEABEexfXgcntdPQ1j5ydXJMkYckqUDsfyJxAgAAAAoQi9mkoQH369CkIHX093RYv/l9/xOJEwAAAFAAWcwmfdi1gcOX71n3Pz39yTbdTEhyWL85jcQJAAAAKMCyYvmeJP0S8Y9qjFmVbwpIkDgBAAAABdzty/cW9H1I7WqXk8VBOVTogSj5vB6qH/adcUyHOYTECQAAAICkWwlUM5/SmvVcQx17I1hDW/vI2Zz5DMqQNOTrfWr8ZlieXb5H4gQAAAAgFess1JEpQap/n4dD+oyKvakaY1bpxa9257nleyROAAAAAO7KYjZpyYCH1a95FYf1uergOVXLY8v3SJwAAAAApGt0+9o6NiVIneuXd9j+pyFf71OnGZsd01kWI3ECAAAAkCEuTma916WeQ/c/7T8dqxfmhzsguqxF4gQAAADAJo7e/7Th6AXdTHRAYFmIxAkAAACAXRy5/2lJhOPOkMoKOZ44zZw5U97e3nJzc1ODBg20efO91zhu3LhRDRo0kJubm6pWrapZs2ZlU6QAAAAA0mLd/1S9jLvdfRy6SOJ0V4sXL9bQoUM1evRo7d27V82bN1dQUJBOnTqV5vUREREKDg5W8+bNtXfvXr3++usaPHiwvv/++2yOHAAAAMDtXJzMChvxqGY8UzenQ8kSOZo4TZs2TX369FHfvn1Vq1YtTZ8+XZUqVdLHH3+c5vWzZs3Sfffdp+nTp6tWrVrq27evnn/+eb377rvZHDkAAACAtHSoW0En3gxWlZJuNt1XyyN3n+vklFMvfPPmTe3Zs0cjR45M0d62bVtt27YtzXu2b9+utm3bpmgLDAzU7NmzFR8fL2dn51T3xMXFKS4uLvlxbGysJCk+Pl7x8fGZfRuZZo0hN8SCvINxA1sxZmAPxg3swbiBVdiwFlq+76yGf38gQ9d3rmpk+7ix5fVyLHG6cOGCEhMTVa5cuRTt5cqVU1RUVJr3REVFpXl9QkKCLly4IC8vr1T3TJ06VRMnTkzVvnbtWrm7278G09HCwsJyOgTkQYwb2IoxA3swbmAPxg0kySIppLH02g6Tbsos6c59TLdmmfyKJ8nFkv3j5tq1axm+NscSJyuTKeU3zzCMVG3pXZ9Wu9WoUaM0fPjw5MexsbGqVKmS2rZtq2LFitkbtsPEx8crLCxMAQEBac6YAWlh3MBWjBnYg3EDezBukJYO7aV+X+7Wz8dj7njGpNY1y+jDLn45Mm6sq9EyIscSp9KlS8tisaSaXTp//nyqWSUrT0/PNK93cnJSqVKl0rzH1dVVrq6uqdqdnZ1z1Q9zbosHeQPjBrZizMAejBvYg3GDO83r00TXbybqzdBDOhl9TVVKuev1YF8VcrEkL5nL7nFjy2vlWOLk4uKiBg0aKCwsTE888URye1hYmB577LE072nSpImWL1+eom3t2rVq2LAhP5gAAABALlfIxaLJj9fJ6TDskqNV9YYPH67PP/9cc+bM0eHDhzVs2DCdOnVK/fv3l3RrmV2PHj2Sr+/fv7/+/PNPDR8+XIcPH9acOXM0e/Zsvfzyyzn1FgAAAAAUADm6x+npp59WdHS0Jk2apMjISPn5+Sk0NFSVK1eWJEVGRqY408nb21uhoaEaNmyYPvroI5UvX14ffPCBOnfunFNvAQAAAEABkOPFIQYMGKABAwak+dy8efNStbVs2VLh4eFZHBUAAAAA/CtHl+oBAAAAQF5A4gQAAAAA6SBxAgAAAIB0kDgBAAAAQDpInAAAAAAgHSROAAAAAJAOEicAAAAASAeJEwAAAACkg8QJAAAAANJB4gQAAAAA6XDK6QCym2EYkqTY2NgcjuSW+Ph4Xbt2TbGxsXJ2ds7pcJBHMG5gK8YM7MG4gT0YN7BHTo0ba05gzRHupcAlTpcvX5YkVapUKYcjAQAAAJAbXL58WR4eHve8xmRkJL3KR5KSknT27FkVLVpUJpMpp8NRbGysKlWqpL/++kvFihXL6XCQRzBuYCvGDOzBuIE9GDewR06NG8MwdPnyZZUvX15m8713MRW4GSez2ayKFSvmdBipFCtWjA8X2IxxA1sxZmAPxg3swbiBPXJi3KQ302RFcQgAAAAASAeJEwAAAACkg8Qph7m6umr8+PFydXXN6VCQhzBuYCvGDOzBuIE9GDewR14YNwWuOAQAAAAA2IoZJwAAAABIB4kTAAAAAKSDxAkAAAAA0kHiBAAAAADpIHHKYjNnzpS3t7fc3NzUoEEDbd68+Z7Xb9y4UQ0aNJCbm5uqVq2qWbNmZVOkyE1sGTdLlixRQECAypQpo2LFiqlJkyZas2ZNNkaL3MLWzxurrVu3ysnJSXXr1s3aAJEr2Tpu4uLiNHr0aFWuXFmurq6qVq2a5syZk03RIrewddwsWLBADzzwgNzd3eXl5aXevXsrOjo6m6JFbrBp0yZ17NhR5cuXl8lk0rJly9K9J7f9XkzilIUWL16soUOHavTo0dq7d6+aN2+uoKAgnTp1Ks3rIyIiFBwcrObNm2vv3r16/fXXNXjwYH3//ffZHDlykq3jZtOmTQoICFBoaKj27NmjRx99VB07dtTevXuzOXLkJFvHjdWlS5fUo0cPtW7dOpsiRW5iz7jp0qWL1q9fr9mzZ+vo0aNatGiRatasmY1RI6fZOm62bNmiHj16qE+fPjp48KC+/fZb7dq1S3379s3myJGTrl69qgceeEAzZszI0PW58vdiA1mmUaNGRv/+/VO01axZ0xg5cmSa17/66qtGzZo1U7S98MILRuPGjbMsRuQ+to6btPj6+hoTJ050dGjIxewdN08//bQxZswYY/z48cYDDzyQhREiN7J13Kxatcrw8PAwoqOjsyM85FK2jpt33nnHqFq1aoq2Dz74wKhYsWKWxYjcTZKxdOnSe16TG38vZsYpi9y8eVN79uxR27ZtU7S3bdtW27ZtS/Oe7du3p7o+MDBQu3fvVnx8fJbFitzDnnFzp6SkJF2+fFklS5bMihCRC9k7bubOnasTJ05o/PjxWR0iciF7xs2PP/6ohg0b6u2331aFChVUo0YNvfzyy7p+/Xp2hIxcwJ5x07RpU50+fVqhoaEyDEPnzp3Td999p/bt22dHyMijcuPvxU458qoFwIULF5SYmKhy5cqlaC9XrpyioqLSvCcqKirN6xMSEnThwgV5eXllWbzIHewZN3d67733dPXqVXXp0iUrQkQuZM+4OX78uEaOHKnNmzfLyYn/FRRE9oybP/74Q1u2bJGbm5uWLl2qCxcuaMCAAYqJiWGfUwFhz7hp2rSpFixYoKefflo3btxQQkKCOnXqpA8//DA7QkYelRt/L2bGKYuZTKYUjw3DSNWW3vVptSN/s3XcWC1atEgTJkzQ4sWLVbZs2awKD7lURsdNYmKiunbtqokTJ6pGjRrZFR5yKVs+b5KSkmQymbRgwQI1atRIwcHBmjZtmubNm8esUwFjy7g5dOiQBg8erHHjxmnPnj1avXq1IiIi1L9//+wIFXlYbvu9mD8zZpHSpUvLYrGk+uvL+fPnU2XPVp6enmle7+TkpFKlSmVZrMg97Bk3VosXL1afPn307bffqk2bNlkZJnIZW8fN5cuXtXv3bu3du1cDBw6UdOsXYsMw5OTkpLVr16pVq1bZEjtyjj2fN15eXqpQoYI8PDyS22rVqiXDMHT69GlVr149S2NGzrNn3EydOlXNmjXTK6+8Ikny9/dX4cKF1bx5c02ZMoUVNUhTbvy9mBmnLOLi4qIGDRooLCwsRXtYWJiaNm2a5j1NmjRJdf3atWvVsGFDOTs7Z1msyD3sGTfSrZmmXr16aeHChawZL4BsHTfFihXTb7/9pn379iV/9e/fX/fff7/27dunhx56KLtCRw6y5/OmWbNmOnv2rK5cuZLcduzYMZnNZlWsWDFL40XuYM+4uXbtmszmlL9yWiwWSf/OIAB3ypW/F+dQUYoC4euvvzacnZ2N2bNnG4cOHTKGDh1qFC5c2Dh58qRhGIYxcuRI47nnnku+/o8//jDc3d2NYcOGGYcOHTJmz55tODs7G999911OvQXkAFvHzcKFCw0nJyfjo48+MiIjI5O/Ll68mFNvATnA1nFzJ6rqFUy2jpvLly8bFStWNJ566inj4MGDxsaNG43q1asbffv2zam3gBxg67iZO3eu4eTkZMycOdM4ceKEsWXLFqNhw4ZGo0aNcuotIAdcvnzZ2Lt3r7F3715DkjFt2jRj7969xp9//mkYRt74vZjEKYt99NFHRuXKlQ0XFxejfv36xsaNG5Of69mzp9GyZcsU1//8889GvXr1DBcXF6NKlSrGxx9/nM0RIzewZdy0bNnSkJTqq2fPntkfOHKUrZ83tyNxKrhsHTeHDx822rRpYxQqVMioWLGiMXz4cOPatWvZHDVymq3j5oMPPjB8fX2NQoUKGV5eXka3bt2M06dPZ3PUyEk//fTTPX9fyQu/F5sMgzlSAAAAALgX9jgBAAAAQDpInAAAAAAgHSROAAAAAJAOEicAAAAASAeJEwAAAACkg8QJAAAAANJB4gQAAAAA6SBxAgAAAIB0kDgBADLFZDJp2bJl2f66VapU0fTp0zPVx7Vr19S5c2cVK1ZMJpNJFy9eTLPNlteaN2+eihcvnqm4AAC5D4kTAOCuzp8/rxdeeEH33XefXF1d5enpqcDAQG3fvj35msjISAUFBeVglGmbMGGCTCZTqq+aNWsmX/PFF19o8+bN2rZtmyIjI+Xh4ZFm265du/Tf//43Q6/79NNP69ixY1n1tgAAOcQppwMAAORenTt3Vnx8vL744gtVrVpV586d0/r16xUTE5N8jaenZw5GeG+1a9fWunXrUrQ5Of37v74TJ06oVq1a8vPzu2dbmTJlMvyahQoVUqFChTIRNQAgN2LGCQCQposXL2rLli363//+p0cffVSVK1dWo0aNNGrUKLVv3z75ujuX6m3btk1169aVm5ubGjZsqGXLlslkMmnfvn2SpJ9//lkmk0nr169Xw4YN5e7urqZNm+ro0aPJfZw4cUKPPfaYypUrpyJFiujBBx9MlQBlhJOTkzw9PVN8lS5dWpL0yCOP6L333tOmTZtkMpn0yCOPpNkmpV4WePHiRf33v/9VuXLl5ObmJj8/P61YsUJS2kv1li9frgYNGsjNzU1Vq1bVxIkTlZCQkOJ7+Pnnn+uJJ56Qu7u7qlevrh9//DFFHwcPHlT79u1VrFgxFS1aVM2bN9eJEye0adMmOTs7KyoqKsX1I0aMUIsWLWz+ngEA0kbiBABIU5EiRVSkSBEtW7ZMcXFxGbrn8uXL6tixo+rUqaPw8HBNnjxZr732WprXjh49Wu+99552794tJycnPf/888nPXblyRcHBwVq3bp327t2rwMBAdezYUadOnXLIe5OkJUuWqF+/fmrSpIkiIyO1ZMmSNNvulJSUpKCgIG3btk3z58/XoUOH9NZbb8lisaT5OmvWrFH37t01ePBgHTp0SJ988onmzZunN954I8V1EydOVJcuXbR//34FBwerW7duyTN7Z86cUYsWLeTm5qYNGzZoz549ev7555WQkKAWLVqoatWq+uqrr5L7SkhI0Pz589W7d2+Hfb8AoMAzAAC4i++++84oUaKE4ebmZjRt2tQYNWqU8euvv6a4RpKxdOlSwzAM4+OPPzZKlSplXL9+Pfn5zz77zJBk7N271zAMw/jpp58MSca6deuSr1m5cqUhKcV9d/L19TU+/PDD5MeVK1c2QkJC7nr9+PHjDbPZbBQuXDjFV58+fZKvGTJkiNGyZcsU96XVdvtrrVmzxjCbzcbRo0fTfN25c+caHh4eyY+bN29uvPnmmymu+eqrrwwvL6/kx5KMMWPGJD++cuWKYTKZjFWrVhmGYRijRo0yvL29jZs3b6b5mv/73/+MWrVqJT9etmyZUaRIEePKlStpXg8AsB0zTgCAu+rcubPOnj2rH3/8UYGBgfr5559Vv359zZs3L83rjx49Kn9/f7m5uSW3NWrUKM1r/f39k//by8tL0q1iFJJ09epVvfrqq/L19VXx4sVVpEgRHTlyxOYZp/vvv1/79u1L8XXnTI+t9u3bp4oVK6pGjRoZun7Pnj2aNGlS8gxekSJF1K9fP0VGRuratWvJ193+/ShcuLCKFi2a/P3Yt2+fmjdvLmdn5zRfo1evXvr999+1Y8cOSdKcOXPUpUsXFS5c2N63CQC4A8UhAAD35ObmpoCAAAUEBGjcuHHq27evxo8fr169eqW61jAMmUymVG1puT0JsN6TlJQkSXrllVe0Zs0avfvuu/Lx8VGhQoX01FNP6ebNmzbF7uLiIh8fH5vuSY+thR+SkpI0ceJEPfnkk6meuz3BvDMpMplMyd+P9F6zbNmy6tixo+bOnauqVasqNDRUP//8s01xAgDujcQJAGATX1/fu57bVLNmTS1YsEBxcXFydXWVJO3evdvm19i8ebN69eqlJ554QtKtPU8nT560N2SH8vf31+nTp3Xs2LEMzTrVr19fR48ezVQC5+/vry+++ELx8fF3nXXq27evnnnmGVWsWFHVqlVTs2bN7H49AEBqLNUDAKQpOjparVq10vz587V//35FRETo22+/1dtvv63HHnsszXu6du2qpKQk/fe//9Xhw4eTZ40kpZqJuhcfHx8tWbJE+/bt06+//prcr60SEhIUFRWV4uvcuXM293O7li1bqkWLFurcubPCwsIUERGhVatWafXq1WleP27cOH355ZeaMGGCDh48qMOHD2vx4sUaM2ZMhl9z4MCBio2N1TPPPKPdu3fr+PHj+uqrr1JUIgwMDJSHh4emTJlCUQgAyAIkTgCANBUpUkQPPfSQQkJC1KJFC/n5+Wns2LHq16+fZsyYkeY9xYoV0/Lly7Vv3z7VrVtXo0eP1rhx4ySlXJaWnpCQEJUoUUJNmzZVx44dFRgYqPr169v8Hg4ePCgvL68UX5UrV7a5nzt9//33evDBB/Xss8/K19dXr776qhITE9O8NjAwUCtWrFBYWJgefPBBNW7cWNOmTbMpjlKlSmnDhg26cuWKWrZsqQYNGuizzz5LMftkNpvVq1cvJSYmqkePHpl+jwCAlEzG3RafAwDgAAsWLFDv3r116dIlDobNYv369dO5c+dSnQEFAMg89jgBABzqyy+/VNWqVVWhQgX9+uuveu2119SlSxeSpix06dIl7dq1SwsWLNAPP/yQ0+EAQL5E4gQAcKioqCiNGzdOUVFR8vLy0n/+859MlwDHvT322GPauXOnXnjhBQUEBOR0OACQL7FUDwAAAADSQXEIAAAAAEgHiRMAAAAApIPECQAAAADSQeIEAAAAAOkgcQIAAACAdJA4AQAAAEA6SJwAAAAAIB0kTgAAAACQjv8Dx8kK3L4wrqoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.8726754594278616, 0.12620122306348283), (0.901063169047532, 0.0980270821199767), (0.92996236893062, 0.06934333139196272), (0.9602498995286982, 0.03956755969714618), (0.9797230645573782, 0.021731217239370996), (0.9899894048445435, 0.011138613861386138), (0.9928391363121551, 0.0071345369831100755), (0.9928391363121551, 0.0071345369831100755)]\n"
     ]
    }
   ],
   "source": [
    "test_results = test_model(data, new_model, HYPERPARAMETERS)\n",
    "metrics = getTargetMetrics(test_results)\n",
    "displayPerformance(data, test_results, metrics, HYPERPARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Save the model when done\n",
    "model.save(f'./DNN_L3_S32_best_performance_quant.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Functional model inputs must come from `tf.keras.Input` (thus holding past layer metadata). They cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model_1\" was not an Input tensor, it was generated by layer \"y_timed_input\".\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: KerasTensor(type_spec=TensorSpec(shape=(None, 105), dtype=tf.float32, name='y_timed_input'), name='y_timed_input', description=\"created by layer 'y_timed_input'\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Functional model inputs must come from `tf.keras.Input` (thus holding past layer metadata). They cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model_1\" was not an Input tensor, it was generated by layer \"y_timed_input\".\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: KerasTensor(type_spec=TensorSpec(shape=(None, 105), dtype=tf.float32, name='y_timed_input'), name='y_timed_input', description=\"created by layer 'y_timed_input'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_timed_input (InputLayer)  multiple                  0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 24)                2544      \n",
      "                                                                 \n",
      " q_activation_32 (QActivati  (None, 24)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 12)                300       \n",
      "                                                                 \n",
      " q_activation_33 (QActivati  (None, 12)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense_output (QDense)       (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2857 (11.16 KB)\n",
      "Trainable params: 2857 (11.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load in a saved model from the h5 file\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "co['PruneLowMagnitude'] = pruning_wrapper.PruneLowMagnitude\n",
    "loaded_model = load_model('./DNN_L2_S24_best_performance_single_quant_10_15new_folded.h5', custom_objects=co)\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1714/1714 [==============================] - 3s 2ms/step\n",
      "[[0.6915344 ]\n",
      " [0.6043785 ]\n",
      " [0.43324563]\n",
      " [0.68143016]\n",
      " [0.4688447 ]\n",
      " [0.7013606 ]\n",
      " [0.681559  ]\n",
      " [0.65928006]\n",
      " [0.6024071 ]\n",
      " [0.6219051 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.8727119944466771, 0.4163875946418171), (0.9005882138029301, 0.3835905649388468), (0.9297066237989112, 0.3346316249271986), (0.9601402944722517, 0.26248543972044264), (0.979978809689087, 0.18742719860221316), (0.9900259398633591, 0.13555620267909144), (0.9949947024222717, 0.10490681421083285), (0.9990135544919806, 0.05598427489807804)]\n"
     ]
    }
   ],
   "source": [
    "test_results = test_model(data, loaded_model, HYPERPARAMETERS)\n",
    "metrics = getTargetMetrics(test_results)\n",
    "displayPerformance(data, test_results, metrics, HYPERPARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write input data to file\n",
    "with open('DNN_hp_input_features.dat', 'w') as file:\n",
    "    for row in input_train_data_combined:\n",
    "        line = ' '.join(map(str, row))  # Convert each number to string and join with space\n",
    "        file.write(line + '\\n')\n",
    "# Write target data to file\n",
    "with open('./DNN_hp_predictions_small.dat', 'w') as file:\n",
    "    for score in target_test_data_coded:\n",
    "        file.write(str(score[0]) + '\\n')  # Convert number to string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set display by time slice\n",
    "def display_dataset(input_dataset, target_dataset, i, gif=False):\n",
    "    # Extract the i-th data point from both datasets\n",
    "    input_datapoint = input_dataset[i]\n",
    "    target_datapoint = target_dataset[i]\n",
    "\n",
    "    # Check if the index is valid\n",
    "    if input_datapoint.shape != (20, 13, 21):\n",
    "        raise ValueError(f\"{input_datapoint.shape } is an invalid shape for the input data point\")\n",
    "    \n",
    "    for i in range(8):\n",
    "        for j in range(13):\n",
    "            for k in range(21):\n",
    "                print(input_datapoint[i, j, k], end=\", \")\n",
    "            print()\n",
    "        print(\"--------\", i)\n",
    "\n",
    "    # Extracting the transverse momentum (pt) from the target_data dataset\n",
    "    pt = target_datapoint[8]  # Assuming the 9th variable is at index 8\n",
    "\n",
    "    fig, ax_main = plt.subplots(figsize=(8, 6))\n",
    "    divider = make_axes_locatable(ax_main)\n",
    "\n",
    "    # Add row sum plot as an inset to the main plot\n",
    "    ax_row = divider.append_axes(\"right\", size=\"20%\", pad=0.4)\n",
    "\n",
    "    # Add column sum plot below the main plot\n",
    "    ax_column = divider.append_axes(\"bottom\", size=\"20%\", pad=0.5)\n",
    "\n",
    "    # Initial plot\n",
    "    im = ax_main.imshow(input_datapoint[0, :, :], cmap='plasma')\n",
    "    ax_main.invert_yaxis()\n",
    "    ax_main.set_yticks(np.arange(input_datapoint.shape[1]))\n",
    "    ax_main.set_xticks(np.arange(input_datapoint.shape[2]))\n",
    "    ax_main.grid(True, color='gray', alpha=0.7)\n",
    "\n",
    "    # Function to update the animation\n",
    "    def update(t):\n",
    "        # Update main plot\n",
    "        data = input_datapoint[t, :, :]\n",
    "        im.set_data(data)\n",
    "\n",
    "        # Update row sum plot\n",
    "        ax_row.clear()\n",
    "        ax_row.barh(np.arange(data.shape[0]), np.sum(data, axis=1), color='red')\n",
    "        ax_row.set_ylim(0, data.shape[0]-1)\n",
    "        ax_row.set_yticks(np.arange(data.shape[0]))\n",
    "        ax_row.set_xlim(np.min(input_datapoint[:, :, :].sum(axis=2)) * 1.1, np.max(input_datapoint[:, :, :].sum(axis=2)) * 1.1)\n",
    "        ax_row.set_xlabel(\"Row Sum\")\n",
    "\n",
    "        # Update column sum plot\n",
    "        ax_column.clear()\n",
    "        ax_column.bar(np.arange(data.shape[1]), np.sum(data, axis=0), color='blue')\n",
    "        ax_column.set_xlim(0, data.shape[1]-1)\n",
    "        ax_column.set_xticks(np.arange(data.shape[1]))\n",
    "        ax_column.set_ylim(np.min(input_datapoint[:, :, :].sum(axis=1)) * 1.1, np.max(input_datapoint[:, :, :].sum(axis=1)) * 1.1)\n",
    "        ax_column.set_ylabel(\"Column Sum\")\n",
    "\n",
    "        # Update labels and grid\n",
    "        ax_main.set_xlabel(\"X Position\")\n",
    "        ax_main.set_ylabel(\"Y Position\")\n",
    "\n",
    "        # Update title for the entire figure\n",
    "        fig.suptitle(f\"Timestep: {t+1} | Data Point: {i} | pt: {pt:.2f} GeV\")\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=20, repeat=True)\n",
    "\n",
    "    gif_path = f\"data_point.gif\"\n",
    "    if gif:\n",
    "        # Save the animation as a GIF\n",
    "        writer = PillowWriter(fps=1000 // FRAME_TIME)\n",
    "        ani.save(gif_path, writer=writer)\n",
    "\n",
    "    plt.close()\n",
    "    return display(HTML(ani.to_jshtml())), gif_path\n",
    "\n",
    "def display_model_IO(input_dataset_combined, target_dataset_coded, i):\n",
    "    # Extract the i-th data point from both datasets\n",
    "    input_datapoint = input_dataset_combined[i]\n",
    "    target_datapoint = target_dataset_coded[i]\n",
    "\n",
    "    # Check if the index is valid\n",
    "    if (MODEL_TYPE == \"DNN\"):\n",
    "        if input_datapoint.shape != (NUM_TIME_SLICES * 13 + 1,):\n",
    "            raise ValueError(f\"{input_datapoint.shape } is an invalid shape for the input data point 2\")\n",
    "        input_datapoint = input_datapoint[:-1].reshape(NUM_TIME_SLICES, 13)\n",
    "    elif (MODEL_TYPE == \"CNN\"):\n",
    "        if input_datapoint[0].shape != (NUM_TIME_SLICES, 13):\n",
    "            raise ValueError(f\"{input_datapoint.shape } is an invalid shape for the input data point 3\")\n",
    "        input_datapoint = input_datapoint[0]\n",
    "        \n",
    "    # Extracting the label from the target datapoint\n",
    "    if target_datapoint[0] == 1:\n",
    "        label = f\"High p_t (over {TEST_PT_THRESHOLD} GeV)\"\n",
    "    elif target_datapoint[1] == 1:\n",
    "        label = f\"low p_t and negative charge\"\n",
    "    elif target_datapoint[2] == 1:\n",
    "        label = f\"low p_t and positive charge\"\n",
    "    else: \n",
    "        raise ValueError(\"Invalid labelling for the target data point\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Create the heatmap\n",
    "    fig, ax_main = plt.subplots(figsize=(4,4))\n",
    "    print(input_datapoint.shape)\n",
    "    print(input_datapoint)\n",
    "    im = ax_main.imshow(input_datapoint.T, cmap='coolwarm_r', vmin=-1, vmax=1)\n",
    "    ax_main.invert_yaxis()\n",
    "    ax_main.set_xticks(np.arange(input_datapoint.shape[0]))\n",
    "    ax_main.set_yticks(np.arange(input_datapoint.shape[1]))\n",
    "    ax_main.grid(True, color='gray', alpha=0.7)\n",
    "\n",
    "\n",
    "    # Update labels and grid\n",
    "    ax_main.set_xlabel(\"Time Slice\")\n",
    "    ax_main.set_ylabel(\"Y Position\")\n",
    "\n",
    "\n",
    "    # Update title for the entire figure\n",
    "    fig.suptitle(f\"Data Point: {i} | label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'display_model_IO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m rand_idx \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      3\u001b[0m FRAME_TIME \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m120\u001b[39m  \u001b[38;5;66;03m# milliseconds between frames\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdisplay_model_IO\u001b[49m(input_data_combined_example, target_data_coded_example, rand_idx)\n\u001b[1;32m      5\u001b[0m animation, gif \u001b[38;5;241m=\u001b[39m display_dataset(input_data_example, target_data_example, rand_idx, gif\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'display_model_IO' is not defined"
     ]
    }
   ],
   "source": [
    "# DATASET DISPLAY\n",
    "rand_idx = random.randint(0, 100)\n",
    "FRAME_TIME = 120  # milliseconds between frames\n",
    "display_model_IO(input_data_combined_example, target_data_coded_example, rand_idx)\n",
    "animation, gif = display_dataset(input_data_example, target_data_example, rand_idx, gif=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C++ Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "import os\n",
    "os.environ['XILINX_HLS'] = '/afs/slac.stanford.edu/g/reseng/vol39/xilinx/2023.1/Vitis_HLS/2023.1'\n",
    "os.environ['XILINX_VIVADO'] = '/afs/slac.stanford.edu/g/reseng/vol39/xilinx/2023.1/Vivado/2023.1'\n",
    "os.environ['XILINX_VITIS'] = '/afs/slac.stanford.edu/g/reseng/vol39/xilinx/2023.1/Vitis/2023.1'\n",
    "os.environ['XILINX_AP_INCLUDE'] = '/fs/ddn/sdf/group/atlas/d/hjia625/Smart_Pixel/HLS_arbitrary_Precision_Types/include'\n",
    "os.environ['PATH'] = os.environ['XILINX_HLS'] + '/bin:' + os.environ['PATH']\n",
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']\n",
    "os.environ['PATH'] = os.environ['XILINX_VITIS'] + '/bin:' + os.environ['PATH']\n",
    "os.environ['PATH'] = os.environ['XILINX_AP_INCLUDE'] + '/bin:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "strip_model = strip_pruning(qmodel_pruned)\n",
    "hls_config = hls4ml.utils.config_from_keras_model(strip_model , granularity='name')\n",
    "\n",
    "# Set the precision and reuse factor for the full model\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<10,2,AP_RND_ZERO,AP_SAT>'\n",
    "hls_config['Model']['ReuseFactor'] = 1\n",
    "\n",
    "for Layer in hls_config['LayerName'].keys():\n",
    "    print(Layer)\n",
    "    hls_config['LayerName'][Layer]['Strategy'] = 'Resource'\n",
    "    hls_config['LayerName'][Layer]['ReuseFactor'] = 1\n",
    "    hls_config['LayerName'][Layer]['Precision'] = 'ap_fixed<10,2,AP_RND_ZERO,AP_SAT>'\n",
    "\n",
    "# If you want best numerical performance for high-accuray models, while the default latency strategy is faster but numerically more unstable\n",
    "hls_config['LayerName']['output_sigmoid']['Strategy'] = 'Stable'\n",
    "hls_config['LayerName']['output_sigmoid']['Precision'] = 'ap_fixed<32,8,AP_RND_ZERO,AP_SAT>'\n",
    "\n",
    "cfg = hls4ml.converters.create_config(backend='Vitis')\n",
    "\n",
    "cfg['IOType'] = 'io_stream'  # Must set this if using CNNs!\n",
    "cfg['HLSConfig'] = hls_config\n",
    "cfg['KerasModel'] = model\n",
    "cfg['OutputDir'] = 'cnn_debug/'\n",
    "cfg['XilinxPart'] = 'xcku040-ffva1156-2-e'\n",
    "\n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "hls_model.compile()\n",
    "#hls_model.profile()\n",
    "hls_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in qmodel_pruned.layers:\n",
    "    for i, w in enumerate(layer.weights):\n",
    "        try:\n",
    "            print(\"weight is\", w.numpy(), \"for layer number\", i)  # TF 2.x\n",
    "        except Exception:\n",
    "            print(\"weight is\", layer.get_weights()[i], \"for layer number\", i) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Smart_Pixel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
