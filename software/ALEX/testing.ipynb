{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.13.1\n",
      "keras version: 2.13.1\n",
      "qkeras version: 2.13.1\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "# IMPORTS\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "# Machine Learning imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import PReLU, Input, LSTM, Flatten, Concatenate, Dense, Conv2D, TimeDistributed, MaxPooling2D, ReLU, Dropout, BatchNormalization, Activation, Reshape\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.metrics import Precision\n",
    "import tensorflow_model_optimization\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "print(\"tensorflow version:\", tf.__version__)\n",
    "import keras\n",
    "print(\"keras version:\",keras.__version__)\n",
    "import qkeras\n",
    "from qkeras import QActivation, QDense, QConv2D, QBatchNormalization, QConv2DBatchnorm\n",
    "from qkeras import quantized_relu, quantized_bits\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "from qkeras.autoqkeras.utils import print_qmodel_summary\n",
    "print(\"qkeras version:\",keras.__version__)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Display and plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.animation import PillowWriter\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Data management\n",
    "import psutil\n",
    "import h5py\n",
    "# Memory management\n",
    "import gc\n",
    "# Notifications\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "def send_email_notification(subject, content):\n",
    "    sender_email = os.getenv('EMAIL_USER')\n",
    "    receiver_email = \"alexander.j.yue@gmail.com\"\n",
    "    password = os.getenv('EMAIL_PASS')\n",
    "\n",
    "    message = MIMEMultipart()\n",
    "    message[\"From\"] = sender_email\n",
    "    message[\"To\"] = receiver_email\n",
    "    message[\"Subject\"] = subject\n",
    "    body = content\n",
    "    message.attach(MIMEText(body, \"plain\"))\n",
    "\n",
    "    with smtplib.SMTP(\"smtp.gmail.com\", 587) as server:\n",
    "        server.starttls()\n",
    "        server.login(sender_email, password)\n",
    "        server.sendmail(sender_email, receiver_email, message.as_string())\n",
    "\n",
    "# Memory monitoring functions\n",
    "def print_memory_usage():\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"Total memory: {memory.total / (1024**3):.2f} GB\")\n",
    "    print(f\"Available memory: {memory.available / (1024**3):.2f} GB\")\n",
    "    print(f\"Used memory: {memory.used / (1024**3):.2f} GB\")\n",
    "    print(f\"Memory usage percentage: {memory.percent}%\")\n",
    "\n",
    "def print_cpu_usage():\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "    print(f\"CPU Usage: {cpu_percent}%\")\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "# Load the pixel cluster to transverse momentum dataset into the input_data and target_data\n",
    "def load_combine_shuffle_data_optimized_hdf5():\n",
    "    # Load the dataset from Kenny's computer\n",
    "    with h5py.File('/fs/ddn/sdf/group/atlas/d/hjia625/Smart_Pixel/fl32_data_v3.hdf5', 'r') as h5f:\n",
    "        combined_input = None\n",
    "        combined_target = None\n",
    "\n",
    "        for data_type in ['sig', 'bkg']:\n",
    "            # Construct dataset names\n",
    "            input_dataset_name = f'{data_type}_input'\n",
    "            target_dataset_name = f'{data_type}_target'\n",
    "\n",
    "            # Check if the dataset exists and load data sequentially\n",
    "            if input_dataset_name in h5f and target_dataset_name in h5f:\n",
    "                input_data = h5f[input_dataset_name][:].astype(np.float32)\n",
    "                target_data = h5f[target_dataset_name][:].astype(np.float32)\n",
    "\n",
    "                if combined_input is None:\n",
    "                    combined_input = input_data\n",
    "                    combined_target = target_data\n",
    "                    # Free memory of the loaded data\n",
    "                    del input_data, target_data\n",
    "                    gc.collect()\n",
    "\n",
    "                else:\n",
    "                    print_memory_usage()\n",
    "                    combined_input = np.vstack((combined_input, input_data))\n",
    "                    combined_target = np.vstack((combined_target, target_data))\n",
    "                    # Free memory of the loaded data\n",
    "                    del input_data, target_data\n",
    "                    gc.collect()\n",
    "\n",
    "            else:\n",
    "                print(f\"Dataset {input_dataset_name} or {target_dataset_name} not found.\")\n",
    "\n",
    "        # Shuffling\n",
    "        indices = np.arange(combined_input.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        combined_input = combined_input[indices]\n",
    "        combined_target = combined_target[indices]\n",
    "\n",
    "        return combined_input, combined_target\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "def load_dataset():\n",
    "    # Load dataset into memory\n",
    "    input_data, target_data = load_combine_shuffle_data_optimized_hdf5()\n",
    "    # Format the dataset into a 20x13x21 tensor (time, y, x)\n",
    "    input_data = input_data.reshape(input_data.shape[0],20,13,21)\n",
    "    return input_data, target_data\n",
    "\n",
    "def process_dataset(input_data, target_data, hyperparams):\n",
    "    NUM_TIME_SLICES = hyperparams[\"NUM_TIME_SLICES\"]\n",
    "    MODEL_TYPE = hyperparams[\"MODEL_TYPE\"]\n",
    "    TRAIN_PT_THRESHOLD = hyperparams[\"TRAIN_PT_THRESHOLD\"]\n",
    "    TEST_PT_THRESHOLD = hyperparams[\"TEST_PT_THRESHOLD\"]\n",
    "    INPUT_SCALING = hyperparams[\"INPUT_SCALING\"]\n",
    "\n",
    "    # Split 80% of data into training data, 10% for validation data and 10% for testing data\n",
    "    input_train_data, input_temp, target_train_data, target_temp = \\\n",
    "    train_test_split(input_data, target_data, test_size=0.2, random_state=42)\n",
    "    del input_data\n",
    "    del target_data\n",
    "    gc.collect()\n",
    "    input_validate_data, input_test_data, target_validate_data, target_test_data = \\\n",
    "    train_test_split(input_temp, target_temp, test_size=0.5, random_state=42)\n",
    "    del input_temp\n",
    "    del target_temp\n",
    "    gc.collect()\n",
    "\n",
    "    # Save some data for displaying\n",
    "    input_data_example = input_test_data[0:100,:]\n",
    "    target_data_example = target_test_data[0:100,:]\n",
    "\n",
    "    # Fit the scalers on the training data to it all scales the exact same\n",
    "    if INPUT_SCALING == \"Standard\":\n",
    "        input_scaler = StandardScaler()\n",
    "        input_scaler.fit(input_train_data[:, :NUM_TIME_SLICES, :, :].reshape(-1,8*13))\n",
    "        y0_scaler = StandardScaler()\n",
    "        y0_scaler.fit(target_train_data[:,7].reshape(-1, 1))\n",
    "    elif INPUT_SCALING == \"MinMax\":\n",
    "        input_scaler = MinMaxScaler()\n",
    "        input_scaler.fit(input_train_data[:, :NUM_TIME_SLICES, :, :].reshape(-1,8*13))\n",
    "        y0_scaler = MinMaxScaler()\n",
    "        y0_scaler.fit(target_train_data[:,7].reshape(-1, 1))\n",
    "    elif INPUT_SCALING == \"Log\":\n",
    "        _temp = \"null\" # no steps here \n",
    "    else: \n",
    "        raise ValueError(f\"unsupported INPUT_SCALING {INPUT_SCALING}\")\n",
    "\n",
    "    # Process the data into input shape and labels for training\n",
    "    def process_data(input_data, target_data, pt_threshold):\n",
    "        if input_data.shape[1:] == (20, 13, 21) and target_data.shape[1:] == (13, ):\n",
    "\n",
    "            # Truncate down to first time slices\n",
    "            input_data = input_data[:, :NUM_TIME_SLICES, :, :]\n",
    "\n",
    "            # sum over the x axis to turn the input data into a 2D NUM_TIME_SLICES x 13 tensor (time, y)\n",
    "            input_data = np.sum(input_data, axis=3)\n",
    "\n",
    "            # Encode the target data into one_hot encoding\n",
    "            one_hot = np.zeros((target_data.shape[0], 3))\n",
    "            # Assign 1 for p_t > pt_threshold in GeV, for low p_t put 1 in slot 2 for negative and a 1 in slot 3 for positive\n",
    "            one_hot[np.abs(target_data[:, 8]) >= pt_threshold, 0] = 1\n",
    "            one_hot[(np.abs(target_data[:, 8]) < pt_threshold) & (target_data[:, 8] > 0), 1] = 1\n",
    "            one_hot[(np.abs(target_data[:, 8]) < pt_threshold) & (target_data[:, 8] < 0), 2] = 1\n",
    "\n",
    "            # Flatten the input data\n",
    "            input_data = input_data.reshape(-1,NUM_TIME_SLICES*13)\n",
    "\n",
    "            # Get the y_0 data\n",
    "            y0_data = target_data[:,7].reshape(-1, 1)\n",
    "\n",
    "            # Normalize the input data according to scaling method\n",
    "            if INPUT_SCALING == \"Standard\" or INPUT_SCALING == \"MinMax\":\n",
    "                input_data = input_scaler.transform(input_data)\n",
    "                y0_data = y0_scaler.transform(y0_data)\n",
    "            elif INPUT_SCALING == \"Log\":\n",
    "                # Replace all values < 1 with 1 so they log to 0\n",
    "                input_data = np.where(np.abs(input_data) < 1.0, 1.0, input_data)\n",
    "                # Apply logarithmic scaling\n",
    "                input_data = np.log(np.abs(input_data)) * np.sign(input_data)\n",
    "                # Min-max normalization (global)\n",
    "                min_val = np.min(input_data)\n",
    "                max_val = np.max(input_data)\n",
    "                print(f\"max of log of data is {max_val} and min is {min_val}\")\n",
    "                input_data = (input_data) / np.max([max_val,min_val])\n",
    "            else: \n",
    "                raise ValueError(f\"unsupported INPUT_SCALING {INPUT_SCALING}\") \n",
    "\n",
    "            \n",
    "            # Combine with input data\n",
    "            if (MODEL_TYPE == \"DNN\"):\n",
    "                # For DNN we concatenate in the y_0 data\n",
    "                input_data_combined = np.hstack((input_data, y0_data))\n",
    "            elif (MODEL_TYPE == \"CNN\"):\n",
    "                # Reshape data into a matrix for the convolutions\n",
    "                input_data = input_data.reshape(-1, NUM_TIME_SLICES, 13)\n",
    "                # Package with the y_0 data to be added later\n",
    "                input_data_combined = [input_data, y0_data]\n",
    "            elif (MODEL_TYPE == \"AE\"):\n",
    "                # Reshape data into a matrix for the convolutions\n",
    "                input_data_combined = input_data.reshape(-1, NUM_TIME_SLICES, 13)\n",
    "            else: \n",
    "                raise ValueError(f\"unsupported MODEL_TYPE {MODEL_TYPE}\") \n",
    "            \n",
    "            return input_data_combined, one_hot\n",
    "        else:\n",
    "            raise ValueError(\"Wrong array shape!\")\n",
    "\n",
    "    # Apply data processing to our datasets\n",
    "    input_train_data_combined, target_train_data_coded = process_data(input_train_data, target_train_data, TRAIN_PT_THRESHOLD)\n",
    "    input_validate_data_combined, target_validate_data_coded = process_data(input_validate_data, target_validate_data, TRAIN_PT_THRESHOLD)\n",
    "    input_test_data_combined, target_test_data_coded = process_data(input_test_data, target_test_data, TEST_PT_THRESHOLD)\n",
    "\n",
    "    # Save some data for displaying\n",
    "    if MODEL_TYPE == \"DNN\" or MODEL_TYPE == \"AE\":\n",
    "        input_data_combined_example = input_test_data_combined[0:100,:]\n",
    "        target_data_coded_example = target_test_data_coded[0:100,:]\n",
    "    elif MODEL_TYPE == \"CNN\":\n",
    "        input_data_combined_example = np.hstack((input_test_data_combined[0][0:100,:].reshape(100, -1), input_test_data_combined[1][0:100,:]))\n",
    "        target_data_coded_example = target_test_data_coded[0:100,:]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type\")\n",
    "\n",
    "    print_memory_usage()\n",
    "\n",
    "    processed_dataset = {\n",
    "        \"input_train_data_combined\": input_train_data_combined,\n",
    "        \"target_train_data_coded\": target_train_data_coded,\n",
    "        \"input_validate_data_combined\": input_validate_data_combined,\n",
    "        \"target_validate_data_coded\": target_validate_data_coded,\n",
    "        \"input_test_data_combined\": input_test_data_combined,\n",
    "        \"target_test_data_coded\": target_test_data_coded,\n",
    "\n",
    "        \"input_data_example\": input_data_example,\n",
    "        \"target_data_example\": target_data_example,\n",
    "        \"input_data_combined_example\": input_data_combined_example,\n",
    "        \"target_data_coded_example\": target_data_coded_example,\n",
    "    }\n",
    "\n",
    "    return processed_dataset\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "# Defining the model\n",
    "def qDNNmodel(hyperparams):\n",
    "    NUM_TIME_SLICES = hyperparams[\"NUM_TIME_SLICES\"]\n",
    "    DNN_LAYERS = hyperparams[\"DNN_LAYERS\"]\n",
    "    WEIGHTS_BITS = hyperparams[\"WEIGHTS_BITS\"]\n",
    "    BIAS_BITS = hyperparams[\"BIAS_BITS\"]\n",
    "    ACTIVATION_BITS = hyperparams[\"ACTIVATION_BITS\"]\n",
    "    LEARNING_RATE = hyperparams[\"LEARNING_RATE\"]\n",
    "    \n",
    "    y_timed_input = Input(shape=(NUM_TIME_SLICES*13 + 1,), name='y_timed_input')\n",
    "    layer = y_timed_input\n",
    "    \n",
    "    for i, size in enumerate(DNN_LAYERS):\n",
    "        layer = QDense(size, kernel_quantizer=quantized_bits(WEIGHTS_BITS), bias_quantizer=quantized_bits(BIAS_BITS), name=f'dense{i+1}')(layer)\n",
    "        layer = QActivation(quantized_relu(ACTIVATION_BITS))(layer)\n",
    "        layer = BatchNormalization()(layer)\n",
    "    \n",
    "    output = QDense(3, kernel_quantizer=quantized_bits(WEIGHTS_BITS), bias_quantizer=quantized_bits(BIAS_BITS), name='dense_output')(layer)\n",
    "    output_softmax = Activation(\"softmax\", name='output_softmax')(output)\n",
    "   \n",
    "    model = Model(inputs=y_timed_input, outputs=output_softmax)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='categorical_crossentropy', metrics=[Precision()])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def qCNNmodel(hyperparams):\n",
    "    NUM_TIME_SLICES = hyperparams[\"NUM_TIME_SLICES\"]\n",
    "    CONV_LAYER_DEPTHS = hyperparams[\"CONV_LAYER_DEPTHS\"]\n",
    "    CONV_LAYER_KERNELS = hyperparams[\"CONV_LAYER_KERNELS\"]\n",
    "    CONV_LAYER_STRIDES = hyperparams[\"CONV_LAYER_STRIDES\"]\n",
    "    MAX_POOLING_SIZE = hyperparams[\"MAX_POOLING_SIZE\"]\n",
    "    FLATTENED_LAYERS = hyperparams[\"FLATTENED_LAYERS\"]\n",
    "    WEIGHTS_BITS = hyperparams[\"WEIGHTS_BITS\"]\n",
    "    BIAS_BITS = hyperparams[\"BIAS_BITS\"]\n",
    "    INTEGER_BITS = hyperparams[\"INTEGER_BITS\"]\n",
    "    ACTIVATION_BITS = hyperparams[\"ACTIVATION_BITS\"]\n",
    "    LEARNING_RATE = hyperparams[\"LEARNING_RATE\"]\n",
    "\n",
    "    y_profile_input = Input(shape=(NUM_TIME_SLICES, 13, 1), name='y_profile_input')  # Adjust the shape based on your input\n",
    "    layer = y_profile_input\n",
    "\n",
    "    # Convolutional layers\n",
    "    for i in range(len(CONV_LAYER_DEPTHS)):\n",
    "        layer = QConv2D(\n",
    "        CONV_LAYER_DEPTHS[i],\n",
    "        kernel_size=CONV_LAYER_KERNELS[i],\n",
    "        strides=CONV_LAYER_STRIDES,\n",
    "        kernel_quantizer=quantized_bits(WEIGHTS_BITS,INTEGER_BITS,alpha=1.0),\n",
    "        bias_quantizer=quantized_bits(BIAS_BITS,INTEGER_BITS,alpha=1.0),\n",
    "        padding='same',\n",
    "        use_bias=True,\n",
    "        name=f'conv{i+1}'\n",
    "        )(layer)\n",
    "        layer = QActivation(quantized_relu(ACTIVATION_BITS), name=f'relu{i+1}')(layer)\n",
    "        layer = MaxPooling2D(pool_size=MAX_POOLING_SIZE, name=f'maxpool{i+1}')(layer)\n",
    "\n",
    "    # Flatten the output to feed into a dense layer\n",
    "    layer = Flatten(name='flattened')(layer)\n",
    "\n",
    "    # Flatten and concatenate with y0 input\n",
    "    y0_input = Input(shape=(1,), name='y0_input')\n",
    "    layer = Concatenate(name='concat')([layer, y0_input])\n",
    "\n",
    "    # Post-flattening dense layers\n",
    "    for i in range(len(FLATTENED_LAYERS)):\n",
    "        layer = QDense(FLATTENED_LAYERS[i], kernel_quantizer=quantized_bits(WEIGHTS_BITS,INTEGER_BITS,alpha=1.0),\n",
    "                    bias_quantizer=quantized_bits(BIAS_BITS,INTEGER_BITS,alpha=1.0), name=f'dense{i+1}')(layer)\n",
    "        layer = QActivation(quantized_relu(10), name=f'relu{len(CONV_LAYER_DEPTHS)+i+1}')(layer)\n",
    "\n",
    "    # Output layer (adjust based on your classification problem)\n",
    "    output = QDense(3, kernel_quantizer=quantized_bits(WEIGHTS_BITS), bias_quantizer=quantized_bits(BIAS_BITS), name='dense_output')(layer)\n",
    "    output = Activation(\"softmax\", name='output_softmax')(output)\n",
    "    # layer = QDense(1, kernel_quantizer=quantized_bits(WEIGHTS_BITS,INTEGER_BITS,alpha=1.0), \n",
    "    #                bias_quantizer=quantized_bits(BIAS_BITS,INTEGER_BITS,alpha=1.0), name='output_dense')(layer)\n",
    "    # output = Activation(\"sigmoid\", name='output_sigmoid')(layer)\n",
    "\n",
    "    model = Model(inputs=[y_profile_input, y0_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='categorical_crossentropy', metrics=['accuracy']) # loss='binary_crossentropy'\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def qAEmodel(hyperparams):\n",
    "    NUM_TIME_SLICES = hyperparams[\"NUM_TIME_SLICES\"]\n",
    "    AU_ENCODER_LAYERS = hyperparams[\"AU_ENCODER_LAYERS\"]\n",
    "    AU_DECODER_LAYERS = hyperparams[\"AU_DECODER_LAYERS\"]\n",
    "    CONV_LAYER_STRIDES = hyperparams[\"CONV_LAYER_STRIDES\"]\n",
    "    MAX_POOLING_SIZE = hyperparams[\"MAX_POOLING_SIZE\"]\n",
    "    WEIGHTS_BITS = hyperparams[\"WEIGHTS_BITS\"]\n",
    "    BIAS_BITS = hyperparams[\"BIAS_BITS\"]\n",
    "    INTEGER_BITS = hyperparams[\"INTEGER_BITS\"]\n",
    "    ACTIVATION_BITS = hyperparams[\"ACTIVATION_BITS\"]\n",
    "    LEARNING_RATE = hyperparams[\"LEARNING_RATE\"]\n",
    "\n",
    "    y_profile_input = Input(shape=(NUM_TIME_SLICES, 13, 1), name='y_profile_input')  # Adjust the shape based on your input\n",
    "    layer = y_profile_input\n",
    "\n",
    "    print(layer.shape)\n",
    "    layer = Flatten(name='flatten_input')(layer)\n",
    "    print(layer.shape)\n",
    "\n",
    "    all_layer_specs = AU_ENCODER_LAYERS + AU_DECODER_LAYERS\n",
    "    # Add encoder layers\n",
    "    for i in range(len(all_layer_specs)):\n",
    "        layer_specs = all_layer_specs[i]\n",
    "\n",
    "        if isinstance(layer_specs, int):\n",
    "            # Flatten layer if necessary\n",
    "            if (len(layer.shape) != 2):\n",
    "                layer = Flatten(name=f'flatten{i}')(layer)\n",
    "            layer = QDense(layer_specs, kernel_quantizer=quantized_bits(WEIGHTS_BITS), bias_quantizer=quantized_bits(BIAS_BITS), name=f'dense{i+1}')(layer)\n",
    "            layer = QActivation(quantized_relu(ACTIVATION_BITS))(layer)\n",
    "            layer = BatchNormalization()(layer)\n",
    "\n",
    "        elif isinstance(layer_specs, tuple):\n",
    "            # Reshape layer if necessary\n",
    "            if (len(layer.shape) != 4):\n",
    "                layer = Reshape((NUM_TIME_SLICES, 13, 1), name=f'reshape{i}')(layer)\n",
    "            layer = QConv2D(\n",
    "            layer_specs[0],\n",
    "            kernel_size=(layer_specs[1], layer_specs[2]),\n",
    "            strides=CONV_LAYER_STRIDES,\n",
    "            kernel_quantizer=quantized_bits(WEIGHTS_BITS,INTEGER_BITS,alpha=1.0),\n",
    "            bias_quantizer=quantized_bits(BIAS_BITS,INTEGER_BITS,alpha=1.0),\n",
    "            padding='same',\n",
    "            use_bias=True,\n",
    "            name=f'conv{i+1}'\n",
    "            )(layer)\n",
    "            layer = QActivation(quantized_relu(ACTIVATION_BITS), name=f'relu{i+1}')(layer)\n",
    "            layer = MaxPooling2D(pool_size=MAX_POOLING_SIZE, name=f'maxpool{i+1}')(layer)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported layer specification: {layer_specs}\")\n",
    "        print(layer.shape)\n",
    "\n",
    "    # Reshape output layer if necessary\n",
    "    if (len(layer.shape) != 4):\n",
    "        layer = Reshape((NUM_TIME_SLICES, 13, 1), name=f'reshape_output')(layer)\n",
    "\n",
    "    ## TODO figure out what the output should be for autoencoder including y0 and supporting convolutions\n",
    "\n",
    "    model = Model(inputs=y_profile_input, outputs=layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='categorical_crossentropy', metrics=['accuracy']) # loss='binary_crossentropy'\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Pruning the model\n",
    "def pruneFunction(layer, train_data_size, hyperparams):\n",
    "    BATCH_SIZE = hyperparams[\"BATCH_SIZE\"]\n",
    "    FINAL_SPARSITY = hyperparams[\"FINAL_SPARSITY\"]\n",
    "    PRUNE_START_EPOCH = hyperparams[\"PRUNE_START_EPOCH\"]\n",
    "    NUM_PRUNE_EPOCHS = hyperparams[\"NUM_PRUNE_EPOCHS\"]\n",
    "\n",
    "    steps_per_epoch = train_data_size // BATCH_SIZE #input_train_data_combined.shape[0]\n",
    "    pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=0.0,\n",
    "            final_sparsity=FINAL_SPARSITY,\n",
    "            begin_step=steps_per_epoch * PRUNE_START_EPOCH,\n",
    "            end_step=steps_per_epoch * (PRUNE_START_EPOCH + NUM_PRUNE_EPOCHS),\n",
    "            frequency=steps_per_epoch # prune after every epoch\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "    if isinstance(layer, QDense):\n",
    "        if layer.name != 'output_softmax' and layer.name != 'dense2':\n",
    "            print(f\"pruning layer {layer.name}\")\n",
    "            return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "        elif layer.name != 'output_softmax' and layer.name != 'dense1':\n",
    "            print(f\"pruning layer {layer.name}\")\n",
    "            return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "        else:\n",
    "            print(f\"cannot prune layer {layer.name}\")\n",
    "            return layer\n",
    "\n",
    "    else:\n",
    "        print(f\"cannot prune layer {layer.name}\")\n",
    "        return layer\n",
    "    \n",
    "def pruneFunctionWrapper(train_data_size, hyperparams):\n",
    "    def wrapper(layer):\n",
    "        return pruneFunction(layer, train_data_size, hyperparams)\n",
    "    return wrapper\n",
    "    \n",
    "\n",
    "# Function to calculate sparsity\n",
    "def calculate_sparsity(model):\n",
    "    total_params = 0\n",
    "    zero_params = 0\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Dense):\n",
    "            weights = layer.get_weights()[0]\n",
    "            total_params += weights.size\n",
    "            zero_params += np.sum(weights == 0)\n",
    "    sparsity = zero_params / total_params\n",
    "    return sparsity\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "def train_model(data, hyperparams):\n",
    "    input_train_data_combined = data[\"input_train_data_combined\"]\n",
    "    target_train_data_coded = data[\"target_train_data_coded\"]\n",
    "    input_validate_data_combined = data[\"input_validate_data_combined\"]\n",
    "    target_validate_data_coded = data[\"target_validate_data_coded\"]\n",
    "\n",
    "    MODEL_TYPE = hyperparams[\"MODEL_TYPE\"]\n",
    "    PATIENCE = hyperparams[\"PATIENCE\"]\n",
    "    EPOCHS = hyperparams[\"EPOCHS\"]\n",
    "    BATCH_SIZE = hyperparams[\"BATCH_SIZE\"]\n",
    "    LEARNING_RATE = hyperparams[\"LEARNING_RATE\"]\n",
    "    POST_PRUNE_EPOCHS = hyperparams[\"POST_PRUNE_EPOCHS\"]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Define the model\n",
    "    if (MODEL_TYPE == \"DNN\"):\n",
    "        model = qDNNmodel(hyperparams)\n",
    "    elif (MODEL_TYPE == \"CNN\"):\n",
    "        model = qCNNmodel(hyperparams)\n",
    "    elif (MODEL_TYPE == \"AE\"):\n",
    "        model = qAEmodel(hyperparams)\n",
    "    else:\n",
    "        raise ValueError(\"Not a supported model type\")\n",
    "\n",
    "    model.summary()\n",
    "    print_qmodel_summary(model)\n",
    "    print(f\"Initial Sparsity: {calculate_sparsity(model) * 100:.2f}%\")\n",
    "\n",
    "    train_metrics = {}\n",
    "\n",
    "    # Train the model\n",
    "    earlyStop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=PATIENCE, restore_best_weights=True)\n",
    "    if MODEL_TYPE == \"DNN\" or MODEL_TYPE == \"CNN\":\n",
    "        history = model.fit(\n",
    "            input_train_data_combined, target_train_data_coded,  # Training data and labels\n",
    "            validation_data=(input_validate_data_combined, target_validate_data_coded),  # Validation data\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks=[earlyStop_callback]\n",
    "        )\n",
    "    elif (MODEL_TYPE == \"AE\"):\n",
    "        history = model.fit(\n",
    "            input_train_data_combined, input_train_data_combined,  # Training data and labels\n",
    "            validation_data=(input_validate_data_combined, input_validate_data_combined),  # Validation data\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks=[earlyStop_callback]\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Not a supported model type\")\n",
    "    \n",
    "    \n",
    "    # Best at this step val_loss 0.7085\n",
    "    train_metrics[\"val_loss\"] = history.history['val_loss'][-1]\n",
    "\n",
    "    # Prune the model\n",
    "    model_pruned = keras.models.clone_model(model, clone_function=pruneFunctionWrapper(input_train_data_combined.shape[0], hyperparams))\n",
    "    model_pruned.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    if MODEL_TYPE == \"DNN\" or MODEL_TYPE == \"CNN\":\n",
    "        history = model_pruned.fit(\n",
    "            input_train_data_combined, target_train_data_coded,\n",
    "            validation_data=(input_validate_data_combined, target_validate_data_coded),\n",
    "            epochs=POST_PRUNE_EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks = [pruning_callbacks.UpdatePruningStep()]\n",
    "        )\n",
    "    if MODEL_TYPE == \"AE\":\n",
    "        history = model_pruned.fit(\n",
    "            input_train_data_combined, input_train_data_combined,\n",
    "            validation_data=(input_validate_data_combined, input_validate_data_combined), \n",
    "            epochs=POST_PRUNE_EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks = [pruning_callbacks.UpdatePruningStep()]\n",
    "        ) \n",
    "\n",
    "    model = strip_pruning(model_pruned)\n",
    "    # train_metrics[\"pruned_sparsity\"] = calculate_sparsity(model)\n",
    "\n",
    "    try:\n",
    "        train_metrics[\"pruned_val_loss\"] = history.history['val_loss'][-1]\n",
    "    except:\n",
    "        print(\"Error: no post-pruning val_loss found\")\n",
    "        train_metrics[\"pruned_val_loss\"] = train_metrics[\"val_loss\"]\n",
    "\n",
    "    return model, train_metrics\n",
    "\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "def test_model(data, model):\n",
    "    input_test_data_combined = data[\"input_test_data_combined\"]\n",
    "    target_test_data_coded = data[\"target_test_data_coded\"]\n",
    "\n",
    "    \n",
    "    # Test the model at threshold 0.5\n",
    "    predictions_prob = model.predict(input_test_data_combined)[:,0]\n",
    "    predictions_labels = (predictions_prob >= 0.5).astype(int).flatten()\n",
    "\n",
    "    # Test the model at different thresholds\n",
    "    thresholds = np.linspace(0.0, 1.0, 1000)\n",
    "    signal_efficiencies = []\n",
    "    background_rejections = []\n",
    "    max_sum_se = 0\n",
    "    max_sum_br = 0\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        # predicted_class = ((predictions_prob[:, 0] + threshold > predictions_prob[:, 1]) & (predictions_prob[:, 0] + threshold > predictions_prob[:, 2])).astype(int)\n",
    "        predicted_class = (predictions_prob > threshold).astype(int)\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(target_test_data_coded[:, 0], predicted_class)\n",
    "\n",
    "        # Calculate signal efficiency and background rejection\n",
    "        signal_efficiency = cm[1, 1] / np.sum(cm[1, :])\n",
    "        background_rejection = cm[0, 0] / np.sum(cm[0, :])\n",
    "\n",
    "        # Store metrics\n",
    "        signal_efficiencies.append(signal_efficiency)\n",
    "        background_rejections.append(background_rejection)\n",
    "\n",
    "        # get maximum added score\n",
    "        if signal_efficiency + background_rejection > max_sum_se + max_sum_br:\n",
    "            max_sum_se = signal_efficiency\n",
    "            max_sum_br = background_rejection\n",
    "    \n",
    "    test_results = {\n",
    "        \"predictions_prob\": predictions_prob,\n",
    "        \"predictions_labels\": predictions_labels,\n",
    "        \"thresholds\": thresholds,\n",
    "        \"signal_efficiencies\": signal_efficiencies,\n",
    "        \"background_rejections\": background_rejections,\n",
    "        \"max_sum_se\": max_sum_se,\n",
    "        \"max_sum_br\": max_sum_br,\n",
    "    }\n",
    "\n",
    "    return test_results\n",
    "\n",
    "def ShowConfusionMatrix(test_results):\n",
    "    target_test_data_coded = test_results[\"target_test_data_coded\"]\n",
    "    predictions_labels = test_results[\"predictions_labels\"]\n",
    "\n",
    "    cm = confusion_matrix(target_test_data_coded[:,0], predictions_labels)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='YlGnBu')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def showMetricsByThreshold(test_results):\n",
    "    thresholds = test_results[\"thresholds\"]\n",
    "    signal_efficiencies = test_results[\"signal_efficiencies\"]\n",
    "    background_rejections = test_results[\"background_rejections\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(thresholds, signal_efficiencies, label='Signal Efficiency')\n",
    "    plt.plot(thresholds, background_rejections, label='Background Rejection')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.title('Effect of Threshold on Signal Efficiency and Background Rejection')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def showEfficiencyVSRejection(test_results):\n",
    "    signal_efficiencies = test_results[\"signal_efficiencies\"]\n",
    "    background_rejections = test_results[\"background_rejections\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(signal_efficiencies, background_rejections, marker='o')\n",
    "    plt.xlabel('Signal Efficiency')\n",
    "    plt.ylabel('Background Rejection')\n",
    "    plt.title('Background Rejection vs. Signal Efficiency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def find_closest(sorted_array, value):\n",
    "    # Ensure the array is a NumPy array\n",
    "    sorted_array = np.array(sorted_array)\n",
    "    # Compute the absolute difference\n",
    "    abs_diff = np.abs(sorted_array - value)\n",
    "    # Find the index of the minimum difference\n",
    "    closest_index = np.argmin(abs_diff)\n",
    "    return closest_index\n",
    "\n",
    "def getTargetMetrics(test_results):\n",
    "    signal_efficiencies = test_results[\"signal_efficiencies\"]\n",
    "    background_rejections = test_results[\"background_rejections\"]\n",
    "\n",
    "    target_efficiencies = [0.90, 0.93, 0.96, 0.98, 0.99, 0.995, 0.999]\n",
    "    metrics = []\n",
    "    for target in target_efficiencies:\n",
    "        index = find_closest(signal_efficiencies, target)\n",
    "        metrics.append((signal_efficiencies[index], background_rejections[index]))\n",
    "        # print(f\"Signal Efficiency: {signal_efficiencies[index]*100:.1f}%,\",f\"Background Rejections: {background_rejections[index]*100:.1f}%\")\n",
    "    return metrics\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "def hyperparameter_search(data, base_hyperparams, param_grid, result_file='hyperparameter_results.json'):\n",
    "    # Load existing results from file if it exists\n",
    "    if os.path.exists(result_file):\n",
    "        with open(result_file, 'r') as file:\n",
    "            all_results = json.load(file)\n",
    "    else:\n",
    "        all_results = {}\n",
    "\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    for v in itertools.product(*values):\n",
    "        hyperparams = dict(zip(keys, v))\n",
    "        # Update base hyperparameters with the current set\n",
    "        current_hyperparams = base_hyperparams.copy()\n",
    "        current_hyperparams.update(hyperparams)\n",
    "\n",
    "        # Convert hyperparameters to a string for use as a dictionary key\n",
    "        hyperparams_str = json.dumps(current_hyperparams, sort_keys=True)\n",
    "\n",
    "        # Check if these hyperparameters have been tried before\n",
    "        if hyperparams_str in all_results:\n",
    "            print(f\"Skipping already tested hyperparameters: {current_hyperparams}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Testing hyperparameters: {current_hyperparams}\")\n",
    "\n",
    "        # Train the model\n",
    "        model, train_metrics = train_model(data, current_hyperparams)\n",
    "\n",
    "        # Test the model\n",
    "        test_results = test_model(data, model)\n",
    "        metrics = getTargetMetrics(test_results)\n",
    "        metrics_str = \", \".join([f\"({m1:.4f}, {m2:.4f})\" for m1, m2 in metrics])\n",
    "        \n",
    "        test_scores = {\n",
    "            \"max_sum_se\": test_results[\"max_sum_se\"],\n",
    "            \"max_sum_br\": test_results[\"max_sum_br\"],\n",
    "            \"metrics\": metrics_str,\n",
    "        }\n",
    "        # Add all keys and values from train_metrics into test_scores\n",
    "        test_scores.update(train_metrics)\n",
    "\n",
    "        # Save the results to the file\n",
    "        all_results[hyperparams_str] = test_scores\n",
    "        with open(result_file, 'w') as file:\n",
    "            json.dump(all_results, file, indent=4)\n",
    "\n",
    "\n",
    "        # If new best found, email alex\n",
    "        if test_scores[\"pruned_val_loss\"] < find_min_pruned_val_loss(result_file):\n",
    "\n",
    "            # email results\n",
    "            model_name = \"undefined\"\n",
    "            if (current_hyperparams[\"MODEL_TYPE\"] == \"DNN\"):\n",
    "                model_name = \"Dean\"\n",
    "            elif (current_hyperparams[\"MODEL_TYPE\"] == \"CNN\"):\n",
    "                model_name = \"Connor\"\n",
    "            elif (current_hyperparams[\"MODEL_TYPE\"] == \"AE\"):\n",
    "                model_name = \"Audrey\"\n",
    "            send_email_notification(\"ML Training Report\", \n",
    "                f' \\\n",
    "                Your model {model_name} has finished training. \\\n",
    "                He got a grade of {test_scores[\"max_sum_se\"]*100:.1f}% in SE and {test_scores[\"max_sum_br\"]*100:.1f}% in BR. \\\n",
    "                New lowest validated loss: {test_scores[\"pruned_val_loss\"]} \\n \\\n",
    "                All metrics: {metrics_str} \\n \\\n",
    "                Hyperparams: {hyperparams_str} \\\n",
    "                ')\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def find_min_pruned_val_loss(result_file='hyperparameter_results.json'):\n",
    "    # Load existing results from file\n",
    "    if os.path.exists(result_file):\n",
    "        with open(result_file, 'r') as file:\n",
    "            all_results = json.load(file)\n",
    "    else:\n",
    "        print(f\"No results found in {result_file}\")\n",
    "        return None\n",
    "\n",
    "    min_loss = float('inf')\n",
    "    min_hyperparams = None\n",
    "\n",
    "    # Iterate through the results to find the minimum pruned_val_loss\n",
    "    for hyperparams_str, results in all_results.items():\n",
    "        if \"pruned_val_loss\" in results:\n",
    "            pruned_val_loss = results[\"pruned_val_loss\"]\n",
    "            if pruned_val_loss < min_loss:\n",
    "                min_loss = pruned_val_loss\n",
    "                min_hyperparams = hyperparams_str\n",
    "\n",
    "    # Print the hyperparameters with the minimum pruned_val_loss\n",
    "    if min_hyperparams is not None:\n",
    "        print(f\"Hyperparameters with minimum pruned_val_loss: {min_hyperparams}\")\n",
    "        print(f\"Minimum pruned_val_loss: {min_loss}\")\n",
    "    else:\n",
    "        print(\"No entry with pruned_val_loss found\")\n",
    "\n",
    "    return min_loss\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results found in AE_hyperparameter_results.json\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "HYPERPARAMETERS = {\n",
    "    # Model Type\n",
    "    \"MODEL_TYPE\": \"AE\",  # DNN or CNN or AE\n",
    "    # Input format\n",
    "    \"NUM_TIME_SLICES\": 8,\n",
    "    \"TRAIN_PT_THRESHOLD\": 2,  # in GeV\n",
    "    \"TEST_PT_THRESHOLD\": 2,  # in GeV\n",
    "    \"INPUT_SCALING\": \"MinMax\", # Standard, MinMax or Log\n",
    "    # DNN model mormat\n",
    "    \"DNN_LAYERS\": [128, 64, 32, 16], # [32, (16, 3, 3), (16, 3, 3), 32]\n",
    "    # CNN model format\n",
    "    \"CONV_LAYER_DEPTHS\": [4, 7],\n",
    "    \"CONV_LAYER_KERNELS\": [(3, 3), (3, 3)],\n",
    "    \"FLATTENED_LAYERS\": [7],\n",
    "    \"CONV_LAYER_STRIDES\": (1, 1),\n",
    "    \"MAX_POOLING_SIZE\": (2, 2),\n",
    "    # AU model format. n is dense layer of size n, (n, m, l) is conv layer of dept n and kernel size (m, l)\n",
    "    ## TODO: add maxpooling and sampling and crop to support CNN for AE\n",
    "    \"AU_ENCODER_LAYERS\": [(4, 3, 3), 64],\n",
    "    \"AU_DECODER_LAYERS\": [8*13], # Includes output. Must result in NUM_TIME_SLICES * 13 or (NUM_TIME_SLICES, 13) sized final layer\n",
    "    # Model quantization\n",
    "    \"WEIGHTS_BITS\": 10,\n",
    "    \"BIAS_BITS\": 10,\n",
    "    \"ACTIVATION_BITS\": 15,\n",
    "    \"INTEGER_BITS\": 2,\n",
    "    # Training\n",
    "    \"LEARNING_RATE\": 0.001,\n",
    "    \"BATCH_SIZE\": 1024,  # Number of samples per gradient update\n",
    "    \"EPOCHS\": 100,  # Number of epochs to train\n",
    "    \"PATIENCE\": 20,  # Stop after this number of epochs without improvement\n",
    "    # Pruning\n",
    "    \"PRUNE_START_EPOCH\": 0,  # Number of epochs before pruning\n",
    "    \"NUM_PRUNE_EPOCHS\": 10,\n",
    "    \"FINAL_SPARSITY\": 0.35,\n",
    "    \"POST_PRUNE_EPOCHS\": 50,\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    \"LEARNING_RATE\": [0.005, 0.001, 0.0005],\n",
    "    \"BATCH_SIZE\": [512, 1024, 2048],\n",
    "    \"EPOCHS\": [4, 50, 100, 200], \n",
    "    \"POST_PRUNE_EPOCHS\": [4,35, 50, 100], \n",
    "}\n",
    "\n",
    "find_min_pruned_val_loss(result_file=(HYPERPARAMETERS[\"MODEL_TYPE\"]+\"_hyperparameter_results.json\"))\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 376.23 GB\n",
      "Available memory: 258.77 GB\n",
      "Used memory: 107.57 GB\n",
      "Memory usage percentage: 31.2%\n",
      "Total memory: 376.23 GB\n",
      "Available memory: 258.51 GB\n",
      "Used memory: 107.84 GB\n",
      "Memory usage percentage: 31.3%\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "input_data, target_data = load_dataset()\n",
    "data = process_dataset(input_data, target_data, HYPERPARAMETERS) \n",
    "# Depends only on: NUM_TIME_SLICES MODEL_TYPE TRAIN_PT_THRESHOLD TEST_PT_THRESHOLD\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 8, 13, 1)\n",
      "(None, 104)\n",
      "(None, 4, 6, 4)\n",
      "(None, 64)\n",
      "(None, 104)\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_profile_input (InputLaye  [(None, 8, 13, 1)]        0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " flatten_input (Flatten)     (None, 104)               0         \n",
      "                                                                 \n",
      " reshape0 (Reshape)          (None, 8, 13, 1)          0         \n",
      "                                                                 \n",
      " conv1 (QConv2D)             (None, 8, 13, 4)          40        \n",
      "                                                                 \n",
      " relu1 (QActivation)         (None, 8, 13, 4)          0         \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling2D)     (None, 4, 6, 4)           0         \n",
      "                                                                 \n",
      " flatten1 (Flatten)          (None, 96)                0         \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 64)                6208      \n",
      "                                                                 \n",
      " q_activation_43 (QActivati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " batch_normalization_43 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense3 (QDense)             (None, 104)               6760      \n",
      "                                                                 \n",
      " q_activation_44 (QActivati  (None, 104)               0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " batch_normalization_44 (Ba  (None, 104)               416       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " reshape_output (Reshape)    (None, 8, 13, 1)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13680 (53.44 KB)\n",
      "Trainable params: 13344 (52.12 KB)\n",
      "Non-trainable params: 336 (1.31 KB)\n",
      "_________________________________________________________________\n",
      "conv1                f=4 quantized_bits(10,2,0,alpha=1.0) quantized_bits(10,2,0,alpha=1.0) \n",
      "relu1                quantized_relu(15,0)\n",
      "dense2               u=64 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "q_activation_43      quantized_relu(15,0)\n",
      "batch_normalization_43 is normal keras bn layer\n",
      "dense3               u=104 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "q_activation_44      quantized_relu(15,0)\n",
      "batch_normalization_44 is normal keras bn layer\n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "Epoch 1/100\n",
      "429/429 [==============================] - 16s 26ms/step - loss: 7.4756 - accuracy: 6.5748e-08 - val_loss: 5.9044 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 5.1682 - accuracy: 8.7664e-08 - val_loss: 4.7775 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 4.4215 - accuracy: 8.7664e-08 - val_loss: 4.2563 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 4.1530 - accuracy: 8.7664e-08 - val_loss: 4.3055 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 4.0687 - accuracy: 8.7664e-08 - val_loss: 4.2853 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 4.0012 - accuracy: 8.7664e-08 - val_loss: 3.9921 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.9283 - accuracy: 8.7664e-08 - val_loss: 3.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.9498 - accuracy: 8.7664e-08 - val_loss: 3.9783 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.9150 - accuracy: 8.7664e-08 - val_loss: 3.9036 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.9006 - accuracy: 8.7664e-08 - val_loss: 3.9243 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8607 - accuracy: 8.7664e-08 - val_loss: 3.8614 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8237 - accuracy: 8.7664e-08 - val_loss: 3.8248 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8366 - accuracy: 8.7664e-08 - val_loss: 3.8358 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8158 - accuracy: 8.7664e-08 - val_loss: 3.8149 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8244 - accuracy: 8.7664e-08 - val_loss: 4.0220 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8104 - accuracy: 8.7664e-08 - val_loss: 3.7734 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7738 - accuracy: 8.7664e-08 - val_loss: 3.7676 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7417 - accuracy: 8.7664e-08 - val_loss: 3.7401 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7927 - accuracy: 8.7664e-08 - val_loss: 3.9055 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7700 - accuracy: 8.7664e-08 - val_loss: 3.8711 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8311 - accuracy: 8.7664e-08 - val_loss: 3.8558 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7799 - accuracy: 8.7664e-08 - val_loss: 3.7646 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7695 - accuracy: 8.7664e-08 - val_loss: 3.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7719 - accuracy: 8.7664e-08 - val_loss: 3.7576 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7468 - accuracy: 8.7664e-08 - val_loss: 3.9792 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8288 - accuracy: 8.7664e-08 - val_loss: 3.8812 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7864 - accuracy: 8.7664e-08 - val_loss: 3.7752 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7623 - accuracy: 8.7664e-08 - val_loss: 3.7467 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7296 - accuracy: 8.7664e-08 - val_loss: 3.7434 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7283 - accuracy: 8.7664e-08 - val_loss: 3.7296 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8125 - accuracy: 8.7664e-08 - val_loss: 3.9330 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7879 - accuracy: 8.7664e-08 - val_loss: 3.7917 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7407 - accuracy: 8.7664e-08 - val_loss: 3.7562 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7548 - accuracy: 8.7664e-08 - val_loss: 3.7593 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8202 - accuracy: 8.7664e-08 - val_loss: 4.3518 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.9175 - accuracy: 4.3832e-08 - val_loss: 4.3411 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.9796 - accuracy: 0.0000e+00 - val_loss: 3.9373 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8834 - accuracy: 0.0000e+00 - val_loss: 3.8938 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 4.7067 - accuracy: 0.0000e+00 - val_loss: 4.2271 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 4.4377 - accuracy: 0.0000e+00 - val_loss: 4.0386 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8622 - accuracy: 0.0000e+00 - val_loss: 3.9776 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8160 - accuracy: 0.0000e+00 - val_loss: 3.8341 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8435 - accuracy: 0.0000e+00 - val_loss: 3.9482 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8988 - accuracy: 0.0000e+00 - val_loss: 3.9775 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8460 - accuracy: 0.0000e+00 - val_loss: 3.8805 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.8115 - accuracy: 0.0000e+00 - val_loss: 3.7700 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7949 - accuracy: 0.0000e+00 - val_loss: 3.7630 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.7270 - accuracy: 0.0000e+00 - val_loss: 3.7204 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 3.6943 - accuracy: 0.0000e+00 - val_loss: 3.6666 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 3.7086 - accuracy: 0.0000e+00 - val_loss: 4.4073 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 4.4023 - accuracy: 0.0000e+00 - val_loss: 4.7075 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 4.4248 - accuracy: 0.0000e+00 - val_loss: 4.2117 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 4.1556 - accuracy: 0.0000e+00 - val_loss: 4.2942 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "429/429 [==============================] - 8s 19ms/step - loss: 4.2784 - accuracy: 0.0000e+00 - val_loss: 4.9448 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "429/429 [==============================] - 8s 19ms/step - loss: 4.9643 - accuracy: 0.0000e+00 - val_loss: 5.0773 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "429/429 [==============================] - 8s 19ms/step - loss: 6.3701 - accuracy: 0.0000e+00 - val_loss: 6.3425 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "429/429 [==============================] - 8s 19ms/step - loss: 6.9129 - accuracy: 0.0000e+00 - val_loss: 7.4874 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "429/429 [==============================] - 8s 19ms/step - loss: 6.7662 - accuracy: 0.0000e+00 - val_loss: 7.4859 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "429/429 [==============================] - 8s 19ms/step - loss: 6.7653 - accuracy: 0.0000e+00 - val_loss: 7.4855 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "429/429 [==============================] - 8s 19ms/step - loss: 6.7646 - accuracy: 0.0000e+00 - val_loss: 7.4847 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "429/429 [==============================] - 8s 19ms/step - loss: 6.7640 - accuracy: 0.0000e+00 - val_loss: 7.4838 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "429/429 [==============================] - 8s 19ms/step - loss: 6.7635 - accuracy: 0.0000e+00 - val_loss: 7.4833 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "429/429 [==============================] - 8s 19ms/step - loss: 6.7631 - accuracy: 0.0000e+00 - val_loss: 7.4828 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "429/429 [==============================] - 8s 19ms/step - loss: 6.7628 - accuracy: 0.0000e+00 - val_loss: 7.4823 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "429/429 [==============================] - 8s 19ms/step - loss: 6.7627 - accuracy: 0.0000e+00 - val_loss: 7.4823 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "429/429 [==============================] - 9s 21ms/step - loss: 6.7626 - accuracy: 0.0000e+00 - val_loss: 7.4820 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 6.7625 - accuracy: 0.0000e+00 - val_loss: 7.4818 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 6.7625 - accuracy: 0.0000e+00 - val_loss: 7.4823 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 6.7625 - accuracy: 0.0000e+00 - val_loss: 7.4826 - val_accuracy: 0.0000e+00\n",
      "cannot prune layer flatten_input\n",
      "cannot prune layer reshape0\n",
      "cannot prune layer conv1\n",
      "cannot prune layer relu1\n",
      "cannot prune layer maxpool1\n",
      "cannot prune layer flatten1\n",
      "pruning layer dense2\n",
      "cannot prune layer q_activation_43\n",
      "cannot prune layer batch_normalization_43\n",
      "pruning layer dense3\n",
      "cannot prune layer q_activation_44\n",
      "cannot prune layer batch_normalization_44\n",
      "cannot prune layer reshape_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 17s 27ms/step - loss: 0.9054 - accuracy: 0.0000e+00 - val_loss: 0.9900 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.8809 - accuracy: 0.0000e+00 - val_loss: 1.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.8806 - accuracy: 0.0000e+00 - val_loss: 0.9857 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 1.0173 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 1.0016 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 1.0017 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.9658 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.9292 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.9336 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8807 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8808 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8812 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8808 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8808 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8808 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8809 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8809 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8808 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8812 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8811 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8807 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8808 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8879 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8808 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8809 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8880 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8813 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8833 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8884 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8814 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8811 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8818 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8814 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8810 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8945 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8822 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8814 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8648 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8841 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8844 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8895 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8813 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8823 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8818 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8691 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8815 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 10s 23ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8662 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 10s 24ms/step - loss: 0.8805 - accuracy: 0.0000e+00 - val_loss: 0.9064 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model, train_metrics = train_model(data, HYPERPARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sdf/home/a/alexyue/miniconda3/envs/SmartPixel/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(f'./{HYPERPARAMETERS[\"MODEL_TYPE\"]}_best_perfomance.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "results = hyperparameter_search(data, HYPERPARAMETERS, param_grid, result_file=(HYPERPARAMETERS[\"MODEL_TYPE\"]+\"_hyperparameter_results.json\"))\n",
    "\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_metrics(metrics):\n",
    "    # Convert metrics list of tuples to a formatted string\n",
    "    return \", \".join([f\"({m1:.4f}, {m2:.4f})\" for m1, m2 in metrics])\n",
    "\n",
    "def reformat_hyperparameter_results(input_file, output_file):\n",
    "    # Read the original JSON file\n",
    "    with open(input_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Process and format the metrics\n",
    "    for key, value in data.items():\n",
    "        if \"metrics\" in value:\n",
    "            value[\"metrics\"] = format_metrics(value[\"metrics\"])\n",
    "\n",
    "    # Write the updated data to the new JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "# Define input and output file names\n",
    "input_file = 'OLD_DNN_hyperparameter_results.json'\n",
    "output_file = 'DNN_hyperparameter_results.json'\n",
    "\n",
    "# Call the function to reformat the JSON data\n",
    "reformat_hyperparameter_results(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SmartPixel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
