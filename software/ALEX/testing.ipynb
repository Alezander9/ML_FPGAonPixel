{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 11:45:30.079293: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-15 11:45:30.251997: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-15 11:45:30.253854: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-15 11:45:32.962797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.13.1\n",
      "keras version: 2.13.1\n",
      "qkeras version: 2.13.1\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "# IMPORTS\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "# Machine Learning imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import PReLU, Input, LSTM, Flatten, Concatenate, Dense, Conv2D, TimeDistributed, MaxPooling2D, ReLU, Dropout, BatchNormalization, Activation, Reshape\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.metrics import Precision\n",
    "import tensorflow_model_optimization\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "print(\"tensorflow version:\", tf.__version__)\n",
    "import keras\n",
    "print(\"keras version:\",keras.__version__)\n",
    "import qkeras\n",
    "from qkeras import QActivation, QDense, QConv2D, QBatchNormalization, QConv2DBatchnorm\n",
    "from qkeras import quantized_relu, quantized_bits\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "from qkeras.autoqkeras.utils import print_qmodel_summary\n",
    "print(\"qkeras version:\",keras.__version__)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Display and plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.animation import PillowWriter\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Data management\n",
    "import psutil\n",
    "import h5py\n",
    "# Memory management\n",
    "import gc\n",
    "# Notifications\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "def send_email_notification(subject, content):\n",
    "    sender_email = os.getenv('EMAIL_USER')\n",
    "    receiver_email = \"alexander.j.yue@gmail.com\"\n",
    "    password = os.getenv('EMAIL_PASS')\n",
    "\n",
    "    message = MIMEMultipart()\n",
    "    message[\"From\"] = sender_email\n",
    "    message[\"To\"] = receiver_email\n",
    "    message[\"Subject\"] = subject\n",
    "    body = content\n",
    "    message.attach(MIMEText(body, \"plain\"))\n",
    "\n",
    "    with smtplib.SMTP(\"smtp.gmail.com\", 587) as server:\n",
    "        server.starttls()\n",
    "        server.login(sender_email, password)\n",
    "        server.sendmail(sender_email, receiver_email, message.as_string())\n",
    "\n",
    "# Memory monitoring functions\n",
    "def print_memory_usage():\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"Total memory: {memory.total / (1024**3):.2f} GB\")\n",
    "    print(f\"Available memory: {memory.available / (1024**3):.2f} GB\")\n",
    "    print(f\"Used memory: {memory.used / (1024**3):.2f} GB\")\n",
    "    print(f\"Memory usage percentage: {memory.percent}%\")\n",
    "\n",
    "def print_cpu_usage():\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "    print(f\"CPU Usage: {cpu_percent}%\")\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "# Load the pixel cluster to transverse momentum dataset into the input_data and target_data\n",
    "def load_combine_shuffle_data_optimized_hdf5():\n",
    "    # Load the dataset from Kenny's computer\n",
    "    with h5py.File('/fs/ddn/sdf/group/atlas/d/hjia625/Smart_Pixel/fl32_data_v3.hdf5', 'r') as h5f:\n",
    "        combined_input = None\n",
    "        combined_target = None\n",
    "\n",
    "        for data_type in ['sig', 'bkg']:\n",
    "            # Construct dataset names\n",
    "            input_dataset_name = f'{data_type}_input'\n",
    "            target_dataset_name = f'{data_type}_target'\n",
    "\n",
    "            # Check if the dataset exists and load data sequentially\n",
    "            if input_dataset_name in h5f and target_dataset_name in h5f:\n",
    "                input_data = h5f[input_dataset_name][:].astype(np.float32)\n",
    "                target_data = h5f[target_dataset_name][:].astype(np.float32)\n",
    "\n",
    "                if combined_input is None:\n",
    "                    combined_input = input_data\n",
    "                    combined_target = target_data\n",
    "                    # Free memory of the loaded data\n",
    "                    del input_data, target_data\n",
    "                    gc.collect()\n",
    "\n",
    "                else:\n",
    "                    print_memory_usage()\n",
    "                    combined_input = np.vstack((combined_input, input_data))\n",
    "                    combined_target = np.vstack((combined_target, target_data))\n",
    "                    # Free memory of the loaded data\n",
    "                    del input_data, target_data\n",
    "                    gc.collect()\n",
    "\n",
    "            else:\n",
    "                print(f\"Dataset {input_dataset_name} or {target_dataset_name} not found.\")\n",
    "\n",
    "        # Shuffling\n",
    "        indices = np.arange(combined_input.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        combined_input = combined_input[indices]\n",
    "        combined_target = combined_target[indices]\n",
    "\n",
    "        return combined_input, combined_target\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "def load_dataset():\n",
    "    # Load dataset into memory\n",
    "    input_data, target_data = load_combine_shuffle_data_optimized_hdf5()\n",
    "    # Format the dataset into a 20x13x21 tensor (time, y, x)\n",
    "    input_data = input_data.reshape(input_data.shape[0],20,13,21)\n",
    "    return input_data, target_data\n",
    "\n",
    "def process_dataset(input_data, target_data, hyperparams):\n",
    "    NUM_TIME_SLICES = hyperparams[\"NUM_TIME_SLICES\"]\n",
    "    MODEL_TYPE = hyperparams[\"MODEL_TYPE\"]\n",
    "    TRAIN_PT_THRESHOLD = hyperparams[\"TRAIN_PT_THRESHOLD\"]\n",
    "    TEST_PT_THRESHOLD = hyperparams[\"TEST_PT_THRESHOLD\"]\n",
    "    INPUT_SCALING = hyperparams[\"INPUT_SCALING\"]\n",
    "\n",
    "    # Split 80% of data into training data, 10% for validation data and 10% for testing data\n",
    "    input_train_data, input_temp, target_train_data, target_temp = \\\n",
    "    train_test_split(input_data, target_data, test_size=0.2, random_state=42)\n",
    "    del input_data\n",
    "    del target_data\n",
    "    gc.collect()\n",
    "    input_validate_data, input_test_data, target_validate_data, target_test_data = \\\n",
    "    train_test_split(input_temp, target_temp, test_size=0.5, random_state=42)\n",
    "    del input_temp\n",
    "    del target_temp\n",
    "    gc.collect()\n",
    "\n",
    "    # Save some data for displaying\n",
    "    input_data_example = input_test_data[0:100,:]\n",
    "    target_data_example = target_test_data[0:100,:]\n",
    "\n",
    "    # Fit the scalers on the training data to it all scales the exact same\n",
    "    if INPUT_SCALING == \"Standard\":\n",
    "        input_scaler = StandardScaler()\n",
    "        input_scaler.fit(input_train_data[:, :NUM_TIME_SLICES, :, :].reshape(-1,8*13))\n",
    "        y0_scaler = StandardScaler()\n",
    "        y0_scaler.fit(target_train_data[:,7].reshape(-1, 1))\n",
    "    elif INPUT_SCALING == \"MinMax\":\n",
    "        input_scaler = MinMaxScaler()\n",
    "        input_scaler.fit(input_train_data[:, :NUM_TIME_SLICES, :, :].reshape(-1,8*13))\n",
    "        y0_scaler = MinMaxScaler()\n",
    "        y0_scaler.fit(target_train_data[:,7].reshape(-1, 1))\n",
    "    elif INPUT_SCALING == \"Log\":\n",
    "        _temp = \"null\" # no steps here \n",
    "    else: \n",
    "        raise ValueError(f\"unsupported INPUT_SCALING {INPUT_SCALING}\")\n",
    "\n",
    "    # Process the data into input shape and labels for training\n",
    "    def process_data(input_data, target_data, pt_threshold):\n",
    "        if input_data.shape[1:] == (20, 13, 21) and target_data.shape[1:] == (13, ):\n",
    "\n",
    "            # Truncate down to first time slices\n",
    "            input_data = input_data[:, :NUM_TIME_SLICES, :, :]\n",
    "\n",
    "            # sum over the x axis to turn the input data into a 2D NUM_TIME_SLICES x 13 tensor (time, y)\n",
    "            input_data = np.sum(input_data, axis=3)\n",
    "\n",
    "            # Encode the target data into one_hot encoding\n",
    "            one_hot = np.zeros((target_data.shape[0], 3))\n",
    "            # Assign 1 for p_t > pt_threshold in GeV, for low p_t put 1 in slot 2 for negative and a 1 in slot 3 for positive\n",
    "            one_hot[np.abs(target_data[:, 8]) >= pt_threshold, 0] = 1\n",
    "            one_hot[(np.abs(target_data[:, 8]) < pt_threshold) & (target_data[:, 8] > 0), 1] = 1\n",
    "            one_hot[(np.abs(target_data[:, 8]) < pt_threshold) & (target_data[:, 8] < 0), 2] = 1\n",
    "\n",
    "            # Flatten the input data\n",
    "            input_data = input_data.reshape(-1,NUM_TIME_SLICES*13)\n",
    "\n",
    "            # Get the y_0 data\n",
    "            y0_data = target_data[:,7].reshape(-1, 1)\n",
    "\n",
    "            # Normalize the input data according to scaling method\n",
    "            if INPUT_SCALING == \"Standard\" or INPUT_SCALING == \"MinMax\":\n",
    "                input_data = input_scaler.transform(input_data)\n",
    "                y0_data = y0_scaler.transform(y0_data)\n",
    "            elif INPUT_SCALING == \"Log\":\n",
    "                # Replace all values < 1 with 1 so they log to 0\n",
    "                input_data = np.where(np.abs(input_data) < 1.0, 1.0, input_data)\n",
    "                # Apply logarithmic scaling\n",
    "                input_data = np.log(np.abs(input_data)) * np.sign(input_data)\n",
    "                # Min-max normalization (global)\n",
    "                min_val = np.min(input_data)\n",
    "                max_val = np.max(input_data)\n",
    "                print(f\"max of log of data is {max_val} and min is {min_val}\")\n",
    "                input_data = (input_data) / np.max([max_val,min_val])\n",
    "            else: \n",
    "                raise ValueError(f\"unsupported INPUT_SCALING {INPUT_SCALING}\") \n",
    "\n",
    "            \n",
    "            # Combine with input data\n",
    "            if (MODEL_TYPE == \"DNN\"):\n",
    "                # For DNN we concatenate in the y_0 data\n",
    "                input_data_combined = np.hstack((input_data, y0_data))\n",
    "            elif (MODEL_TYPE == \"CNN\"):\n",
    "                # Reshape data into a matrix for the convolutions\n",
    "                input_data = input_data.reshape(-1, NUM_TIME_SLICES, 13)\n",
    "                # Package with the y_0 data to be added later\n",
    "                input_data_combined = [input_data, y0_data]\n",
    "            elif (MODEL_TYPE == \"AE\"):\n",
    "                # Reshape data into a matrix for the convolutions\n",
    "                input_data_combined = input_data.reshape(-1, NUM_TIME_SLICES, 13)\n",
    "            else: \n",
    "                raise ValueError(f\"unsupported MODEL_TYPE {MODEL_TYPE}\") \n",
    "            \n",
    "            return input_data_combined, one_hot\n",
    "        else:\n",
    "            raise ValueError(\"Wrong array shape!\")\n",
    "\n",
    "    # Apply data processing to our datasets\n",
    "    input_train_data_combined, target_train_data_coded = process_data(input_train_data, target_train_data, TRAIN_PT_THRESHOLD)\n",
    "    input_validate_data_combined, target_validate_data_coded = process_data(input_validate_data, target_validate_data, TRAIN_PT_THRESHOLD)\n",
    "    input_test_data_combined, target_test_data_coded = process_data(input_test_data, target_test_data, TEST_PT_THRESHOLD)\n",
    "\n",
    "    # Save some data for displaying\n",
    "    if MODEL_TYPE == \"DNN\" or MODEL_TYPE == \"AE\":\n",
    "        input_data_combined_example = input_test_data_combined[0:100,:]\n",
    "        target_data_coded_example = target_test_data_coded[0:100,:]\n",
    "    elif MODEL_TYPE == \"CNN\":\n",
    "        input_data_combined_example = np.hstack((input_test_data_combined[0][0:100,:].reshape(100, -1), input_test_data_combined[1][0:100,:]))\n",
    "        target_data_coded_example = target_test_data_coded[0:100,:]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type\")\n",
    "\n",
    "    print_memory_usage()\n",
    "\n",
    "    processed_dataset = {\n",
    "        \"input_train_data_combined\": input_train_data_combined,\n",
    "        \"target_train_data_coded\": target_train_data_coded,\n",
    "        \"input_validate_data_combined\": input_validate_data_combined,\n",
    "        \"target_validate_data_coded\": target_validate_data_coded,\n",
    "        \"input_test_data_combined\": input_test_data_combined,\n",
    "        \"target_test_data_coded\": target_test_data_coded,\n",
    "\n",
    "        \"input_data_example\": input_data_example,\n",
    "        \"target_data_example\": target_data_example,\n",
    "        \"input_data_combined_example\": input_data_combined_example,\n",
    "        \"target_data_coded_example\": target_data_coded_example,\n",
    "    }\n",
    "\n",
    "    return processed_dataset\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "# Defining the model\n",
    "def qDNNmodel(hyperparams):\n",
    "    NUM_TIME_SLICES = hyperparams[\"NUM_TIME_SLICES\"]\n",
    "    DNN_LAYERS = hyperparams[\"DNN_LAYERS\"]\n",
    "    WEIGHTS_BITS = hyperparams[\"WEIGHTS_BITS\"]\n",
    "    BIAS_BITS = hyperparams[\"BIAS_BITS\"]\n",
    "    ACTIVATION_BITS = hyperparams[\"ACTIVATION_BITS\"]\n",
    "    LEARNING_RATE = hyperparams[\"LEARNING_RATE\"]\n",
    "    \n",
    "    y_timed_input = Input(shape=(NUM_TIME_SLICES*13 + 1,), name='y_timed_input')\n",
    "    layer = y_timed_input\n",
    "    \n",
    "    for i, size in enumerate(DNN_LAYERS):\n",
    "        layer = QDense(size, kernel_quantizer=quantized_bits(WEIGHTS_BITS), bias_quantizer=quantized_bits(BIAS_BITS), name=f'dense{i+1}')(layer)\n",
    "        layer = BatchNormalization()(layer)\n",
    "        layer = QActivation(quantized_relu(ACTIVATION_BITS))(layer)\n",
    "        \n",
    "    \n",
    "    output = QDense(3, kernel_quantizer=quantized_bits(WEIGHTS_BITS), bias_quantizer=quantized_bits(BIAS_BITS), name='dense_output')(layer)\n",
    "    output_softmax = Activation(\"softmax\", name='output_softmax')(output)\n",
    "   \n",
    "    model = Model(inputs=y_timed_input, outputs=output_softmax)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='categorical_crossentropy', metrics=[Precision()])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def qCNNmodel(hyperparams):\n",
    "    NUM_TIME_SLICES = hyperparams[\"NUM_TIME_SLICES\"]\n",
    "    CONV_LAYER_DEPTHS = hyperparams[\"CONV_LAYER_DEPTHS\"]\n",
    "    CONV_LAYER_KERNELS = hyperparams[\"CONV_LAYER_KERNELS\"]\n",
    "    CONV_LAYER_STRIDES = hyperparams[\"CONV_LAYER_STRIDES\"]\n",
    "    MAX_POOLING_SIZE = hyperparams[\"MAX_POOLING_SIZE\"]\n",
    "    FLATTENED_LAYERS = hyperparams[\"FLATTENED_LAYERS\"]\n",
    "    WEIGHTS_BITS = hyperparams[\"WEIGHTS_BITS\"]\n",
    "    BIAS_BITS = hyperparams[\"BIAS_BITS\"]\n",
    "    INTEGER_BITS = hyperparams[\"INTEGER_BITS\"]\n",
    "    ACTIVATION_BITS = hyperparams[\"ACTIVATION_BITS\"]\n",
    "    LEARNING_RATE = hyperparams[\"LEARNING_RATE\"]\n",
    "\n",
    "    y_profile_input = Input(shape=(NUM_TIME_SLICES, 13, 1), name='y_profile_input')  # Adjust the shape based on your input\n",
    "    layer = y_profile_input\n",
    "\n",
    "    # Convolutional layers\n",
    "    for i in range(len(CONV_LAYER_DEPTHS)):\n",
    "        layer = QConv2D(\n",
    "        CONV_LAYER_DEPTHS[i],\n",
    "        kernel_size=CONV_LAYER_KERNELS[i],\n",
    "        strides=CONV_LAYER_STRIDES,\n",
    "        kernel_quantizer=quantized_bits(WEIGHTS_BITS,INTEGER_BITS,alpha=1.0),\n",
    "        bias_quantizer=quantized_bits(BIAS_BITS,INTEGER_BITS,alpha=1.0),\n",
    "        padding='same',\n",
    "        use_bias=True,\n",
    "        name=f'conv{i+1}'\n",
    "        )(layer)\n",
    "        layer = QActivation(quantized_relu(ACTIVATION_BITS), name=f'relu{i+1}')(layer)\n",
    "        layer = MaxPooling2D(pool_size=MAX_POOLING_SIZE, name=f'maxpool{i+1}')(layer)\n",
    "\n",
    "    # Flatten the output to feed into a dense layer\n",
    "    layer = Flatten(name='flattened')(layer)\n",
    "\n",
    "    # Flatten and concatenate with y0 input\n",
    "    y0_input = Input(shape=(1,), name='y0_input')\n",
    "    layer = Concatenate(name='concat')([layer, y0_input])\n",
    "\n",
    "    # Post-flattening dense layers\n",
    "    for i in range(len(FLATTENED_LAYERS)):\n",
    "        layer = QDense(FLATTENED_LAYERS[i], kernel_quantizer=quantized_bits(WEIGHTS_BITS,INTEGER_BITS,alpha=1.0),\n",
    "                    bias_quantizer=quantized_bits(BIAS_BITS,INTEGER_BITS,alpha=1.0), name=f'dense{i+1}')(layer)\n",
    "        layer = QActivation(quantized_relu(10), name=f'relu{len(CONV_LAYER_DEPTHS)+i+1}')(layer)\n",
    "\n",
    "    # Output layer (adjust based on your classification problem)\n",
    "    output = QDense(3, kernel_quantizer=quantized_bits(WEIGHTS_BITS), bias_quantizer=quantized_bits(BIAS_BITS), name='dense_output')(layer)\n",
    "    output = Activation(\"softmax\", name='output_softmax')(output)\n",
    "    # layer = QDense(1, kernel_quantizer=quantized_bits(WEIGHTS_BITS,INTEGER_BITS,alpha=1.0), \n",
    "    #                bias_quantizer=quantized_bits(BIAS_BITS,INTEGER_BITS,alpha=1.0), name='output_dense')(layer)\n",
    "    # output = Activation(\"sigmoid\", name='output_sigmoid')(layer)\n",
    "\n",
    "    model = Model(inputs=[y_profile_input, y0_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='categorical_crossentropy', metrics=['accuracy']) # loss='binary_crossentropy'\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def qAEmodel(hyperparams):\n",
    "    NUM_TIME_SLICES = hyperparams[\"NUM_TIME_SLICES\"]\n",
    "    AU_ENCODER_LAYERS = hyperparams[\"AU_ENCODER_LAYERS\"]\n",
    "    AU_DECODER_LAYERS = hyperparams[\"AU_DECODER_LAYERS\"]\n",
    "    CONV_LAYER_STRIDES = hyperparams[\"CONV_LAYER_STRIDES\"]\n",
    "    MAX_POOLING_SIZE = hyperparams[\"MAX_POOLING_SIZE\"]\n",
    "    WEIGHTS_BITS = hyperparams[\"WEIGHTS_BITS\"]\n",
    "    BIAS_BITS = hyperparams[\"BIAS_BITS\"]\n",
    "    INTEGER_BITS = hyperparams[\"INTEGER_BITS\"]\n",
    "    ACTIVATION_BITS = hyperparams[\"ACTIVATION_BITS\"]\n",
    "    LEARNING_RATE = hyperparams[\"LEARNING_RATE\"]\n",
    "\n",
    "    y_profile_input = Input(shape=(NUM_TIME_SLICES, 13, 1), name='y_profile_input')  # Adjust the shape based on your input\n",
    "    layer = y_profile_input\n",
    "\n",
    "    print(layer.shape)\n",
    "    layer = Flatten(name='flatten_input')(layer)\n",
    "    print(layer.shape)\n",
    "\n",
    "    all_layer_specs = AU_ENCODER_LAYERS + AU_DECODER_LAYERS\n",
    "    # Add encoder layers\n",
    "    for i in range(len(all_layer_specs)):\n",
    "        layer_specs = all_layer_specs[i]\n",
    "\n",
    "        if isinstance(layer_specs, int):\n",
    "            # Flatten layer if necessary\n",
    "            if (len(layer.shape) != 2):\n",
    "                layer = Flatten(name=f'flatten{i}')(layer)\n",
    "            layer = QDense(layer_specs, kernel_quantizer=quantized_bits(WEIGHTS_BITS), bias_quantizer=quantized_bits(BIAS_BITS), name=f'dense{i+1}')(layer)\n",
    "            layer = QActivation(quantized_relu(ACTIVATION_BITS))(layer)\n",
    "            layer = BatchNormalization()(layer)\n",
    "\n",
    "        elif isinstance(layer_specs, tuple):\n",
    "            # Reshape layer if necessary\n",
    "            if (len(layer.shape) != 4):\n",
    "                layer = Reshape((NUM_TIME_SLICES, 13, 1), name=f'reshape{i}')(layer)\n",
    "            layer = QConv2D(\n",
    "            layer_specs[0],\n",
    "            kernel_size=(layer_specs[1], layer_specs[2]),\n",
    "            strides=CONV_LAYER_STRIDES,\n",
    "            kernel_quantizer=quantized_bits(WEIGHTS_BITS,INTEGER_BITS,alpha=1.0),\n",
    "            bias_quantizer=quantized_bits(BIAS_BITS,INTEGER_BITS,alpha=1.0),\n",
    "            padding='same',\n",
    "            use_bias=True,\n",
    "            name=f'conv{i+1}'\n",
    "            )(layer)\n",
    "            layer = QActivation(quantized_relu(ACTIVATION_BITS), name=f'relu{i+1}')(layer)\n",
    "            layer = MaxPooling2D(pool_size=MAX_POOLING_SIZE, name=f'maxpool{i+1}')(layer)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported layer specification: {layer_specs}\")\n",
    "        print(layer.shape)\n",
    "\n",
    "    # Reshape output layer if necessary\n",
    "    if (len(layer.shape) != 4):\n",
    "        layer = Reshape((NUM_TIME_SLICES, 13, 1), name=f'reshape_output')(layer)\n",
    "\n",
    "    ## TODO figure out what the output should be for autoencoder including y0 and supporting convolutions\n",
    "\n",
    "    model = Model(inputs=y_profile_input, outputs=layer)\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='categorical_crossentropy', metrics=['accuracy']) # loss='binary_crossentropy'\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Pruning the model\n",
    "def pruneFunction(layer, train_data_size, hyperparams):\n",
    "    BATCH_SIZE = hyperparams[\"BATCH_SIZE\"]\n",
    "    FINAL_SPARSITY = hyperparams[\"FINAL_SPARSITY\"]\n",
    "    PRUNE_START_EPOCH = hyperparams[\"PRUNE_START_EPOCH\"]\n",
    "    NUM_PRUNE_EPOCHS = hyperparams[\"NUM_PRUNE_EPOCHS\"]\n",
    "\n",
    "    steps_per_epoch = train_data_size // BATCH_SIZE #input_train_data_combined.shape[0]\n",
    "    pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=0.0,\n",
    "            final_sparsity=FINAL_SPARSITY,\n",
    "            begin_step=steps_per_epoch * PRUNE_START_EPOCH,\n",
    "            end_step=steps_per_epoch * (PRUNE_START_EPOCH + NUM_PRUNE_EPOCHS),\n",
    "            frequency=steps_per_epoch # prune after every epoch\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "    if isinstance(layer, QDense):\n",
    "        if layer.name != 'output_softmax' and layer.name != 'dense2':\n",
    "            print(f\"pruning layer {layer.name}\")\n",
    "            return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "        elif layer.name != 'output_softmax' and layer.name != 'dense1':\n",
    "            print(f\"pruning layer {layer.name}\")\n",
    "            return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "        else:\n",
    "            print(f\"cannot prune layer {layer.name}\")\n",
    "            return layer\n",
    "\n",
    "    else:\n",
    "        print(f\"cannot prune layer {layer.name}\")\n",
    "        return layer\n",
    "    \n",
    "def pruneFunctionWrapper(train_data_size, hyperparams):\n",
    "    def wrapper(layer):\n",
    "        return pruneFunction(layer, train_data_size, hyperparams)\n",
    "    return wrapper\n",
    "    \n",
    "\n",
    "# Function to calculate sparsity\n",
    "def calculate_sparsity(model):\n",
    "    total_params = 0\n",
    "    zero_params = 0\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Dense):\n",
    "            weights = layer.get_weights()[0]\n",
    "            total_params += weights.size\n",
    "            zero_params += np.sum(weights == 0)\n",
    "    sparsity = zero_params / total_params\n",
    "    return sparsity\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "def train_model(data, hyperparams):\n",
    "    input_train_data_combined = data[\"input_train_data_combined\"]\n",
    "    target_train_data_coded = data[\"target_train_data_coded\"]\n",
    "    input_validate_data_combined = data[\"input_validate_data_combined\"]\n",
    "    target_validate_data_coded = data[\"target_validate_data_coded\"]\n",
    "\n",
    "    MODEL_TYPE = hyperparams[\"MODEL_TYPE\"]\n",
    "    PATIENCE = hyperparams[\"PATIENCE\"]\n",
    "    EPOCHS = hyperparams[\"EPOCHS\"]\n",
    "    BATCH_SIZE = hyperparams[\"BATCH_SIZE\"]\n",
    "    LEARNING_RATE = hyperparams[\"LEARNING_RATE\"]\n",
    "    POST_PRUNE_EPOCHS = hyperparams[\"POST_PRUNE_EPOCHS\"]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Define the model\n",
    "    if (MODEL_TYPE == \"DNN\"):\n",
    "        model = qDNNmodel(hyperparams)\n",
    "    elif (MODEL_TYPE == \"CNN\"):\n",
    "        model = qCNNmodel(hyperparams)\n",
    "    elif (MODEL_TYPE == \"AE\"):\n",
    "        model = qAEmodel(hyperparams)\n",
    "    else:\n",
    "        raise ValueError(\"Not a supported model type\")\n",
    "\n",
    "    model.summary()\n",
    "    print_qmodel_summary(model)\n",
    "    print(f\"Initial Sparsity: {calculate_sparsity(model) * 100:.2f}%\")\n",
    "\n",
    "    train_metrics = {}\n",
    "\n",
    "    # Train the model\n",
    "    earlyStop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=PATIENCE, restore_best_weights=True)\n",
    "    if MODEL_TYPE == \"DNN\" or MODEL_TYPE == \"CNN\":\n",
    "        history = model.fit(\n",
    "            input_train_data_combined, target_train_data_coded,  # Training data and labels\n",
    "            validation_data=(input_validate_data_combined, target_validate_data_coded),  # Validation data\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks=[earlyStop_callback]\n",
    "        )\n",
    "    elif (MODEL_TYPE == \"AE\"):\n",
    "        history = model.fit(\n",
    "            input_train_data_combined, input_train_data_combined,  # Training data and labels\n",
    "            validation_data=(input_validate_data_combined, input_validate_data_combined),  # Validation data\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks=[earlyStop_callback]\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Not a supported model type\")\n",
    "    \n",
    "    \n",
    "    # Best at this step val_loss 0.7085\n",
    "    train_metrics[\"val_loss\"] = history.history['val_loss'][-1]\n",
    "\n",
    "    # Prune the model\n",
    "    model_pruned = keras.models.clone_model(model, clone_function=pruneFunctionWrapper(input_train_data_combined.shape[0], hyperparams))\n",
    "    model_pruned.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    if MODEL_TYPE == \"DNN\" or MODEL_TYPE == \"CNN\":\n",
    "        history = model_pruned.fit(\n",
    "            input_train_data_combined, target_train_data_coded,\n",
    "            validation_data=(input_validate_data_combined, target_validate_data_coded),\n",
    "            epochs=POST_PRUNE_EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks = [pruning_callbacks.UpdatePruningStep()]\n",
    "        )\n",
    "    if MODEL_TYPE == \"AE\":\n",
    "        history = model_pruned.fit(\n",
    "            input_train_data_combined, input_train_data_combined,\n",
    "            validation_data=(input_validate_data_combined, input_validate_data_combined), \n",
    "            epochs=POST_PRUNE_EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks = [pruning_callbacks.UpdatePruningStep()]\n",
    "        ) \n",
    "\n",
    "    model = strip_pruning(model_pruned)\n",
    "    # train_metrics[\"pruned_sparsity\"] = calculate_sparsity(model)\n",
    "\n",
    "    try:\n",
    "        train_metrics[\"pruned_val_loss\"] = history.history['val_loss'][-1]\n",
    "    except:\n",
    "        print(\"Error: no post-pruning val_loss found\")\n",
    "        train_metrics[\"pruned_val_loss\"] = train_metrics[\"val_loss\"]\n",
    "\n",
    "    return model, train_metrics\n",
    "\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "def test_model(data, model):\n",
    "    input_test_data_combined = data[\"input_test_data_combined\"]\n",
    "    target_test_data_coded = data[\"target_test_data_coded\"]\n",
    "\n",
    "    \n",
    "    # Test the model at threshold 0.5\n",
    "    predictions_prob = model.predict(input_test_data_combined)[:,0]\n",
    "    predictions_labels = (predictions_prob >= 0.5).astype(int).flatten()\n",
    "\n",
    "    # Test the model at different thresholds\n",
    "    thresholds = np.linspace(0.0, 1.0, 1000)\n",
    "    signal_efficiencies = []\n",
    "    background_rejections = []\n",
    "    max_sum_se = 0\n",
    "    max_sum_br = 0\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        # predicted_class = ((predictions_prob[:, 0] + threshold > predictions_prob[:, 1]) & (predictions_prob[:, 0] + threshold > predictions_prob[:, 2])).astype(int)\n",
    "        predicted_class = (predictions_prob > threshold).astype(int)\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(target_test_data_coded[:, 0], predicted_class)\n",
    "\n",
    "        # Calculate signal efficiency and background rejection\n",
    "        signal_efficiency = cm[1, 1] / np.sum(cm[1, :])\n",
    "        background_rejection = cm[0, 0] / np.sum(cm[0, :])\n",
    "\n",
    "        # Store metrics\n",
    "        signal_efficiencies.append(signal_efficiency)\n",
    "        background_rejections.append(background_rejection)\n",
    "\n",
    "        # get maximum added score\n",
    "        if signal_efficiency + background_rejection > max_sum_se + max_sum_br:\n",
    "            max_sum_se = signal_efficiency\n",
    "            max_sum_br = background_rejection\n",
    "    \n",
    "    test_results = {\n",
    "        \"predictions_prob\": predictions_prob,\n",
    "        \"predictions_labels\": predictions_labels,\n",
    "        \"thresholds\": thresholds,\n",
    "        \"signal_efficiencies\": signal_efficiencies,\n",
    "        \"background_rejections\": background_rejections,\n",
    "        \"max_sum_se\": max_sum_se,\n",
    "        \"max_sum_br\": max_sum_br,\n",
    "    }\n",
    "\n",
    "    return test_results\n",
    "\n",
    "def ShowConfusionMatrix(test_results):\n",
    "    target_test_data_coded = test_results[\"target_test_data_coded\"]\n",
    "    predictions_labels = test_results[\"predictions_labels\"]\n",
    "\n",
    "    cm = confusion_matrix(target_test_data_coded[:,0], predictions_labels)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='YlGnBu')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def showMetricsByThreshold(test_results):\n",
    "    thresholds = test_results[\"thresholds\"]\n",
    "    signal_efficiencies = test_results[\"signal_efficiencies\"]\n",
    "    background_rejections = test_results[\"background_rejections\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(thresholds, signal_efficiencies, label='Signal Efficiency')\n",
    "    plt.plot(thresholds, background_rejections, label='Background Rejection')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.title('Effect of Threshold on Signal Efficiency and Background Rejection')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def showEfficiencyVSRejection(test_results):\n",
    "    signal_efficiencies = test_results[\"signal_efficiencies\"]\n",
    "    background_rejections = test_results[\"background_rejections\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(signal_efficiencies, background_rejections, marker='o')\n",
    "    plt.xlabel('Signal Efficiency')\n",
    "    plt.ylabel('Background Rejection')\n",
    "    plt.title('Background Rejection vs. Signal Efficiency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def find_closest(sorted_array, value):\n",
    "    # Ensure the array is a NumPy array\n",
    "    sorted_array = np.array(sorted_array)\n",
    "    # Compute the absolute difference\n",
    "    abs_diff = np.abs(sorted_array - value)\n",
    "    # Find the index of the minimum difference\n",
    "    closest_index = np.argmin(abs_diff)\n",
    "    return closest_index\n",
    "\n",
    "def getTargetMetrics(test_results):\n",
    "    signal_efficiencies = test_results[\"signal_efficiencies\"]\n",
    "    background_rejections = test_results[\"background_rejections\"]\n",
    "\n",
    "    target_efficiencies = [0.90, 0.93, 0.96, 0.98, 0.99, 0.995, 0.999]\n",
    "    metrics = []\n",
    "    for target in target_efficiencies:\n",
    "        index = find_closest(signal_efficiencies, target)\n",
    "        metrics.append((signal_efficiencies[index], background_rejections[index]))\n",
    "        # print(f\"Signal Efficiency: {signal_efficiencies[index]*100:.1f}%,\",f\"Background Rejections: {background_rejections[index]*100:.1f}%\")\n",
    "    return metrics\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "def hyperparameter_search(data, base_hyperparams, param_grid, result_file='hyperparameter_results.json'):\n",
    "\n",
    "    # Load existing results from file if it exists\n",
    "    if os.path.exists(result_file):\n",
    "        with open(result_file, 'r') as file:\n",
    "            all_results = json.load(file)\n",
    "    else:\n",
    "        all_results = {}\n",
    "\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    for v in itertools.product(*values):\n",
    "        hyperparams = dict(zip(keys, v))\n",
    "        # Update base hyperparameters with the current set\n",
    "        current_hyperparams = base_hyperparams.copy()\n",
    "        current_hyperparams.update(hyperparams)\n",
    "        MODEL_TYPE = current_hyperparams[\"MODEL_TYPE\"]\n",
    "\n",
    "        # Convert hyperparameters to a string for use as a dictionary key\n",
    "        hyperparams_str = json.dumps(current_hyperparams, sort_keys=True)\n",
    "\n",
    "        # Check if these hyperparameters have been tried before\n",
    "        if hyperparams_str in all_results:\n",
    "            print(f\"Skipping already tested hyperparameters: {current_hyperparams}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Testing hyperparameters: {current_hyperparams}\")\n",
    "\n",
    "        # Train the model\n",
    "        model, train_metrics = train_model(data, current_hyperparams)\n",
    "\n",
    "        if (MODEL_TYPE == \"DNN\" or MODEL_TYPE == \"CNN\"):\n",
    "            # Test the model\n",
    "            test_results = test_model(data, model)\n",
    "            metrics = getTargetMetrics(test_results)\n",
    "            metrics_str = \", \".join([f\"({m1:.4f}, {m2:.4f})\" for m1, m2 in metrics])\n",
    "            \n",
    "            test_scores = {\n",
    "                \"max_sum_se\": test_results[\"max_sum_se\"],\n",
    "                \"max_sum_br\": test_results[\"max_sum_br\"],\n",
    "                \"metrics\": metrics_str,\n",
    "            }\n",
    "            # Add all keys and values from train_metrics into test_scores\n",
    "            test_scores.update(train_metrics)\n",
    "        else:\n",
    "            test_scores = train_metrics\n",
    "\n",
    "        # Save the results to the file\n",
    "        all_results[hyperparams_str] = test_scores\n",
    "        with open(result_file, 'w') as file:\n",
    "            json.dump(all_results, file, indent=4)\n",
    "\n",
    "\n",
    "        # If new best found, email alex\n",
    "        if test_scores[\"pruned_val_loss\"] < find_min_pruned_val_loss(result_file):\n",
    "\n",
    "            # email results\n",
    "            model_name = \"undefined\"\n",
    "            if (current_hyperparams[\"MODEL_TYPE\"] == \"DNN\"):\n",
    "                model_name = \"Dean\"\n",
    "            elif (current_hyperparams[\"MODEL_TYPE\"] == \"CNN\"):\n",
    "                model_name = \"Connor\"\n",
    "            elif (current_hyperparams[\"MODEL_TYPE\"] == \"AE\"):\n",
    "                model_name = \"Audrey\"\n",
    "            send_email_notification(\"ML Training Report\", \n",
    "                f' \\\n",
    "                Your model {model_name} has finished training. \\\n",
    "                He got a grade of {test_scores[\"max_sum_se\"]*100:.1f}% in SE and {test_scores[\"max_sum_br\"]*100:.1f}% in BR. \\\n",
    "                New lowest validated loss: {test_scores[\"pruned_val_loss\"]} \\n \\\n",
    "                All metrics: {metrics_str} \\n \\\n",
    "                Hyperparams: {hyperparams_str} \\\n",
    "                ')\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def find_min_pruned_val_loss(result_file='hyperparameter_results.json'):\n",
    "    # Load existing results from file\n",
    "    if os.path.exists(result_file):\n",
    "        with open(result_file, 'r') as file:\n",
    "            all_results = json.load(file)\n",
    "    else:\n",
    "        print(f\"No results found in {result_file}\")\n",
    "        return None\n",
    "\n",
    "    min_loss = float('inf')\n",
    "    min_hyperparams = None\n",
    "\n",
    "    # Iterate through the results to find the minimum pruned_val_loss\n",
    "    for hyperparams_str, results in all_results.items():\n",
    "        if \"pruned_val_loss\" in results:\n",
    "            pruned_val_loss = results[\"pruned_val_loss\"]\n",
    "            if pruned_val_loss < min_loss:\n",
    "                min_loss = pruned_val_loss\n",
    "                min_hyperparams = hyperparams_str\n",
    "\n",
    "    # Print the hyperparameters with the minimum pruned_val_loss\n",
    "    if min_hyperparams is not None:\n",
    "        print(f\"Hyperparameters with minimum pruned_val_loss: {min_hyperparams}\")\n",
    "        print(f\"Minimum pruned_val_loss: {min_loss}\")\n",
    "    else:\n",
    "        print(\"No entry with pruned_val_loss found\")\n",
    "\n",
    "    return min_loss\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters with minimum pruned_val_loss: {\"ACTIVATION_BITS\": 15, \"AU_DECODER_LAYERS\": [64, 104], \"AU_ENCODER_LAYERS\": [32], \"BATCH_SIZE\": 1024, \"BIAS_BITS\": 10, \"CONV_LAYER_DEPTHS\": [4, 7], \"CONV_LAYER_KERNELS\": [[3, 3], [3, 3]], \"CONV_LAYER_STRIDES\": [1, 1], \"DNN_LAYERS\": [128, 64, 32, 16], \"EPOCHS\": 100, \"FINAL_SPARSITY\": 0.45, \"FLATTENED_LAYERS\": [7], \"INPUT_SCALING\": \"MinMax\", \"INTEGER_BITS\": 2, \"LEARNING_RATE\": 0.001, \"MAX_POOLING_SIZE\": [2, 2], \"MODEL_TYPE\": \"AE\", \"NUM_PRUNE_EPOCHS\": 10, \"NUM_TIME_SLICES\": 8, \"PATIENCE\": 20, \"POST_PRUNE_EPOCHS\": 50, \"PRUNE_START_EPOCH\": 0, \"TEST_PT_THRESHOLD\": 2, \"TRAIN_PT_THRESHOLD\": 2, \"WEIGHTS_BITS\": 10}\n",
      "Minimum pruned_val_loss: 0.34005746245384216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34005746245384216"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "HYPERPARAMETERS = {\n",
    "    # Model Type\n",
    "    \"MODEL_TYPE\": \"AE\",  # DNN or CNN or AE\n",
    "    # Input format\n",
    "    \"NUM_TIME_SLICES\": 8,\n",
    "    \"TRAIN_PT_THRESHOLD\": 2,  # in GeV\n",
    "    \"TEST_PT_THRESHOLD\": 2,  # in GeV\n",
    "    \"INPUT_SCALING\": \"MinMax\", # Standard, MinMax or Log\n",
    "    # DNN model mormat\n",
    "    \"DNN_LAYERS\": [32, 16, 8], # [32, (16, 3, 3), (16, 3, 3), 32]\n",
    "    # CNN model format\n",
    "    \"CONV_LAYER_DEPTHS\": [4, 7],\n",
    "    \"CONV_LAYER_KERNELS\": [(3, 3), (3, 3)],\n",
    "    \"FLATTENED_LAYERS\": [7],\n",
    "    \"CONV_LAYER_STRIDES\": (1, 1),\n",
    "    \"MAX_POOLING_SIZE\": (2, 2),\n",
    "    # AU model format. n is dense layer of size n, (n, m, l) is conv layer of dept n and kernel size (m, l)\n",
    "    ## TODO: add maxpooling and sampling and crop to support CNN for AE\n",
    "    \"AU_ENCODER_LAYERS\": [64],\n",
    "    \"AU_DECODER_LAYERS\": [8*13], # Includes output. Must result in NUM_TIME_SLICES * 13 or (NUM_TIME_SLICES, 13) sized final layer\n",
    "    # Model quantization\n",
    "    \"WEIGHTS_BITS\": 10,\n",
    "    \"BIAS_BITS\": 10,\n",
    "    \"ACTIVATION_BITS\": 15,\n",
    "    \"INTEGER_BITS\": 2,\n",
    "    # Training\n",
    "    \"LEARNING_RATE\": 0.001,\n",
    "    \"BATCH_SIZE\": 1024,  # Number of samples per gradient update\n",
    "    \"EPOCHS\": 100,  # Number of epochs to train\n",
    "    \"PATIENCE\": 20,  # Stop after this number of epochs without improvement\n",
    "    # Pruning\n",
    "    \"PRUNE_START_EPOCH\": 0,  # Number of epochs before pruning\n",
    "    \"NUM_PRUNE_EPOCHS\": 10,\n",
    "    \"FINAL_SPARSITY\": 0.35,\n",
    "    \"POST_PRUNE_EPOCHS\": 50,\n",
    "}\n",
    "\n",
    "SAVE_FILE = \"small\"+HYPERPARAMETERS[\"MODEL_TYPE\"]+\"_results.json\"\n",
    "\n",
    "param_grid = {\n",
    "    \"AU_ENCODER_LAYERS\": [[32], [64, 32], [96, 32]],\n",
    "    \"AU_DECODER_LAYERS\": [[8*13], [64, 8*13]],\n",
    "    \"FINAL_SPARSITY\": [0.35, 0.4, 0.45],\n",
    "}\n",
    "\n",
    "find_min_pruned_val_loss(result_file=SAVE_FILE)\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 376.23 GB\n",
      "Available memory: 275.21 GB\n",
      "Used memory: 90.24 GB\n",
      "Memory usage percentage: 26.9%\n",
      "Total memory: 376.23 GB\n",
      "Available memory: 263.59 GB\n",
      "Used memory: 101.85 GB\n",
      "Memory usage percentage: 29.9%\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "input_data, target_data = load_dataset()\n",
    "data = process_dataset(input_data, target_data, HYPERPARAMETERS) \n",
    "# Depends only on: NUM_TIME_SLICES MODEL_TYPE TRAIN_PT_THRESHOLD TEST_PT_THRESHOLD\n",
    "\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 8, 13, 1)\n",
      "(None, 104)\n",
      "(None, 64)\n",
      "(None, 104)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_profile_input (InputLaye  [(None, 8, 13, 1)]        0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " flatten_input (Flatten)     (None, 104)               0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 64)                6720      \n",
      "                                                                 \n",
      " q_activation (QActivation)  (None, 64)                0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 64)                256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 104)               6760      \n",
      "                                                                 \n",
      " q_activation_1 (QActivatio  (None, 104)               0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 104)               416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " reshape_output (Reshape)    (None, 8, 13, 1)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14152 (55.28 KB)\n",
      "Trainable params: 13816 (53.97 KB)\n",
      "Non-trainable params: 336 (1.31 KB)\n",
      "_________________________________________________________________\n",
      "dense1               u=64 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "q_activation         quantized_relu(15,0)\n",
      "batch_normalization  is normal keras bn layer\n",
      "dense2               u=104 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "q_activation_1       quantized_relu(15,0)\n",
      "batch_normalization_1 is normal keras bn layer\n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "Epoch 1/100\n",
      "429/429 [==============================] - 11s 17ms/step - loss: 7.8030 - accuracy: 4.3832e-08 - val_loss: 6.6426 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "429/429 [==============================] - 6s 14ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "429/429 [==============================] - 6s 14ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "429/429 [==============================] - 6s 14ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "429/429 [==============================] - 6s 14ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "429/429 [==============================] - 6s 14ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "429/429 [==============================] - 6s 13ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "429/429 [==============================] - 6s 13ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "429/429 [==============================] - 6s 13ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "429/429 [==============================] - 6s 14ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "429/429 [==============================] - 6s 13ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "429/429 [==============================] - 6s 13ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "429/429 [==============================] - 6s 13ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "429/429 [==============================] - 6s 13ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "429/429 [==============================] - 6s 14ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "429/429 [==============================] - 5s 13ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "429/429 [==============================] - 6s 13ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "429/429 [==============================] - 5s 12ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "429/429 [==============================] - 5s 13ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "429/429 [==============================] - 5s 13ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "429/429 [==============================] - 6s 13ms/step - loss: nan - accuracy: 4.3832e-08 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "cannot prune layer flatten_input\n",
      "pruning layer dense1\n",
      "cannot prune layer q_activation\n",
      "cannot prune layer batch_normalization\n",
      "pruning layer dense2\n",
      "cannot prune layer q_activation_1\n",
      "cannot prune layer batch_normalization_1\n",
      "cannot prune layer reshape_output\n",
      "Epoch 1/50\n",
      "429/429 [==============================] - 12s 16ms/step - loss: 2.6997 - accuracy: 1.0958e-07 - val_loss: 2.8118 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 6s 13ms/step - loss: 1.8643 - accuracy: 1.0958e-07 - val_loss: 1.8673 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 1.5355 - accuracy: 1.0958e-07 - val_loss: 1.4578 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 6s 13ms/step - loss: 1.3633 - accuracy: 1.0958e-07 - val_loss: 1.3691 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 6s 13ms/step - loss: 1.2457 - accuracy: 1.0958e-07 - val_loss: 1.2162 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 6s 13ms/step - loss: 1.1603 - accuracy: 1.0958e-07 - val_loss: 1.1271 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 6s 13ms/step - loss: 1.0897 - accuracy: 8.7664e-08 - val_loss: 1.0533 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 1.0309 - accuracy: 8.7664e-08 - val_loss: 1.0198 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 6s 13ms/step - loss: 0.9987 - accuracy: 6.5748e-08 - val_loss: 0.9765 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 6s 13ms/step - loss: 0.9698 - accuracy: 6.5748e-08 - val_loss: 0.9586 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 6s 13ms/step - loss: 0.9364 - accuracy: 6.5748e-08 - val_loss: 0.9251 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 6s 13ms/step - loss: 0.9096 - accuracy: 6.5748e-08 - val_loss: 0.8969 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.8877 - accuracy: 6.5748e-08 - val_loss: 0.8690 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.8626 - accuracy: 6.5748e-08 - val_loss: 0.8560 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.8497 - accuracy: 6.5748e-08 - val_loss: 0.8802 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.8381 - accuracy: 6.5748e-08 - val_loss: 0.8188 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.8126 - accuracy: 6.5748e-08 - val_loss: 0.8072 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.8038 - accuracy: 6.5748e-08 - val_loss: 0.7998 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7956 - accuracy: 6.5748e-08 - val_loss: 0.7913 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7888 - accuracy: 6.5748e-08 - val_loss: 0.7855 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7827 - accuracy: 6.5748e-08 - val_loss: 0.7749 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7727 - accuracy: 6.5748e-08 - val_loss: 0.7638 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7618 - accuracy: 6.5748e-08 - val_loss: 0.7594 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7580 - accuracy: 6.5748e-08 - val_loss: 0.7557 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7542 - accuracy: 6.5748e-08 - val_loss: 0.7533 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7527 - accuracy: 6.5748e-08 - val_loss: 0.7523 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7541 - accuracy: 6.5748e-08 - val_loss: 0.7566 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7550 - accuracy: 6.5748e-08 - val_loss: 0.7531 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 6s 15ms/step - loss: 0.7523 - accuracy: 6.5748e-08 - val_loss: 0.7583 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7488 - accuracy: 6.5748e-08 - val_loss: 0.7447 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7417 - accuracy: 6.5748e-08 - val_loss: 0.7393 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7368 - accuracy: 6.5748e-08 - val_loss: 0.7359 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7351 - accuracy: 6.5748e-08 - val_loss: 0.7339 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7332 - accuracy: 6.5748e-08 - val_loss: 0.7324 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7315 - accuracy: 6.5748e-08 - val_loss: 0.7313 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7312 - accuracy: 6.5748e-08 - val_loss: 0.7316 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7307 - accuracy: 6.5748e-08 - val_loss: 0.7307 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7304 - accuracy: 6.5748e-08 - val_loss: 0.7308 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7296 - accuracy: 6.5748e-08 - val_loss: 0.7297 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7298 - accuracy: 6.5748e-08 - val_loss: 0.7301 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7301 - accuracy: 6.5748e-08 - val_loss: 0.7345 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7309 - accuracy: 6.5748e-08 - val_loss: 0.7320 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7309 - accuracy: 6.5748e-08 - val_loss: 0.7308 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7298 - accuracy: 6.5748e-08 - val_loss: 0.7303 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7285 - accuracy: 6.5748e-08 - val_loss: 0.7244 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7236 - accuracy: 6.5748e-08 - val_loss: 0.7201 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7200 - accuracy: 6.5748e-08 - val_loss: 0.7185 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7149 - accuracy: 6.5748e-08 - val_loss: 0.7120 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7107 - accuracy: 6.5748e-08 - val_loss: 0.7095 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 6s 14ms/step - loss: 0.7092 - accuracy: 6.5748e-08 - val_loss: 0.7091 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model, train_metrics = train_model(data, HYPERPARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.engine.input_layer.InputLayer at 0x7f734c77c370>,\n",
       " <keras.src.layers.reshaping.flatten.Flatten at 0x7f765cb77b80>,\n",
       " <qkeras.qlayers.QDense at 0x7f765ccd55b0>,\n",
       " <qkeras.qlayers.QActivation at 0x7f765ccba970>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f765ce75e80>,\n",
       " <qkeras.qlayers.QDense at 0x7f738c6b1370>,\n",
       " <qkeras.qlayers.QActivation at 0x7f765cf9d070>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7f7658fb3ee0>,\n",
       " <keras.src.layers.reshaping.reshape.Reshape at 0x7f765cce1250>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = model.layers[2]\n",
    "bn_layer = model.layers[2]\n",
    "\n",
    "W, b = dense_layer.get_weights()\n",
    "gamma, beta, moving_mean, moving_var = bn_layer.get_weights()\n",
    "\n",
    "# Calculate new weights and biases\n",
    "epsilon = bn_layer.epsilon\n",
    "std = np.sqrt(moving_var + epsilon)\n",
    "new_W = gamma / std * W\n",
    "new_b = gamma / std * (b - moving_mean) + beta\n",
    "\n",
    "# Create new model without BN layer\n",
    "inputs = Input(shape=(64,))\n",
    "x = Dense(32, weights=[new_W, new_b])(inputs)\n",
    "outputs = Dense(10)(x)\n",
    "\n",
    "new_model = Model(inputs, outputs)\n",
    "\n",
    "# Verify the new model\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sdf/home/a/alexyue/miniconda3/envs/SmartPixel/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(f'./{HYPERPARAMETERS[\"MODEL_TYPE\"]}_best_perfomance.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hyperparameters: {'MODEL_TYPE': 'AE', 'NUM_TIME_SLICES': 8, 'TRAIN_PT_THRESHOLD': 2, 'TEST_PT_THRESHOLD': 2, 'INPUT_SCALING': 'MinMax', 'DNN_LAYERS': [128, 64, 32, 16], 'CONV_LAYER_DEPTHS': [4, 7], 'CONV_LAYER_KERNELS': [(3, 3), (3, 3)], 'FLATTENED_LAYERS': [7], 'CONV_LAYER_STRIDES': (1, 1), 'MAX_POOLING_SIZE': (2, 2), 'AU_ENCODER_LAYERS': [32], 'AU_DECODER_LAYERS': [104], 'WEIGHTS_BITS': 10, 'BIAS_BITS': 10, 'ACTIVATION_BITS': 15, 'INTEGER_BITS': 2, 'LEARNING_RATE': 0.001, 'BATCH_SIZE': 1024, 'EPOCHS': 100, 'PATIENCE': 20, 'PRUNE_START_EPOCH': 0, 'NUM_PRUNE_EPOCHS': 10, 'FINAL_SPARSITY': 0.35, 'POST_PRUNE_EPOCHS': 50}\n",
      "(None, 8, 13, 1)\n",
      "(None, 104)\n",
      "(None, 32)\n",
      "(None, 104)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " y_profile_input (InputLaye  [(None, 8, 13, 1)]        0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " flatten_input (Flatten)     (None, 104)               0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 32)                3360      \n",
      "                                                                 \n",
      " q_activation_2 (QActivatio  (None, 32)                0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 104)               3432      \n",
      "                                                                 \n",
      " q_activation_3 (QActivatio  (None, 104)               0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 104)               416       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " reshape_output (Reshape)    (None, 8, 13, 1)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7336 (28.66 KB)\n",
      "Trainable params: 7064 (27.59 KB)\n",
      "Non-trainable params: 272 (1.06 KB)\n",
      "_________________________________________________________________\n",
      "dense1               u=32 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "q_activation_2       quantized_relu(15,0)\n",
      "batch_normalization_2 is normal keras bn layer\n",
      "dense2               u=104 quantized_bits(10,0,1,alpha='auto_po2') quantized_bits(10,0,0) \n",
      "q_activation_3       quantized_relu(15,0)\n",
      "batch_normalization_3 is normal keras bn layer\n",
      "\n",
      "Initial Sparsity: 0.00%\n",
      "Epoch 1/100\n",
      "429/429 [==============================] - 8s 13ms/step - loss: 9.3047 - accuracy: 4.3832e-08 - val_loss: 7.9701 - val_accuracy: 1.7533e-07\n",
      "Epoch 2/100\n",
      " 14/429 [..............................] - ETA: 5s - loss: 8.0318 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################\n",
    "\n",
    "# results = hyperparameter_search(data, HYPERPARAMETERS, param_grid, result_file=SAVE_FILE)\n",
    "\n",
    "try:\n",
    "    results = hyperparameter_search(data, HYPERPARAMETERS, param_grid, result_file=SAVE_FILE)\n",
    "    send_email_notification(\"All done with hyperparameter search\", 'Done!')\n",
    "except Exception as e:\n",
    "    print(\"Error encountered:\", e)\n",
    "    send_email_notification(\"Hyperparameter search ran into an error\", 'Go fix it')\n",
    "######################################################################################################\n",
    "##################################         TESTING          ##########################################\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_metrics(metrics):\n",
    "    # Convert metrics list of tuples to a formatted string\n",
    "    return \", \".join([f\"({m1:.4f}, {m2:.4f})\" for m1, m2 in metrics])\n",
    "\n",
    "def reformat_hyperparameter_results(input_file, output_file):\n",
    "    # Read the original JSON file\n",
    "    with open(input_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Process and format the metrics\n",
    "    for key, value in data.items():\n",
    "        if \"metrics\" in value:\n",
    "            value[\"metrics\"] = format_metrics(value[\"metrics\"])\n",
    "\n",
    "    # Write the updated data to the new JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "# Define input and output file names\n",
    "input_file = 'OLD_CNN_hyperparameter_results.json'\n",
    "output_file = 'CNN_hyperparameter_results.json'\n",
    "\n",
    "# Call the function to reformat the JSON data\n",
    "reformat_hyperparameter_results(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SmartPixel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
